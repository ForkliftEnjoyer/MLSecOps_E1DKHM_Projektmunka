2025-10-12 15:38:17,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 15:38:17,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 15:38:17,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 15:38:17,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 15:38:21,289:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\mlflow\utils\requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources  # noqa: TID251

2025-10-12 15:43:16,864:INFO:PyCaret ClassificationExperiment
2025-10-12 15:43:16,864:INFO:Logging name: titanic_exp_1
2025-10-12 15:43:16,864:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-12 15:43:16,864:INFO:version 3.3.2
2025-10-12 15:43:16,864:INFO:Initializing setup()
2025-10-12 15:43:16,864:INFO:self.USI: 2e54
2025-10-12 15:43:16,864:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y', 'y_test', 'exp_id', 'X_train', 'memory', 'exp_name_log', 'X_test', 'pipeline', 'X', '_ml_usecase', 'seed', 'logging_param', 'fold_generator', 'gpu_param', 'target_param', 'html_param', 'idx', 'USI', 'n_jobs_param', 'fix_imbalance', 'fold_shuffle_param', '_available_plots', 'is_multiclass', 'data', 'y_train', 'fold_groups_param', 'log_plots_param'}
2025-10-12 15:43:16,865:INFO:Checking environment
2025-10-12 15:43:16,865:INFO:python_version: 3.9.13
2025-10-12 15:43:16,865:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2025-10-12 15:43:16,865:INFO:machine: AMD64
2025-10-12 15:43:16,865:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-12 15:43:16,865:INFO:Memory: svmem(total=16778072064, available=2112700416, percent=87.4, used=14665371648, free=2112700416)
2025-10-12 15:43:16,865:INFO:Physical Core: 10
2025-10-12 15:43:16,865:INFO:Logical Core: 16
2025-10-12 15:43:16,865:INFO:Checking libraries
2025-10-12 15:43:16,865:INFO:System:
2025-10-12 15:43:16,866:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2025-10-12 15:43:16,866:INFO:executable: c:\Users\david\Programming\MLOps\.venv\Scripts\python.exe
2025-10-12 15:43:16,866:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-12 15:43:16,866:INFO:PyCaret required dependencies:
2025-10-12 15:43:19,530:INFO:                 pip: 25.2
2025-10-12 15:43:19,530:INFO:          setuptools: 80.9.0
2025-10-12 15:43:19,530:INFO:             pycaret: 3.3.2
2025-10-12 15:43:19,530:INFO:             IPython: 8.18.1
2025-10-12 15:43:19,530:INFO:          ipywidgets: 8.1.7
2025-10-12 15:43:19,530:INFO:                tqdm: 4.67.1
2025-10-12 15:43:19,530:INFO:               numpy: 1.26.4
2025-10-12 15:43:19,530:INFO:              pandas: 2.1.4
2025-10-12 15:43:19,530:INFO:              jinja2: 3.1.6
2025-10-12 15:43:19,530:INFO:               scipy: 1.11.4
2025-10-12 15:43:19,530:INFO:              joblib: 1.3.2
2025-10-12 15:43:19,530:INFO:             sklearn: 1.4.2
2025-10-12 15:43:19,530:INFO:                pyod: 2.0.5
2025-10-12 15:43:19,530:INFO:            imblearn: 0.12.4
2025-10-12 15:43:19,530:INFO:   category_encoders: 2.6.4
2025-10-12 15:43:19,531:INFO:            lightgbm: 4.6.0
2025-10-12 15:43:19,531:INFO:               numba: 0.60.0
2025-10-12 15:43:19,531:INFO:            requests: 2.32.5
2025-10-12 15:43:19,531:INFO:          matplotlib: 3.7.5
2025-10-12 15:43:19,531:INFO:          scikitplot: 0.3.7
2025-10-12 15:43:19,531:INFO:         yellowbrick: 1.5
2025-10-12 15:43:19,531:INFO:              plotly: 5.24.1
2025-10-12 15:43:19,531:INFO:    plotly-resampler: Not installed
2025-10-12 15:43:19,531:INFO:             kaleido: 1.1.0
2025-10-12 15:43:19,531:INFO:           schemdraw: 0.15
2025-10-12 15:43:19,531:INFO:         statsmodels: 0.14.5
2025-10-12 15:43:19,531:INFO:              sktime: 0.26.0
2025-10-12 15:43:19,531:INFO:               tbats: 1.1.3
2025-10-12 15:43:19,531:INFO:            pmdarima: 2.0.4
2025-10-12 15:43:19,531:INFO:              psutil: 7.1.0
2025-10-12 15:43:19,531:INFO:          markupsafe: 2.1.5
2025-10-12 15:43:19,531:INFO:             pickle5: Not installed
2025-10-12 15:43:19,531:INFO:         cloudpickle: 3.1.1
2025-10-12 15:43:19,531:INFO:         deprecation: 2.1.0
2025-10-12 15:43:19,531:INFO:              xxhash: 3.6.0
2025-10-12 15:43:19,531:INFO:           wurlitzer: Not installed
2025-10-12 15:43:19,531:INFO:PyCaret optional dependencies:
2025-10-12 15:43:25,800:INFO:                shap: 0.44.1
2025-10-12 15:43:25,800:INFO:           interpret: 0.7.2
2025-10-12 15:43:25,801:INFO:                umap: 0.5.7
2025-10-12 15:43:25,801:INFO:     ydata_profiling: 4.17.0
2025-10-12 15:43:25,801:INFO:  explainerdashboard: 0.5.1
2025-10-12 15:43:25,801:INFO:             autoviz: Not installed
2025-10-12 15:43:25,801:INFO:           fairlearn: 0.7.0
2025-10-12 15:43:25,801:INFO:          deepchecks: Not installed
2025-10-12 15:43:25,801:INFO:             xgboost: 2.1.4
2025-10-12 15:43:25,801:INFO:            catboost: 1.2.8
2025-10-12 15:43:25,801:INFO:              kmodes: 0.12.2
2025-10-12 15:43:25,801:INFO:             mlxtend: 0.23.4
2025-10-12 15:43:25,801:INFO:       statsforecast: 1.5.0
2025-10-12 15:43:25,801:INFO:        tune_sklearn: Not installed
2025-10-12 15:43:25,801:INFO:                 ray: Not installed
2025-10-12 15:43:25,801:INFO:            hyperopt: 0.2.7
2025-10-12 15:43:25,801:INFO:              optuna: 4.5.0
2025-10-12 15:43:25,801:INFO:               skopt: 0.10.2
2025-10-12 15:43:25,801:INFO:              mlflow: 3.1.4
2025-10-12 15:43:25,801:INFO:              gradio: Not installed
2025-10-12 15:43:25,801:INFO:             fastapi: 0.119.0
2025-10-12 15:43:25,801:INFO:             uvicorn: 0.37.0
2025-10-12 15:43:25,801:INFO:              m2cgen: 0.10.0
2025-10-12 15:43:25,801:INFO:           evidently: 0.4.40
2025-10-12 15:43:25,801:INFO:               fugue: 0.8.7
2025-10-12 15:43:25,801:INFO:           streamlit: Not installed
2025-10-12 15:43:25,801:INFO:             prophet: Not installed
2025-10-12 15:43:25,801:INFO:None
2025-10-12 15:43:25,801:INFO:Set up data.
2025-10-12 15:43:25,808:INFO:Set up folding strategy.
2025-10-12 15:43:25,808:INFO:Set up train/test split.
2025-10-12 15:43:25,815:INFO:Set up index.
2025-10-12 15:43:25,815:INFO:Assigning column types.
2025-10-12 15:43:25,818:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-12 15:43:25,854:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 15:43:25,858:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 15:43:25,899:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:43:25,901:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:43:31,420:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 15:43:31,422:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 15:43:31,443:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:43:31,446:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:43:31,447:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-12 15:43:31,480:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 15:43:31,502:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:43:31,505:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:43:31,545:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 15:43:31,569:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:43:31,573:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:43:31,573:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-12 15:43:31,632:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:43:31,634:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:43:31,689:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:43:31,690:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:43:31,696:INFO:Preparing preprocessing pipeline...
2025-10-12 15:43:31,699:INFO:Set up simple imputation.
2025-10-12 15:43:31,704:INFO:Set up encoding of ordinal features.
2025-10-12 15:43:31,706:INFO:Set up encoding of categorical features.
2025-10-12 15:43:31,848:INFO:Finished creating preprocessing pipeline.
2025-10-12 15:43:31,862:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-10-12 15:43:31,862:INFO:Creating final display dataframe.
2025-10-12 15:43:32,201:INFO:Setup _display_container:                     Description            Value
0                    Session id             8231
1                        Target         Survived
2                   Target type           Binary
3           Original data shape        (712, 12)
4        Transformed data shape        (712, 14)
5   Transformed train set shape        (498, 14)
6    Transformed test set shape        (214, 14)
7              Numeric features                6
8          Categorical features                5
9      Rows with missing values            80.1%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16               Fold Generator  StratifiedKFold
17                  Fold Number               10
18                     CPU Jobs               -1
19                      Use GPU            False
20               Log Experiment     MlflowLogger
21              Experiment Name    titanic_exp_1
22                          USI             2e54
2025-10-12 15:43:32,263:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:43:32,265:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:43:32,317:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:43:32,318:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:43:32,319:INFO:Logging experiment in loggers
2025-10-12 15:43:32,684:INFO:SubProcess save_model() called ==================================
2025-10-12 15:43:32,710:INFO:Initializing save_model()
2025-10-12 15:43:32,710:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\david\AppData\Local\Temp\tmp7wu_2qbu\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 15:43:32,710:INFO:Adding model into prep_pipe
2025-10-12 15:43:32,710:WARNING:Only Model saved as it was a pipeline.
2025-10-12 15:43:32,717:INFO:C:\Users\david\AppData\Local\Temp\tmp7wu_2qbu\Transformation Pipeline.pkl saved in current working directory
2025-10-12 15:43:32,730:INFO:Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-10-12 15:43:32,730:INFO:save_model() successfully completed......................................
2025-10-12 15:43:32,833:INFO:SubProcess save_model() end ==================================
2025-10-12 15:43:33,035:INFO:setup() successfully completed in 15.46s...............
2025-10-12 15:44:09,896:INFO:Initializing compare_models()
2025-10-12 15:44:09,896:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 15:44:09,896:INFO:Checking exceptions
2025-10-12 15:44:09,982:INFO:Preparing display monitor
2025-10-12 15:44:10,008:INFO:Initializing Logistic Regression
2025-10-12 15:44:10,008:INFO:Total runtime is 0.0 minutes
2025-10-12 15:44:10,014:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:10,014:INFO:Initializing create_model()
2025-10-12 15:44:10,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:10,016:INFO:Checking exceptions
2025-10-12 15:44:10,017:INFO:Importing libraries
2025-10-12 15:44:10,017:INFO:Copying training dataset
2025-10-12 15:44:10,024:INFO:Defining folds
2025-10-12 15:44:10,025:INFO:Declaring metric variables
2025-10-12 15:44:10,030:INFO:Importing untrained model
2025-10-12 15:44:10,038:INFO:Logistic Regression Imported successfully
2025-10-12 15:44:10,048:INFO:Starting cross validation
2025-10-12 15:44:10,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:25,309:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:44:25,309:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:44:25,309:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:44:25,309:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:44:25,309:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:44:25,309:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:44:25,309:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:44:25,423:INFO:Calculating mean and std
2025-10-12 15:44:25,426:INFO:Creating metrics dataframe
2025-10-12 15:44:25,431:INFO:Uploading results into container
2025-10-12 15:44:25,432:INFO:Uploading model into container now
2025-10-12 15:44:25,433:INFO:_master_model_container: 1
2025-10-12 15:44:25,433:INFO:_display_container: 2
2025-10-12 15:44:25,434:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8231, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:44:25,434:INFO:create_model() successfully completed......................................
2025-10-12 15:44:25,583:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:25,583:INFO:Creating metrics dataframe
2025-10-12 15:44:25,589:INFO:Initializing K Neighbors Classifier
2025-10-12 15:44:25,589:INFO:Total runtime is 0.259687614440918 minutes
2025-10-12 15:44:25,593:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:25,593:INFO:Initializing create_model()
2025-10-12 15:44:25,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:25,594:INFO:Checking exceptions
2025-10-12 15:44:25,594:INFO:Importing libraries
2025-10-12 15:44:25,594:INFO:Copying training dataset
2025-10-12 15:44:25,600:INFO:Defining folds
2025-10-12 15:44:25,600:INFO:Declaring metric variables
2025-10-12 15:44:25,604:INFO:Importing untrained model
2025-10-12 15:44:25,608:INFO:K Neighbors Classifier Imported successfully
2025-10-12 15:44:25,618:INFO:Starting cross validation
2025-10-12 15:44:25,620:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:33,058:INFO:Calculating mean and std
2025-10-12 15:44:33,060:INFO:Creating metrics dataframe
2025-10-12 15:44:33,065:INFO:Uploading results into container
2025-10-12 15:44:33,066:INFO:Uploading model into container now
2025-10-12 15:44:33,067:INFO:_master_model_container: 2
2025-10-12 15:44:33,067:INFO:_display_container: 2
2025-10-12 15:44:33,068:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 15:44:33,068:INFO:create_model() successfully completed......................................
2025-10-12 15:44:33,214:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:33,214:INFO:Creating metrics dataframe
2025-10-12 15:44:33,221:INFO:Initializing Naive Bayes
2025-10-12 15:44:33,221:INFO:Total runtime is 0.38688497145970663 minutes
2025-10-12 15:44:33,224:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:33,225:INFO:Initializing create_model()
2025-10-12 15:44:33,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:33,225:INFO:Checking exceptions
2025-10-12 15:44:33,225:INFO:Importing libraries
2025-10-12 15:44:33,225:INFO:Copying training dataset
2025-10-12 15:44:33,229:INFO:Defining folds
2025-10-12 15:44:33,229:INFO:Declaring metric variables
2025-10-12 15:44:33,233:INFO:Importing untrained model
2025-10-12 15:44:33,237:INFO:Naive Bayes Imported successfully
2025-10-12 15:44:33,244:INFO:Starting cross validation
2025-10-12 15:44:33,246:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:33,472:INFO:Calculating mean and std
2025-10-12 15:44:33,474:INFO:Creating metrics dataframe
2025-10-12 15:44:33,476:INFO:Uploading results into container
2025-10-12 15:44:33,476:INFO:Uploading model into container now
2025-10-12 15:44:33,477:INFO:_master_model_container: 3
2025-10-12 15:44:33,477:INFO:_display_container: 2
2025-10-12 15:44:33,477:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 15:44:33,477:INFO:create_model() successfully completed......................................
2025-10-12 15:44:33,576:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:33,576:INFO:Creating metrics dataframe
2025-10-12 15:44:33,582:INFO:Initializing Decision Tree Classifier
2025-10-12 15:44:33,582:INFO:Total runtime is 0.3928924838701884 minutes
2025-10-12 15:44:33,585:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:33,585:INFO:Initializing create_model()
2025-10-12 15:44:33,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:33,585:INFO:Checking exceptions
2025-10-12 15:44:33,585:INFO:Importing libraries
2025-10-12 15:44:33,586:INFO:Copying training dataset
2025-10-12 15:44:33,588:INFO:Defining folds
2025-10-12 15:44:33,589:INFO:Declaring metric variables
2025-10-12 15:44:33,592:INFO:Importing untrained model
2025-10-12 15:44:33,596:INFO:Decision Tree Classifier Imported successfully
2025-10-12 15:44:33,603:INFO:Starting cross validation
2025-10-12 15:44:33,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:33,814:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:33,814:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:33,814:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:33,814:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:33,814:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:33,814:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:33,814:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:33,833:INFO:Calculating mean and std
2025-10-12 15:44:33,835:INFO:Creating metrics dataframe
2025-10-12 15:44:33,836:INFO:Uploading results into container
2025-10-12 15:44:33,837:INFO:Uploading model into container now
2025-10-12 15:44:33,838:INFO:_master_model_container: 4
2025-10-12 15:44:33,838:INFO:_display_container: 2
2025-10-12 15:44:33,838:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8231, splitter='best')
2025-10-12 15:44:33,838:INFO:create_model() successfully completed......................................
2025-10-12 15:44:33,937:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:33,938:INFO:Creating metrics dataframe
2025-10-12 15:44:33,945:INFO:Initializing SVM - Linear Kernel
2025-10-12 15:44:33,945:INFO:Total runtime is 0.39894365072250365 minutes
2025-10-12 15:44:33,948:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:33,948:INFO:Initializing create_model()
2025-10-12 15:44:33,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:33,948:INFO:Checking exceptions
2025-10-12 15:44:33,948:INFO:Importing libraries
2025-10-12 15:44:33,948:INFO:Copying training dataset
2025-10-12 15:44:33,951:INFO:Defining folds
2025-10-12 15:44:33,951:INFO:Declaring metric variables
2025-10-12 15:44:33,955:INFO:Importing untrained model
2025-10-12 15:44:33,960:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 15:44:33,966:INFO:Starting cross validation
2025-10-12 15:44:33,968:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:34,190:INFO:Calculating mean and std
2025-10-12 15:44:34,192:INFO:Creating metrics dataframe
2025-10-12 15:44:34,194:INFO:Uploading results into container
2025-10-12 15:44:34,195:INFO:Uploading model into container now
2025-10-12 15:44:34,195:INFO:_master_model_container: 5
2025-10-12 15:44:34,195:INFO:_display_container: 2
2025-10-12 15:44:34,196:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8231, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 15:44:34,196:INFO:create_model() successfully completed......................................
2025-10-12 15:44:34,291:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:34,291:INFO:Creating metrics dataframe
2025-10-12 15:44:34,298:INFO:Initializing Ridge Classifier
2025-10-12 15:44:34,298:INFO:Total runtime is 0.4048288424809774 minutes
2025-10-12 15:44:34,302:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:34,302:INFO:Initializing create_model()
2025-10-12 15:44:34,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:34,302:INFO:Checking exceptions
2025-10-12 15:44:34,302:INFO:Importing libraries
2025-10-12 15:44:34,302:INFO:Copying training dataset
2025-10-12 15:44:34,307:INFO:Defining folds
2025-10-12 15:44:34,307:INFO:Declaring metric variables
2025-10-12 15:44:34,310:INFO:Importing untrained model
2025-10-12 15:44:34,313:INFO:Ridge Classifier Imported successfully
2025-10-12 15:44:34,319:INFO:Starting cross validation
2025-10-12 15:44:34,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:34,531:INFO:Calculating mean and std
2025-10-12 15:44:34,533:INFO:Creating metrics dataframe
2025-10-12 15:44:34,535:INFO:Uploading results into container
2025-10-12 15:44:34,536:INFO:Uploading model into container now
2025-10-12 15:44:34,536:INFO:_master_model_container: 6
2025-10-12 15:44:34,536:INFO:_display_container: 2
2025-10-12 15:44:34,537:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8231, solver='auto',
                tol=0.0001)
2025-10-12 15:44:34,537:INFO:create_model() successfully completed......................................
2025-10-12 15:44:34,632:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:34,632:INFO:Creating metrics dataframe
2025-10-12 15:44:34,638:INFO:Initializing Random Forest Classifier
2025-10-12 15:44:34,639:INFO:Total runtime is 0.41051816940307617 minutes
2025-10-12 15:44:34,642:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:34,642:INFO:Initializing create_model()
2025-10-12 15:44:34,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:34,642:INFO:Checking exceptions
2025-10-12 15:44:34,642:INFO:Importing libraries
2025-10-12 15:44:34,643:INFO:Copying training dataset
2025-10-12 15:44:34,646:INFO:Defining folds
2025-10-12 15:44:34,646:INFO:Declaring metric variables
2025-10-12 15:44:34,649:INFO:Importing untrained model
2025-10-12 15:44:34,653:INFO:Random Forest Classifier Imported successfully
2025-10-12 15:44:34,661:INFO:Starting cross validation
2025-10-12 15:44:34,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:35,152:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,170:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,210:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,211:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,301:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,308:INFO:Calculating mean and std
2025-10-12 15:44:35,308:INFO:Creating metrics dataframe
2025-10-12 15:44:35,310:INFO:Uploading results into container
2025-10-12 15:44:35,311:INFO:Uploading model into container now
2025-10-12 15:44:35,311:INFO:_master_model_container: 7
2025-10-12 15:44:35,311:INFO:_display_container: 2
2025-10-12 15:44:35,312:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8231, verbose=0,
                       warm_start=False)
2025-10-12 15:44:35,312:INFO:create_model() successfully completed......................................
2025-10-12 15:44:35,410:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:35,410:INFO:Creating metrics dataframe
2025-10-12 15:44:35,418:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 15:44:35,418:INFO:Total runtime is 0.42350531021753945 minutes
2025-10-12 15:44:35,422:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:35,422:INFO:Initializing create_model()
2025-10-12 15:44:35,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:35,422:INFO:Checking exceptions
2025-10-12 15:44:35,423:INFO:Importing libraries
2025-10-12 15:44:35,423:INFO:Copying training dataset
2025-10-12 15:44:35,426:INFO:Defining folds
2025-10-12 15:44:35,427:INFO:Declaring metric variables
2025-10-12 15:44:35,430:INFO:Importing untrained model
2025-10-12 15:44:35,434:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 15:44:35,440:INFO:Starting cross validation
2025-10-12 15:44:35,444:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:35,616:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:44:35,616:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:44:35,616:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:44:35,616:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:44:35,616:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:44:35,618:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:44:35,622:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:44:35,633:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:44:35,639:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:44:35,668:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,670:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,672:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,678:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,679:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,684:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,684:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,691:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,693:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:35,710:INFO:Calculating mean and std
2025-10-12 15:44:35,712:INFO:Creating metrics dataframe
2025-10-12 15:44:35,714:INFO:Uploading results into container
2025-10-12 15:44:35,714:INFO:Uploading model into container now
2025-10-12 15:44:35,715:INFO:_master_model_container: 8
2025-10-12 15:44:35,715:INFO:_display_container: 2
2025-10-12 15:44:35,715:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 15:44:35,715:INFO:create_model() successfully completed......................................
2025-10-12 15:44:35,814:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:35,814:INFO:Creating metrics dataframe
2025-10-12 15:44:35,822:INFO:Initializing Ada Boost Classifier
2025-10-12 15:44:35,822:INFO:Total runtime is 0.4302248875300089 minutes
2025-10-12 15:44:35,825:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:35,826:INFO:Initializing create_model()
2025-10-12 15:44:35,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:35,826:INFO:Checking exceptions
2025-10-12 15:44:35,826:INFO:Importing libraries
2025-10-12 15:44:35,826:INFO:Copying training dataset
2025-10-12 15:44:35,830:INFO:Defining folds
2025-10-12 15:44:35,832:INFO:Declaring metric variables
2025-10-12 15:44:35,835:INFO:Importing untrained model
2025-10-12 15:44:35,840:INFO:Ada Boost Classifier Imported successfully
2025-10-12 15:44:35,847:INFO:Starting cross validation
2025-10-12 15:44:35,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:35,999:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:44:35,999:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:44:35,999:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:44:35,999:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:44:35,999:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:44:35,999:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:44:35,999:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:44:36,059:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,059:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,060:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,062:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,063:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,064:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,065:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,063:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,067:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,069:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,079:INFO:Calculating mean and std
2025-10-12 15:44:36,081:INFO:Creating metrics dataframe
2025-10-12 15:44:36,082:INFO:Uploading results into container
2025-10-12 15:44:36,083:INFO:Uploading model into container now
2025-10-12 15:44:36,083:INFO:_master_model_container: 9
2025-10-12 15:44:36,084:INFO:_display_container: 2
2025-10-12 15:44:36,084:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8231)
2025-10-12 15:44:36,084:INFO:create_model() successfully completed......................................
2025-10-12 15:44:36,186:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:36,186:INFO:Creating metrics dataframe
2025-10-12 15:44:36,195:INFO:Initializing Gradient Boosting Classifier
2025-10-12 15:44:36,195:INFO:Total runtime is 0.43644727468490596 minutes
2025-10-12 15:44:36,199:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:36,199:INFO:Initializing create_model()
2025-10-12 15:44:36,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:36,200:INFO:Checking exceptions
2025-10-12 15:44:36,200:INFO:Importing libraries
2025-10-12 15:44:36,200:INFO:Copying training dataset
2025-10-12 15:44:36,203:INFO:Defining folds
2025-10-12 15:44:36,203:INFO:Declaring metric variables
2025-10-12 15:44:36,207:INFO:Importing untrained model
2025-10-12 15:44:36,211:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 15:44:36,218:INFO:Starting cross validation
2025-10-12 15:44:36,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:36,527:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,556:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,557:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,560:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,560:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,563:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,572:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,573:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,577:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,579:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,593:INFO:Calculating mean and std
2025-10-12 15:44:36,595:INFO:Creating metrics dataframe
2025-10-12 15:44:36,596:INFO:Uploading results into container
2025-10-12 15:44:36,597:INFO:Uploading model into container now
2025-10-12 15:44:36,597:INFO:_master_model_container: 10
2025-10-12 15:44:36,598:INFO:_display_container: 2
2025-10-12 15:44:36,598:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8231, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 15:44:36,598:INFO:create_model() successfully completed......................................
2025-10-12 15:44:36,700:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:36,701:INFO:Creating metrics dataframe
2025-10-12 15:44:36,708:INFO:Initializing Linear Discriminant Analysis
2025-10-12 15:44:36,708:INFO:Total runtime is 0.4449962774912516 minutes
2025-10-12 15:44:36,711:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:36,711:INFO:Initializing create_model()
2025-10-12 15:44:36,712:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:36,712:INFO:Checking exceptions
2025-10-12 15:44:36,712:INFO:Importing libraries
2025-10-12 15:44:36,712:INFO:Copying training dataset
2025-10-12 15:44:36,715:INFO:Defining folds
2025-10-12 15:44:36,716:INFO:Declaring metric variables
2025-10-12 15:44:36,719:INFO:Importing untrained model
2025-10-12 15:44:36,722:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 15:44:36,732:INFO:Starting cross validation
2025-10-12 15:44:36,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:36,932:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,935:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,943:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,948:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,953:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,953:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,954:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,958:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,958:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,962:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:36,982:INFO:Calculating mean and std
2025-10-12 15:44:36,983:INFO:Creating metrics dataframe
2025-10-12 15:44:36,985:INFO:Uploading results into container
2025-10-12 15:44:36,986:INFO:Uploading model into container now
2025-10-12 15:44:36,986:INFO:_master_model_container: 11
2025-10-12 15:44:36,986:INFO:_display_container: 2
2025-10-12 15:44:36,987:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 15:44:36,987:INFO:create_model() successfully completed......................................
2025-10-12 15:44:37,095:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:37,096:INFO:Creating metrics dataframe
2025-10-12 15:44:37,103:INFO:Initializing Extra Trees Classifier
2025-10-12 15:44:37,103:INFO:Total runtime is 0.4515862504641215 minutes
2025-10-12 15:44:37,107:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:37,107:INFO:Initializing create_model()
2025-10-12 15:44:37,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:37,107:INFO:Checking exceptions
2025-10-12 15:44:37,107:INFO:Importing libraries
2025-10-12 15:44:37,108:INFO:Copying training dataset
2025-10-12 15:44:37,111:INFO:Defining folds
2025-10-12 15:44:37,111:INFO:Declaring metric variables
2025-10-12 15:44:37,115:INFO:Importing untrained model
2025-10-12 15:44:37,119:INFO:Extra Trees Classifier Imported successfully
2025-10-12 15:44:37,129:INFO:Starting cross validation
2025-10-12 15:44:37,130:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:37,621:INFO:Calculating mean and std
2025-10-12 15:44:37,623:INFO:Creating metrics dataframe
2025-10-12 15:44:37,625:INFO:Uploading results into container
2025-10-12 15:44:37,625:INFO:Uploading model into container now
2025-10-12 15:44:37,626:INFO:_master_model_container: 12
2025-10-12 15:44:37,626:INFO:_display_container: 2
2025-10-12 15:44:37,626:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8231, verbose=0,
                     warm_start=False)
2025-10-12 15:44:37,627:INFO:create_model() successfully completed......................................
2025-10-12 15:44:37,736:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:37,737:INFO:Creating metrics dataframe
2025-10-12 15:44:37,744:INFO:Initializing Extreme Gradient Boosting
2025-10-12 15:44:37,744:INFO:Total runtime is 0.46226926644643146 minutes
2025-10-12 15:44:37,747:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:37,747:INFO:Initializing create_model()
2025-10-12 15:44:37,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:37,748:INFO:Checking exceptions
2025-10-12 15:44:37,748:INFO:Importing libraries
2025-10-12 15:44:37,748:INFO:Copying training dataset
2025-10-12 15:44:37,752:INFO:Defining folds
2025-10-12 15:44:37,752:INFO:Declaring metric variables
2025-10-12 15:44:37,755:INFO:Importing untrained model
2025-10-12 15:44:37,759:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 15:44:37,768:INFO:Starting cross validation
2025-10-12 15:44:37,770:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:38,526:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:38,775:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:38,795:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:38,798:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:38,799:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:38,810:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:38,813:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:38,816:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:38,818:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:38,827:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:38,841:INFO:Calculating mean and std
2025-10-12 15:44:38,843:INFO:Creating metrics dataframe
2025-10-12 15:44:38,845:INFO:Uploading results into container
2025-10-12 15:44:38,846:INFO:Uploading model into container now
2025-10-12 15:44:38,846:INFO:_master_model_container: 13
2025-10-12 15:44:38,846:INFO:_display_container: 2
2025-10-12 15:44:38,847:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 15:44:38,847:INFO:create_model() successfully completed......................................
2025-10-12 15:44:38,985:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:38,985:INFO:Creating metrics dataframe
2025-10-12 15:44:38,997:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 15:44:38,998:INFO:Total runtime is 0.48315791686375936 minutes
2025-10-12 15:44:39,002:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:39,003:INFO:Initializing create_model()
2025-10-12 15:44:39,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:39,003:INFO:Checking exceptions
2025-10-12 15:44:39,003:INFO:Importing libraries
2025-10-12 15:44:39,003:INFO:Copying training dataset
2025-10-12 15:44:39,008:INFO:Defining folds
2025-10-12 15:44:39,008:INFO:Declaring metric variables
2025-10-12 15:44:39,013:INFO:Importing untrained model
2025-10-12 15:44:39,019:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 15:44:39,032:INFO:Starting cross validation
2025-10-12 15:44:39,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:43,538:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:43,620:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:43,678:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:43,796:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:43,805:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:43,818:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:43,978:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:43,986:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:44,036:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:44,076:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:44,100:INFO:Calculating mean and std
2025-10-12 15:44:44,103:INFO:Creating metrics dataframe
2025-10-12 15:44:44,106:INFO:Uploading results into container
2025-10-12 15:44:44,107:INFO:Uploading model into container now
2025-10-12 15:44:44,108:INFO:_master_model_container: 14
2025-10-12 15:44:44,108:INFO:_display_container: 2
2025-10-12 15:44:44,109:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8231, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 15:44:44,109:INFO:create_model() successfully completed......................................
2025-10-12 15:44:44,268:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:44,268:INFO:Creating metrics dataframe
2025-10-12 15:44:44,286:INFO:Initializing CatBoost Classifier
2025-10-12 15:44:44,286:INFO:Total runtime is 0.5712929368019104 minutes
2025-10-12 15:44:44,291:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:44,291:INFO:Initializing create_model()
2025-10-12 15:44:44,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:44,291:INFO:Checking exceptions
2025-10-12 15:44:44,293:INFO:Importing libraries
2025-10-12 15:44:44,293:INFO:Copying training dataset
2025-10-12 15:44:44,299:INFO:Defining folds
2025-10-12 15:44:44,299:INFO:Declaring metric variables
2025-10-12 15:44:44,305:INFO:Importing untrained model
2025-10-12 15:44:44,311:INFO:CatBoost Classifier Imported successfully
2025-10-12 15:44:44,321:INFO:Starting cross validation
2025-10-12 15:44:44,323:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:48,019:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:48,310:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:48,326:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
8 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
8 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 5245, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 2410, in _fit
    self._train(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 1790, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 5023, in _catboost._CatBoost._train
  File "_catboost.pyx", line 5072, in _catboost._CatBoost._train
_catboost.CatBoostError: catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info


2025-10-12 15:44:48,326:INFO:Calculating mean and std
2025-10-12 15:44:48,328:INFO:Creating metrics dataframe
2025-10-12 15:44:48,332:INFO:Uploading results into container
2025-10-12 15:44:48,332:INFO:Uploading model into container now
2025-10-12 15:44:48,333:INFO:_master_model_container: 15
2025-10-12 15:44:48,333:INFO:_display_container: 2
2025-10-12 15:44:48,334:INFO:<catboost.core.CatBoostClassifier object at 0x0000028FC8A71C40>
2025-10-12 15:44:48,334:INFO:create_model() successfully completed......................................
2025-10-12 15:44:48,470:WARNING:create_model() for <catboost.core.CatBoostClassifier object at 0x0000028FC8A71C40> raised an exception or returned all 0.0, trying without fit_kwargs:
2025-10-12 15:44:48,473:WARNING:Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

2025-10-12 15:44:48,474:INFO:Initializing create_model()
2025-10-12 15:44:48,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:48,474:INFO:Checking exceptions
2025-10-12 15:44:48,474:INFO:Importing libraries
2025-10-12 15:44:48,474:INFO:Copying training dataset
2025-10-12 15:44:48,480:INFO:Defining folds
2025-10-12 15:44:48,480:INFO:Declaring metric variables
2025-10-12 15:44:48,485:INFO:Importing untrained model
2025-10-12 15:44:48,488:INFO:CatBoost Classifier Imported successfully
2025-10-12 15:44:48,494:INFO:Starting cross validation
2025-10-12 15:44:48,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:50,703:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:50,724:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:50,747:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:50,749:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:55,340:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:55,430:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:55,528:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:55,612:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:55,615:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:55,801:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:55,814:INFO:Calculating mean and std
2025-10-12 15:44:55,815:INFO:Creating metrics dataframe
2025-10-12 15:44:55,817:INFO:Uploading results into container
2025-10-12 15:44:55,818:INFO:Uploading model into container now
2025-10-12 15:44:55,818:INFO:_master_model_container: 16
2025-10-12 15:44:55,818:INFO:_display_container: 2
2025-10-12 15:44:55,818:INFO:<catboost.core.CatBoostClassifier object at 0x0000028FC8A5F0A0>
2025-10-12 15:44:55,819:INFO:create_model() successfully completed......................................
2025-10-12 15:44:55,920:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:55,920:INFO:Creating metrics dataframe
2025-10-12 15:44:55,928:INFO:Initializing Dummy Classifier
2025-10-12 15:44:55,929:INFO:Total runtime is 0.7653551657994588 minutes
2025-10-12 15:44:55,932:INFO:SubProcess create_model() called ==================================
2025-10-12 15:44:55,932:INFO:Initializing create_model()
2025-10-12 15:44:55,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC9E93250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:55,932:INFO:Checking exceptions
2025-10-12 15:44:55,932:INFO:Importing libraries
2025-10-12 15:44:55,932:INFO:Copying training dataset
2025-10-12 15:44:55,935:INFO:Defining folds
2025-10-12 15:44:55,936:INFO:Declaring metric variables
2025-10-12 15:44:55,939:INFO:Importing untrained model
2025-10-12 15:44:55,942:INFO:Dummy Classifier Imported successfully
2025-10-12 15:44:55,949:INFO:Starting cross validation
2025-10-12 15:44:55,951:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:44:56,108:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:56,117:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:56,121:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:56,122:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:56,126:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:56,132:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:56,135:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:56,141:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:56,177:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:56,183:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:44:56,190:INFO:Calculating mean and std
2025-10-12 15:44:56,195:INFO:Creating metrics dataframe
2025-10-12 15:44:56,197:INFO:Uploading results into container
2025-10-12 15:44:56,197:INFO:Uploading model into container now
2025-10-12 15:44:56,198:INFO:_master_model_container: 17
2025-10-12 15:44:56,198:INFO:_display_container: 2
2025-10-12 15:44:56,198:INFO:DummyClassifier(constant=None, random_state=8231, strategy='prior')
2025-10-12 15:44:56,198:INFO:create_model() successfully completed......................................
2025-10-12 15:44:56,302:INFO:SubProcess create_model() end ==================================
2025-10-12 15:44:56,302:INFO:Creating metrics dataframe
2025-10-12 15:44:56,312:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 15:44:56,319:INFO:Initializing create_model()
2025-10-12 15:44:56,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8231, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:44:56,320:INFO:Checking exceptions
2025-10-12 15:44:56,321:INFO:Importing libraries
2025-10-12 15:44:56,321:INFO:Copying training dataset
2025-10-12 15:44:56,324:INFO:Defining folds
2025-10-12 15:44:56,324:INFO:Declaring metric variables
2025-10-12 15:44:56,324:INFO:Importing untrained model
2025-10-12 15:44:56,324:INFO:Declaring custom model
2025-10-12 15:44:56,324:INFO:Logistic Regression Imported successfully
2025-10-12 15:44:56,326:INFO:Cross validation set to False
2025-10-12 15:44:56,326:INFO:Fitting Model
2025-10-12 15:44:56,489:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:44:56,490:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8231, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:44:56,490:INFO:create_model() successfully completed......................................
2025-10-12 15:44:56,598:INFO:Creating Dashboard logs
2025-10-12 15:44:56,601:INFO:Model: Logistic Regression
2025-10-12 15:44:56,678:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 8231, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 15:44:56,961:INFO:Initializing predict_model()
2025-10-12 15:44:56,961:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8231, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028FC9FBD550>)
2025-10-12 15:44:56,961:INFO:Checking exceptions
2025-10-12 15:44:56,961:INFO:Preloading libraries
2025-10-12 15:44:57,333:INFO:SubProcess plot_model() called ==================================
2025-10-12 15:44:57,333:INFO:Initializing plot_model()
2025-10-12 15:44:57,333:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8231, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp119c2plz, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, system=False)
2025-10-12 15:44:57,333:INFO:Checking exceptions
2025-10-12 15:44:57,336:INFO:Preloading libraries
2025-10-12 15:44:57,337:INFO:Copying training dataset
2025-10-12 15:44:57,337:INFO:Plot type: auc
2025-10-12 15:44:57,668:INFO:Fitting Model
2025-10-12 15:44:57,669:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:44:57,670:INFO:Scoring test/hold-out set
2025-10-12 15:44:57,696:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp119c2plz\AUC.png'
2025-10-12 15:44:58,069:INFO:Visual Rendered Successfully
2025-10-12 15:44:58,188:INFO:plot_model() successfully completed......................................
2025-10-12 15:44:58,204:INFO:Initializing plot_model()
2025-10-12 15:44:58,204:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8231, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp119c2plz, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, system=False)
2025-10-12 15:44:58,204:INFO:Checking exceptions
2025-10-12 15:44:58,206:INFO:Preloading libraries
2025-10-12 15:44:58,206:INFO:Copying training dataset
2025-10-12 15:44:58,206:INFO:Plot type: confusion_matrix
2025-10-12 15:44:58,524:INFO:Fitting Model
2025-10-12 15:44:58,525:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:44:58,525:INFO:Scoring test/hold-out set
2025-10-12 15:44:58,540:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp119c2plz\Confusion Matrix.png'
2025-10-12 15:44:58,678:INFO:Visual Rendered Successfully
2025-10-12 15:44:58,807:INFO:plot_model() successfully completed......................................
2025-10-12 15:44:58,822:INFO:Initializing plot_model()
2025-10-12 15:44:58,822:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8231, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp119c2plz, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FC05D2850>, system=False)
2025-10-12 15:44:58,822:INFO:Checking exceptions
2025-10-12 15:44:58,824:INFO:Preloading libraries
2025-10-12 15:44:58,824:INFO:Copying training dataset
2025-10-12 15:44:58,824:INFO:Plot type: feature
2025-10-12 15:44:59,054:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp119c2plz\Feature Importance.png'
2025-10-12 15:44:59,188:INFO:Visual Rendered Successfully
2025-10-12 15:44:59,294:INFO:plot_model() successfully completed......................................
2025-10-12 15:44:59,309:INFO:SubProcess plot_model() end ==================================
2025-10-12 15:45:02,856:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\_distutils_hack\__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.

2025-10-12 15:45:02,857:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml

2025-10-12 15:45:03,143:INFO:Creating Dashboard logs
2025-10-12 15:45:03,146:INFO:Model: Ridge Classifier
2025-10-12 15:45:03,221:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 8231, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 15:45:03,652:INFO:Creating Dashboard logs
2025-10-12 15:45:03,656:INFO:Model: Extra Trees Classifier
2025-10-12 15:45:03,739:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8231, 'verbose': 0, 'warm_start': False}
2025-10-12 15:45:04,171:INFO:Creating Dashboard logs
2025-10-12 15:45:04,174:INFO:Model: Naive Bayes
2025-10-12 15:45:04,250:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 15:45:04,660:INFO:Creating Dashboard logs
2025-10-12 15:45:04,664:INFO:Model: Random Forest Classifier
2025-10-12 15:45:04,743:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8231, 'verbose': 0, 'warm_start': False}
2025-10-12 15:45:05,186:INFO:Creating Dashboard logs
2025-10-12 15:45:05,190:INFO:Model: K Neighbors Classifier
2025-10-12 15:45:05,268:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 15:45:05,714:INFO:Creating Dashboard logs
2025-10-12 15:45:05,717:INFO:Model: Decision Tree Classifier
2025-10-12 15:45:05,802:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 8231, 'splitter': 'best'}
2025-10-12 15:45:06,182:INFO:Creating Dashboard logs
2025-10-12 15:45:06,185:INFO:Model: Ada Boost Classifier
2025-10-12 15:45:06,261:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 8231}
2025-10-12 15:45:06,673:INFO:Creating Dashboard logs
2025-10-12 15:45:06,679:INFO:Model: Gradient Boosting Classifier
2025-10-12 15:45:06,765:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8231, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 15:45:07,255:INFO:Creating Dashboard logs
2025-10-12 15:45:07,259:INFO:Model: Linear Discriminant Analysis
2025-10-12 15:45:07,344:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 15:45:07,790:INFO:Creating Dashboard logs
2025-10-12 15:45:07,794:INFO:Model: Extreme Gradient Boosting
2025-10-12 15:45:07,877:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 8231, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 15:45:08,377:INFO:Creating Dashboard logs
2025-10-12 15:45:08,381:INFO:Model: Light Gradient Boosting Machine
2025-10-12 15:45:08,459:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 8231, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 15:45:08,904:INFO:Creating Dashboard logs
2025-10-12 15:45:08,908:INFO:Model: CatBoost Classifier
2025-10-12 15:45:08,990:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-10-12 15:45:08,990:INFO:Logged params: {}
2025-10-12 15:45:09,368:INFO:Creating Dashboard logs
2025-10-12 15:45:09,370:INFO:Model: Dummy Classifier
2025-10-12 15:45:09,452:INFO:Logged params: {'constant': None, 'random_state': 8231, 'strategy': 'prior'}
2025-10-12 15:45:09,826:INFO:Creating Dashboard logs
2025-10-12 15:45:09,830:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 15:45:09,921:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 15:45:10,324:INFO:Creating Dashboard logs
2025-10-12 15:45:10,328:INFO:Model: SVM - Linear Kernel
2025-10-12 15:45:10,413:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 8231, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 15:45:10,907:INFO:_master_model_container: 17
2025-10-12 15:45:10,907:INFO:_display_container: 2
2025-10-12 15:45:10,907:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8231, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:45:10,907:INFO:compare_models() successfully completed......................................
2025-10-12 15:46:53,318:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 15:46:53,318:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 15:46:53,318:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 15:46:53,318:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 15:46:54,494:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\mlflow\utils\requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources  # noqa: TID251

2025-10-12 15:47:06,649:INFO:PyCaret ClassificationExperiment
2025-10-12 15:47:06,649:INFO:Logging name: titanic_exp_1
2025-10-12 15:47:06,649:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-12 15:47:06,649:INFO:version 3.3.2
2025-10-12 15:47:06,649:INFO:Initializing setup()
2025-10-12 15:47:06,650:INFO:self.USI: 6371
2025-10-12 15:47:06,650:INFO:self._variable_keys: {'fold_generator', 'is_multiclass', 'pipeline', 'y', 'target_param', '_ml_usecase', 'fold_shuffle_param', 'X_train', 'html_param', 'gpu_n_jobs_param', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', 'exp_id', 'data', 'y_test', 'exp_name_log', 'memory', 'y_train', 'X_test', 'seed', 'fix_imbalance', 'n_jobs_param', 'X', 'logging_param', '_available_plots', 'idx'}
2025-10-12 15:47:06,650:INFO:Checking environment
2025-10-12 15:47:06,650:INFO:python_version: 3.9.13
2025-10-12 15:47:06,650:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2025-10-12 15:47:06,650:INFO:machine: AMD64
2025-10-12 15:47:06,650:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-12 15:47:06,650:INFO:Memory: svmem(total=16778072064, available=4278063104, percent=74.5, used=12500008960, free=4278063104)
2025-10-12 15:47:06,650:INFO:Physical Core: 10
2025-10-12 15:47:06,650:INFO:Logical Core: 16
2025-10-12 15:47:06,650:INFO:Checking libraries
2025-10-12 15:47:06,650:INFO:System:
2025-10-12 15:47:06,650:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2025-10-12 15:47:06,650:INFO:executable: c:\Users\david\Programming\MLOps\.venv\Scripts\python.exe
2025-10-12 15:47:06,650:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-12 15:47:06,650:INFO:PyCaret required dependencies:
2025-10-12 15:47:07,657:INFO:                 pip: 25.2
2025-10-12 15:47:07,657:INFO:          setuptools: 80.9.0
2025-10-12 15:47:07,657:INFO:             pycaret: 3.3.2
2025-10-12 15:47:07,657:INFO:             IPython: 8.18.1
2025-10-12 15:47:07,657:INFO:          ipywidgets: 8.1.7
2025-10-12 15:47:07,657:INFO:                tqdm: 4.67.1
2025-10-12 15:47:07,657:INFO:               numpy: 1.26.4
2025-10-12 15:47:07,657:INFO:              pandas: 2.1.4
2025-10-12 15:47:07,657:INFO:              jinja2: 3.1.6
2025-10-12 15:47:07,657:INFO:               scipy: 1.11.4
2025-10-12 15:47:07,657:INFO:              joblib: 1.3.2
2025-10-12 15:47:07,657:INFO:             sklearn: 1.4.2
2025-10-12 15:47:07,657:INFO:                pyod: 2.0.5
2025-10-12 15:47:07,657:INFO:            imblearn: 0.12.4
2025-10-12 15:47:07,657:INFO:   category_encoders: 2.6.4
2025-10-12 15:47:07,657:INFO:            lightgbm: 4.6.0
2025-10-12 15:47:07,657:INFO:               numba: 0.60.0
2025-10-12 15:47:07,657:INFO:            requests: 2.32.5
2025-10-12 15:47:07,657:INFO:          matplotlib: 3.7.5
2025-10-12 15:47:07,657:INFO:          scikitplot: 0.3.7
2025-10-12 15:47:07,657:INFO:         yellowbrick: 1.5
2025-10-12 15:47:07,657:INFO:              plotly: 5.24.1
2025-10-12 15:47:07,657:INFO:    plotly-resampler: Not installed
2025-10-12 15:47:07,657:INFO:             kaleido: 1.1.0
2025-10-12 15:47:07,657:INFO:           schemdraw: 0.15
2025-10-12 15:47:07,657:INFO:         statsmodels: 0.14.5
2025-10-12 15:47:07,657:INFO:              sktime: 0.26.0
2025-10-12 15:47:07,657:INFO:               tbats: 1.1.3
2025-10-12 15:47:07,657:INFO:            pmdarima: 2.0.4
2025-10-12 15:47:07,659:INFO:              psutil: 7.1.0
2025-10-12 15:47:07,659:INFO:          markupsafe: 2.1.5
2025-10-12 15:47:07,659:INFO:             pickle5: Not installed
2025-10-12 15:47:07,659:INFO:         cloudpickle: 3.1.1
2025-10-12 15:47:07,659:INFO:         deprecation: 2.1.0
2025-10-12 15:47:07,659:INFO:              xxhash: 3.6.0
2025-10-12 15:47:07,659:INFO:           wurlitzer: Not installed
2025-10-12 15:47:07,659:INFO:PyCaret optional dependencies:
2025-10-12 15:47:09,662:INFO:                shap: 0.44.1
2025-10-12 15:47:09,662:INFO:           interpret: 0.7.2
2025-10-12 15:47:09,662:INFO:                umap: 0.5.7
2025-10-12 15:47:09,662:INFO:     ydata_profiling: 4.17.0
2025-10-12 15:47:09,662:INFO:  explainerdashboard: 0.5.1
2025-10-12 15:47:09,663:INFO:             autoviz: Not installed
2025-10-12 15:47:09,663:INFO:           fairlearn: 0.7.0
2025-10-12 15:47:09,663:INFO:          deepchecks: Not installed
2025-10-12 15:47:09,663:INFO:             xgboost: 2.1.4
2025-10-12 15:47:09,663:INFO:            catboost: 1.2.8
2025-10-12 15:47:09,663:INFO:              kmodes: 0.12.2
2025-10-12 15:47:09,663:INFO:             mlxtend: 0.23.4
2025-10-12 15:47:09,663:INFO:       statsforecast: 1.5.0
2025-10-12 15:47:09,663:INFO:        tune_sklearn: Not installed
2025-10-12 15:47:09,663:INFO:                 ray: Not installed
2025-10-12 15:47:09,663:INFO:            hyperopt: 0.2.7
2025-10-12 15:47:09,663:INFO:              optuna: 4.5.0
2025-10-12 15:47:09,663:INFO:               skopt: 0.10.2
2025-10-12 15:47:09,663:INFO:              mlflow: 3.1.4
2025-10-12 15:47:09,663:INFO:              gradio: Not installed
2025-10-12 15:47:09,663:INFO:             fastapi: 0.119.0
2025-10-12 15:47:09,663:INFO:             uvicorn: 0.37.0
2025-10-12 15:47:09,663:INFO:              m2cgen: 0.10.0
2025-10-12 15:47:09,663:INFO:           evidently: 0.4.40
2025-10-12 15:47:09,663:INFO:               fugue: 0.8.7
2025-10-12 15:47:09,663:INFO:           streamlit: Not installed
2025-10-12 15:47:09,663:INFO:             prophet: Not installed
2025-10-12 15:47:09,663:INFO:None
2025-10-12 15:47:09,663:INFO:Set up data.
2025-10-12 15:47:09,669:INFO:Set up folding strategy.
2025-10-12 15:47:09,669:INFO:Set up train/test split.
2025-10-12 15:47:09,672:INFO:Set up index.
2025-10-12 15:47:09,672:INFO:Assigning column types.
2025-10-12 15:47:09,674:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-12 15:47:09,705:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 15:47:09,708:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 15:47:09,739:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:47:09,741:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:47:09,800:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 15:47:09,800:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 15:47:09,820:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:47:09,821:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:47:09,822:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-12 15:47:09,861:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 15:47:09,881:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:47:09,883:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:47:09,914:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 15:47:09,933:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:47:09,935:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:47:09,936:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-12 15:47:09,987:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:47:09,989:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:47:10,039:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:47:10,042:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:47:10,045:INFO:Preparing preprocessing pipeline...
2025-10-12 15:47:10,045:INFO:Set up simple imputation.
2025-10-12 15:47:10,047:INFO:Set up encoding of ordinal features.
2025-10-12 15:47:10,048:INFO:Set up encoding of categorical features.
2025-10-12 15:47:10,162:INFO:Finished creating preprocessing pipeline.
2025-10-12 15:47:10,177:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-10-12 15:47:10,177:INFO:Creating final display dataframe.
2025-10-12 15:47:10,512:INFO:Setup _display_container:                     Description            Value
0                    Session id             1760
1                        Target         Survived
2                   Target type           Binary
3           Original data shape        (712, 12)
4        Transformed data shape        (712, 14)
5   Transformed train set shape        (498, 14)
6    Transformed test set shape        (214, 14)
7              Numeric features                6
8          Categorical features                5
9      Rows with missing values            80.1%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16               Fold Generator  StratifiedKFold
17                  Fold Number               10
18                     CPU Jobs               -1
19                      Use GPU            False
20               Log Experiment     MlflowLogger
21              Experiment Name    titanic_exp_1
22                          USI             6371
2025-10-12 15:47:10,577:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:47:10,580:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:47:10,635:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 15:47:10,637:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 15:47:10,638:INFO:Logging experiment in loggers
2025-10-12 15:47:10,925:INFO:SubProcess save_model() called ==================================
2025-10-12 15:47:10,951:INFO:Initializing save_model()
2025-10-12 15:47:10,952:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\david\AppData\Local\Temp\tmpamu_gogx\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 15:47:10,952:INFO:Adding model into prep_pipe
2025-10-12 15:47:10,952:WARNING:Only Model saved as it was a pipeline.
2025-10-12 15:47:10,957:INFO:C:\Users\david\AppData\Local\Temp\tmpamu_gogx\Transformation Pipeline.pkl saved in current working directory
2025-10-12 15:47:10,982:INFO:Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-10-12 15:47:10,982:INFO:save_model() successfully completed......................................
2025-10-12 15:47:11,114:INFO:SubProcess save_model() end ==================================
2025-10-12 15:47:11,238:INFO:setup() successfully completed in 3.99s...............
2025-10-12 15:47:15,620:INFO:Initializing compare_models()
2025-10-12 15:47:15,620:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 15:47:15,620:INFO:Checking exceptions
2025-10-12 15:47:15,622:INFO:Preparing display monitor
2025-10-12 15:47:15,641:INFO:Initializing Logistic Regression
2025-10-12 15:47:15,642:INFO:Total runtime is 1.6768773396809895e-05 minutes
2025-10-12 15:47:15,644:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:15,645:INFO:Initializing create_model()
2025-10-12 15:47:15,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:15,645:INFO:Checking exceptions
2025-10-12 15:47:15,646:INFO:Importing libraries
2025-10-12 15:47:15,646:INFO:Copying training dataset
2025-10-12 15:47:15,651:INFO:Defining folds
2025-10-12 15:47:15,651:INFO:Declaring metric variables
2025-10-12 15:47:15,655:INFO:Importing untrained model
2025-10-12 15:47:15,659:INFO:Logistic Regression Imported successfully
2025-10-12 15:47:15,666:INFO:Starting cross validation
2025-10-12 15:47:15,668:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:22,889:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:47:22,921:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:47:22,933:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:47:23,030:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:47:23,030:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:47:23,057:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:47:23,072:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:47:23,101:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:47:23,108:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:47:23,119:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:47:23,175:INFO:Calculating mean and std
2025-10-12 15:47:23,176:INFO:Creating metrics dataframe
2025-10-12 15:47:23,178:INFO:Uploading results into container
2025-10-12 15:47:23,178:INFO:Uploading model into container now
2025-10-12 15:47:23,179:INFO:_master_model_container: 1
2025-10-12 15:47:23,179:INFO:_display_container: 2
2025-10-12 15:47:23,179:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:47:23,179:INFO:create_model() successfully completed......................................
2025-10-12 15:47:23,287:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:23,287:INFO:Creating metrics dataframe
2025-10-12 15:47:23,292:INFO:Initializing K Neighbors Classifier
2025-10-12 15:47:23,292:INFO:Total runtime is 0.12750447988510133 minutes
2025-10-12 15:47:23,295:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:23,295:INFO:Initializing create_model()
2025-10-12 15:47:23,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:23,295:INFO:Checking exceptions
2025-10-12 15:47:23,295:INFO:Importing libraries
2025-10-12 15:47:23,295:INFO:Copying training dataset
2025-10-12 15:47:23,299:INFO:Defining folds
2025-10-12 15:47:23,299:INFO:Declaring metric variables
2025-10-12 15:47:23,302:INFO:Importing untrained model
2025-10-12 15:47:23,306:INFO:K Neighbors Classifier Imported successfully
2025-10-12 15:47:23,312:INFO:Starting cross validation
2025-10-12 15:47:23,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:28,046:INFO:Calculating mean and std
2025-10-12 15:47:28,048:INFO:Creating metrics dataframe
2025-10-12 15:47:28,051:INFO:Uploading results into container
2025-10-12 15:47:28,052:INFO:Uploading model into container now
2025-10-12 15:47:28,052:INFO:_master_model_container: 2
2025-10-12 15:47:28,052:INFO:_display_container: 2
2025-10-12 15:47:28,053:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 15:47:28,053:INFO:create_model() successfully completed......................................
2025-10-12 15:47:28,157:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:28,157:INFO:Creating metrics dataframe
2025-10-12 15:47:28,161:INFO:Initializing Naive Bayes
2025-10-12 15:47:28,161:INFO:Total runtime is 0.20866928497950238 minutes
2025-10-12 15:47:28,164:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:28,165:INFO:Initializing create_model()
2025-10-12 15:47:28,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:28,165:INFO:Checking exceptions
2025-10-12 15:47:28,165:INFO:Importing libraries
2025-10-12 15:47:28,165:INFO:Copying training dataset
2025-10-12 15:47:28,169:INFO:Defining folds
2025-10-12 15:47:28,169:INFO:Declaring metric variables
2025-10-12 15:47:28,174:INFO:Importing untrained model
2025-10-12 15:47:28,177:INFO:Naive Bayes Imported successfully
2025-10-12 15:47:28,182:INFO:Starting cross validation
2025-10-12 15:47:28,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:28,373:INFO:Calculating mean and std
2025-10-12 15:47:28,374:INFO:Creating metrics dataframe
2025-10-12 15:47:28,377:INFO:Uploading results into container
2025-10-12 15:47:28,377:INFO:Uploading model into container now
2025-10-12 15:47:28,379:INFO:_master_model_container: 3
2025-10-12 15:47:28,379:INFO:_display_container: 2
2025-10-12 15:47:28,379:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 15:47:28,379:INFO:create_model() successfully completed......................................
2025-10-12 15:47:28,472:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:28,472:INFO:Creating metrics dataframe
2025-10-12 15:47:28,476:INFO:Initializing Decision Tree Classifier
2025-10-12 15:47:28,476:INFO:Total runtime is 0.2139141360918681 minutes
2025-10-12 15:47:28,480:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:28,480:INFO:Initializing create_model()
2025-10-12 15:47:28,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:28,480:INFO:Checking exceptions
2025-10-12 15:47:28,480:INFO:Importing libraries
2025-10-12 15:47:28,480:INFO:Copying training dataset
2025-10-12 15:47:28,483:INFO:Defining folds
2025-10-12 15:47:28,484:INFO:Declaring metric variables
2025-10-12 15:47:28,487:INFO:Importing untrained model
2025-10-12 15:47:28,489:INFO:Decision Tree Classifier Imported successfully
2025-10-12 15:47:28,495:INFO:Starting cross validation
2025-10-12 15:47:28,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:28,665:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:28,665:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:28,665:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:28,671:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:28,672:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:28,673:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:28,676:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:28,676:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:28,678:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:28,681:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:28,700:INFO:Calculating mean and std
2025-10-12 15:47:28,701:INFO:Creating metrics dataframe
2025-10-12 15:47:28,703:INFO:Uploading results into container
2025-10-12 15:47:28,703:INFO:Uploading model into container now
2025-10-12 15:47:28,703:INFO:_master_model_container: 4
2025-10-12 15:47:28,703:INFO:_display_container: 2
2025-10-12 15:47:28,704:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1760, splitter='best')
2025-10-12 15:47:28,704:INFO:create_model() successfully completed......................................
2025-10-12 15:47:28,796:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:28,797:INFO:Creating metrics dataframe
2025-10-12 15:47:28,803:INFO:Initializing SVM - Linear Kernel
2025-10-12 15:47:28,803:INFO:Total runtime is 0.2193657755851746 minutes
2025-10-12 15:47:28,806:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:28,806:INFO:Initializing create_model()
2025-10-12 15:47:28,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:28,806:INFO:Checking exceptions
2025-10-12 15:47:28,806:INFO:Importing libraries
2025-10-12 15:47:28,806:INFO:Copying training dataset
2025-10-12 15:47:28,811:INFO:Defining folds
2025-10-12 15:47:28,811:INFO:Declaring metric variables
2025-10-12 15:47:28,814:INFO:Importing untrained model
2025-10-12 15:47:28,818:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 15:47:28,824:INFO:Starting cross validation
2025-10-12 15:47:28,825:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:29,027:INFO:Calculating mean and std
2025-10-12 15:47:29,028:INFO:Creating metrics dataframe
2025-10-12 15:47:29,029:INFO:Uploading results into container
2025-10-12 15:47:29,030:INFO:Uploading model into container now
2025-10-12 15:47:29,031:INFO:_master_model_container: 5
2025-10-12 15:47:29,031:INFO:_display_container: 2
2025-10-12 15:47:29,032:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1760, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 15:47:29,032:INFO:create_model() successfully completed......................................
2025-10-12 15:47:29,122:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:29,122:INFO:Creating metrics dataframe
2025-10-12 15:47:29,127:INFO:Initializing Ridge Classifier
2025-10-12 15:47:29,127:INFO:Total runtime is 0.22476040919621787 minutes
2025-10-12 15:47:29,130:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:29,130:INFO:Initializing create_model()
2025-10-12 15:47:29,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:29,131:INFO:Checking exceptions
2025-10-12 15:47:29,131:INFO:Importing libraries
2025-10-12 15:47:29,131:INFO:Copying training dataset
2025-10-12 15:47:29,134:INFO:Defining folds
2025-10-12 15:47:29,135:INFO:Declaring metric variables
2025-10-12 15:47:29,138:INFO:Importing untrained model
2025-10-12 15:47:29,142:INFO:Ridge Classifier Imported successfully
2025-10-12 15:47:29,147:INFO:Starting cross validation
2025-10-12 15:47:29,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:29,337:INFO:Calculating mean and std
2025-10-12 15:47:29,338:INFO:Creating metrics dataframe
2025-10-12 15:47:29,340:INFO:Uploading results into container
2025-10-12 15:47:29,341:INFO:Uploading model into container now
2025-10-12 15:47:29,341:INFO:_master_model_container: 6
2025-10-12 15:47:29,342:INFO:_display_container: 2
2025-10-12 15:47:29,342:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1760, solver='auto',
                tol=0.0001)
2025-10-12 15:47:29,342:INFO:create_model() successfully completed......................................
2025-10-12 15:47:29,433:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:29,433:INFO:Creating metrics dataframe
2025-10-12 15:47:29,439:INFO:Initializing Random Forest Classifier
2025-10-12 15:47:29,439:INFO:Total runtime is 0.22996765375137332 minutes
2025-10-12 15:47:29,442:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:29,442:INFO:Initializing create_model()
2025-10-12 15:47:29,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:29,442:INFO:Checking exceptions
2025-10-12 15:47:29,442:INFO:Importing libraries
2025-10-12 15:47:29,442:INFO:Copying training dataset
2025-10-12 15:47:29,446:INFO:Defining folds
2025-10-12 15:47:29,446:INFO:Declaring metric variables
2025-10-12 15:47:29,448:INFO:Importing untrained model
2025-10-12 15:47:29,452:INFO:Random Forest Classifier Imported successfully
2025-10-12 15:47:29,458:INFO:Starting cross validation
2025-10-12 15:47:29,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:29,890:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:29,890:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:29,904:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:29,905:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:29,905:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:29,933:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:29,946:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:29,955:INFO:Calculating mean and std
2025-10-12 15:47:29,956:INFO:Creating metrics dataframe
2025-10-12 15:47:29,958:INFO:Uploading results into container
2025-10-12 15:47:29,958:INFO:Uploading model into container now
2025-10-12 15:47:29,959:INFO:_master_model_container: 7
2025-10-12 15:47:29,959:INFO:_display_container: 2
2025-10-12 15:47:29,959:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1760, verbose=0,
                       warm_start=False)
2025-10-12 15:47:29,959:INFO:create_model() successfully completed......................................
2025-10-12 15:47:30,053:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:30,053:INFO:Creating metrics dataframe
2025-10-12 15:47:30,059:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 15:47:30,059:INFO:Total runtime is 0.24030078252156578 minutes
2025-10-12 15:47:30,062:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:30,062:INFO:Initializing create_model()
2025-10-12 15:47:30,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:30,063:INFO:Checking exceptions
2025-10-12 15:47:30,063:INFO:Importing libraries
2025-10-12 15:47:30,063:INFO:Copying training dataset
2025-10-12 15:47:30,067:INFO:Defining folds
2025-10-12 15:47:30,067:INFO:Declaring metric variables
2025-10-12 15:47:30,071:INFO:Importing untrained model
2025-10-12 15:47:30,074:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 15:47:30,085:INFO:Starting cross validation
2025-10-12 15:47:30,087:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:30,206:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:47:30,207:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:47:30,212:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:47:30,217:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:47:30,219:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:47:30,220:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:47:30,225:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:47:30,226:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:47:30,232:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:47:30,259:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,259:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,266:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,266:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,273:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,275:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,277:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,278:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,296:INFO:Calculating mean and std
2025-10-12 15:47:30,297:INFO:Creating metrics dataframe
2025-10-12 15:47:30,299:INFO:Uploading results into container
2025-10-12 15:47:30,300:INFO:Uploading model into container now
2025-10-12 15:47:30,301:INFO:_master_model_container: 8
2025-10-12 15:47:30,301:INFO:_display_container: 2
2025-10-12 15:47:30,301:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 15:47:30,301:INFO:create_model() successfully completed......................................
2025-10-12 15:47:30,391:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:30,391:INFO:Creating metrics dataframe
2025-10-12 15:47:30,397:INFO:Initializing Ada Boost Classifier
2025-10-12 15:47:30,397:INFO:Total runtime is 0.24592573245366417 minutes
2025-10-12 15:47:30,401:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:30,402:INFO:Initializing create_model()
2025-10-12 15:47:30,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:30,402:INFO:Checking exceptions
2025-10-12 15:47:30,402:INFO:Importing libraries
2025-10-12 15:47:30,402:INFO:Copying training dataset
2025-10-12 15:47:30,406:INFO:Defining folds
2025-10-12 15:47:30,406:INFO:Declaring metric variables
2025-10-12 15:47:30,409:INFO:Importing untrained model
2025-10-12 15:47:30,412:INFO:Ada Boost Classifier Imported successfully
2025-10-12 15:47:30,418:INFO:Starting cross validation
2025-10-12 15:47:30,419:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:30,525:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:47:30,531:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:47:30,531:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:47:30,532:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:47:30,537:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:47:30,537:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:47:30,540:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:47:30,547:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:47:30,551:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:47:30,556:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:47:30,585:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,587:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,589:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,590:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,594:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,597:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,598:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,600:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,602:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,608:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:30,621:INFO:Calculating mean and std
2025-10-12 15:47:30,622:INFO:Creating metrics dataframe
2025-10-12 15:47:30,624:INFO:Uploading results into container
2025-10-12 15:47:30,624:INFO:Uploading model into container now
2025-10-12 15:47:30,625:INFO:_master_model_container: 9
2025-10-12 15:47:30,625:INFO:_display_container: 2
2025-10-12 15:47:30,625:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1760)
2025-10-12 15:47:30,626:INFO:create_model() successfully completed......................................
2025-10-12 15:47:30,718:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:30,718:INFO:Creating metrics dataframe
2025-10-12 15:47:30,723:INFO:Initializing Gradient Boosting Classifier
2025-10-12 15:47:30,724:INFO:Total runtime is 0.25137662490208945 minutes
2025-10-12 15:47:30,726:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:30,726:INFO:Initializing create_model()
2025-10-12 15:47:30,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:30,726:INFO:Checking exceptions
2025-10-12 15:47:30,726:INFO:Importing libraries
2025-10-12 15:47:30,726:INFO:Copying training dataset
2025-10-12 15:47:30,730:INFO:Defining folds
2025-10-12 15:47:30,731:INFO:Declaring metric variables
2025-10-12 15:47:30,734:INFO:Importing untrained model
2025-10-12 15:47:30,738:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 15:47:30,742:INFO:Starting cross validation
2025-10-12 15:47:30,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:31,007:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,016:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,024:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,025:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,026:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,031:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,033:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,034:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,036:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,055:INFO:Calculating mean and std
2025-10-12 15:47:31,056:INFO:Creating metrics dataframe
2025-10-12 15:47:31,057:INFO:Uploading results into container
2025-10-12 15:47:31,059:INFO:Uploading model into container now
2025-10-12 15:47:31,059:INFO:_master_model_container: 10
2025-10-12 15:47:31,059:INFO:_display_container: 2
2025-10-12 15:47:31,059:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1760, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 15:47:31,059:INFO:create_model() successfully completed......................................
2025-10-12 15:47:31,148:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:31,148:INFO:Creating metrics dataframe
2025-10-12 15:47:31,155:INFO:Initializing Linear Discriminant Analysis
2025-10-12 15:47:31,155:INFO:Total runtime is 0.25855836868286136 minutes
2025-10-12 15:47:31,157:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:31,157:INFO:Initializing create_model()
2025-10-12 15:47:31,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:31,158:INFO:Checking exceptions
2025-10-12 15:47:31,158:INFO:Importing libraries
2025-10-12 15:47:31,158:INFO:Copying training dataset
2025-10-12 15:47:31,161:INFO:Defining folds
2025-10-12 15:47:31,161:INFO:Declaring metric variables
2025-10-12 15:47:31,164:INFO:Importing untrained model
2025-10-12 15:47:31,168:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 15:47:31,173:INFO:Starting cross validation
2025-10-12 15:47:31,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:31,340:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,340:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,342:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,343:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,347:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,348:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,351:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,352:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,361:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,365:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:31,384:INFO:Calculating mean and std
2025-10-12 15:47:31,385:INFO:Creating metrics dataframe
2025-10-12 15:47:31,387:INFO:Uploading results into container
2025-10-12 15:47:31,388:INFO:Uploading model into container now
2025-10-12 15:47:31,389:INFO:_master_model_container: 11
2025-10-12 15:47:31,389:INFO:_display_container: 2
2025-10-12 15:47:31,389:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 15:47:31,390:INFO:create_model() successfully completed......................................
2025-10-12 15:47:31,491:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:31,491:INFO:Creating metrics dataframe
2025-10-12 15:47:31,504:INFO:Initializing Extra Trees Classifier
2025-10-12 15:47:31,504:INFO:Total runtime is 0.2643721421559652 minutes
2025-10-12 15:47:31,509:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:31,509:INFO:Initializing create_model()
2025-10-12 15:47:31,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:31,510:INFO:Checking exceptions
2025-10-12 15:47:31,510:INFO:Importing libraries
2025-10-12 15:47:31,510:INFO:Copying training dataset
2025-10-12 15:47:31,516:INFO:Defining folds
2025-10-12 15:47:31,517:INFO:Declaring metric variables
2025-10-12 15:47:31,521:INFO:Importing untrained model
2025-10-12 15:47:31,524:INFO:Extra Trees Classifier Imported successfully
2025-10-12 15:47:31,534:INFO:Starting cross validation
2025-10-12 15:47:31,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:32,005:INFO:Calculating mean and std
2025-10-12 15:47:32,006:INFO:Creating metrics dataframe
2025-10-12 15:47:32,009:INFO:Uploading results into container
2025-10-12 15:47:32,010:INFO:Uploading model into container now
2025-10-12 15:47:32,010:INFO:_master_model_container: 12
2025-10-12 15:47:32,010:INFO:_display_container: 2
2025-10-12 15:47:32,010:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1760, verbose=0,
                     warm_start=False)
2025-10-12 15:47:32,010:INFO:create_model() successfully completed......................................
2025-10-12 15:47:32,106:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:32,106:INFO:Creating metrics dataframe
2025-10-12 15:47:32,113:INFO:Initializing Extreme Gradient Boosting
2025-10-12 15:47:32,113:INFO:Total runtime is 0.2745246052742005 minutes
2025-10-12 15:47:32,117:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:32,117:INFO:Initializing create_model()
2025-10-12 15:47:32,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:32,117:INFO:Checking exceptions
2025-10-12 15:47:32,117:INFO:Importing libraries
2025-10-12 15:47:32,117:INFO:Copying training dataset
2025-10-12 15:47:32,121:INFO:Defining folds
2025-10-12 15:47:32,121:INFO:Declaring metric variables
2025-10-12 15:47:32,124:INFO:Importing untrained model
2025-10-12 15:47:32,127:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 15:47:32,134:INFO:Starting cross validation
2025-10-12 15:47:32,136:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:32,821:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:32,831:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:32,832:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:32,849:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:32,862:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:32,864:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:32,894:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:32,902:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:32,903:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:32,907:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:32,924:INFO:Calculating mean and std
2025-10-12 15:47:32,925:INFO:Creating metrics dataframe
2025-10-12 15:47:32,927:INFO:Uploading results into container
2025-10-12 15:47:32,927:INFO:Uploading model into container now
2025-10-12 15:47:32,927:INFO:_master_model_container: 13
2025-10-12 15:47:32,927:INFO:_display_container: 2
2025-10-12 15:47:32,929:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 15:47:32,929:INFO:create_model() successfully completed......................................
2025-10-12 15:47:33,057:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:33,058:INFO:Creating metrics dataframe
2025-10-12 15:47:33,065:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 15:47:33,066:INFO:Total runtime is 0.29040773709615075 minutes
2025-10-12 15:47:33,068:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:33,068:INFO:Initializing create_model()
2025-10-12 15:47:33,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:33,068:INFO:Checking exceptions
2025-10-12 15:47:33,069:INFO:Importing libraries
2025-10-12 15:47:33,069:INFO:Copying training dataset
2025-10-12 15:47:33,073:INFO:Defining folds
2025-10-12 15:47:33,073:INFO:Declaring metric variables
2025-10-12 15:47:33,078:INFO:Importing untrained model
2025-10-12 15:47:33,083:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 15:47:33,091:INFO:Starting cross validation
2025-10-12 15:47:33,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:33,526:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:33,537:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:33,545:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:33,581:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:33,610:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:33,612:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:33,618:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:33,661:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:33,679:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:33,681:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:33,702:INFO:Calculating mean and std
2025-10-12 15:47:33,703:INFO:Creating metrics dataframe
2025-10-12 15:47:33,705:INFO:Uploading results into container
2025-10-12 15:47:33,706:INFO:Uploading model into container now
2025-10-12 15:47:33,706:INFO:_master_model_container: 14
2025-10-12 15:47:33,707:INFO:_display_container: 2
2025-10-12 15:47:33,708:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1760, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 15:47:33,708:INFO:create_model() successfully completed......................................
2025-10-12 15:47:33,816:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:33,816:INFO:Creating metrics dataframe
2025-10-12 15:47:33,824:INFO:Initializing CatBoost Classifier
2025-10-12 15:47:33,824:INFO:Total runtime is 0.30303777058919273 minutes
2025-10-12 15:47:33,828:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:33,828:INFO:Initializing create_model()
2025-10-12 15:47:33,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:33,829:INFO:Checking exceptions
2025-10-12 15:47:33,829:INFO:Importing libraries
2025-10-12 15:47:33,829:INFO:Copying training dataset
2025-10-12 15:47:33,834:INFO:Defining folds
2025-10-12 15:47:33,834:INFO:Declaring metric variables
2025-10-12 15:47:33,838:INFO:Importing untrained model
2025-10-12 15:47:33,840:INFO:CatBoost Classifier Imported successfully
2025-10-12 15:47:33,849:INFO:Starting cross validation
2025-10-12 15:47:33,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:37,008:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:37,015:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:37,018:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:37,021:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:37,123:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,297:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,331:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,475:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,553:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,566:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,578:INFO:Calculating mean and std
2025-10-12 15:47:39,580:INFO:Creating metrics dataframe
2025-10-12 15:47:39,582:INFO:Uploading results into container
2025-10-12 15:47:39,583:INFO:Uploading model into container now
2025-10-12 15:47:39,583:INFO:_master_model_container: 15
2025-10-12 15:47:39,584:INFO:_display_container: 2
2025-10-12 15:47:39,584:INFO:<catboost.core.CatBoostClassifier object at 0x00000265DA0534F0>
2025-10-12 15:47:39,584:INFO:create_model() successfully completed......................................
2025-10-12 15:47:39,694:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:39,694:INFO:Creating metrics dataframe
2025-10-12 15:47:39,703:INFO:Initializing Dummy Classifier
2025-10-12 15:47:39,703:INFO:Total runtime is 0.4010221560796102 minutes
2025-10-12 15:47:39,706:INFO:SubProcess create_model() called ==================================
2025-10-12 15:47:39,707:INFO:Initializing create_model()
2025-10-12 15:47:39,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B31910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:39,707:INFO:Checking exceptions
2025-10-12 15:47:39,707:INFO:Importing libraries
2025-10-12 15:47:39,707:INFO:Copying training dataset
2025-10-12 15:47:39,711:INFO:Defining folds
2025-10-12 15:47:39,711:INFO:Declaring metric variables
2025-10-12 15:47:39,714:INFO:Importing untrained model
2025-10-12 15:47:39,717:INFO:Dummy Classifier Imported successfully
2025-10-12 15:47:39,725:INFO:Starting cross validation
2025-10-12 15:47:39,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:47:39,906:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,906:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,915:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,916:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,922:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,925:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,931:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,937:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,938:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,938:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:47:39,951:INFO:Calculating mean and std
2025-10-12 15:47:39,953:INFO:Creating metrics dataframe
2025-10-12 15:47:39,954:INFO:Uploading results into container
2025-10-12 15:47:39,955:INFO:Uploading model into container now
2025-10-12 15:47:39,956:INFO:_master_model_container: 16
2025-10-12 15:47:39,956:INFO:_display_container: 2
2025-10-12 15:47:39,956:INFO:DummyClassifier(constant=None, random_state=1760, strategy='prior')
2025-10-12 15:47:39,956:INFO:create_model() successfully completed......................................
2025-10-12 15:47:40,050:INFO:SubProcess create_model() end ==================================
2025-10-12 15:47:40,050:INFO:Creating metrics dataframe
2025-10-12 15:47:40,059:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 15:47:40,069:INFO:Initializing create_model()
2025-10-12 15:47:40,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:40,069:INFO:Checking exceptions
2025-10-12 15:47:40,070:INFO:Importing libraries
2025-10-12 15:47:40,072:INFO:Copying training dataset
2025-10-12 15:47:40,074:INFO:Defining folds
2025-10-12 15:47:40,074:INFO:Declaring metric variables
2025-10-12 15:47:40,074:INFO:Importing untrained model
2025-10-12 15:47:40,075:INFO:Declaring custom model
2025-10-12 15:47:40,075:INFO:Logistic Regression Imported successfully
2025-10-12 15:47:40,077:INFO:Cross validation set to False
2025-10-12 15:47:40,077:INFO:Fitting Model
2025-10-12 15:47:40,211:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:47:40,211:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:47:40,211:INFO:create_model() successfully completed......................................
2025-10-12 15:47:40,321:INFO:Creating Dashboard logs
2025-10-12 15:47:40,327:INFO:Model: Logistic Regression
2025-10-12 15:47:40,400:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1760, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 15:47:40,652:INFO:Initializing predict_model()
2025-10-12 15:47:40,652:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DB7CB940>)
2025-10-12 15:47:40,652:INFO:Checking exceptions
2025-10-12 15:47:40,652:INFO:Preloading libraries
2025-10-12 15:47:41,006:INFO:SubProcess plot_model() called ==================================
2025-10-12 15:47:41,006:INFO:Initializing plot_model()
2025-10-12 15:47:41,006:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmplitquecf, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:47:41,006:INFO:Checking exceptions
2025-10-12 15:47:41,007:INFO:Preloading libraries
2025-10-12 15:47:41,007:INFO:Copying training dataset
2025-10-12 15:47:41,008:INFO:Plot type: auc
2025-10-12 15:47:41,289:INFO:Fitting Model
2025-10-12 15:47:41,290:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:47:41,290:INFO:Scoring test/hold-out set
2025-10-12 15:47:41,306:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmplitquecf\AUC.png'
2025-10-12 15:47:41,510:INFO:Visual Rendered Successfully
2025-10-12 15:47:41,610:INFO:plot_model() successfully completed......................................
2025-10-12 15:47:41,645:INFO:Initializing plot_model()
2025-10-12 15:47:41,645:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmplitquecf, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:47:41,645:INFO:Checking exceptions
2025-10-12 15:47:41,647:INFO:Preloading libraries
2025-10-12 15:47:41,647:INFO:Copying training dataset
2025-10-12 15:47:41,647:INFO:Plot type: confusion_matrix
2025-10-12 15:47:41,968:INFO:Fitting Model
2025-10-12 15:47:41,968:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:47:41,968:INFO:Scoring test/hold-out set
2025-10-12 15:47:41,981:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmplitquecf\Confusion Matrix.png'
2025-10-12 15:47:42,092:INFO:Visual Rendered Successfully
2025-10-12 15:47:42,211:INFO:plot_model() successfully completed......................................
2025-10-12 15:47:42,229:INFO:Initializing plot_model()
2025-10-12 15:47:42,229:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmplitquecf, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:47:42,229:INFO:Checking exceptions
2025-10-12 15:47:42,232:INFO:Preloading libraries
2025-10-12 15:47:42,233:INFO:Copying training dataset
2025-10-12 15:47:42,233:INFO:Plot type: feature
2025-10-12 15:47:42,420:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmplitquecf\Feature Importance.png'
2025-10-12 15:47:42,538:INFO:Visual Rendered Successfully
2025-10-12 15:47:42,640:INFO:plot_model() successfully completed......................................
2025-10-12 15:47:42,664:INFO:SubProcess plot_model() end ==================================
2025-10-12 15:47:42,666:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml

2025-10-12 15:47:44,713:INFO:Creating Dashboard logs
2025-10-12 15:47:44,716:INFO:Model: Ridge Classifier
2025-10-12 15:47:44,811:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 1760, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 15:47:45,240:INFO:Creating Dashboard logs
2025-10-12 15:47:45,244:INFO:Model: Extra Trees Classifier
2025-10-12 15:47:45,322:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1760, 'verbose': 0, 'warm_start': False}
2025-10-12 15:47:45,736:INFO:Creating Dashboard logs
2025-10-12 15:47:45,738:INFO:Model: Naive Bayes
2025-10-12 15:47:45,818:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 15:47:46,215:INFO:Creating Dashboard logs
2025-10-12 15:47:46,218:INFO:Model: K Neighbors Classifier
2025-10-12 15:47:46,296:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 15:47:46,731:INFO:Creating Dashboard logs
2025-10-12 15:47:46,734:INFO:Model: Decision Tree Classifier
2025-10-12 15:47:46,802:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 1760, 'splitter': 'best'}
2025-10-12 15:47:47,203:INFO:Creating Dashboard logs
2025-10-12 15:47:47,207:INFO:Model: Random Forest Classifier
2025-10-12 15:47:47,281:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1760, 'verbose': 0, 'warm_start': False}
2025-10-12 15:47:47,778:INFO:Creating Dashboard logs
2025-10-12 15:47:47,781:INFO:Model: Ada Boost Classifier
2025-10-12 15:47:47,853:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 1760}
2025-10-12 15:47:48,217:INFO:Creating Dashboard logs
2025-10-12 15:47:48,225:INFO:Model: Gradient Boosting Classifier
2025-10-12 15:47:48,319:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1760, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 15:47:48,701:INFO:Creating Dashboard logs
2025-10-12 15:47:48,704:INFO:Model: Linear Discriminant Analysis
2025-10-12 15:47:48,765:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 15:47:49,108:INFO:Creating Dashboard logs
2025-10-12 15:47:49,112:INFO:Model: Extreme Gradient Boosting
2025-10-12 15:47:49,180:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 1760, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 15:47:49,586:INFO:Creating Dashboard logs
2025-10-12 15:47:49,588:INFO:Model: Light Gradient Boosting Machine
2025-10-12 15:47:49,657:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1760, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 15:47:50,031:INFO:Creating Dashboard logs
2025-10-12 15:47:50,034:INFO:Model: CatBoost Classifier
2025-10-12 15:47:50,100:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-10-12 15:47:50,100:INFO:Logged params: {}
2025-10-12 15:47:50,448:INFO:Creating Dashboard logs
2025-10-12 15:47:50,450:INFO:Model: Dummy Classifier
2025-10-12 15:47:50,514:INFO:Logged params: {'constant': None, 'random_state': 1760, 'strategy': 'prior'}
2025-10-12 15:47:50,841:INFO:Creating Dashboard logs
2025-10-12 15:47:50,845:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 15:47:50,925:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 15:47:51,302:INFO:Creating Dashboard logs
2025-10-12 15:47:51,305:INFO:Model: SVM - Linear Kernel
2025-10-12 15:47:51,375:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 1760, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 15:47:51,817:INFO:_master_model_container: 16
2025-10-12 15:47:51,817:INFO:_display_container: 2
2025-10-12 15:47:51,817:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:47:51,817:INFO:compare_models() successfully completed......................................
2025-10-12 15:47:54,307:INFO:Initializing finalize_model()
2025-10-12 15:47:54,308:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-12 15:47:54,308:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:47:54,311:INFO:Initializing create_model()
2025-10-12 15:47:54,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:47:54,312:INFO:Checking exceptions
2025-10-12 15:47:54,314:INFO:Importing libraries
2025-10-12 15:47:54,314:INFO:Copying training dataset
2025-10-12 15:47:54,314:INFO:Defining folds
2025-10-12 15:47:54,314:INFO:Declaring metric variables
2025-10-12 15:47:54,315:INFO:Importing untrained model
2025-10-12 15:47:54,315:INFO:Declaring custom model
2025-10-12 15:47:54,315:INFO:Logistic Regression Imported successfully
2025-10-12 15:47:54,316:INFO:Cross validation set to False
2025-10-12 15:47:54,316:INFO:Fitting Model
2025-10-12 15:47:55,013:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:47:55,030:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1760,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-10-12 15:47:55,030:INFO:create_model() successfully completed......................................
2025-10-12 15:47:55,137:INFO:Creating Dashboard logs
2025-10-12 15:47:55,138:INFO:Model: Logistic Regression
2025-10-12 15:47:55,212:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1760, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 15:47:55,365:INFO:SubProcess plot_model() called ==================================
2025-10-12 15:47:55,382:INFO:Initializing plot_model()
2025-10-12 15:47:55,382:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1760,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpk7gdjcfy, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:47:55,382:INFO:Checking exceptions
2025-10-12 15:47:55,384:INFO:Preloading libraries
2025-10-12 15:47:55,384:INFO:Copying training dataset
2025-10-12 15:47:55,384:INFO:Plot type: auc
2025-10-12 15:47:55,726:INFO:Fitting Model
2025-10-12 15:47:55,726:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:47:55,726:INFO:Scoring test/hold-out set
2025-10-12 15:47:55,748:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpk7gdjcfy\AUC.png'
2025-10-12 15:47:55,993:INFO:Visual Rendered Successfully
2025-10-12 15:47:56,101:INFO:plot_model() successfully completed......................................
2025-10-12 15:47:56,138:INFO:Initializing plot_model()
2025-10-12 15:47:56,138:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1760,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpk7gdjcfy, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:47:56,138:INFO:Checking exceptions
2025-10-12 15:47:56,139:INFO:Preloading libraries
2025-10-12 15:47:56,141:INFO:Copying training dataset
2025-10-12 15:47:56,141:INFO:Plot type: confusion_matrix
2025-10-12 15:47:56,505:INFO:Fitting Model
2025-10-12 15:47:56,505:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:47:56,505:INFO:Scoring test/hold-out set
2025-10-12 15:47:56,526:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpk7gdjcfy\Confusion Matrix.png'
2025-10-12 15:47:56,631:INFO:Visual Rendered Successfully
2025-10-12 15:47:56,751:INFO:plot_model() successfully completed......................................
2025-10-12 15:47:56,791:INFO:Initializing plot_model()
2025-10-12 15:47:56,791:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1760,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpk7gdjcfy, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:47:56,791:INFO:Checking exceptions
2025-10-12 15:47:56,793:INFO:Preloading libraries
2025-10-12 15:47:56,793:INFO:Copying training dataset
2025-10-12 15:47:56,793:INFO:Plot type: feature
2025-10-12 15:47:57,020:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpk7gdjcfy\Feature Importance.png'
2025-10-12 15:47:57,180:INFO:Visual Rendered Successfully
2025-10-12 15:47:57,300:INFO:plot_model() successfully completed......................................
2025-10-12 15:47:57,319:INFO:SubProcess plot_model() end ==================================
2025-10-12 15:47:57,522:INFO:_master_model_container: 16
2025-10-12 15:47:57,522:INFO:_display_container: 2
2025-10-12 15:47:57,539:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1760,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-10-12 15:47:57,539:INFO:finalize_model() successfully completed......................................
2025-10-12 15:47:57,689:INFO:Initializing save_model()
2025-10-12 15:47:57,689:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1760,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), model_name=Titanic_modelV1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 15:47:57,689:INFO:Adding model into prep_pipe
2025-10-12 15:47:57,689:WARNING:Only Model saved as it was a pipeline.
2025-10-12 15:47:57,701:INFO:Titanic_modelV1.pkl saved in current working directory
2025-10-12 15:47:57,715:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1760,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-10-12 15:47:57,715:INFO:save_model() successfully completed......................................
2025-10-12 15:49:02,814:INFO:Initializing tune_model()
2025-10-12 15:49:02,814:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>)
2025-10-12 15:49:02,814:INFO:Checking exceptions
2025-10-12 15:49:02,836:INFO:Copying training dataset
2025-10-12 15:49:02,839:INFO:Checking base model
2025-10-12 15:49:02,839:INFO:Base model : Logistic Regression
2025-10-12 15:49:02,843:INFO:Declaring metric variables
2025-10-12 15:49:02,846:INFO:Defining Hyperparameters
2025-10-12 15:49:02,958:INFO:Tuning with n_jobs=-1
2025-10-12 15:49:02,959:INFO:Initializing RandomizedSearchCV
2025-10-12 15:49:03,186:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,204:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,204:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,207:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,208:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,302:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,305:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,321:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,351:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,401:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,401:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,429:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,454:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,462:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,470:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,506:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,554:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,558:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,608:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,672:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,704:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,708:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,709:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,712:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,712:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,714:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,743:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,792:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,816:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,887:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,895:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,910:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,945:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,947:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:03,957:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,001:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,007:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,030:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,159:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,205:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,212:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,289:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,305:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,311:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,325:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,355:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,363:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,414:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,416:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,421:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,442:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,444:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,455:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,553:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,590:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,596:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,623:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,626:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,635:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,693:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,693:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,697:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,732:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,757:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,760:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,765:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,788:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,792:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,810:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,846:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,905:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,923:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,931:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,940:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,942:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:04,950:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,012:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,033:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,052:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,059:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,088:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,094:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,098:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,108:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,164:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,164:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,175:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,176:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,179:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,193:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,221:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 5.453}
2025-10-12 15:49:05,222:INFO:Hyperparameter search completed
2025-10-12 15:49:05,222:INFO:SubProcess create_model() called ==================================
2025-10-12 15:49:05,222:INFO:Initializing create_model()
2025-10-12 15:49:05,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D98C5100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 5.453})
2025-10-12 15:49:05,222:INFO:Checking exceptions
2025-10-12 15:49:05,222:INFO:Importing libraries
2025-10-12 15:49:05,223:INFO:Copying training dataset
2025-10-12 15:49:05,225:INFO:Defining folds
2025-10-12 15:49:05,225:INFO:Declaring metric variables
2025-10-12 15:49:05,228:INFO:Importing untrained model
2025-10-12 15:49:05,228:INFO:Declaring custom model
2025-10-12 15:49:05,232:INFO:Logistic Regression Imported successfully
2025-10-12 15:49:05,236:INFO:Starting cross validation
2025-10-12 15:49:05,238:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:49:05,423:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,441:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,463:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,472:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,473:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,474:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,475:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,475:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,483:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,495:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,533:INFO:Calculating mean and std
2025-10-12 15:49:05,535:INFO:Creating metrics dataframe
2025-10-12 15:49:05,538:INFO:Finalizing model
2025-10-12 15:49:05,639:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:05,642:INFO:Uploading results into container
2025-10-12 15:49:05,643:INFO:Uploading model into container now
2025-10-12 15:49:05,644:INFO:_master_model_container: 17
2025-10-12 15:49:05,644:INFO:_display_container: 3
2025-10-12 15:49:05,644:INFO:LogisticRegression(C=5.453, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:49:05,644:INFO:create_model() successfully completed......................................
2025-10-12 15:49:05,744:INFO:SubProcess create_model() end ==================================
2025-10-12 15:49:05,744:INFO:choose_better activated
2025-10-12 15:49:05,747:INFO:SubProcess create_model() called ==================================
2025-10-12 15:49:05,748:INFO:Initializing create_model()
2025-10-12 15:49:05,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:49:05,748:INFO:Checking exceptions
2025-10-12 15:49:05,750:INFO:Importing libraries
2025-10-12 15:49:05,750:INFO:Copying training dataset
2025-10-12 15:49:05,753:INFO:Defining folds
2025-10-12 15:49:05,753:INFO:Declaring metric variables
2025-10-12 15:49:05,753:INFO:Importing untrained model
2025-10-12 15:49:05,753:INFO:Declaring custom model
2025-10-12 15:49:05,754:INFO:Logistic Regression Imported successfully
2025-10-12 15:49:05,754:INFO:Starting cross validation
2025-10-12 15:49:05,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:49:05,929:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,944:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,946:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,966:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,966:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,967:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,969:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,969:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,985:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:05,990:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:06,031:INFO:Calculating mean and std
2025-10-12 15:49:06,031:INFO:Creating metrics dataframe
2025-10-12 15:49:06,033:INFO:Finalizing model
2025-10-12 15:49:06,127:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:06,127:INFO:Uploading results into container
2025-10-12 15:49:06,128:INFO:Uploading model into container now
2025-10-12 15:49:06,128:INFO:_master_model_container: 18
2025-10-12 15:49:06,128:INFO:_display_container: 4
2025-10-12 15:49:06,128:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:49:06,128:INFO:create_model() successfully completed......................................
2025-10-12 15:49:06,223:INFO:SubProcess create_model() end ==================================
2025-10-12 15:49:06,224:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8836
2025-10-12 15:49:06,224:INFO:LogisticRegression(C=5.453, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8937
2025-10-12 15:49:06,224:INFO:LogisticRegression(C=5.453, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-10-12 15:49:06,224:INFO:choose_better completed
2025-10-12 15:49:06,224:INFO:Creating Dashboard logs
2025-10-12 15:49:06,227:INFO:Model: Logistic Regression
2025-10-12 15:49:06,292:INFO:Logged params: {'C': 5.453, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1760, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 15:49:06,558:INFO:Initializing predict_model()
2025-10-12 15:49:06,558:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=5.453, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DA072700>)
2025-10-12 15:49:06,558:INFO:Checking exceptions
2025-10-12 15:49:06,558:INFO:Preloading libraries
2025-10-12 15:49:06,861:INFO:SubProcess plot_model() called ==================================
2025-10-12 15:49:06,862:INFO:Initializing plot_model()
2025-10-12 15:49:06,862:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=5.453, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpjp_odgt2, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:49:06,862:INFO:Checking exceptions
2025-10-12 15:49:06,863:INFO:Preloading libraries
2025-10-12 15:49:06,864:INFO:Copying training dataset
2025-10-12 15:49:06,864:INFO:Plot type: auc
2025-10-12 15:49:07,162:INFO:Fitting Model
2025-10-12 15:49:07,163:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:49:07,163:INFO:Scoring test/hold-out set
2025-10-12 15:49:07,174:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpjp_odgt2\AUC.png'
2025-10-12 15:49:07,326:INFO:Visual Rendered Successfully
2025-10-12 15:49:07,427:INFO:plot_model() successfully completed......................................
2025-10-12 15:49:07,447:INFO:Initializing plot_model()
2025-10-12 15:49:07,447:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=5.453, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpjp_odgt2, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:49:07,447:INFO:Checking exceptions
2025-10-12 15:49:07,449:INFO:Preloading libraries
2025-10-12 15:49:07,449:INFO:Copying training dataset
2025-10-12 15:49:07,449:INFO:Plot type: confusion_matrix
2025-10-12 15:49:07,713:INFO:Fitting Model
2025-10-12 15:49:07,713:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:49:07,713:INFO:Scoring test/hold-out set
2025-10-12 15:49:07,725:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpjp_odgt2\Confusion Matrix.png'
2025-10-12 15:49:07,809:INFO:Visual Rendered Successfully
2025-10-12 15:49:07,929:INFO:plot_model() successfully completed......................................
2025-10-12 15:49:07,948:INFO:Initializing plot_model()
2025-10-12 15:49:07,948:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=5.453, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpjp_odgt2, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:49:07,948:INFO:Checking exceptions
2025-10-12 15:49:07,950:INFO:Preloading libraries
2025-10-12 15:49:07,950:INFO:Copying training dataset
2025-10-12 15:49:07,950:INFO:Plot type: feature
2025-10-12 15:49:08,112:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpjp_odgt2\Feature Importance.png'
2025-10-12 15:49:08,236:INFO:Visual Rendered Successfully
2025-10-12 15:49:08,361:INFO:plot_model() successfully completed......................................
2025-10-12 15:49:08,382:INFO:SubProcess plot_model() end ==================================
2025-10-12 15:49:08,575:INFO:_master_model_container: 18
2025-10-12 15:49:08,575:INFO:_display_container: 3
2025-10-12 15:49:08,575:INFO:LogisticRegression(C=5.453, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:49:08,577:INFO:tune_model() successfully completed......................................
2025-10-12 15:49:27,713:INFO:Initializing tune_model()
2025-10-12 15:49:27,713:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>)
2025-10-12 15:49:27,713:INFO:Checking exceptions
2025-10-12 15:49:27,713:INFO:Soft dependency imported: optuna: 4.5.0
2025-10-12 15:49:27,835:INFO:Copying training dataset
2025-10-12 15:49:27,838:INFO:Checking base model
2025-10-12 15:49:27,838:INFO:Base model : Logistic Regression
2025-10-12 15:49:27,840:INFO:Declaring metric variables
2025-10-12 15:49:27,843:INFO:Defining Hyperparameters
2025-10-12 15:49:27,947:INFO:Tuning with n_jobs=-1
2025-10-12 15:49:27,948:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.

2025-10-12 15:49:27,948:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.

2025-10-12 15:49:27,948:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.

2025-10-12 15:49:27,948:INFO:Initializing optuna.integration.OptunaSearchCV
2025-10-12 15:49:27,961:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.

2025-10-12 15:49:29,824:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:29,830:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:29,903:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:29,906:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:29,958:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:30,019:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:30,038:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:30,048:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:30,051:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:30,543:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:31,834:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:31,896:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:31,929:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:32,039:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:32,059:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:32,111:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:32,139:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:32,173:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:32,252:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:32,530:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:33,929:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:33,944:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:33,951:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:34,028:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:34,183:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:34,215:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:34,243:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:34,246:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:34,597:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:34,632:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:35,971:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:36,044:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:36,060:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:36,089:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:36,117:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:36,283:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:36,409:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:36,512:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:36,556:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:36,639:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:38,029:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:38,058:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:38,080:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:38,129:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:38,141:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:38,300:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:38,545:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:38,604:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:38,658:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:38,772:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:40,083:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:40,116:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:40,122:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:40,247:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:40,351:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:40,364:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:40,435:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:40,666:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:40,688:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:40,765:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:42,040:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:42,152:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:42,209:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:42,218:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:42,250:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:42,468:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:42,593:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:42,705:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:42,709:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:42,783:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:44,083:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:44,146:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:44,162:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:44,282:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:44,398:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:44,613:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:44,655:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:44,739:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:44,749:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:44,756:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:46,120:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:46,158:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:46,159:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:46,303:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:46,434:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:46,624:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:46,674:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:46,681:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:46,822:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:47,004:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:48,143:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:48,210:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:48,226:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:48,257:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:48,281:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:48,377:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:48,414:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:48,451:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:48,453:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:48,503:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:48,522:INFO:best_params: {'actual_estimator__C': 3.8724114568242056, 'actual_estimator__class_weight': 'balanced'}
2025-10-12 15:49:48,523:INFO:Hyperparameter search completed
2025-10-12 15:49:48,523:INFO:SubProcess create_model() called ==================================
2025-10-12 15:49:48,523:INFO:Initializing create_model()
2025-10-12 15:49:48,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DA056550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'C': 3.8724114568242056, 'class_weight': 'balanced'})
2025-10-12 15:49:48,524:INFO:Checking exceptions
2025-10-12 15:49:48,524:INFO:Importing libraries
2025-10-12 15:49:48,524:INFO:Copying training dataset
2025-10-12 15:49:48,528:INFO:Defining folds
2025-10-12 15:49:48,528:INFO:Declaring metric variables
2025-10-12 15:49:48,530:INFO:Importing untrained model
2025-10-12 15:49:48,531:INFO:Declaring custom model
2025-10-12 15:49:48,533:INFO:Logistic Regression Imported successfully
2025-10-12 15:49:48,538:INFO:Starting cross validation
2025-10-12 15:49:48,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:49:48,719:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:48,725:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:48,729:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:48,732:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:48,738:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:48,741:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:48,742:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:48,750:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:48,750:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:48,766:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:48,805:INFO:Calculating mean and std
2025-10-12 15:49:48,806:INFO:Creating metrics dataframe
2025-10-12 15:49:48,810:INFO:Finalizing model
2025-10-12 15:49:48,904:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:48,908:INFO:Uploading results into container
2025-10-12 15:49:48,909:INFO:Uploading model into container now
2025-10-12 15:49:48,910:INFO:_master_model_container: 19
2025-10-12 15:49:48,910:INFO:_display_container: 4
2025-10-12 15:49:48,910:INFO:LogisticRegression(C=3.8724114568242056, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:49:48,910:INFO:create_model() successfully completed......................................
2025-10-12 15:49:49,011:INFO:SubProcess create_model() end ==================================
2025-10-12 15:49:49,011:INFO:choose_better activated
2025-10-12 15:49:49,014:INFO:SubProcess create_model() called ==================================
2025-10-12 15:49:49,015:INFO:Initializing create_model()
2025-10-12 15:49:49,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:49:49,015:INFO:Checking exceptions
2025-10-12 15:49:49,016:INFO:Importing libraries
2025-10-12 15:49:49,017:INFO:Copying training dataset
2025-10-12 15:49:49,019:INFO:Defining folds
2025-10-12 15:49:49,019:INFO:Declaring metric variables
2025-10-12 15:49:49,019:INFO:Importing untrained model
2025-10-12 15:49:49,019:INFO:Declaring custom model
2025-10-12 15:49:49,019:INFO:Logistic Regression Imported successfully
2025-10-12 15:49:49,020:INFO:Starting cross validation
2025-10-12 15:49:49,021:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:49:49,221:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:49,228:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:49,233:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:49,233:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:49,234:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:49,236:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:49,238:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:49,238:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:49,247:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:49,254:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:49:49,302:INFO:Calculating mean and std
2025-10-12 15:49:49,302:INFO:Creating metrics dataframe
2025-10-12 15:49:49,303:INFO:Finalizing model
2025-10-12 15:49:49,396:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:49:49,396:INFO:Uploading results into container
2025-10-12 15:49:49,397:INFO:Uploading model into container now
2025-10-12 15:49:49,397:INFO:_master_model_container: 20
2025-10-12 15:49:49,397:INFO:_display_container: 5
2025-10-12 15:49:49,397:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:49:49,397:INFO:create_model() successfully completed......................................
2025-10-12 15:49:49,492:INFO:SubProcess create_model() end ==================================
2025-10-12 15:49:49,492:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8836
2025-10-12 15:49:49,492:INFO:LogisticRegression(C=3.8724114568242056, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.894
2025-10-12 15:49:49,493:INFO:LogisticRegression(C=3.8724114568242056, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-10-12 15:49:49,493:INFO:choose_better completed
2025-10-12 15:49:49,493:INFO:Creating Dashboard logs
2025-10-12 15:49:49,495:INFO:Model: Logistic Regression
2025-10-12 15:49:49,560:INFO:Logged params: {'C': 3.8724114568242056, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1760, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 15:49:49,819:INFO:Initializing predict_model()
2025-10-12 15:49:49,819:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=3.8724114568242056, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265CEB3C0D0>)
2025-10-12 15:49:49,819:INFO:Checking exceptions
2025-10-12 15:49:49,819:INFO:Preloading libraries
2025-10-12 15:49:50,077:INFO:SubProcess plot_model() called ==================================
2025-10-12 15:49:50,077:INFO:Initializing plot_model()
2025-10-12 15:49:50,077:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=3.8724114568242056, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp3h1qasm2, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:49:50,077:INFO:Checking exceptions
2025-10-12 15:49:50,079:INFO:Preloading libraries
2025-10-12 15:49:50,079:INFO:Copying training dataset
2025-10-12 15:49:50,079:INFO:Plot type: auc
2025-10-12 15:49:50,328:INFO:Fitting Model
2025-10-12 15:49:50,329:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:49:50,329:INFO:Scoring test/hold-out set
2025-10-12 15:49:50,340:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp3h1qasm2\AUC.png'
2025-10-12 15:49:50,490:INFO:Visual Rendered Successfully
2025-10-12 15:49:50,589:INFO:plot_model() successfully completed......................................
2025-10-12 15:49:50,608:INFO:Initializing plot_model()
2025-10-12 15:49:50,608:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=3.8724114568242056, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp3h1qasm2, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:49:50,608:INFO:Checking exceptions
2025-10-12 15:49:50,610:INFO:Preloading libraries
2025-10-12 15:49:50,610:INFO:Copying training dataset
2025-10-12 15:49:50,610:INFO:Plot type: confusion_matrix
2025-10-12 15:49:50,845:INFO:Fitting Model
2025-10-12 15:49:50,845:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:49:50,845:INFO:Scoring test/hold-out set
2025-10-12 15:49:50,855:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp3h1qasm2\Confusion Matrix.png'
2025-10-12 15:49:50,926:INFO:Visual Rendered Successfully
2025-10-12 15:49:51,024:INFO:plot_model() successfully completed......................................
2025-10-12 15:49:51,040:INFO:Initializing plot_model()
2025-10-12 15:49:51,040:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=3.8724114568242056, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp3h1qasm2, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:49:51,040:INFO:Checking exceptions
2025-10-12 15:49:51,042:INFO:Preloading libraries
2025-10-12 15:49:51,043:INFO:Copying training dataset
2025-10-12 15:49:51,043:INFO:Plot type: feature
2025-10-12 15:49:51,177:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp3h1qasm2\Feature Importance.png'
2025-10-12 15:49:51,269:INFO:Visual Rendered Successfully
2025-10-12 15:49:51,370:INFO:plot_model() successfully completed......................................
2025-10-12 15:49:51,386:INFO:SubProcess plot_model() end ==================================
2025-10-12 15:49:51,584:INFO:_master_model_container: 20
2025-10-12 15:49:51,584:INFO:_display_container: 4
2025-10-12 15:49:51,584:INFO:LogisticRegression(C=3.8724114568242056, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:49:51,584:INFO:tune_model() successfully completed......................................
2025-10-12 15:50:21,079:INFO:Initializing ensemble_model()
2025-10-12 15:50:21,079:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), method=Bagging, fold=None, n_estimators=5, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 15:50:21,079:INFO:Checking exceptions
2025-10-12 15:50:21,093:INFO:Importing libraries
2025-10-12 15:50:21,093:INFO:Copying training dataset
2025-10-12 15:50:21,093:INFO:Checking base model
2025-10-12 15:50:21,093:INFO:Base model : Logistic Regression
2025-10-12 15:50:21,100:INFO:Importing untrained ensembler
2025-10-12 15:50:21,101:INFO:Ensemble method set to Bagging
2025-10-12 15:50:21,101:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:21,102:INFO:Initializing create_model()
2025-10-12 15:50:21,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=1760,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=1760, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB327610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:21,102:INFO:Checking exceptions
2025-10-12 15:50:21,102:INFO:Importing libraries
2025-10-12 15:50:21,102:INFO:Copying training dataset
2025-10-12 15:50:21,105:INFO:Defining folds
2025-10-12 15:50:21,105:INFO:Declaring metric variables
2025-10-12 15:50:21,107:INFO:Importing untrained model
2025-10-12 15:50:21,107:INFO:Declaring custom model
2025-10-12 15:50:21,111:INFO:Logistic Regression Imported successfully
2025-10-12 15:50:21,120:INFO:Starting cross validation
2025-10-12 15:50:21,122:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:21,276:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,301:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,310:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,314:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,319:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,346:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,350:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,353:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,372:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,389:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,410:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,416:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,416:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,418:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,440:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,460:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,465:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,473:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,505:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,509:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,514:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,522:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,534:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,550:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,570:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,572:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,572:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,589:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,599:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,601:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,609:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,630:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,655:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,669:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,671:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,679:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,685:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,690:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,706:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,729:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,729:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,747:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,763:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,771:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,775:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,775:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,786:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,788:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,809:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,862:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:21,902:INFO:Calculating mean and std
2025-10-12 15:50:21,902:INFO:Creating metrics dataframe
2025-10-12 15:50:21,906:INFO:Finalizing model
2025-10-12 15:50:22,026:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:50:22,086:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:50:22,153:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:50:22,211:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:50:22,266:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:50:22,273:INFO:Uploading results into container
2025-10-12 15:50:22,274:INFO:Uploading model into container now
2025-10-12 15:50:22,275:INFO:_master_model_container: 21
2025-10-12 15:50:22,276:INFO:_display_container: 5
2025-10-12 15:50:22,278:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=1760,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=1760, verbose=0,
                  warm_start=False)
2025-10-12 15:50:22,278:INFO:create_model() successfully completed......................................
2025-10-12 15:50:22,385:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:22,385:INFO:Creating Dashboard logs
2025-10-12 15:50:22,388:INFO:Model: Logistic Regression
2025-10-12 15:50:22,462:INFO:Logged params: {'bootstrap': True, 'bootstrap_features': False, 'estimator__C': 1.0, 'estimator__class_weight': None, 'estimator__dual': False, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__l1_ratio': None, 'estimator__max_iter': 1000, 'estimator__multi_class': 'auto', 'estimator__n_jobs': None, 'estimator__penalty': 'l2', 'estimator__random_state': 1760, 'estimator__solver': 'lbfgs', 'estimator__tol': 0.0001, 'estimator__verbose': 0, 'estimator__warm_start': False, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 5, 'n_jobs': None, 'oob_score': False, 'random_state': 1760, 'verbose': 0, 'warm_start': False}
2025-10-12 15:50:22,752:INFO:Initializing predict_model()
2025-10-12 15:50:22,752:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=1760,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=1760, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265CEB5CDC0>)
2025-10-12 15:50:22,752:INFO:Checking exceptions
2025-10-12 15:50:22,752:INFO:Preloading libraries
2025-10-12 15:50:23,013:INFO:SubProcess plot_model() called ==================================
2025-10-12 15:50:23,013:INFO:Initializing plot_model()
2025-10-12 15:50:23,014:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=1760,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=1760, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp0bj__nqd, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:23,014:INFO:Checking exceptions
2025-10-12 15:50:23,015:INFO:Preloading libraries
2025-10-12 15:50:23,015:INFO:Copying training dataset
2025-10-12 15:50:23,015:INFO:Plot type: auc
2025-10-12 15:50:23,272:INFO:Fitting Model
2025-10-12 15:50:23,273:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 15:50:23,273:INFO:Scoring test/hold-out set
2025-10-12 15:50:23,295:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp0bj__nqd\AUC.png'
2025-10-12 15:50:23,453:INFO:Visual Rendered Successfully
2025-10-12 15:50:23,562:INFO:plot_model() successfully completed......................................
2025-10-12 15:50:23,577:INFO:Initializing plot_model()
2025-10-12 15:50:23,578:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=1760,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=1760, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp0bj__nqd, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:23,578:INFO:Checking exceptions
2025-10-12 15:50:23,578:INFO:Preloading libraries
2025-10-12 15:50:23,578:INFO:Copying training dataset
2025-10-12 15:50:23,580:INFO:Plot type: confusion_matrix
2025-10-12 15:50:23,847:INFO:Fitting Model
2025-10-12 15:50:23,848:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 15:50:23,848:INFO:Scoring test/hold-out set
2025-10-12 15:50:23,858:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp0bj__nqd\Confusion Matrix.png'
2025-10-12 15:50:23,946:INFO:Visual Rendered Successfully
2025-10-12 15:50:24,045:INFO:plot_model() successfully completed......................................
2025-10-12 15:50:24,069:INFO:Initializing plot_model()
2025-10-12 15:50:24,069:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=1760,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=1760, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp0bj__nqd, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:24,069:INFO:Checking exceptions
2025-10-12 15:50:24,070:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 15:50:24,070:INFO:SubProcess plot_model() end ==================================
2025-10-12 15:50:24,252:INFO:_master_model_container: 21
2025-10-12 15:50:24,252:INFO:_display_container: 5
2025-10-12 15:50:24,253:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=1760,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=1760, verbose=0,
                  warm_start=False)
2025-10-12 15:50:24,253:INFO:ensemble_model() successfully completed......................................
2025-10-12 15:50:24,356:INFO:Initializing predict_model()
2025-10-12 15:50:24,356:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=1760,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=1760, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265D9693700>)
2025-10-12 15:50:24,356:INFO:Checking exceptions
2025-10-12 15:50:24,356:INFO:Preloading libraries
2025-10-12 15:50:42,971:INFO:Initializing create_model()
2025-10-12 15:50:42,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:42,971:INFO:Checking exceptions
2025-10-12 15:50:42,988:INFO:Importing libraries
2025-10-12 15:50:42,988:INFO:Copying training dataset
2025-10-12 15:50:42,995:INFO:Defining folds
2025-10-12 15:50:42,995:INFO:Declaring metric variables
2025-10-12 15:50:42,999:INFO:Importing untrained model
2025-10-12 15:50:43,002:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 15:50:43,009:INFO:Starting cross validation
2025-10-12 15:50:43,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:43,143:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:43,145:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:43,146:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:43,150:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:43,154:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:43,154:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:43,156:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:43,165:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:43,165:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:43,165:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:43,179:INFO:Calculating mean and std
2025-10-12 15:50:43,179:INFO:Creating metrics dataframe
2025-10-12 15:50:43,182:INFO:Finalizing model
2025-10-12 15:50:43,234:INFO:Creating Dashboard logs
2025-10-12 15:50:43,236:INFO:Model: Linear Discriminant Analysis
2025-10-12 15:50:43,300:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 15:50:43,475:INFO:Initializing predict_model()
2025-10-12 15:50:43,475:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265CE9D0B80>)
2025-10-12 15:50:43,475:INFO:Checking exceptions
2025-10-12 15:50:43,475:INFO:Preloading libraries
2025-10-12 15:50:43,638:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-12 15:50:43,767:INFO:SubProcess plot_model() called ==================================
2025-10-12 15:50:43,768:INFO:Initializing plot_model()
2025-10-12 15:50:43,768:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpcih0ovba, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:43,768:INFO:Checking exceptions
2025-10-12 15:50:43,769:INFO:Preloading libraries
2025-10-12 15:50:43,770:INFO:Copying training dataset
2025-10-12 15:50:43,770:INFO:Plot type: auc
2025-10-12 15:50:44,052:INFO:Fitting Model
2025-10-12 15:50:44,053:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 15:50:44,053:INFO:Scoring test/hold-out set
2025-10-12 15:50:44,069:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpcih0ovba\AUC.png'
2025-10-12 15:50:44,238:INFO:Visual Rendered Successfully
2025-10-12 15:50:44,341:INFO:plot_model() successfully completed......................................
2025-10-12 15:50:44,356:INFO:Initializing plot_model()
2025-10-12 15:50:44,356:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpcih0ovba, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:44,356:INFO:Checking exceptions
2025-10-12 15:50:44,358:INFO:Preloading libraries
2025-10-12 15:50:44,358:INFO:Copying training dataset
2025-10-12 15:50:44,358:INFO:Plot type: confusion_matrix
2025-10-12 15:50:44,622:INFO:Fitting Model
2025-10-12 15:50:44,622:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 15:50:44,623:INFO:Scoring test/hold-out set
2025-10-12 15:50:44,635:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpcih0ovba\Confusion Matrix.png'
2025-10-12 15:50:44,715:INFO:Visual Rendered Successfully
2025-10-12 15:50:44,820:INFO:plot_model() successfully completed......................................
2025-10-12 15:50:44,836:INFO:Initializing plot_model()
2025-10-12 15:50:44,836:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpcih0ovba, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:44,836:INFO:Checking exceptions
2025-10-12 15:50:44,838:INFO:Preloading libraries
2025-10-12 15:50:44,838:INFO:Copying training dataset
2025-10-12 15:50:44,838:INFO:Plot type: feature
2025-10-12 15:50:44,977:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpcih0ovba\Feature Importance.png'
2025-10-12 15:50:45,078:INFO:Visual Rendered Successfully
2025-10-12 15:50:45,184:INFO:plot_model() successfully completed......................................
2025-10-12 15:50:45,199:INFO:SubProcess plot_model() end ==================================
2025-10-12 15:50:45,382:INFO:Uploading results into container
2025-10-12 15:50:45,382:INFO:Uploading model into container now
2025-10-12 15:50:45,390:INFO:_master_model_container: 22
2025-10-12 15:50:45,390:INFO:_display_container: 7
2025-10-12 15:50:45,390:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 15:50:45,390:INFO:create_model() successfully completed......................................
2025-10-12 15:50:45,512:INFO:Initializing create_model()
2025-10-12 15:50:45,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=ridge, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:45,512:INFO:Checking exceptions
2025-10-12 15:50:45,524:INFO:Importing libraries
2025-10-12 15:50:45,524:INFO:Copying training dataset
2025-10-12 15:50:45,527:INFO:Defining folds
2025-10-12 15:50:45,529:INFO:Declaring metric variables
2025-10-12 15:50:45,531:INFO:Importing untrained model
2025-10-12 15:50:45,534:INFO:Ridge Classifier Imported successfully
2025-10-12 15:50:45,540:INFO:Starting cross validation
2025-10-12 15:50:45,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:45,727:INFO:Calculating mean and std
2025-10-12 15:50:45,728:INFO:Creating metrics dataframe
2025-10-12 15:50:45,731:INFO:Finalizing model
2025-10-12 15:50:45,786:INFO:Creating Dashboard logs
2025-10-12 15:50:45,789:INFO:Model: Ridge Classifier
2025-10-12 15:50:45,859:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 1760, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 15:50:46,091:INFO:Initializing predict_model()
2025-10-12 15:50:46,091:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1760, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265CEAEBB80>)
2025-10-12 15:50:46,091:INFO:Checking exceptions
2025-10-12 15:50:46,091:INFO:Preloading libraries
2025-10-12 15:50:46,366:INFO:SubProcess plot_model() called ==================================
2025-10-12 15:50:46,366:INFO:Initializing plot_model()
2025-10-12 15:50:46,366:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1760, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpgqqhvlr3, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:46,366:INFO:Checking exceptions
2025-10-12 15:50:46,367:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 15:50:46,367:INFO:Initializing plot_model()
2025-10-12 15:50:46,367:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1760, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpgqqhvlr3, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:46,367:INFO:Checking exceptions
2025-10-12 15:50:46,369:INFO:Preloading libraries
2025-10-12 15:50:46,369:INFO:Copying training dataset
2025-10-12 15:50:46,369:INFO:Plot type: confusion_matrix
2025-10-12 15:50:46,640:INFO:Fitting Model
2025-10-12 15:50:46,640:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names

2025-10-12 15:50:46,640:INFO:Scoring test/hold-out set
2025-10-12 15:50:46,651:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpgqqhvlr3\Confusion Matrix.png'
2025-10-12 15:50:46,725:INFO:Visual Rendered Successfully
2025-10-12 15:50:46,832:INFO:plot_model() successfully completed......................................
2025-10-12 15:50:46,854:INFO:Initializing plot_model()
2025-10-12 15:50:46,854:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1760, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpgqqhvlr3, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:46,854:INFO:Checking exceptions
2025-10-12 15:50:46,856:INFO:Preloading libraries
2025-10-12 15:50:46,858:INFO:Copying training dataset
2025-10-12 15:50:46,858:INFO:Plot type: feature
2025-10-12 15:50:47,006:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpgqqhvlr3\Feature Importance.png'
2025-10-12 15:50:47,104:INFO:Visual Rendered Successfully
2025-10-12 15:50:47,216:INFO:plot_model() successfully completed......................................
2025-10-12 15:50:47,234:INFO:SubProcess plot_model() end ==================================
2025-10-12 15:50:47,421:INFO:Uploading results into container
2025-10-12 15:50:47,422:INFO:Uploading model into container now
2025-10-12 15:50:47,430:INFO:_master_model_container: 23
2025-10-12 15:50:47,430:INFO:_display_container: 8
2025-10-12 15:50:47,430:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1760, solver='auto',
                tol=0.0001)
2025-10-12 15:50:47,430:INFO:create_model() successfully completed......................................
2025-10-12 15:50:47,538:INFO:Initializing create_model()
2025-10-12 15:50:47,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:47,540:INFO:Checking exceptions
2025-10-12 15:50:47,550:INFO:Importing libraries
2025-10-12 15:50:47,550:INFO:Copying training dataset
2025-10-12 15:50:47,553:INFO:Defining folds
2025-10-12 15:50:47,553:INFO:Declaring metric variables
2025-10-12 15:50:47,556:INFO:Importing untrained model
2025-10-12 15:50:47,560:INFO:Logistic Regression Imported successfully
2025-10-12 15:50:47,566:INFO:Starting cross validation
2025-10-12 15:50:47,568:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:47,763:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:47,775:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:47,778:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:47,781:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:47,821:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:47,838:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:47,839:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:47,839:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:47,843:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:47,848:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:47,907:INFO:Calculating mean and std
2025-10-12 15:50:47,907:INFO:Creating metrics dataframe
2025-10-12 15:50:47,912:INFO:Finalizing model
2025-10-12 15:50:48,012:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:50:48,013:INFO:Creating Dashboard logs
2025-10-12 15:50:48,016:INFO:Model: Logistic Regression
2025-10-12 15:50:48,090:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1760, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 15:50:48,345:INFO:Initializing predict_model()
2025-10-12 15:50:48,346:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265CEB463A0>)
2025-10-12 15:50:48,346:INFO:Checking exceptions
2025-10-12 15:50:48,346:INFO:Preloading libraries
2025-10-12 15:50:48,610:INFO:SubProcess plot_model() called ==================================
2025-10-12 15:50:48,610:INFO:Initializing plot_model()
2025-10-12 15:50:48,611:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpekr25sbr, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:48,611:INFO:Checking exceptions
2025-10-12 15:50:48,612:INFO:Preloading libraries
2025-10-12 15:50:48,612:INFO:Copying training dataset
2025-10-12 15:50:48,612:INFO:Plot type: auc
2025-10-12 15:50:48,871:INFO:Fitting Model
2025-10-12 15:50:48,871:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:50:48,871:INFO:Scoring test/hold-out set
2025-10-12 15:50:48,884:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpekr25sbr\AUC.png'
2025-10-12 15:50:49,021:INFO:Visual Rendered Successfully
2025-10-12 15:50:49,124:INFO:plot_model() successfully completed......................................
2025-10-12 15:50:49,140:INFO:Initializing plot_model()
2025-10-12 15:50:49,140:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpekr25sbr, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:49,140:INFO:Checking exceptions
2025-10-12 15:50:49,141:INFO:Preloading libraries
2025-10-12 15:50:49,141:INFO:Copying training dataset
2025-10-12 15:50:49,141:INFO:Plot type: confusion_matrix
2025-10-12 15:50:49,382:INFO:Fitting Model
2025-10-12 15:50:49,383:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:50:49,383:INFO:Scoring test/hold-out set
2025-10-12 15:50:49,394:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpekr25sbr\Confusion Matrix.png'
2025-10-12 15:50:49,466:INFO:Visual Rendered Successfully
2025-10-12 15:50:49,572:INFO:plot_model() successfully completed......................................
2025-10-12 15:50:49,590:INFO:Initializing plot_model()
2025-10-12 15:50:49,590:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpekr25sbr, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:49,590:INFO:Checking exceptions
2025-10-12 15:50:49,592:INFO:Preloading libraries
2025-10-12 15:50:49,592:INFO:Copying training dataset
2025-10-12 15:50:49,592:INFO:Plot type: feature
2025-10-12 15:50:49,724:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpekr25sbr\Feature Importance.png'
2025-10-12 15:50:49,837:INFO:Visual Rendered Successfully
2025-10-12 15:50:49,941:INFO:plot_model() successfully completed......................................
2025-10-12 15:50:49,965:INFO:SubProcess plot_model() end ==================================
2025-10-12 15:50:50,144:INFO:Uploading results into container
2025-10-12 15:50:50,145:INFO:Uploading model into container now
2025-10-12 15:50:50,162:INFO:_master_model_container: 24
2025-10-12 15:50:50,162:INFO:_display_container: 9
2025-10-12 15:50:50,162:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:50:50,162:INFO:create_model() successfully completed......................................
2025-10-12 15:50:50,267:INFO:Initializing blend_models()
2025-10-12 15:50:50,267:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator_list=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1760, solver='auto',
                tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 15:50:50,268:INFO:Checking exceptions
2025-10-12 15:50:50,268:INFO:Estimator RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1760, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-12 15:50:50,280:INFO:Importing libraries
2025-10-12 15:50:50,280:INFO:Copying training dataset
2025-10-12 15:50:50,283:INFO:Getting model names
2025-10-12 15:50:50,288:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:50,291:INFO:Initializing create_model()
2025-10-12 15:50:50,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CEAFFCA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:50,291:INFO:Checking exceptions
2025-10-12 15:50:50,291:INFO:Importing libraries
2025-10-12 15:50:50,291:INFO:Copying training dataset
2025-10-12 15:50:50,295:INFO:Defining folds
2025-10-12 15:50:50,295:INFO:Declaring metric variables
2025-10-12 15:50:50,299:INFO:Importing untrained model
2025-10-12 15:50:50,299:INFO:Declaring custom model
2025-10-12 15:50:50,303:INFO:Voting Classifier Imported successfully
2025-10-12 15:50:50,310:INFO:Starting cross validation
2025-10-12 15:50:50,311:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:50,735:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:50,746:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:50,756:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:50,793:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:50,798:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:50,799:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:50,800:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:50,804:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:50,835:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 15:50:50,835:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 15:50:50,835:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 15:50:50,835:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 15:50:50,836:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 15:50:50,851:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 15:50:50,854:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 15:50:50,854:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 15:50:50,855:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 15:50:50,856:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:50,885:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 15:50:50,892:INFO:Calculating mean and std
2025-10-12 15:50:50,892:INFO:Creating metrics dataframe
2025-10-12 15:50:50,896:INFO:Finalizing model
2025-10-12 15:50:50,998:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:50,999:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:51,005:INFO:Uploading results into container
2025-10-12 15:50:51,006:INFO:Uploading model into container now
2025-10-12 15:50:51,006:INFO:_master_model_container: 25
2025-10-12 15:50:51,006:INFO:_display_container: 10
2025-10-12 15:50:51,009:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 15:50:51,009:INFO:create_model() successfully completed......................................
2025-10-12 15:50:51,110:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:51,110:INFO:Creating Dashboard logs
2025-10-12 15:50:51,113:INFO:Model: Voting Classifier
2025-10-12 15:50:51,210:INFO:Logged params: {'flatten_transform': True, 'n_jobs': -1, 'verbose': False, 'voting': 'hard', 'weights': None, 'Linear Discriminant Analysis': LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), 'Ridge Classifier': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1760, solver='auto',
                tol=0.0001), 'Logistic Regression__C': 1.0, 'Logistic Regression__class_weight': None, 'Logistic Regression__dual': False, 'Logistic Regression__fit_intercept': True, 'Logistic Regression__intercept_scaling': 1, 'Logistic Regression__l1_ratio': None, 'Logistic Regression__max_iter': 1000, 'Logistic Regression__multi_class': 'auto', 'Logistic Regression__n_jobs': None, 'Logistic Regression__penalty': 'l2', 'Logistic Regression__random_state': 1760, 'Logistic Regression__solver': 'lbfgs', 'Logistic Regression__tol': 0.0001, 'Logistic Regression__verbose': 0, 'Logistic Regression__warm_start': False, 'Linear Discriminant Analysis__covariance_estimator': None, 'Linear Discriminant Analysis__n_components': None, 'Linear Discriminant Analysis__priors': None, 'Linear Discriminant Analysis__shrinkage': None, 'Linear Discriminant Analysis__solver': 'svd', 'Linear Discriminant Analysis__store_covariance': False, 'Linear Discriminant Analysis__tol': 0.0001, 'Ridge Classifier__alpha': 1.0, 'Ridge Classifier__class_weight': None, 'Ridge Classifier__copy_X': True, 'Ridge Classifier__fit_intercept': True, 'Ridge Classifier__max_iter': None, 'Ridge Classifier__positive': False, 'Ridge Classifier__random_state': 1760, 'Ridge Classifier__solver': 'auto', 'Ridge Classifier__tol': 0.0001, 'Logistic Regression_1__C': 1.0, 'Logistic Regression_1__class_weight': None, 'Logistic Regression_1__dual': False, 'Logistic Regression_1__fit_intercept': True, 'Logistic Regression_1__intercept_scaling': 1, 'Logistic Regression_1__l1_ratio': None, 'Logistic Regression_1__max_iter': 1000, 'Logistic Regression_1__multi_class': 'auto', 'Logistic Regression_1__n_jobs': None, 'Logistic Regression_1__penalty': 'l2', 'Logistic Regression_1__random_state': 1760, 'Logistic Regression_1__solver': 'lbfgs', 'Logistic Regression_1__tol': 0.0001, 'Logistic Regression_1__verbose': 0, 'Logistic Regression_1__warm_start': False}
2025-10-12 15:50:51,538:INFO:Initializing predict_model()
2025-10-12 15:50:51,538:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265CEDB2790>)
2025-10-12 15:50:51,538:INFO:Checking exceptions
2025-10-12 15:50:51,538:INFO:Preloading libraries
2025-10-12 15:50:51,839:INFO:SubProcess plot_model() called ==================================
2025-10-12 15:50:51,841:INFO:Initializing plot_model()
2025-10-12 15:50:51,841:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpd21rbby6, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:51,841:INFO:Checking exceptions
2025-10-12 15:50:51,842:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 15:50:51,844:INFO:Initializing plot_model()
2025-10-12 15:50:51,844:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpd21rbby6, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:51,844:INFO:Checking exceptions
2025-10-12 15:50:51,845:INFO:Preloading libraries
2025-10-12 15:50:51,846:INFO:Copying training dataset
2025-10-12 15:50:51,846:INFO:Plot type: confusion_matrix
2025-10-12 15:50:52,177:INFO:Fitting Model
2025-10-12 15:50:52,178:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:50:52,178:INFO:Scoring test/hold-out set
2025-10-12 15:50:52,202:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpd21rbby6\Confusion Matrix.png'
2025-10-12 15:50:52,314:INFO:Visual Rendered Successfully
2025-10-12 15:50:52,431:INFO:plot_model() successfully completed......................................
2025-10-12 15:50:52,451:INFO:Initializing plot_model()
2025-10-12 15:50:52,451:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpd21rbby6, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:50:52,451:INFO:Checking exceptions
2025-10-12 15:50:52,451:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 15:50:52,451:INFO:SubProcess plot_model() end ==================================
2025-10-12 15:50:52,652:INFO:_master_model_container: 25
2025-10-12 15:50:52,652:INFO:_display_container: 10
2025-10-12 15:50:52,656:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=1760,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 15:50:52,657:INFO:blend_models() successfully completed......................................
2025-10-12 15:50:52,787:INFO:Initializing compare_models()
2025-10-12 15:50:52,788:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 15:50:52,788:INFO:Checking exceptions
2025-10-12 15:50:52,789:INFO:Preparing display monitor
2025-10-12 15:50:52,814:INFO:Initializing Logistic Regression
2025-10-12 15:50:52,815:INFO:Total runtime is 1.6808509826660156e-05 minutes
2025-10-12 15:50:52,820:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:52,820:INFO:Initializing create_model()
2025-10-12 15:50:52,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:52,820:INFO:Checking exceptions
2025-10-12 15:50:52,820:INFO:Importing libraries
2025-10-12 15:50:52,821:INFO:Copying training dataset
2025-10-12 15:50:52,825:INFO:Defining folds
2025-10-12 15:50:52,825:INFO:Declaring metric variables
2025-10-12 15:50:52,831:INFO:Importing untrained model
2025-10-12 15:50:52,836:INFO:Logistic Regression Imported successfully
2025-10-12 15:50:52,843:INFO:Starting cross validation
2025-10-12 15:50:52,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:53,049:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:53,051:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:53,057:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:53,069:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:53,138:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:53,146:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:53,151:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:53,152:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:53,154:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:53,166:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 15:50:53,212:INFO:Calculating mean and std
2025-10-12 15:50:53,212:INFO:Creating metrics dataframe
2025-10-12 15:50:53,214:INFO:Uploading results into container
2025-10-12 15:50:53,214:INFO:Uploading model into container now
2025-10-12 15:50:53,214:INFO:_master_model_container: 26
2025-10-12 15:50:53,214:INFO:_display_container: 11
2025-10-12 15:50:53,215:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:50:53,215:INFO:create_model() successfully completed......................................
2025-10-12 15:50:53,318:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:53,318:INFO:Creating metrics dataframe
2025-10-12 15:50:53,324:INFO:Initializing K Neighbors Classifier
2025-10-12 15:50:53,324:INFO:Total runtime is 0.008502097924550374 minutes
2025-10-12 15:50:53,326:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:53,328:INFO:Initializing create_model()
2025-10-12 15:50:53,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:53,328:INFO:Checking exceptions
2025-10-12 15:50:53,328:INFO:Importing libraries
2025-10-12 15:50:53,328:INFO:Copying training dataset
2025-10-12 15:50:53,330:INFO:Defining folds
2025-10-12 15:50:53,330:INFO:Declaring metric variables
2025-10-12 15:50:53,333:INFO:Importing untrained model
2025-10-12 15:50:53,336:INFO:K Neighbors Classifier Imported successfully
2025-10-12 15:50:53,342:INFO:Starting cross validation
2025-10-12 15:50:53,344:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:53,557:INFO:Calculating mean and std
2025-10-12 15:50:53,557:INFO:Creating metrics dataframe
2025-10-12 15:50:53,559:INFO:Uploading results into container
2025-10-12 15:50:53,559:INFO:Uploading model into container now
2025-10-12 15:50:53,559:INFO:_master_model_container: 27
2025-10-12 15:50:53,559:INFO:_display_container: 11
2025-10-12 15:50:53,559:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 15:50:53,559:INFO:create_model() successfully completed......................................
2025-10-12 15:50:53,660:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:53,660:INFO:Creating metrics dataframe
2025-10-12 15:50:53,664:INFO:Initializing Naive Bayes
2025-10-12 15:50:53,664:INFO:Total runtime is 0.01416776974995931 minutes
2025-10-12 15:50:53,666:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:53,668:INFO:Initializing create_model()
2025-10-12 15:50:53,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:53,668:INFO:Checking exceptions
2025-10-12 15:50:53,668:INFO:Importing libraries
2025-10-12 15:50:53,668:INFO:Copying training dataset
2025-10-12 15:50:53,670:INFO:Defining folds
2025-10-12 15:50:53,670:INFO:Declaring metric variables
2025-10-12 15:50:53,672:INFO:Importing untrained model
2025-10-12 15:50:53,674:INFO:Naive Bayes Imported successfully
2025-10-12 15:50:53,680:INFO:Starting cross validation
2025-10-12 15:50:53,682:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:53,852:INFO:Calculating mean and std
2025-10-12 15:50:53,853:INFO:Creating metrics dataframe
2025-10-12 15:50:53,854:INFO:Uploading results into container
2025-10-12 15:50:53,855:INFO:Uploading model into container now
2025-10-12 15:50:53,855:INFO:_master_model_container: 28
2025-10-12 15:50:53,855:INFO:_display_container: 11
2025-10-12 15:50:53,855:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 15:50:53,855:INFO:create_model() successfully completed......................................
2025-10-12 15:50:53,960:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:53,960:INFO:Creating metrics dataframe
2025-10-12 15:50:53,965:INFO:Initializing Decision Tree Classifier
2025-10-12 15:50:53,965:INFO:Total runtime is 0.019185288747151693 minutes
2025-10-12 15:50:53,969:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:53,969:INFO:Initializing create_model()
2025-10-12 15:50:53,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:53,969:INFO:Checking exceptions
2025-10-12 15:50:53,969:INFO:Importing libraries
2025-10-12 15:50:53,969:INFO:Copying training dataset
2025-10-12 15:50:53,972:INFO:Defining folds
2025-10-12 15:50:53,972:INFO:Declaring metric variables
2025-10-12 15:50:53,975:INFO:Importing untrained model
2025-10-12 15:50:53,979:INFO:Decision Tree Classifier Imported successfully
2025-10-12 15:50:53,984:INFO:Starting cross validation
2025-10-12 15:50:53,985:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:54,108:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:54,118:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:54,132:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:54,133:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:54,133:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:54,135:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:54,136:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:54,138:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:54,140:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:54,143:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:54,162:INFO:Calculating mean and std
2025-10-12 15:50:54,164:INFO:Creating metrics dataframe
2025-10-12 15:50:54,166:INFO:Uploading results into container
2025-10-12 15:50:54,166:INFO:Uploading model into container now
2025-10-12 15:50:54,167:INFO:_master_model_container: 29
2025-10-12 15:50:54,167:INFO:_display_container: 11
2025-10-12 15:50:54,167:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1760, splitter='best')
2025-10-12 15:50:54,169:INFO:create_model() successfully completed......................................
2025-10-12 15:50:54,271:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:54,271:INFO:Creating metrics dataframe
2025-10-12 15:50:54,277:INFO:Initializing SVM - Linear Kernel
2025-10-12 15:50:54,277:INFO:Total runtime is 0.024378907680511475 minutes
2025-10-12 15:50:54,279:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:54,280:INFO:Initializing create_model()
2025-10-12 15:50:54,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:54,280:INFO:Checking exceptions
2025-10-12 15:50:54,280:INFO:Importing libraries
2025-10-12 15:50:54,280:INFO:Copying training dataset
2025-10-12 15:50:54,283:INFO:Defining folds
2025-10-12 15:50:54,283:INFO:Declaring metric variables
2025-10-12 15:50:54,285:INFO:Importing untrained model
2025-10-12 15:50:54,288:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 15:50:54,292:INFO:Starting cross validation
2025-10-12 15:50:54,293:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:54,459:INFO:Calculating mean and std
2025-10-12 15:50:54,460:INFO:Creating metrics dataframe
2025-10-12 15:50:54,461:INFO:Uploading results into container
2025-10-12 15:50:54,461:INFO:Uploading model into container now
2025-10-12 15:50:54,462:INFO:_master_model_container: 30
2025-10-12 15:50:54,462:INFO:_display_container: 11
2025-10-12 15:50:54,462:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1760, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 15:50:54,462:INFO:create_model() successfully completed......................................
2025-10-12 15:50:54,561:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:54,561:INFO:Creating metrics dataframe
2025-10-12 15:50:54,568:INFO:Initializing Ridge Classifier
2025-10-12 15:50:54,568:INFO:Total runtime is 0.02923161586125692 minutes
2025-10-12 15:50:54,570:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:54,570:INFO:Initializing create_model()
2025-10-12 15:50:54,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:54,570:INFO:Checking exceptions
2025-10-12 15:50:54,570:INFO:Importing libraries
2025-10-12 15:50:54,570:INFO:Copying training dataset
2025-10-12 15:50:54,573:INFO:Defining folds
2025-10-12 15:50:54,573:INFO:Declaring metric variables
2025-10-12 15:50:54,577:INFO:Importing untrained model
2025-10-12 15:50:54,579:INFO:Ridge Classifier Imported successfully
2025-10-12 15:50:54,584:INFO:Starting cross validation
2025-10-12 15:50:54,586:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:54,756:INFO:Calculating mean and std
2025-10-12 15:50:54,758:INFO:Creating metrics dataframe
2025-10-12 15:50:54,759:INFO:Uploading results into container
2025-10-12 15:50:54,760:INFO:Uploading model into container now
2025-10-12 15:50:54,760:INFO:_master_model_container: 31
2025-10-12 15:50:54,760:INFO:_display_container: 11
2025-10-12 15:50:54,760:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1760, solver='auto',
                tol=0.0001)
2025-10-12 15:50:54,760:INFO:create_model() successfully completed......................................
2025-10-12 15:50:54,860:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:54,860:INFO:Creating metrics dataframe
2025-10-12 15:50:54,865:INFO:Initializing Random Forest Classifier
2025-10-12 15:50:54,865:INFO:Total runtime is 0.034182953834533694 minutes
2025-10-12 15:50:54,867:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:54,868:INFO:Initializing create_model()
2025-10-12 15:50:54,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:54,868:INFO:Checking exceptions
2025-10-12 15:50:54,868:INFO:Importing libraries
2025-10-12 15:50:54,868:INFO:Copying training dataset
2025-10-12 15:50:54,871:INFO:Defining folds
2025-10-12 15:50:54,871:INFO:Declaring metric variables
2025-10-12 15:50:54,874:INFO:Importing untrained model
2025-10-12 15:50:54,876:INFO:Random Forest Classifier Imported successfully
2025-10-12 15:50:54,881:INFO:Starting cross validation
2025-10-12 15:50:54,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:55,253:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,294:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,295:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,300:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,301:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,309:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,310:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,353:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,362:INFO:Calculating mean and std
2025-10-12 15:50:55,363:INFO:Creating metrics dataframe
2025-10-12 15:50:55,366:INFO:Uploading results into container
2025-10-12 15:50:55,366:INFO:Uploading model into container now
2025-10-12 15:50:55,366:INFO:_master_model_container: 32
2025-10-12 15:50:55,366:INFO:_display_container: 11
2025-10-12 15:50:55,368:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1760, verbose=0,
                       warm_start=False)
2025-10-12 15:50:55,368:INFO:create_model() successfully completed......................................
2025-10-12 15:50:55,469:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:55,469:INFO:Creating metrics dataframe
2025-10-12 15:50:55,475:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 15:50:55,475:INFO:Total runtime is 0.04435069561004639 minutes
2025-10-12 15:50:55,479:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:55,479:INFO:Initializing create_model()
2025-10-12 15:50:55,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:55,480:INFO:Checking exceptions
2025-10-12 15:50:55,480:INFO:Importing libraries
2025-10-12 15:50:55,480:INFO:Copying training dataset
2025-10-12 15:50:55,482:INFO:Defining folds
2025-10-12 15:50:55,482:INFO:Declaring metric variables
2025-10-12 15:50:55,485:INFO:Importing untrained model
2025-10-12 15:50:55,489:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 15:50:55,494:INFO:Starting cross validation
2025-10-12 15:50:55,495:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:55,584:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:50:55,584:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:50:55,584:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:50:55,586:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:50:55,586:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:50:55,588:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:50:55,588:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:50:55,591:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:50:55,595:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:50:55,604:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 15:50:55,622:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,625:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,626:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,628:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,628:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,631:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,631:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,642:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,660:INFO:Calculating mean and std
2025-10-12 15:50:55,660:INFO:Creating metrics dataframe
2025-10-12 15:50:55,662:INFO:Uploading results into container
2025-10-12 15:50:55,663:INFO:Uploading model into container now
2025-10-12 15:50:55,663:INFO:_master_model_container: 33
2025-10-12 15:50:55,663:INFO:_display_container: 11
2025-10-12 15:50:55,664:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 15:50:55,664:INFO:create_model() successfully completed......................................
2025-10-12 15:50:55,766:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:55,766:INFO:Creating metrics dataframe
2025-10-12 15:50:55,772:INFO:Initializing Ada Boost Classifier
2025-10-12 15:50:55,772:INFO:Total runtime is 0.04930690526962281 minutes
2025-10-12 15:50:55,775:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:55,775:INFO:Initializing create_model()
2025-10-12 15:50:55,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:55,775:INFO:Checking exceptions
2025-10-12 15:50:55,775:INFO:Importing libraries
2025-10-12 15:50:55,776:INFO:Copying training dataset
2025-10-12 15:50:55,780:INFO:Defining folds
2025-10-12 15:50:55,780:INFO:Declaring metric variables
2025-10-12 15:50:55,783:INFO:Importing untrained model
2025-10-12 15:50:55,787:INFO:Ada Boost Classifier Imported successfully
2025-10-12 15:50:55,793:INFO:Starting cross validation
2025-10-12 15:50:55,794:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:55,886:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:50:55,887:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:50:55,896:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:50:55,897:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:50:55,898:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:50:55,898:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:50:55,898:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:50:55,902:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:50:55,903:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:50:55,909:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 15:50:55,926:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,928:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,929:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,932:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,936:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,942:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,943:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,943:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,946:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,949:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:55,968:INFO:Calculating mean and std
2025-10-12 15:50:55,969:INFO:Creating metrics dataframe
2025-10-12 15:50:55,971:INFO:Uploading results into container
2025-10-12 15:50:55,971:INFO:Uploading model into container now
2025-10-12 15:50:55,972:INFO:_master_model_container: 34
2025-10-12 15:50:55,972:INFO:_display_container: 11
2025-10-12 15:50:55,972:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1760)
2025-10-12 15:50:55,972:INFO:create_model() successfully completed......................................
2025-10-12 15:50:56,082:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:56,082:INFO:Creating metrics dataframe
2025-10-12 15:50:56,090:INFO:Initializing Gradient Boosting Classifier
2025-10-12 15:50:56,090:INFO:Total runtime is 0.05459869702657064 minutes
2025-10-12 15:50:56,092:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:56,092:INFO:Initializing create_model()
2025-10-12 15:50:56,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:56,092:INFO:Checking exceptions
2025-10-12 15:50:56,092:INFO:Importing libraries
2025-10-12 15:50:56,092:INFO:Copying training dataset
2025-10-12 15:50:56,095:INFO:Defining folds
2025-10-12 15:50:56,096:INFO:Declaring metric variables
2025-10-12 15:50:56,098:INFO:Importing untrained model
2025-10-12 15:50:56,102:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 15:50:56,106:INFO:Starting cross validation
2025-10-12 15:50:56,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:56,315:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,334:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,334:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,335:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,336:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,346:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,348:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,352:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,359:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,401:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,420:INFO:Calculating mean and std
2025-10-12 15:50:56,423:INFO:Creating metrics dataframe
2025-10-12 15:50:56,425:INFO:Uploading results into container
2025-10-12 15:50:56,425:INFO:Uploading model into container now
2025-10-12 15:50:56,426:INFO:_master_model_container: 35
2025-10-12 15:50:56,426:INFO:_display_container: 11
2025-10-12 15:50:56,427:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1760, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 15:50:56,427:INFO:create_model() successfully completed......................................
2025-10-12 15:50:56,539:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:56,539:INFO:Creating metrics dataframe
2025-10-12 15:50:56,545:INFO:Initializing Linear Discriminant Analysis
2025-10-12 15:50:56,545:INFO:Total runtime is 0.062177336215972906 minutes
2025-10-12 15:50:56,548:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:56,548:INFO:Initializing create_model()
2025-10-12 15:50:56,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:56,549:INFO:Checking exceptions
2025-10-12 15:50:56,549:INFO:Importing libraries
2025-10-12 15:50:56,549:INFO:Copying training dataset
2025-10-12 15:50:56,551:INFO:Defining folds
2025-10-12 15:50:56,552:INFO:Declaring metric variables
2025-10-12 15:50:56,555:INFO:Importing untrained model
2025-10-12 15:50:56,558:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 15:50:56,563:INFO:Starting cross validation
2025-10-12 15:50:56,564:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:56,701:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,706:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,708:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,710:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,710:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,712:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,713:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,715:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,719:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,719:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:56,730:INFO:Calculating mean and std
2025-10-12 15:50:56,731:INFO:Creating metrics dataframe
2025-10-12 15:50:56,733:INFO:Uploading results into container
2025-10-12 15:50:56,734:INFO:Uploading model into container now
2025-10-12 15:50:56,734:INFO:_master_model_container: 36
2025-10-12 15:50:56,734:INFO:_display_container: 11
2025-10-12 15:50:56,734:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 15:50:56,735:INFO:create_model() successfully completed......................................
2025-10-12 15:50:56,841:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:56,841:INFO:Creating metrics dataframe
2025-10-12 15:50:56,848:INFO:Initializing Extra Trees Classifier
2025-10-12 15:50:56,848:INFO:Total runtime is 0.0672287901242574 minutes
2025-10-12 15:50:56,850:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:56,851:INFO:Initializing create_model()
2025-10-12 15:50:56,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:56,851:INFO:Checking exceptions
2025-10-12 15:50:56,851:INFO:Importing libraries
2025-10-12 15:50:56,851:INFO:Copying training dataset
2025-10-12 15:50:56,854:INFO:Defining folds
2025-10-12 15:50:56,854:INFO:Declaring metric variables
2025-10-12 15:50:56,859:INFO:Importing untrained model
2025-10-12 15:50:56,862:INFO:Extra Trees Classifier Imported successfully
2025-10-12 15:50:56,868:INFO:Starting cross validation
2025-10-12 15:50:56,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:57,273:INFO:Calculating mean and std
2025-10-12 15:50:57,274:INFO:Creating metrics dataframe
2025-10-12 15:50:57,275:INFO:Uploading results into container
2025-10-12 15:50:57,276:INFO:Uploading model into container now
2025-10-12 15:50:57,276:INFO:_master_model_container: 37
2025-10-12 15:50:57,276:INFO:_display_container: 11
2025-10-12 15:50:57,277:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1760, verbose=0,
                     warm_start=False)
2025-10-12 15:50:57,277:INFO:create_model() successfully completed......................................
2025-10-12 15:50:57,384:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:57,385:INFO:Creating metrics dataframe
2025-10-12 15:50:57,396:INFO:Initializing Extreme Gradient Boosting
2025-10-12 15:50:57,396:INFO:Total runtime is 0.07636947234471639 minutes
2025-10-12 15:50:57,401:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:57,402:INFO:Initializing create_model()
2025-10-12 15:50:57,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:57,402:INFO:Checking exceptions
2025-10-12 15:50:57,402:INFO:Importing libraries
2025-10-12 15:50:57,402:INFO:Copying training dataset
2025-10-12 15:50:57,406:INFO:Defining folds
2025-10-12 15:50:57,406:INFO:Declaring metric variables
2025-10-12 15:50:57,410:INFO:Importing untrained model
2025-10-12 15:50:57,413:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 15:50:57,421:INFO:Starting cross validation
2025-10-12 15:50:57,423:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:57,575:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:57,583:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:57,590:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:57,604:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:57,607:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:57,623:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:57,624:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:57,780:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:57,806:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:57,813:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:57,819:INFO:Calculating mean and std
2025-10-12 15:50:57,820:INFO:Creating metrics dataframe
2025-10-12 15:50:57,821:INFO:Uploading results into container
2025-10-12 15:50:57,822:INFO:Uploading model into container now
2025-10-12 15:50:57,823:INFO:_master_model_container: 38
2025-10-12 15:50:57,823:INFO:_display_container: 11
2025-10-12 15:50:57,823:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 15:50:57,823:INFO:create_model() successfully completed......................................
2025-10-12 15:50:57,937:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:57,937:INFO:Creating metrics dataframe
2025-10-12 15:50:57,957:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 15:50:57,957:INFO:Total runtime is 0.08571372032165528 minutes
2025-10-12 15:50:57,962:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:57,963:INFO:Initializing create_model()
2025-10-12 15:50:57,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:57,963:INFO:Checking exceptions
2025-10-12 15:50:57,963:INFO:Importing libraries
2025-10-12 15:50:57,963:INFO:Copying training dataset
2025-10-12 15:50:57,967:INFO:Defining folds
2025-10-12 15:50:57,967:INFO:Declaring metric variables
2025-10-12 15:50:57,971:INFO:Importing untrained model
2025-10-12 15:50:57,975:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 15:50:57,983:INFO:Starting cross validation
2025-10-12 15:50:57,984:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:50:58,485:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:58,521:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:58,532:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:58,548:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:58,557:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:58,561:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:58,578:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:58,582:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:58,599:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:58,609:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:50:58,630:INFO:Calculating mean and std
2025-10-12 15:50:58,632:INFO:Creating metrics dataframe
2025-10-12 15:50:58,634:INFO:Uploading results into container
2025-10-12 15:50:58,634:INFO:Uploading model into container now
2025-10-12 15:50:58,635:INFO:_master_model_container: 39
2025-10-12 15:50:58,635:INFO:_display_container: 11
2025-10-12 15:50:58,636:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1760, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 15:50:58,636:INFO:create_model() successfully completed......................................
2025-10-12 15:50:58,753:INFO:SubProcess create_model() end ==================================
2025-10-12 15:50:58,753:INFO:Creating metrics dataframe
2025-10-12 15:50:58,760:INFO:Initializing CatBoost Classifier
2025-10-12 15:50:58,761:INFO:Total runtime is 0.09910046656926473 minutes
2025-10-12 15:50:58,764:INFO:SubProcess create_model() called ==================================
2025-10-12 15:50:58,764:INFO:Initializing create_model()
2025-10-12 15:50:58,764:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:50:58,764:INFO:Checking exceptions
2025-10-12 15:50:58,764:INFO:Importing libraries
2025-10-12 15:50:58,764:INFO:Copying training dataset
2025-10-12 15:50:58,768:INFO:Defining folds
2025-10-12 15:50:58,768:INFO:Declaring metric variables
2025-10-12 15:50:58,770:INFO:Importing untrained model
2025-10-12 15:50:58,773:INFO:CatBoost Classifier Imported successfully
2025-10-12 15:50:58,778:INFO:Starting cross validation
2025-10-12 15:50:58,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:51:00,658:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:00,660:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:00,661:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:00,672:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:01,480:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:02,294:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:02,310:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:02,326:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:03,022:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:03,055:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:03,070:INFO:Calculating mean and std
2025-10-12 15:51:03,071:INFO:Creating metrics dataframe
2025-10-12 15:51:03,072:INFO:Uploading results into container
2025-10-12 15:51:03,073:INFO:Uploading model into container now
2025-10-12 15:51:03,074:INFO:_master_model_container: 40
2025-10-12 15:51:03,074:INFO:_display_container: 11
2025-10-12 15:51:03,074:INFO:<catboost.core.CatBoostClassifier object at 0x00000265CEDACB20>
2025-10-12 15:51:03,074:INFO:create_model() successfully completed......................................
2025-10-12 15:51:03,178:INFO:SubProcess create_model() end ==================================
2025-10-12 15:51:03,178:INFO:Creating metrics dataframe
2025-10-12 15:51:03,184:INFO:Initializing Dummy Classifier
2025-10-12 15:51:03,184:INFO:Total runtime is 0.1728346586227417 minutes
2025-10-12 15:51:03,188:INFO:SubProcess create_model() called ==================================
2025-10-12 15:51:03,188:INFO:Initializing create_model()
2025-10-12 15:51:03,188:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D9F5B940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:51:03,189:INFO:Checking exceptions
2025-10-12 15:51:03,189:INFO:Importing libraries
2025-10-12 15:51:03,189:INFO:Copying training dataset
2025-10-12 15:51:03,192:INFO:Defining folds
2025-10-12 15:51:03,192:INFO:Declaring metric variables
2025-10-12 15:51:03,196:INFO:Importing untrained model
2025-10-12 15:51:03,199:INFO:Dummy Classifier Imported successfully
2025-10-12 15:51:03,204:INFO:Starting cross validation
2025-10-12 15:51:03,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 15:51:03,333:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:03,350:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:03,353:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:03,353:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:03,354:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:03,357:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:03,358:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:03,361:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:03,361:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:03,364:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 15:51:03,379:INFO:Calculating mean and std
2025-10-12 15:51:03,380:INFO:Creating metrics dataframe
2025-10-12 15:51:03,381:INFO:Uploading results into container
2025-10-12 15:51:03,382:INFO:Uploading model into container now
2025-10-12 15:51:03,382:INFO:_master_model_container: 41
2025-10-12 15:51:03,382:INFO:_display_container: 11
2025-10-12 15:51:03,382:INFO:DummyClassifier(constant=None, random_state=1760, strategy='prior')
2025-10-12 15:51:03,382:INFO:create_model() successfully completed......................................
2025-10-12 15:51:03,481:INFO:SubProcess create_model() end ==================================
2025-10-12 15:51:03,481:INFO:Creating metrics dataframe
2025-10-12 15:51:03,488:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 15:51:03,495:INFO:Initializing create_model()
2025-10-12 15:51:03,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 15:51:03,495:INFO:Checking exceptions
2025-10-12 15:51:03,496:INFO:Importing libraries
2025-10-12 15:51:03,496:INFO:Copying training dataset
2025-10-12 15:51:03,500:INFO:Defining folds
2025-10-12 15:51:03,500:INFO:Declaring metric variables
2025-10-12 15:51:03,500:INFO:Importing untrained model
2025-10-12 15:51:03,500:INFO:Declaring custom model
2025-10-12 15:51:03,500:INFO:Logistic Regression Imported successfully
2025-10-12 15:51:03,501:INFO:Cross validation set to False
2025-10-12 15:51:03,501:INFO:Fitting Model
2025-10-12 15:51:03,596:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 15:51:03,597:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:51:03,597:INFO:create_model() successfully completed......................................
2025-10-12 15:51:03,701:INFO:Creating Dashboard logs
2025-10-12 15:51:03,704:INFO:Model: Logistic Regression
2025-10-12 15:51:03,768:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1760, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 15:51:03,988:INFO:Initializing predict_model()
2025-10-12 15:51:03,988:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DBD579D0>)
2025-10-12 15:51:03,988:INFO:Checking exceptions
2025-10-12 15:51:03,988:INFO:Preloading libraries
2025-10-12 15:51:04,240:INFO:SubProcess plot_model() called ==================================
2025-10-12 15:51:04,240:INFO:Initializing plot_model()
2025-10-12 15:51:04,240:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpcprovtcm, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:51:04,240:INFO:Checking exceptions
2025-10-12 15:51:04,241:INFO:Preloading libraries
2025-10-12 15:51:04,242:INFO:Copying training dataset
2025-10-12 15:51:04,242:INFO:Plot type: auc
2025-10-12 15:51:04,498:INFO:Fitting Model
2025-10-12 15:51:04,498:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:51:04,498:INFO:Scoring test/hold-out set
2025-10-12 15:51:04,512:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpcprovtcm\AUC.png'
2025-10-12 15:51:04,655:INFO:Visual Rendered Successfully
2025-10-12 15:51:04,768:INFO:plot_model() successfully completed......................................
2025-10-12 15:51:04,786:INFO:Initializing plot_model()
2025-10-12 15:51:04,786:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpcprovtcm, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:51:04,786:INFO:Checking exceptions
2025-10-12 15:51:04,787:INFO:Preloading libraries
2025-10-12 15:51:04,787:INFO:Copying training dataset
2025-10-12 15:51:04,787:INFO:Plot type: confusion_matrix
2025-10-12 15:51:05,026:INFO:Fitting Model
2025-10-12 15:51:05,026:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 15:51:05,026:INFO:Scoring test/hold-out set
2025-10-12 15:51:05,038:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpcprovtcm\Confusion Matrix.png'
2025-10-12 15:51:05,110:INFO:Visual Rendered Successfully
2025-10-12 15:51:05,217:INFO:plot_model() successfully completed......................................
2025-10-12 15:51:05,239:INFO:Initializing plot_model()
2025-10-12 15:51:05,239:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpcprovtcm, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, system=False)
2025-10-12 15:51:05,239:INFO:Checking exceptions
2025-10-12 15:51:05,240:INFO:Preloading libraries
2025-10-12 15:51:05,240:INFO:Copying training dataset
2025-10-12 15:51:05,240:INFO:Plot type: feature
2025-10-12 15:51:05,375:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpcprovtcm\Feature Importance.png'
2025-10-12 15:51:05,474:INFO:Visual Rendered Successfully
2025-10-12 15:51:05,578:INFO:plot_model() successfully completed......................................
2025-10-12 15:51:05,599:INFO:SubProcess plot_model() end ==================================
2025-10-12 15:51:05,781:INFO:Creating Dashboard logs
2025-10-12 15:51:05,784:INFO:Model: Ridge Classifier
2025-10-12 15:51:05,852:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 1760, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 15:51:06,245:INFO:Creating Dashboard logs
2025-10-12 15:51:06,249:INFO:Model: Extra Trees Classifier
2025-10-12 15:51:06,323:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1760, 'verbose': 0, 'warm_start': False}
2025-10-12 15:51:06,787:INFO:Creating Dashboard logs
2025-10-12 15:51:06,791:INFO:Model: Naive Bayes
2025-10-12 15:51:06,868:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 15:51:07,286:INFO:Creating Dashboard logs
2025-10-12 15:51:07,289:INFO:Model: K Neighbors Classifier
2025-10-12 15:51:07,357:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 15:51:07,769:INFO:Creating Dashboard logs
2025-10-12 15:51:07,771:INFO:Model: Decision Tree Classifier
2025-10-12 15:51:07,844:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 1760, 'splitter': 'best'}
2025-10-12 15:51:08,211:INFO:Creating Dashboard logs
2025-10-12 15:51:08,215:INFO:Model: Random Forest Classifier
2025-10-12 15:51:08,282:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1760, 'verbose': 0, 'warm_start': False}
2025-10-12 15:51:08,713:INFO:Creating Dashboard logs
2025-10-12 15:51:08,716:INFO:Model: Ada Boost Classifier
2025-10-12 15:51:08,780:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 1760}
2025-10-12 15:51:09,117:INFO:Creating Dashboard logs
2025-10-12 15:51:09,120:INFO:Model: Gradient Boosting Classifier
2025-10-12 15:51:09,184:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1760, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 15:51:09,552:INFO:Creating Dashboard logs
2025-10-12 15:51:09,555:INFO:Model: Linear Discriminant Analysis
2025-10-12 15:51:09,623:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 15:51:09,964:INFO:Creating Dashboard logs
2025-10-12 15:51:09,966:INFO:Model: Extreme Gradient Boosting
2025-10-12 15:51:10,045:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 1760, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 15:51:10,471:INFO:Creating Dashboard logs
2025-10-12 15:51:10,474:INFO:Model: Light Gradient Boosting Machine
2025-10-12 15:51:10,548:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1760, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 15:51:10,950:INFO:Creating Dashboard logs
2025-10-12 15:51:10,952:INFO:Model: CatBoost Classifier
2025-10-12 15:51:11,016:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-10-12 15:51:11,016:INFO:Logged params: {}
2025-10-12 15:51:11,360:INFO:Creating Dashboard logs
2025-10-12 15:51:11,362:INFO:Model: Dummy Classifier
2025-10-12 15:51:11,428:INFO:Logged params: {'constant': None, 'random_state': 1760, 'strategy': 'prior'}
2025-10-12 15:51:11,785:INFO:Creating Dashboard logs
2025-10-12 15:51:11,788:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 15:51:11,861:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 15:51:12,253:INFO:Creating Dashboard logs
2025-10-12 15:51:12,256:INFO:Model: SVM - Linear Kernel
2025-10-12 15:51:12,338:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 1760, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 15:51:12,777:INFO:_master_model_container: 41
2025-10-12 15:51:12,777:INFO:_display_container: 11
2025-10-12 15:51:12,777:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1760, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 15:51:12,777:INFO:compare_models() successfully completed......................................
2025-10-12 15:52:00,415:INFO:Initializing predict_model()
2025-10-12 15:52:00,415:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002658D291D60>, estimator=mlflow.pyfunc.loaded_model:
  run_id: 39f894e7d3eb44a99b7896e490c21033
  artifact_path: model
  flavor: mlflow.sklearn
, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DEE5AC10>)
2025-10-12 15:52:00,415:INFO:Checking exceptions
2025-10-12 15:52:00,415:INFO:Preloading libraries
2025-10-12 15:52:00,417:INFO:Set up data.
2025-10-12 15:52:00,426:INFO:Set up index.
2025-10-12 16:00:58,976:INFO:PyCaret ClassificationExperiment
2025-10-12 16:00:58,977:INFO:Logging name: titanic_exp_1
2025-10-12 16:00:58,977:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-12 16:00:58,977:INFO:version 3.3.2
2025-10-12 16:00:58,977:INFO:Initializing setup()
2025-10-12 16:00:58,977:INFO:self.USI: c167
2025-10-12 16:00:58,977:INFO:self._variable_keys: {'fold_generator', 'is_multiclass', 'pipeline', 'y', 'target_param', '_ml_usecase', 'fold_shuffle_param', 'X_train', 'html_param', 'gpu_n_jobs_param', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', 'exp_id', 'data', 'y_test', 'exp_name_log', 'memory', 'y_train', 'X_test', 'seed', 'fix_imbalance', 'n_jobs_param', 'X', 'logging_param', '_available_plots', 'idx'}
2025-10-12 16:00:58,977:INFO:Checking environment
2025-10-12 16:00:58,977:INFO:python_version: 3.9.13
2025-10-12 16:00:58,977:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2025-10-12 16:00:58,977:INFO:machine: AMD64
2025-10-12 16:00:58,977:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-12 16:00:58,977:INFO:Memory: svmem(total=16778072064, available=4109451264, percent=75.5, used=12668620800, free=4109451264)
2025-10-12 16:00:58,977:INFO:Physical Core: 10
2025-10-12 16:00:58,977:INFO:Logical Core: 16
2025-10-12 16:00:58,977:INFO:Checking libraries
2025-10-12 16:00:58,977:INFO:System:
2025-10-12 16:00:58,977:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2025-10-12 16:00:58,977:INFO:executable: c:\Users\david\Programming\MLOps\.venv\Scripts\python.exe
2025-10-12 16:00:58,977:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-12 16:00:58,977:INFO:PyCaret required dependencies:
2025-10-12 16:00:58,977:INFO:                 pip: 25.2
2025-10-12 16:00:58,977:INFO:          setuptools: 80.9.0
2025-10-12 16:00:58,977:INFO:             pycaret: 3.3.2
2025-10-12 16:00:58,977:INFO:             IPython: 8.18.1
2025-10-12 16:00:58,977:INFO:          ipywidgets: 8.1.7
2025-10-12 16:00:58,978:INFO:                tqdm: 4.67.1
2025-10-12 16:00:58,978:INFO:               numpy: 1.26.4
2025-10-12 16:00:58,978:INFO:              pandas: 2.1.4
2025-10-12 16:00:58,978:INFO:              jinja2: 3.1.6
2025-10-12 16:00:58,978:INFO:               scipy: 1.11.4
2025-10-12 16:00:58,978:INFO:              joblib: 1.3.2
2025-10-12 16:00:58,978:INFO:             sklearn: 1.4.2
2025-10-12 16:00:58,978:INFO:                pyod: 2.0.5
2025-10-12 16:00:58,978:INFO:            imblearn: 0.12.4
2025-10-12 16:00:58,978:INFO:   category_encoders: 2.6.4
2025-10-12 16:00:58,978:INFO:            lightgbm: 4.6.0
2025-10-12 16:00:58,978:INFO:               numba: 0.60.0
2025-10-12 16:00:58,978:INFO:            requests: 2.32.5
2025-10-12 16:00:58,978:INFO:          matplotlib: 3.7.5
2025-10-12 16:00:58,978:INFO:          scikitplot: 0.3.7
2025-10-12 16:00:58,978:INFO:         yellowbrick: 1.5
2025-10-12 16:00:58,978:INFO:              plotly: 5.24.1
2025-10-12 16:00:58,978:INFO:    plotly-resampler: Not installed
2025-10-12 16:00:58,978:INFO:             kaleido: 1.1.0
2025-10-12 16:00:58,978:INFO:           schemdraw: 0.15
2025-10-12 16:00:58,978:INFO:         statsmodels: 0.14.5
2025-10-12 16:00:58,978:INFO:              sktime: 0.26.0
2025-10-12 16:00:58,978:INFO:               tbats: 1.1.3
2025-10-12 16:00:58,978:INFO:            pmdarima: 2.0.4
2025-10-12 16:00:58,978:INFO:              psutil: 7.1.0
2025-10-12 16:00:58,978:INFO:          markupsafe: 2.1.5
2025-10-12 16:00:58,978:INFO:             pickle5: Not installed
2025-10-12 16:00:58,978:INFO:         cloudpickle: 3.1.1
2025-10-12 16:00:58,978:INFO:         deprecation: 2.1.0
2025-10-12 16:00:58,978:INFO:              xxhash: 3.6.0
2025-10-12 16:00:58,978:INFO:           wurlitzer: Not installed
2025-10-12 16:00:58,978:INFO:PyCaret optional dependencies:
2025-10-12 16:00:58,978:INFO:                shap: 0.44.1
2025-10-12 16:00:58,978:INFO:           interpret: 0.7.2
2025-10-12 16:00:58,978:INFO:                umap: 0.5.7
2025-10-12 16:00:58,978:INFO:     ydata_profiling: 4.17.0
2025-10-12 16:00:58,978:INFO:  explainerdashboard: 0.5.1
2025-10-12 16:00:58,978:INFO:             autoviz: Not installed
2025-10-12 16:00:58,978:INFO:           fairlearn: 0.7.0
2025-10-12 16:00:58,978:INFO:          deepchecks: Not installed
2025-10-12 16:00:58,978:INFO:             xgboost: 2.1.4
2025-10-12 16:00:58,978:INFO:            catboost: 1.2.8
2025-10-12 16:00:58,978:INFO:              kmodes: 0.12.2
2025-10-12 16:00:58,978:INFO:             mlxtend: 0.23.4
2025-10-12 16:00:58,978:INFO:       statsforecast: 1.5.0
2025-10-12 16:00:58,978:INFO:        tune_sklearn: Not installed
2025-10-12 16:00:58,978:INFO:                 ray: Not installed
2025-10-12 16:00:58,979:INFO:            hyperopt: 0.2.7
2025-10-12 16:00:58,979:INFO:              optuna: 4.5.0
2025-10-12 16:00:58,979:INFO:               skopt: 0.10.2
2025-10-12 16:00:58,979:INFO:              mlflow: 3.1.4
2025-10-12 16:00:58,979:INFO:              gradio: Not installed
2025-10-12 16:00:58,979:INFO:             fastapi: 0.119.0
2025-10-12 16:00:58,979:INFO:             uvicorn: 0.37.0
2025-10-12 16:00:58,979:INFO:              m2cgen: 0.10.0
2025-10-12 16:00:58,979:INFO:           evidently: 0.4.40
2025-10-12 16:00:58,979:INFO:               fugue: 0.8.7
2025-10-12 16:00:58,979:INFO:           streamlit: Not installed
2025-10-12 16:00:58,979:INFO:             prophet: Not installed
2025-10-12 16:00:58,979:INFO:None
2025-10-12 16:00:58,979:INFO:Set up data.
2025-10-12 16:00:58,985:INFO:Set up folding strategy.
2025-10-12 16:00:58,985:INFO:Set up train/test split.
2025-10-12 16:00:58,988:INFO:Set up index.
2025-10-12 16:00:58,989:INFO:Assigning column types.
2025-10-12 16:00:58,991:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-12 16:00:59,020:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:00:59,020:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:00:59,039:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:00:59,041:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:00:59,066:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:00:59,066:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:00:59,082:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:00:59,084:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:00:59,084:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-12 16:00:59,110:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:00:59,125:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:00:59,127:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:00:59,154:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:00:59,170:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:00:59,172:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:00:59,173:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-12 16:00:59,216:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:00:59,218:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:00:59,263:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:00:59,265:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:00:59,266:INFO:Preparing preprocessing pipeline...
2025-10-12 16:00:59,267:INFO:Set up simple imputation.
2025-10-12 16:00:59,270:INFO:Set up encoding of ordinal features.
2025-10-12 16:00:59,271:INFO:Set up encoding of categorical features.
2025-10-12 16:00:59,354:INFO:Finished creating preprocessing pipeline.
2025-10-12 16:00:59,364:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-10-12 16:00:59,364:INFO:Creating final display dataframe.
2025-10-12 16:00:59,609:INFO:Setup _display_container:                     Description            Value
0                    Session id              988
1                        Target         Survived
2                   Target type           Binary
3           Original data shape        (712, 12)
4        Transformed data shape        (712, 14)
5   Transformed train set shape        (498, 14)
6    Transformed test set shape        (214, 14)
7              Numeric features                6
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name    titanic_exp_1
21                          USI             c167
2025-10-12 16:00:59,658:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:00:59,660:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:00:59,704:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:00:59,705:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:00:59,706:INFO:Logging experiment in loggers
2025-10-12 16:00:59,840:INFO:SubProcess save_model() called ==================================
2025-10-12 16:00:59,861:INFO:Initializing save_model()
2025-10-12 16:00:59,861:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\david\AppData\Local\Temp\tmpw1bezufa\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 16:00:59,861:INFO:Adding model into prep_pipe
2025-10-12 16:00:59,861:WARNING:Only Model saved as it was a pipeline.
2025-10-12 16:00:59,868:INFO:C:\Users\david\AppData\Local\Temp\tmpw1bezufa\Transformation Pipeline.pkl saved in current working directory
2025-10-12 16:00:59,877:INFO:Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-10-12 16:00:59,877:INFO:save_model() successfully completed......................................
2025-10-12 16:01:00,037:INFO:SubProcess save_model() end ==================================
2025-10-12 16:01:00,123:INFO:setup() successfully completed in 0.74s...............
2025-10-12 16:01:02,663:INFO:Initializing compare_models()
2025-10-12 16:01:02,663:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:01:02,663:INFO:Checking exceptions
2025-10-12 16:01:02,667:INFO:Preparing display monitor
2025-10-12 16:01:02,685:INFO:Initializing Logistic Regression
2025-10-12 16:01:02,685:INFO:Total runtime is 0.0 minutes
2025-10-12 16:01:02,691:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:02,691:INFO:Initializing create_model()
2025-10-12 16:01:02,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:02,691:INFO:Checking exceptions
2025-10-12 16:01:02,692:INFO:Importing libraries
2025-10-12 16:01:02,692:INFO:Copying training dataset
2025-10-12 16:01:02,697:INFO:Defining folds
2025-10-12 16:01:02,698:INFO:Declaring metric variables
2025-10-12 16:01:02,702:INFO:Importing untrained model
2025-10-12 16:01:02,705:INFO:Logistic Regression Imported successfully
2025-10-12 16:01:02,713:INFO:Starting cross validation
2025-10-12 16:01:02,715:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:10,221:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:10,223:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:10,226:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:10,232:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:10,233:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:10,233:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:10,237:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:10,240:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:10,240:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:10,254:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:10,323:INFO:Calculating mean and std
2025-10-12 16:01:10,327:INFO:Creating metrics dataframe
2025-10-12 16:01:10,331:INFO:Uploading results into container
2025-10-12 16:01:10,332:INFO:Uploading model into container now
2025-10-12 16:01:10,333:INFO:_master_model_container: 1
2025-10-12 16:01:10,333:INFO:_display_container: 2
2025-10-12 16:01:10,334:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:01:10,334:INFO:create_model() successfully completed......................................
2025-10-12 16:01:10,519:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:10,519:INFO:Creating metrics dataframe
2025-10-12 16:01:10,524:INFO:Initializing K Neighbors Classifier
2025-10-12 16:01:10,524:INFO:Total runtime is 0.13065118789672853 minutes
2025-10-12 16:01:10,527:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:10,528:INFO:Initializing create_model()
2025-10-12 16:01:10,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:10,528:INFO:Checking exceptions
2025-10-12 16:01:10,528:INFO:Importing libraries
2025-10-12 16:01:10,528:INFO:Copying training dataset
2025-10-12 16:01:10,531:INFO:Defining folds
2025-10-12 16:01:10,531:INFO:Declaring metric variables
2025-10-12 16:01:10,534:INFO:Importing untrained model
2025-10-12 16:01:10,536:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:01:10,541:INFO:Starting cross validation
2025-10-12 16:01:10,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:14,701:INFO:Calculating mean and std
2025-10-12 16:01:14,702:INFO:Creating metrics dataframe
2025-10-12 16:01:14,705:INFO:Uploading results into container
2025-10-12 16:01:14,706:INFO:Uploading model into container now
2025-10-12 16:01:14,706:INFO:_master_model_container: 2
2025-10-12 16:01:14,706:INFO:_display_container: 2
2025-10-12 16:01:14,707:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:01:14,707:INFO:create_model() successfully completed......................................
2025-10-12 16:01:14,863:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:14,863:INFO:Creating metrics dataframe
2025-10-12 16:01:14,868:INFO:Initializing Naive Bayes
2025-10-12 16:01:14,868:INFO:Total runtime is 0.2030530611673991 minutes
2025-10-12 16:01:14,871:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:14,871:INFO:Initializing create_model()
2025-10-12 16:01:14,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:14,871:INFO:Checking exceptions
2025-10-12 16:01:14,871:INFO:Importing libraries
2025-10-12 16:01:14,871:INFO:Copying training dataset
2025-10-12 16:01:14,875:INFO:Defining folds
2025-10-12 16:01:14,875:INFO:Declaring metric variables
2025-10-12 16:01:14,878:INFO:Importing untrained model
2025-10-12 16:01:14,880:INFO:Naive Bayes Imported successfully
2025-10-12 16:01:14,887:INFO:Starting cross validation
2025-10-12 16:01:14,889:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:15,090:INFO:Calculating mean and std
2025-10-12 16:01:15,091:INFO:Creating metrics dataframe
2025-10-12 16:01:15,093:INFO:Uploading results into container
2025-10-12 16:01:15,093:INFO:Uploading model into container now
2025-10-12 16:01:15,093:INFO:_master_model_container: 3
2025-10-12 16:01:15,093:INFO:_display_container: 2
2025-10-12 16:01:15,093:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:01:15,095:INFO:create_model() successfully completed......................................
2025-10-12 16:01:15,231:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:15,231:INFO:Creating metrics dataframe
2025-10-12 16:01:15,236:INFO:Initializing Decision Tree Classifier
2025-10-12 16:01:15,236:INFO:Total runtime is 0.20917973121007286 minutes
2025-10-12 16:01:15,239:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:15,239:INFO:Initializing create_model()
2025-10-12 16:01:15,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:15,240:INFO:Checking exceptions
2025-10-12 16:01:15,240:INFO:Importing libraries
2025-10-12 16:01:15,240:INFO:Copying training dataset
2025-10-12 16:01:15,242:INFO:Defining folds
2025-10-12 16:01:15,243:INFO:Declaring metric variables
2025-10-12 16:01:15,246:INFO:Importing untrained model
2025-10-12 16:01:15,250:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:01:15,256:INFO:Starting cross validation
2025-10-12 16:01:15,258:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:15,394:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:15,394:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:15,394:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:15,395:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:15,397:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:15,397:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:15,401:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:15,402:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:15,402:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:15,404:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:15,417:INFO:Calculating mean and std
2025-10-12 16:01:15,418:INFO:Creating metrics dataframe
2025-10-12 16:01:15,420:INFO:Uploading results into container
2025-10-12 16:01:15,420:INFO:Uploading model into container now
2025-10-12 16:01:15,421:INFO:_master_model_container: 4
2025-10-12 16:01:15,421:INFO:_display_container: 2
2025-10-12 16:01:15,421:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=988, splitter='best')
2025-10-12 16:01:15,421:INFO:create_model() successfully completed......................................
2025-10-12 16:01:15,555:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:15,556:INFO:Creating metrics dataframe
2025-10-12 16:01:15,562:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:01:15,562:INFO:Total runtime is 0.21461180448532108 minutes
2025-10-12 16:01:15,565:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:15,566:INFO:Initializing create_model()
2025-10-12 16:01:15,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:15,566:INFO:Checking exceptions
2025-10-12 16:01:15,566:INFO:Importing libraries
2025-10-12 16:01:15,566:INFO:Copying training dataset
2025-10-12 16:01:15,569:INFO:Defining folds
2025-10-12 16:01:15,569:INFO:Declaring metric variables
2025-10-12 16:01:15,572:INFO:Importing untrained model
2025-10-12 16:01:15,576:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:01:15,582:INFO:Starting cross validation
2025-10-12 16:01:15,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:15,717:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:15,743:INFO:Calculating mean and std
2025-10-12 16:01:15,744:INFO:Creating metrics dataframe
2025-10-12 16:01:15,746:INFO:Uploading results into container
2025-10-12 16:01:15,747:INFO:Uploading model into container now
2025-10-12 16:01:15,747:INFO:_master_model_container: 5
2025-10-12 16:01:15,747:INFO:_display_container: 2
2025-10-12 16:01:15,747:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=988, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:01:15,747:INFO:create_model() successfully completed......................................
2025-10-12 16:01:15,886:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:15,886:INFO:Creating metrics dataframe
2025-10-12 16:01:15,891:INFO:Initializing Ridge Classifier
2025-10-12 16:01:15,891:INFO:Total runtime is 0.22009624640146894 minutes
2025-10-12 16:01:15,894:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:15,894:INFO:Initializing create_model()
2025-10-12 16:01:15,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:15,894:INFO:Checking exceptions
2025-10-12 16:01:15,895:INFO:Importing libraries
2025-10-12 16:01:15,895:INFO:Copying training dataset
2025-10-12 16:01:15,897:INFO:Defining folds
2025-10-12 16:01:15,897:INFO:Declaring metric variables
2025-10-12 16:01:15,900:INFO:Importing untrained model
2025-10-12 16:01:15,902:INFO:Ridge Classifier Imported successfully
2025-10-12 16:01:15,907:INFO:Starting cross validation
2025-10-12 16:01:15,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:16,071:INFO:Calculating mean and std
2025-10-12 16:01:16,071:INFO:Creating metrics dataframe
2025-10-12 16:01:16,073:INFO:Uploading results into container
2025-10-12 16:01:16,073:INFO:Uploading model into container now
2025-10-12 16:01:16,073:INFO:_master_model_container: 6
2025-10-12 16:01:16,075:INFO:_display_container: 2
2025-10-12 16:01:16,075:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=988, solver='auto',
                tol=0.0001)
2025-10-12 16:01:16,075:INFO:create_model() successfully completed......................................
2025-10-12 16:01:16,212:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:16,213:INFO:Creating metrics dataframe
2025-10-12 16:01:16,218:INFO:Initializing Random Forest Classifier
2025-10-12 16:01:16,218:INFO:Total runtime is 0.22554992039998376 minutes
2025-10-12 16:01:16,221:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:16,221:INFO:Initializing create_model()
2025-10-12 16:01:16,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:16,221:INFO:Checking exceptions
2025-10-12 16:01:16,221:INFO:Importing libraries
2025-10-12 16:01:16,221:INFO:Copying training dataset
2025-10-12 16:01:16,224:INFO:Defining folds
2025-10-12 16:01:16,224:INFO:Declaring metric variables
2025-10-12 16:01:16,227:INFO:Importing untrained model
2025-10-12 16:01:16,230:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:01:16,235:INFO:Starting cross validation
2025-10-12 16:01:16,237:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:16,622:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:16,636:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:16,661:INFO:Calculating mean and std
2025-10-12 16:01:16,662:INFO:Creating metrics dataframe
2025-10-12 16:01:16,664:INFO:Uploading results into container
2025-10-12 16:01:16,664:INFO:Uploading model into container now
2025-10-12 16:01:16,664:INFO:_master_model_container: 7
2025-10-12 16:01:16,665:INFO:_display_container: 2
2025-10-12 16:01:16,665:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=988, verbose=0,
                       warm_start=False)
2025-10-12 16:01:16,665:INFO:create_model() successfully completed......................................
2025-10-12 16:01:16,805:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:16,805:INFO:Creating metrics dataframe
2025-10-12 16:01:16,812:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:01:16,812:INFO:Total runtime is 0.23544365962346397 minutes
2025-10-12 16:01:16,814:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:16,814:INFO:Initializing create_model()
2025-10-12 16:01:16,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:16,814:INFO:Checking exceptions
2025-10-12 16:01:16,814:INFO:Importing libraries
2025-10-12 16:01:16,814:INFO:Copying training dataset
2025-10-12 16:01:16,819:INFO:Defining folds
2025-10-12 16:01:16,819:INFO:Declaring metric variables
2025-10-12 16:01:16,821:INFO:Importing untrained model
2025-10-12 16:01:16,824:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:01:16,829:INFO:Starting cross validation
2025-10-12 16:01:16,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:16,924:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:01:16,924:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:01:16,929:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:01:16,933:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:01:16,936:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:01:16,936:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:01:16,938:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:01:16,950:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:01:16,950:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:01:16,950:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:01:16,963:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:16,966:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:16,974:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:16,974:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:16,975:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:16,981:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:16,981:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:16,989:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,003:INFO:Calculating mean and std
2025-10-12 16:01:17,004:INFO:Creating metrics dataframe
2025-10-12 16:01:17,005:INFO:Uploading results into container
2025-10-12 16:01:17,006:INFO:Uploading model into container now
2025-10-12 16:01:17,006:INFO:_master_model_container: 8
2025-10-12 16:01:17,006:INFO:_display_container: 2
2025-10-12 16:01:17,006:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:01:17,006:INFO:create_model() successfully completed......................................
2025-10-12 16:01:17,143:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:17,143:INFO:Creating metrics dataframe
2025-10-12 16:01:17,154:INFO:Initializing Ada Boost Classifier
2025-10-12 16:01:17,154:INFO:Total runtime is 0.241144335269928 minutes
2025-10-12 16:01:17,158:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:17,158:INFO:Initializing create_model()
2025-10-12 16:01:17,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:17,158:INFO:Checking exceptions
2025-10-12 16:01:17,158:INFO:Importing libraries
2025-10-12 16:01:17,158:INFO:Copying training dataset
2025-10-12 16:01:17,163:INFO:Defining folds
2025-10-12 16:01:17,163:INFO:Declaring metric variables
2025-10-12 16:01:17,166:INFO:Importing untrained model
2025-10-12 16:01:17,170:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:01:17,176:INFO:Starting cross validation
2025-10-12 16:01:17,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:17,263:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:01:17,264:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:01:17,272:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:01:17,273:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:01:17,273:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:01:17,280:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:01:17,281:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:01:17,283:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:01:17,283:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:01:17,283:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:01:17,306:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,307:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,318:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,318:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,322:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,323:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,325:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,327:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,327:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,327:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,345:INFO:Calculating mean and std
2025-10-12 16:01:17,346:INFO:Creating metrics dataframe
2025-10-12 16:01:17,347:INFO:Uploading results into container
2025-10-12 16:01:17,348:INFO:Uploading model into container now
2025-10-12 16:01:17,348:INFO:_master_model_container: 9
2025-10-12 16:01:17,348:INFO:_display_container: 2
2025-10-12 16:01:17,349:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=988)
2025-10-12 16:01:17,349:INFO:create_model() successfully completed......................................
2025-10-12 16:01:17,493:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:17,493:INFO:Creating metrics dataframe
2025-10-12 16:01:17,499:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:01:17,499:INFO:Total runtime is 0.24690460364023847 minutes
2025-10-12 16:01:17,502:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:17,503:INFO:Initializing create_model()
2025-10-12 16:01:17,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:17,503:INFO:Checking exceptions
2025-10-12 16:01:17,503:INFO:Importing libraries
2025-10-12 16:01:17,503:INFO:Copying training dataset
2025-10-12 16:01:17,506:INFO:Defining folds
2025-10-12 16:01:17,507:INFO:Declaring metric variables
2025-10-12 16:01:17,510:INFO:Importing untrained model
2025-10-12 16:01:17,513:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:01:17,518:INFO:Starting cross validation
2025-10-12 16:01:17,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:17,737:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,741:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,743:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,747:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,753:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,753:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,756:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,757:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,758:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,760:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:17,778:INFO:Calculating mean and std
2025-10-12 16:01:17,779:INFO:Creating metrics dataframe
2025-10-12 16:01:17,780:INFO:Uploading results into container
2025-10-12 16:01:17,781:INFO:Uploading model into container now
2025-10-12 16:01:17,781:INFO:_master_model_container: 10
2025-10-12 16:01:17,781:INFO:_display_container: 2
2025-10-12 16:01:17,782:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=988, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:01:17,782:INFO:create_model() successfully completed......................................
2025-10-12 16:01:17,937:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:17,937:INFO:Creating metrics dataframe
2025-10-12 16:01:17,944:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:01:17,944:INFO:Total runtime is 0.2543140053749085 minutes
2025-10-12 16:01:17,946:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:17,947:INFO:Initializing create_model()
2025-10-12 16:01:17,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:17,947:INFO:Checking exceptions
2025-10-12 16:01:17,948:INFO:Importing libraries
2025-10-12 16:01:17,948:INFO:Copying training dataset
2025-10-12 16:01:17,954:INFO:Defining folds
2025-10-12 16:01:17,954:INFO:Declaring metric variables
2025-10-12 16:01:17,957:INFO:Importing untrained model
2025-10-12 16:01:17,960:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:01:17,967:INFO:Starting cross validation
2025-10-12 16:01:17,969:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:18,116:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:18,117:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:18,120:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:18,120:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:18,122:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:18,125:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:18,129:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:18,129:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:18,135:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:18,136:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:18,151:INFO:Calculating mean and std
2025-10-12 16:01:18,152:INFO:Creating metrics dataframe
2025-10-12 16:01:18,154:INFO:Uploading results into container
2025-10-12 16:01:18,154:INFO:Uploading model into container now
2025-10-12 16:01:18,155:INFO:_master_model_container: 11
2025-10-12 16:01:18,155:INFO:_display_container: 2
2025-10-12 16:01:18,155:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:01:18,155:INFO:create_model() successfully completed......................................
2025-10-12 16:01:18,307:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:18,307:INFO:Creating metrics dataframe
2025-10-12 16:01:18,316:INFO:Initializing Extra Trees Classifier
2025-10-12 16:01:18,316:INFO:Total runtime is 0.26051173210144046 minutes
2025-10-12 16:01:18,320:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:18,320:INFO:Initializing create_model()
2025-10-12 16:01:18,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:18,320:INFO:Checking exceptions
2025-10-12 16:01:18,320:INFO:Importing libraries
2025-10-12 16:01:18,320:INFO:Copying training dataset
2025-10-12 16:01:18,325:INFO:Defining folds
2025-10-12 16:01:18,325:INFO:Declaring metric variables
2025-10-12 16:01:18,328:INFO:Importing untrained model
2025-10-12 16:01:18,331:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:01:18,336:INFO:Starting cross validation
2025-10-12 16:01:18,337:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:18,696:INFO:Calculating mean and std
2025-10-12 16:01:18,697:INFO:Creating metrics dataframe
2025-10-12 16:01:18,698:INFO:Uploading results into container
2025-10-12 16:01:18,699:INFO:Uploading model into container now
2025-10-12 16:01:18,699:INFO:_master_model_container: 12
2025-10-12 16:01:18,699:INFO:_display_container: 2
2025-10-12 16:01:18,699:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=988, verbose=0,
                     warm_start=False)
2025-10-12 16:01:18,699:INFO:create_model() successfully completed......................................
2025-10-12 16:01:18,838:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:18,838:INFO:Creating metrics dataframe
2025-10-12 16:01:18,844:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:01:18,844:INFO:Total runtime is 0.26931937535603845 minutes
2025-10-12 16:01:18,847:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:18,847:INFO:Initializing create_model()
2025-10-12 16:01:18,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:18,847:INFO:Checking exceptions
2025-10-12 16:01:18,847:INFO:Importing libraries
2025-10-12 16:01:18,847:INFO:Copying training dataset
2025-10-12 16:01:18,851:INFO:Defining folds
2025-10-12 16:01:18,851:INFO:Declaring metric variables
2025-10-12 16:01:18,853:INFO:Importing untrained model
2025-10-12 16:01:18,858:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:01:18,863:INFO:Starting cross validation
2025-10-12 16:01:18,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:19,502:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:19,598:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:19,609:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:19,613:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:19,623:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:19,627:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:19,630:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:19,637:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:19,638:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:19,641:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:19,646:INFO:Calculating mean and std
2025-10-12 16:01:19,647:INFO:Creating metrics dataframe
2025-10-12 16:01:19,648:INFO:Uploading results into container
2025-10-12 16:01:19,649:INFO:Uploading model into container now
2025-10-12 16:01:19,649:INFO:_master_model_container: 13
2025-10-12 16:01:19,649:INFO:_display_container: 2
2025-10-12 16:01:19,650:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:01:19,650:INFO:create_model() successfully completed......................................
2025-10-12 16:01:19,799:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:19,800:INFO:Creating metrics dataframe
2025-10-12 16:01:19,806:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:01:19,807:INFO:Total runtime is 0.28536563316981 minutes
2025-10-12 16:01:19,809:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:19,810:INFO:Initializing create_model()
2025-10-12 16:01:19,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:19,810:INFO:Checking exceptions
2025-10-12 16:01:19,810:INFO:Importing libraries
2025-10-12 16:01:19,810:INFO:Copying training dataset
2025-10-12 16:01:19,814:INFO:Defining folds
2025-10-12 16:01:19,814:INFO:Declaring metric variables
2025-10-12 16:01:19,817:INFO:Importing untrained model
2025-10-12 16:01:19,821:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:01:19,827:INFO:Starting cross validation
2025-10-12 16:01:19,829:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:20,132:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:20,151:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:20,156:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:20,159:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:20,160:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:20,174:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:20,192:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:20,208:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:20,211:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:20,227:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:20,236:INFO:Calculating mean and std
2025-10-12 16:01:20,237:INFO:Creating metrics dataframe
2025-10-12 16:01:20,239:INFO:Uploading results into container
2025-10-12 16:01:20,240:INFO:Uploading model into container now
2025-10-12 16:01:20,240:INFO:_master_model_container: 14
2025-10-12 16:01:20,240:INFO:_display_container: 2
2025-10-12 16:01:20,241:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=988, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:01:20,241:INFO:create_model() successfully completed......................................
2025-10-12 16:01:20,397:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:20,397:INFO:Creating metrics dataframe
2025-10-12 16:01:20,405:INFO:Initializing CatBoost Classifier
2025-10-12 16:01:20,405:INFO:Total runtime is 0.29532771905263266 minutes
2025-10-12 16:01:20,407:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:20,407:INFO:Initializing create_model()
2025-10-12 16:01:20,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:20,407:INFO:Checking exceptions
2025-10-12 16:01:20,407:INFO:Importing libraries
2025-10-12 16:01:20,407:INFO:Copying training dataset
2025-10-12 16:01:20,413:INFO:Defining folds
2025-10-12 16:01:20,413:INFO:Declaring metric variables
2025-10-12 16:01:20,416:INFO:Importing untrained model
2025-10-12 16:01:20,420:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:01:20,426:INFO:Starting cross validation
2025-10-12 16:01:20,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:23,597:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:23,603:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:23,640:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:23,671:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:23,679:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,039:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,051:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,073:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,097:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,115:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,122:INFO:Calculating mean and std
2025-10-12 16:01:25,123:INFO:Creating metrics dataframe
2025-10-12 16:01:25,126:INFO:Uploading results into container
2025-10-12 16:01:25,126:INFO:Uploading model into container now
2025-10-12 16:01:25,127:INFO:_master_model_container: 15
2025-10-12 16:01:25,127:INFO:_display_container: 2
2025-10-12 16:01:25,127:INFO:<catboost.core.CatBoostClassifier object at 0x00000265DBCE6DF0>
2025-10-12 16:01:25,127:INFO:create_model() successfully completed......................................
2025-10-12 16:01:25,283:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:25,285:INFO:Creating metrics dataframe
2025-10-12 16:01:25,292:INFO:Initializing Dummy Classifier
2025-10-12 16:01:25,292:INFO:Total runtime is 0.376786474386851 minutes
2025-10-12 16:01:25,296:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:25,296:INFO:Initializing create_model()
2025-10-12 16:01:25,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECC9880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:25,297:INFO:Checking exceptions
2025-10-12 16:01:25,297:INFO:Importing libraries
2025-10-12 16:01:25,297:INFO:Copying training dataset
2025-10-12 16:01:25,301:INFO:Defining folds
2025-10-12 16:01:25,301:INFO:Declaring metric variables
2025-10-12 16:01:25,305:INFO:Importing untrained model
2025-10-12 16:01:25,309:INFO:Dummy Classifier Imported successfully
2025-10-12 16:01:25,314:INFO:Starting cross validation
2025-10-12 16:01:25,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:25,441:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,447:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,453:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,455:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,455:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,455:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,456:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,457:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,457:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,466:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:01:25,480:INFO:Calculating mean and std
2025-10-12 16:01:25,481:INFO:Creating metrics dataframe
2025-10-12 16:01:25,482:INFO:Uploading results into container
2025-10-12 16:01:25,483:INFO:Uploading model into container now
2025-10-12 16:01:25,483:INFO:_master_model_container: 16
2025-10-12 16:01:25,483:INFO:_display_container: 2
2025-10-12 16:01:25,483:INFO:DummyClassifier(constant=None, random_state=988, strategy='prior')
2025-10-12 16:01:25,484:INFO:create_model() successfully completed......................................
2025-10-12 16:01:25,622:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:25,622:INFO:Creating metrics dataframe
2025-10-12 16:01:25,632:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:01:25,640:INFO:Initializing create_model()
2025-10-12 16:01:25,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:25,640:INFO:Checking exceptions
2025-10-12 16:01:25,641:INFO:Importing libraries
2025-10-12 16:01:25,642:INFO:Copying training dataset
2025-10-12 16:01:25,643:INFO:Defining folds
2025-10-12 16:01:25,643:INFO:Declaring metric variables
2025-10-12 16:01:25,644:INFO:Importing untrained model
2025-10-12 16:01:25,644:INFO:Declaring custom model
2025-10-12 16:01:25,644:INFO:Logistic Regression Imported successfully
2025-10-12 16:01:25,645:INFO:Cross validation set to False
2025-10-12 16:01:25,645:INFO:Fitting Model
2025-10-12 16:01:25,742:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:25,742:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:01:25,742:INFO:create_model() successfully completed......................................
2025-10-12 16:01:25,890:INFO:Creating Dashboard logs
2025-10-12 16:01:25,893:INFO:Model: Logistic Regression
2025-10-12 16:01:25,961:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 988, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:01:26,218:INFO:Initializing predict_model()
2025-10-12 16:01:26,218:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DFF500D0>)
2025-10-12 16:01:26,218:INFO:Checking exceptions
2025-10-12 16:01:26,218:INFO:Preloading libraries
2025-10-12 16:01:26,536:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:01:26,537:INFO:Initializing plot_model()
2025-10-12 16:01:26,537:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp9j9dmtc9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:01:26,537:INFO:Checking exceptions
2025-10-12 16:01:26,538:INFO:Preloading libraries
2025-10-12 16:01:26,538:INFO:Copying training dataset
2025-10-12 16:01:26,538:INFO:Plot type: auc
2025-10-12 16:01:26,823:INFO:Fitting Model
2025-10-12 16:01:26,823:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:01:26,823:INFO:Scoring test/hold-out set
2025-10-12 16:01:26,838:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp9j9dmtc9\AUC.png'
2025-10-12 16:01:27,015:INFO:Visual Rendered Successfully
2025-10-12 16:01:27,165:INFO:plot_model() successfully completed......................................
2025-10-12 16:01:27,196:INFO:Initializing plot_model()
2025-10-12 16:01:27,196:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp9j9dmtc9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:01:27,196:INFO:Checking exceptions
2025-10-12 16:01:27,198:INFO:Preloading libraries
2025-10-12 16:01:27,198:INFO:Copying training dataset
2025-10-12 16:01:27,198:INFO:Plot type: confusion_matrix
2025-10-12 16:01:27,473:INFO:Fitting Model
2025-10-12 16:01:27,473:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:01:27,473:INFO:Scoring test/hold-out set
2025-10-12 16:01:27,485:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp9j9dmtc9\Confusion Matrix.png'
2025-10-12 16:01:27,560:INFO:Visual Rendered Successfully
2025-10-12 16:01:27,706:INFO:plot_model() successfully completed......................................
2025-10-12 16:01:27,726:INFO:Initializing plot_model()
2025-10-12 16:01:27,726:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp9j9dmtc9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:01:27,726:INFO:Checking exceptions
2025-10-12 16:01:27,728:INFO:Preloading libraries
2025-10-12 16:01:27,728:INFO:Copying training dataset
2025-10-12 16:01:27,728:INFO:Plot type: feature
2025-10-12 16:01:27,871:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp9j9dmtc9\Feature Importance.png'
2025-10-12 16:01:27,994:INFO:Visual Rendered Successfully
2025-10-12 16:01:28,153:INFO:plot_model() successfully completed......................................
2025-10-12 16:01:28,177:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:01:28,417:INFO:Creating Dashboard logs
2025-10-12 16:01:28,420:INFO:Model: Ridge Classifier
2025-10-12 16:01:28,499:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 988, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:01:28,954:INFO:Creating Dashboard logs
2025-10-12 16:01:28,957:INFO:Model: Extra Trees Classifier
2025-10-12 16:01:29,021:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 988, 'verbose': 0, 'warm_start': False}
2025-10-12 16:01:29,473:INFO:Creating Dashboard logs
2025-10-12 16:01:29,477:INFO:Model: Naive Bayes
2025-10-12 16:01:29,549:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:01:29,973:INFO:Creating Dashboard logs
2025-10-12 16:01:29,977:INFO:Model: K Neighbors Classifier
2025-10-12 16:01:30,044:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:01:30,486:INFO:Creating Dashboard logs
2025-10-12 16:01:30,490:INFO:Model: Random Forest Classifier
2025-10-12 16:01:30,553:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 988, 'verbose': 0, 'warm_start': False}
2025-10-12 16:01:31,008:INFO:Creating Dashboard logs
2025-10-12 16:01:31,012:INFO:Model: Decision Tree Classifier
2025-10-12 16:01:31,079:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 988, 'splitter': 'best'}
2025-10-12 16:01:31,468:INFO:Creating Dashboard logs
2025-10-12 16:01:31,471:INFO:Model: Ada Boost Classifier
2025-10-12 16:01:31,539:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 988}
2025-10-12 16:01:31,905:INFO:Creating Dashboard logs
2025-10-12 16:01:31,907:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:01:31,979:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 988, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:01:32,389:INFO:Creating Dashboard logs
2025-10-12 16:01:32,392:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:01:32,456:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:01:32,857:INFO:Creating Dashboard logs
2025-10-12 16:01:32,859:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:01:32,942:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 988, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:01:33,402:INFO:Creating Dashboard logs
2025-10-12 16:01:33,406:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:01:33,473:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 988, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:01:33,893:INFO:Creating Dashboard logs
2025-10-12 16:01:33,896:INFO:Model: CatBoost Classifier
2025-10-12 16:01:33,960:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-10-12 16:01:33,960:INFO:Logged params: {}
2025-10-12 16:01:34,330:INFO:Creating Dashboard logs
2025-10-12 16:01:34,333:INFO:Model: Dummy Classifier
2025-10-12 16:01:34,398:INFO:Logged params: {'constant': None, 'random_state': 988, 'strategy': 'prior'}
2025-10-12 16:01:34,762:INFO:Creating Dashboard logs
2025-10-12 16:01:34,766:INFO:Model: SVM - Linear Kernel
2025-10-12 16:01:34,836:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 988, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:01:35,312:INFO:Creating Dashboard logs
2025-10-12 16:01:35,314:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 16:01:35,382:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:01:35,818:INFO:_master_model_container: 16
2025-10-12 16:01:35,818:INFO:_display_container: 2
2025-10-12 16:01:35,819:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:01:35,819:INFO:compare_models() successfully completed......................................
2025-10-12 16:01:38,098:INFO:Initializing finalize_model()
2025-10-12 16:01:38,099:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-12 16:01:38,099:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:01:38,102:INFO:Initializing create_model()
2025-10-12 16:01:38,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:38,102:INFO:Checking exceptions
2025-10-12 16:01:38,105:INFO:Importing libraries
2025-10-12 16:01:38,105:INFO:Copying training dataset
2025-10-12 16:01:38,106:INFO:Defining folds
2025-10-12 16:01:38,106:INFO:Declaring metric variables
2025-10-12 16:01:38,106:INFO:Importing untrained model
2025-10-12 16:01:38,106:INFO:Declaring custom model
2025-10-12 16:01:38,106:INFO:Logistic Regression Imported successfully
2025-10-12 16:01:38,107:INFO:Cross validation set to False
2025-10-12 16:01:38,107:INFO:Fitting Model
2025-10-12 16:01:38,669:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:38,685:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=988,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-10-12 16:01:38,685:INFO:create_model() successfully completed......................................
2025-10-12 16:01:38,831:INFO:Creating Dashboard logs
2025-10-12 16:01:38,832:INFO:Model: Logistic Regression
2025-10-12 16:01:38,896:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 988, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:01:39,032:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:01:39,046:INFO:Initializing plot_model()
2025-10-12 16:01:39,046:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=988,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpxtzg2tjh, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:01:39,046:INFO:Checking exceptions
2025-10-12 16:01:39,047:INFO:Preloading libraries
2025-10-12 16:01:39,047:INFO:Copying training dataset
2025-10-12 16:01:39,048:INFO:Plot type: auc
2025-10-12 16:01:39,379:INFO:Fitting Model
2025-10-12 16:01:39,379:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:01:39,379:INFO:Scoring test/hold-out set
2025-10-12 16:01:39,397:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpxtzg2tjh\AUC.png'
2025-10-12 16:01:39,571:INFO:Visual Rendered Successfully
2025-10-12 16:01:39,720:INFO:plot_model() successfully completed......................................
2025-10-12 16:01:39,765:INFO:Initializing plot_model()
2025-10-12 16:01:39,765:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=988,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpxtzg2tjh, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:01:39,766:INFO:Checking exceptions
2025-10-12 16:01:39,766:INFO:Preloading libraries
2025-10-12 16:01:39,767:INFO:Copying training dataset
2025-10-12 16:01:39,767:INFO:Plot type: confusion_matrix
2025-10-12 16:01:40,070:INFO:Fitting Model
2025-10-12 16:01:40,070:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:01:40,070:INFO:Scoring test/hold-out set
2025-10-12 16:01:40,086:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpxtzg2tjh\Confusion Matrix.png'
2025-10-12 16:01:40,171:INFO:Visual Rendered Successfully
2025-10-12 16:01:40,318:INFO:plot_model() successfully completed......................................
2025-10-12 16:01:40,349:INFO:Initializing plot_model()
2025-10-12 16:01:40,349:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=988,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpxtzg2tjh, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:01:40,349:INFO:Checking exceptions
2025-10-12 16:01:40,351:INFO:Preloading libraries
2025-10-12 16:01:40,351:INFO:Copying training dataset
2025-10-12 16:01:40,351:INFO:Plot type: feature
2025-10-12 16:01:40,521:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpxtzg2tjh\Feature Importance.png'
2025-10-12 16:01:40,646:INFO:Visual Rendered Successfully
2025-10-12 16:01:40,799:INFO:plot_model() successfully completed......................................
2025-10-12 16:01:40,823:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:01:41,053:INFO:_master_model_container: 16
2025-10-12 16:01:41,053:INFO:_display_container: 2
2025-10-12 16:01:41,069:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=988,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-10-12 16:01:41,069:INFO:finalize_model() successfully completed......................................
2025-10-12 16:01:41,244:INFO:Initializing save_model()
2025-10-12 16:01:41,244:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=988,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), model_name=Titanic_modelV1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 16:01:41,244:INFO:Adding model into prep_pipe
2025-10-12 16:01:41,244:WARNING:Only Model saved as it was a pipeline.
2025-10-12 16:01:41,251:INFO:Titanic_modelV1.pkl saved in current working directory
2025-10-12 16:01:41,265:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=988,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-10-12 16:01:41,265:INFO:save_model() successfully completed......................................
2025-10-12 16:01:43,280:INFO:Initializing tune_model()
2025-10-12 16:01:43,280:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>)
2025-10-12 16:01:43,280:INFO:Checking exceptions
2025-10-12 16:01:43,293:INFO:Copying training dataset
2025-10-12 16:01:43,298:INFO:Checking base model
2025-10-12 16:01:43,298:INFO:Base model : Logistic Regression
2025-10-12 16:01:43,301:INFO:Declaring metric variables
2025-10-12 16:01:43,304:INFO:Defining Hyperparameters
2025-10-12 16:01:43,466:INFO:Tuning with n_jobs=-1
2025-10-12 16:01:43,466:INFO:Initializing RandomizedSearchCV
2025-10-12 16:01:43,723:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:43,741:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:43,752:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:43,777:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:43,795:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:43,801:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:43,802:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:43,803:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:43,828:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:43,864:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:43,877:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:43,971:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:43,989:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:43,997:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,012:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,020:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,043:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,053:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,108:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,153:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,155:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,170:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,195:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,203:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,214:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,238:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,265:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,276:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,305:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,323:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,369:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,427:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,460:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,473:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,480:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,482:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,507:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,508:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,519:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,525:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,574:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,642:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,700:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,702:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,707:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,727:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,783:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,800:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,819:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,846:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,862:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,876:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,890:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,890:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,953:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:44,987:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,042:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,043:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,087:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,087:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,132:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,146:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,161:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,198:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,198:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,211:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,234:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,240:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,253:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,284:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,296:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,370:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,398:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,444:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,475:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,492:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,503:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,523:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,552:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,553:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,557:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,609:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,617:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,642:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,669:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,688:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,722:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,806:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,806:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,807:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,841:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,844:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,873:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,887:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,887:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,900:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,940:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,950:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,961:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:45,976:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,001:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.938000000000001}
2025-10-12 16:01:46,002:INFO:Hyperparameter search completed
2025-10-12 16:01:46,002:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:46,003:INFO:Initializing create_model()
2025-10-12 16:01:46,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.938000000000001})
2025-10-12 16:01:46,003:INFO:Checking exceptions
2025-10-12 16:01:46,003:INFO:Importing libraries
2025-10-12 16:01:46,003:INFO:Copying training dataset
2025-10-12 16:01:46,007:INFO:Defining folds
2025-10-12 16:01:46,007:INFO:Declaring metric variables
2025-10-12 16:01:46,010:INFO:Importing untrained model
2025-10-12 16:01:46,010:INFO:Declaring custom model
2025-10-12 16:01:46,013:INFO:Logistic Regression Imported successfully
2025-10-12 16:01:46,019:INFO:Starting cross validation
2025-10-12 16:01:46,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:46,197:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,204:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,230:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,261:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,275:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,276:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,279:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,283:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,284:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,320:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,357:INFO:Calculating mean and std
2025-10-12 16:01:46,358:INFO:Creating metrics dataframe
2025-10-12 16:01:46,362:INFO:Finalizing model
2025-10-12 16:01:46,468:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:46,472:INFO:Uploading results into container
2025-10-12 16:01:46,473:INFO:Uploading model into container now
2025-10-12 16:01:46,473:INFO:_master_model_container: 17
2025-10-12 16:01:46,473:INFO:_display_container: 3
2025-10-12 16:01:46,474:INFO:LogisticRegression(C=5.938000000000001, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:01:46,474:INFO:create_model() successfully completed......................................
2025-10-12 16:01:46,614:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:46,614:INFO:choose_better activated
2025-10-12 16:01:46,617:INFO:SubProcess create_model() called ==================================
2025-10-12 16:01:46,618:INFO:Initializing create_model()
2025-10-12 16:01:46,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:01:46,618:INFO:Checking exceptions
2025-10-12 16:01:46,619:INFO:Importing libraries
2025-10-12 16:01:46,619:INFO:Copying training dataset
2025-10-12 16:01:46,622:INFO:Defining folds
2025-10-12 16:01:46,622:INFO:Declaring metric variables
2025-10-12 16:01:46,622:INFO:Importing untrained model
2025-10-12 16:01:46,622:INFO:Declaring custom model
2025-10-12 16:01:46,623:INFO:Logistic Regression Imported successfully
2025-10-12 16:01:46,623:INFO:Starting cross validation
2025-10-12 16:01:46,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:01:46,806:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,818:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,825:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,834:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,897:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,905:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,907:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,910:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,934:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,935:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:01:46,993:INFO:Calculating mean and std
2025-10-12 16:01:46,993:INFO:Creating metrics dataframe
2025-10-12 16:01:46,994:INFO:Finalizing model
2025-10-12 16:01:47,115:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:47,116:INFO:Uploading results into container
2025-10-12 16:01:47,116:INFO:Uploading model into container now
2025-10-12 16:01:47,116:INFO:_master_model_container: 18
2025-10-12 16:01:47,116:INFO:_display_container: 4
2025-10-12 16:01:47,117:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:01:47,117:INFO:create_model() successfully completed......................................
2025-10-12 16:01:47,269:INFO:SubProcess create_model() end ==================================
2025-10-12 16:01:47,269:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8632
2025-10-12 16:01:47,270:INFO:LogisticRegression(C=5.938000000000001, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8779
2025-10-12 16:01:47,270:INFO:LogisticRegression(C=5.938000000000001, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-10-12 16:01:47,270:INFO:choose_better completed
2025-10-12 16:01:47,270:INFO:Creating Dashboard logs
2025-10-12 16:01:47,273:INFO:Model: Logistic Regression
2025-10-12 16:01:47,365:INFO:Logged params: {'C': 5.938000000000001, 'class_weight': {}, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 988, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:01:47,621:INFO:Initializing predict_model()
2025-10-12 16:01:47,621:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=5.938000000000001, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DD68FDC0>)
2025-10-12 16:01:47,621:INFO:Checking exceptions
2025-10-12 16:01:47,621:INFO:Preloading libraries
2025-10-12 16:01:47,963:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:01:47,964:INFO:Initializing plot_model()
2025-10-12 16:01:47,964:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=5.938000000000001, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpi0q3ngvm, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:01:47,964:INFO:Checking exceptions
2025-10-12 16:01:47,965:INFO:Preloading libraries
2025-10-12 16:01:47,965:INFO:Copying training dataset
2025-10-12 16:01:47,965:INFO:Plot type: auc
2025-10-12 16:01:48,257:INFO:Fitting Model
2025-10-12 16:01:48,257:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:01:48,257:INFO:Scoring test/hold-out set
2025-10-12 16:01:48,272:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpi0q3ngvm\AUC.png'
2025-10-12 16:01:48,456:INFO:Visual Rendered Successfully
2025-10-12 16:01:48,595:INFO:plot_model() successfully completed......................................
2025-10-12 16:01:48,611:INFO:Initializing plot_model()
2025-10-12 16:01:48,612:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=5.938000000000001, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpi0q3ngvm, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:01:48,612:INFO:Checking exceptions
2025-10-12 16:01:48,613:INFO:Preloading libraries
2025-10-12 16:01:48,613:INFO:Copying training dataset
2025-10-12 16:01:48,613:INFO:Plot type: confusion_matrix
2025-10-12 16:01:48,883:INFO:Fitting Model
2025-10-12 16:01:48,883:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:01:48,883:INFO:Scoring test/hold-out set
2025-10-12 16:01:48,896:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpi0q3ngvm\Confusion Matrix.png'
2025-10-12 16:01:48,987:INFO:Visual Rendered Successfully
2025-10-12 16:01:49,126:INFO:plot_model() successfully completed......................................
2025-10-12 16:01:49,146:INFO:Initializing plot_model()
2025-10-12 16:01:49,146:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=5.938000000000001, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpi0q3ngvm, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:01:49,146:INFO:Checking exceptions
2025-10-12 16:01:49,148:INFO:Preloading libraries
2025-10-12 16:01:49,148:INFO:Copying training dataset
2025-10-12 16:01:49,148:INFO:Plot type: feature
2025-10-12 16:01:49,300:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpi0q3ngvm\Feature Importance.png'
2025-10-12 16:01:49,426:INFO:Visual Rendered Successfully
2025-10-12 16:01:49,566:INFO:plot_model() successfully completed......................................
2025-10-12 16:01:49,582:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:01:49,845:INFO:_master_model_container: 18
2025-10-12 16:01:49,845:INFO:_display_container: 3
2025-10-12 16:01:49,846:INFO:LogisticRegression(C=5.938000000000001, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:01:49,846:INFO:tune_model() successfully completed......................................
2025-10-12 16:01:51,688:INFO:Initializing tune_model()
2025-10-12 16:01:51,688:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>)
2025-10-12 16:01:51,689:INFO:Checking exceptions
2025-10-12 16:01:51,689:INFO:Soft dependency imported: optuna: 4.5.0
2025-10-12 16:01:51,702:INFO:Copying training dataset
2025-10-12 16:01:51,705:INFO:Checking base model
2025-10-12 16:01:51,705:INFO:Base model : Logistic Regression
2025-10-12 16:01:51,708:INFO:Declaring metric variables
2025-10-12 16:01:51,711:INFO:Defining Hyperparameters
2025-10-12 16:01:51,892:INFO:Tuning with n_jobs=-1
2025-10-12 16:01:51,893:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.

2025-10-12 16:01:51,893:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.

2025-10-12 16:01:51,893:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.

2025-10-12 16:01:51,893:INFO:Initializing optuna.integration.OptunaSearchCV
2025-10-12 16:01:51,893:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.

2025-10-12 16:01:54,185:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:54,228:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:54,235:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:54,281:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:54,359:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:54,376:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:54,380:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:54,382:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:54,607:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:54,773:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:56,814:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:56,856:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:56,957:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:56,965:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:57,116:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:57,178:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:57,222:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:57,259:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:57,398:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:59,233:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:59,403:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:59,540:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:59,597:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:59,697:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:59,701:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:01:59,910:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:00,003:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:00,123:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:00,125:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:01,960:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:02,073:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:02,329:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:02,331:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:02,392:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:02,465:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:02,623:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:02,860:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:02,896:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:03,173:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:04,591:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:04,798:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:04,993:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:04,996:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:05,101:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:05,204:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:05,257:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:05,391:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:05,577:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:05,902:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:07,223:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:07,383:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:07,595:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:07,693:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:07,722:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:07,878:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:07,973:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:08,103:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:08,348:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:08,642:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:09,643:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:09,696:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:09,960:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:10,016:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:10,018:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:10,046:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:10,106:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:10,464:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:10,656:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:10,757:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:11,765:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:11,861:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:12,086:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:12,119:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:12,126:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:12,161:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:12,509:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:12,536:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:12,834:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:12,892:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:13,889:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:14,013:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:14,169:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:14,286:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:14,352:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:14,504:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:14,604:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:14,685:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:14,995:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:15,037:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:15,987:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:16,044:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:16,147:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:16,212:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:16,253:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:16,318:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:16,321:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:16,357:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:16,439:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:16,462:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:16,486:INFO:best_params: {'actual_estimator__C': 7.064061213381749, 'actual_estimator__class_weight': {}}
2025-10-12 16:02:16,487:INFO:Hyperparameter search completed
2025-10-12 16:02:16,487:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:16,487:INFO:Initializing create_model()
2025-10-12 16:02:16,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DDB73F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'C': 7.064061213381749, 'class_weight': {}})
2025-10-12 16:02:16,487:INFO:Checking exceptions
2025-10-12 16:02:16,487:INFO:Importing libraries
2025-10-12 16:02:16,487:INFO:Copying training dataset
2025-10-12 16:02:16,490:INFO:Defining folds
2025-10-12 16:02:16,491:INFO:Declaring metric variables
2025-10-12 16:02:16,493:INFO:Importing untrained model
2025-10-12 16:02:16,493:INFO:Declaring custom model
2025-10-12 16:02:16,497:INFO:Logistic Regression Imported successfully
2025-10-12 16:02:16,503:INFO:Starting cross validation
2025-10-12 16:02:16,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:16,720:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:16,725:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:16,732:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:16,736:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:16,740:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:16,742:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:16,742:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:16,749:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:16,753:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:16,789:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:16,823:INFO:Calculating mean and std
2025-10-12 16:02:16,825:INFO:Creating metrics dataframe
2025-10-12 16:02:16,828:INFO:Finalizing model
2025-10-12 16:02:16,938:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:16,942:INFO:Uploading results into container
2025-10-12 16:02:16,943:INFO:Uploading model into container now
2025-10-12 16:02:16,943:INFO:_master_model_container: 19
2025-10-12 16:02:16,944:INFO:_display_container: 4
2025-10-12 16:02:16,944:INFO:LogisticRegression(C=7.064061213381749, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:02:16,944:INFO:create_model() successfully completed......................................
2025-10-12 16:02:17,123:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:17,123:INFO:choose_better activated
2025-10-12 16:02:17,126:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:17,127:INFO:Initializing create_model()
2025-10-12 16:02:17,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:17,127:INFO:Checking exceptions
2025-10-12 16:02:17,128:INFO:Importing libraries
2025-10-12 16:02:17,128:INFO:Copying training dataset
2025-10-12 16:02:17,131:INFO:Defining folds
2025-10-12 16:02:17,131:INFO:Declaring metric variables
2025-10-12 16:02:17,131:INFO:Importing untrained model
2025-10-12 16:02:17,131:INFO:Declaring custom model
2025-10-12 16:02:17,131:INFO:Logistic Regression Imported successfully
2025-10-12 16:02:17,131:INFO:Starting cross validation
2025-10-12 16:02:17,132:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:17,340:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:17,346:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:17,351:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:17,352:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:17,355:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:17,356:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:17,356:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:17,361:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:17,372:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:17,398:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:17,443:INFO:Calculating mean and std
2025-10-12 16:02:17,443:INFO:Creating metrics dataframe
2025-10-12 16:02:17,445:INFO:Finalizing model
2025-10-12 16:02:17,550:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:17,550:INFO:Uploading results into container
2025-10-12 16:02:17,551:INFO:Uploading model into container now
2025-10-12 16:02:17,551:INFO:_master_model_container: 20
2025-10-12 16:02:17,551:INFO:_display_container: 5
2025-10-12 16:02:17,551:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:02:17,551:INFO:create_model() successfully completed......................................
2025-10-12 16:02:17,701:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:17,702:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8632
2025-10-12 16:02:17,702:INFO:LogisticRegression(C=7.064061213381749, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8742
2025-10-12 16:02:17,703:INFO:LogisticRegression(C=7.064061213381749, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-10-12 16:02:17,703:INFO:choose_better completed
2025-10-12 16:02:17,703:INFO:Creating Dashboard logs
2025-10-12 16:02:17,706:INFO:Model: Logistic Regression
2025-10-12 16:02:17,789:INFO:Logged params: {'C': 7.064061213381749, 'class_weight': {}, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 988, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:02:18,062:INFO:Initializing predict_model()
2025-10-12 16:02:18,062:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=7.064061213381749, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E029BEE0>)
2025-10-12 16:02:18,062:INFO:Checking exceptions
2025-10-12 16:02:18,062:INFO:Preloading libraries
2025-10-12 16:02:18,392:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:02:18,393:INFO:Initializing plot_model()
2025-10-12 16:02:18,393:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=7.064061213381749, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpslj8_8xk, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:18,393:INFO:Checking exceptions
2025-10-12 16:02:18,394:INFO:Preloading libraries
2025-10-12 16:02:18,394:INFO:Copying training dataset
2025-10-12 16:02:18,394:INFO:Plot type: auc
2025-10-12 16:02:18,668:INFO:Fitting Model
2025-10-12 16:02:18,668:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:02:18,669:INFO:Scoring test/hold-out set
2025-10-12 16:02:18,684:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpslj8_8xk\AUC.png'
2025-10-12 16:02:18,837:INFO:Visual Rendered Successfully
2025-10-12 16:02:18,977:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:19,003:INFO:Initializing plot_model()
2025-10-12 16:02:19,003:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=7.064061213381749, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpslj8_8xk, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:19,005:INFO:Checking exceptions
2025-10-12 16:02:19,006:INFO:Preloading libraries
2025-10-12 16:02:19,006:INFO:Copying training dataset
2025-10-12 16:02:19,006:INFO:Plot type: confusion_matrix
2025-10-12 16:02:19,287:INFO:Fitting Model
2025-10-12 16:02:19,287:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:02:19,287:INFO:Scoring test/hold-out set
2025-10-12 16:02:19,302:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpslj8_8xk\Confusion Matrix.png'
2025-10-12 16:02:19,398:INFO:Visual Rendered Successfully
2025-10-12 16:02:19,543:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:19,557:INFO:Initializing plot_model()
2025-10-12 16:02:19,557:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=7.064061213381749, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpslj8_8xk, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:19,557:INFO:Checking exceptions
2025-10-12 16:02:19,558:INFO:Preloading libraries
2025-10-12 16:02:19,558:INFO:Copying training dataset
2025-10-12 16:02:19,558:INFO:Plot type: feature
2025-10-12 16:02:19,698:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpslj8_8xk\Feature Importance.png'
2025-10-12 16:02:19,798:INFO:Visual Rendered Successfully
2025-10-12 16:02:19,941:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:19,963:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:02:20,205:INFO:_master_model_container: 20
2025-10-12 16:02:20,205:INFO:_display_container: 4
2025-10-12 16:02:20,207:INFO:LogisticRegression(C=7.064061213381749, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:02:20,207:INFO:tune_model() successfully completed......................................
2025-10-12 16:02:22,119:INFO:Initializing ensemble_model()
2025-10-12 16:02:22,120:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), method=Bagging, fold=None, n_estimators=5, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:02:22,120:INFO:Checking exceptions
2025-10-12 16:02:22,132:INFO:Importing libraries
2025-10-12 16:02:22,132:INFO:Copying training dataset
2025-10-12 16:02:22,132:INFO:Checking base model
2025-10-12 16:02:22,132:INFO:Base model : Logistic Regression
2025-10-12 16:02:22,137:INFO:Importing untrained ensembler
2025-10-12 16:02:22,138:INFO:Ensemble method set to Bagging
2025-10-12 16:02:22,138:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:22,138:INFO:Initializing create_model()
2025-10-12 16:02:22,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=988,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=988, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB87D640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:22,139:INFO:Checking exceptions
2025-10-12 16:02:22,139:INFO:Importing libraries
2025-10-12 16:02:22,139:INFO:Copying training dataset
2025-10-12 16:02:22,143:INFO:Defining folds
2025-10-12 16:02:22,143:INFO:Declaring metric variables
2025-10-12 16:02:22,146:INFO:Importing untrained model
2025-10-12 16:02:22,146:INFO:Declaring custom model
2025-10-12 16:02:22,149:INFO:Logistic Regression Imported successfully
2025-10-12 16:02:22,156:INFO:Starting cross validation
2025-10-12 16:02:22,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:22,362:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,367:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,375:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,401:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,422:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,422:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,428:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,440:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,454:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,454:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,479:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,481:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,488:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,591:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,598:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,605:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,617:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,630:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,632:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,632:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,639:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,645:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,659:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,691:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,700:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,735:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,736:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,747:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,754:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,761:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,766:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,770:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,796:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,813:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,816:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,860:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,867:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,875:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,887:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,887:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,893:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,899:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,917:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,953:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,975:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,980:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,990:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:22,991:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:23,007:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:23,009:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:23,062:INFO:Calculating mean and std
2025-10-12 16:02:23,062:INFO:Creating metrics dataframe
2025-10-12 16:02:23,067:INFO:Finalizing model
2025-10-12 16:02:23,180:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:23,240:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:23,303:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:23,376:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:23,441:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:23,447:INFO:Uploading results into container
2025-10-12 16:02:23,447:INFO:Uploading model into container now
2025-10-12 16:02:23,448:INFO:_master_model_container: 21
2025-10-12 16:02:23,448:INFO:_display_container: 5
2025-10-12 16:02:23,449:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=988,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=988, verbose=0,
                  warm_start=False)
2025-10-12 16:02:23,449:INFO:create_model() successfully completed......................................
2025-10-12 16:02:23,617:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:23,617:INFO:Creating Dashboard logs
2025-10-12 16:02:23,620:INFO:Model: Logistic Regression
2025-10-12 16:02:23,707:INFO:Logged params: {'bootstrap': True, 'bootstrap_features': False, 'estimator__C': 1.0, 'estimator__class_weight': None, 'estimator__dual': False, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__l1_ratio': None, 'estimator__max_iter': 1000, 'estimator__multi_class': 'auto', 'estimator__n_jobs': None, 'estimator__penalty': 'l2', 'estimator__random_state': 988, 'estimator__solver': 'lbfgs', 'estimator__tol': 0.0001, 'estimator__verbose': 0, 'estimator__warm_start': False, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 5, 'n_jobs': None, 'oob_score': False, 'random_state': 988, 'verbose': 0, 'warm_start': False}
2025-10-12 16:02:23,954:INFO:Initializing predict_model()
2025-10-12 16:02:23,954:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=988,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=988, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DEE75B80>)
2025-10-12 16:02:23,954:INFO:Checking exceptions
2025-10-12 16:02:23,954:INFO:Preloading libraries
2025-10-12 16:02:24,279:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:02:24,280:INFO:Initializing plot_model()
2025-10-12 16:02:24,280:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=988,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=988, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpwkxik6bl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:24,280:INFO:Checking exceptions
2025-10-12 16:02:24,282:INFO:Preloading libraries
2025-10-12 16:02:24,282:INFO:Copying training dataset
2025-10-12 16:02:24,282:INFO:Plot type: auc
2025-10-12 16:02:24,581:INFO:Fitting Model
2025-10-12 16:02:24,582:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 16:02:24,582:INFO:Scoring test/hold-out set
2025-10-12 16:02:24,597:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpwkxik6bl\AUC.png'
2025-10-12 16:02:24,755:INFO:Visual Rendered Successfully
2025-10-12 16:02:24,896:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:24,913:INFO:Initializing plot_model()
2025-10-12 16:02:24,913:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=988,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=988, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpwkxik6bl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:24,913:INFO:Checking exceptions
2025-10-12 16:02:24,914:INFO:Preloading libraries
2025-10-12 16:02:24,914:INFO:Copying training dataset
2025-10-12 16:02:24,914:INFO:Plot type: confusion_matrix
2025-10-12 16:02:25,187:INFO:Fitting Model
2025-10-12 16:02:25,187:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 16:02:25,187:INFO:Scoring test/hold-out set
2025-10-12 16:02:25,200:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpwkxik6bl\Confusion Matrix.png'
2025-10-12 16:02:25,293:INFO:Visual Rendered Successfully
2025-10-12 16:02:25,437:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:25,462:INFO:Initializing plot_model()
2025-10-12 16:02:25,462:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=988,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=988, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpwkxik6bl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:25,463:INFO:Checking exceptions
2025-10-12 16:02:25,463:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 16:02:25,463:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:02:25,688:INFO:_master_model_container: 21
2025-10-12 16:02:25,688:INFO:_display_container: 5
2025-10-12 16:02:25,689:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=988,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=988, verbose=0,
                  warm_start=False)
2025-10-12 16:02:25,689:INFO:ensemble_model() successfully completed......................................
2025-10-12 16:02:25,837:INFO:Initializing predict_model()
2025-10-12 16:02:25,837:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=988,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=988, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DBB50D30>)
2025-10-12 16:02:25,837:INFO:Checking exceptions
2025-10-12 16:02:25,837:INFO:Preloading libraries
2025-10-12 16:02:28,934:INFO:Initializing create_model()
2025-10-12 16:02:28,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:28,934:INFO:Checking exceptions
2025-10-12 16:02:28,955:INFO:Importing libraries
2025-10-12 16:02:28,956:INFO:Copying training dataset
2025-10-12 16:02:28,962:INFO:Defining folds
2025-10-12 16:02:28,962:INFO:Declaring metric variables
2025-10-12 16:02:28,966:INFO:Importing untrained model
2025-10-12 16:02:28,971:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:02:28,980:INFO:Starting cross validation
2025-10-12 16:02:28,982:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:29,123:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:29,125:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:29,127:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:29,129:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:29,130:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:29,131:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:29,131:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:29,133:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:29,142:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:29,144:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:29,153:INFO:Calculating mean and std
2025-10-12 16:02:29,153:INFO:Creating metrics dataframe
2025-10-12 16:02:29,157:INFO:Finalizing model
2025-10-12 16:02:29,199:INFO:Creating Dashboard logs
2025-10-12 16:02:29,202:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:02:29,266:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:02:29,442:INFO:Initializing predict_model()
2025-10-12 16:02:29,442:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DD289310>)
2025-10-12 16:02:29,442:INFO:Checking exceptions
2025-10-12 16:02:29,442:INFO:Preloading libraries
2025-10-12 16:02:29,591:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-12 16:02:29,763:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:02:29,763:INFO:Initializing plot_model()
2025-10-12 16:02:29,763:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpgy1_otm3, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:29,763:INFO:Checking exceptions
2025-10-12 16:02:29,766:INFO:Preloading libraries
2025-10-12 16:02:29,766:INFO:Copying training dataset
2025-10-12 16:02:29,766:INFO:Plot type: auc
2025-10-12 16:02:30,047:INFO:Fitting Model
2025-10-12 16:02:30,047:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:02:30,047:INFO:Scoring test/hold-out set
2025-10-12 16:02:30,063:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpgy1_otm3\AUC.png'
2025-10-12 16:02:30,245:INFO:Visual Rendered Successfully
2025-10-12 16:02:30,389:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:30,419:INFO:Initializing plot_model()
2025-10-12 16:02:30,419:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpgy1_otm3, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:30,419:INFO:Checking exceptions
2025-10-12 16:02:30,421:INFO:Preloading libraries
2025-10-12 16:02:30,421:INFO:Copying training dataset
2025-10-12 16:02:30,421:INFO:Plot type: confusion_matrix
2025-10-12 16:02:30,695:INFO:Fitting Model
2025-10-12 16:02:30,695:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:02:30,695:INFO:Scoring test/hold-out set
2025-10-12 16:02:30,710:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpgy1_otm3\Confusion Matrix.png'
2025-10-12 16:02:30,784:INFO:Visual Rendered Successfully
2025-10-12 16:02:30,927:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:30,950:INFO:Initializing plot_model()
2025-10-12 16:02:30,950:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpgy1_otm3, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:30,950:INFO:Checking exceptions
2025-10-12 16:02:30,952:INFO:Preloading libraries
2025-10-12 16:02:30,952:INFO:Copying training dataset
2025-10-12 16:02:30,952:INFO:Plot type: feature
2025-10-12 16:02:31,095:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpgy1_otm3\Feature Importance.png'
2025-10-12 16:02:31,208:INFO:Visual Rendered Successfully
2025-10-12 16:02:31,350:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:31,370:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:02:31,629:INFO:Uploading results into container
2025-10-12 16:02:31,630:INFO:Uploading model into container now
2025-10-12 16:02:31,641:INFO:_master_model_container: 22
2025-10-12 16:02:31,641:INFO:_display_container: 7
2025-10-12 16:02:31,641:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:02:31,641:INFO:create_model() successfully completed......................................
2025-10-12 16:02:31,796:INFO:Initializing create_model()
2025-10-12 16:02:31,796:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=ridge, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:31,796:INFO:Checking exceptions
2025-10-12 16:02:31,806:INFO:Importing libraries
2025-10-12 16:02:31,806:INFO:Copying training dataset
2025-10-12 16:02:31,811:INFO:Defining folds
2025-10-12 16:02:31,812:INFO:Declaring metric variables
2025-10-12 16:02:31,817:INFO:Importing untrained model
2025-10-12 16:02:31,821:INFO:Ridge Classifier Imported successfully
2025-10-12 16:02:31,827:INFO:Starting cross validation
2025-10-12 16:02:31,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:32,027:INFO:Calculating mean and std
2025-10-12 16:02:32,027:INFO:Creating metrics dataframe
2025-10-12 16:02:32,031:INFO:Finalizing model
2025-10-12 16:02:32,081:INFO:Creating Dashboard logs
2025-10-12 16:02:32,084:INFO:Model: Ridge Classifier
2025-10-12 16:02:32,155:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 988, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:02:32,392:INFO:Initializing predict_model()
2025-10-12 16:02:32,392:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=988, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DFF50DC0>)
2025-10-12 16:02:32,392:INFO:Checking exceptions
2025-10-12 16:02:32,392:INFO:Preloading libraries
2025-10-12 16:02:32,756:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:02:32,757:INFO:Initializing plot_model()
2025-10-12 16:02:32,757:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=988, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpife_t7f9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:32,757:INFO:Checking exceptions
2025-10-12 16:02:32,757:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:02:32,757:INFO:Initializing plot_model()
2025-10-12 16:02:32,758:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=988, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpife_t7f9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:32,758:INFO:Checking exceptions
2025-10-12 16:02:32,759:INFO:Preloading libraries
2025-10-12 16:02:32,759:INFO:Copying training dataset
2025-10-12 16:02:32,759:INFO:Plot type: confusion_matrix
2025-10-12 16:02:33,056:INFO:Fitting Model
2025-10-12 16:02:33,056:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names

2025-10-12 16:02:33,056:INFO:Scoring test/hold-out set
2025-10-12 16:02:33,068:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpife_t7f9\Confusion Matrix.png'
2025-10-12 16:02:33,181:INFO:Visual Rendered Successfully
2025-10-12 16:02:33,353:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:33,385:INFO:Initializing plot_model()
2025-10-12 16:02:33,387:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=988, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpife_t7f9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:33,387:INFO:Checking exceptions
2025-10-12 16:02:33,388:INFO:Preloading libraries
2025-10-12 16:02:33,389:INFO:Copying training dataset
2025-10-12 16:02:33,389:INFO:Plot type: feature
2025-10-12 16:02:33,548:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpife_t7f9\Feature Importance.png'
2025-10-12 16:02:33,659:INFO:Visual Rendered Successfully
2025-10-12 16:02:33,802:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:33,821:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:02:34,040:INFO:Uploading results into container
2025-10-12 16:02:34,041:INFO:Uploading model into container now
2025-10-12 16:02:34,048:INFO:_master_model_container: 23
2025-10-12 16:02:34,048:INFO:_display_container: 8
2025-10-12 16:02:34,048:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=988, solver='auto',
                tol=0.0001)
2025-10-12 16:02:34,049:INFO:create_model() successfully completed......................................
2025-10-12 16:02:34,200:INFO:Initializing create_model()
2025-10-12 16:02:34,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:34,200:INFO:Checking exceptions
2025-10-12 16:02:34,211:INFO:Importing libraries
2025-10-12 16:02:34,211:INFO:Copying training dataset
2025-10-12 16:02:34,216:INFO:Defining folds
2025-10-12 16:02:34,216:INFO:Declaring metric variables
2025-10-12 16:02:34,219:INFO:Importing untrained model
2025-10-12 16:02:34,223:INFO:Logistic Regression Imported successfully
2025-10-12 16:02:34,229:INFO:Starting cross validation
2025-10-12 16:02:34,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:34,425:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:34,441:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:34,446:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:34,482:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:34,483:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:34,486:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:34,489:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:34,493:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:34,507:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:34,511:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:34,554:INFO:Calculating mean and std
2025-10-12 16:02:34,554:INFO:Creating metrics dataframe
2025-10-12 16:02:34,559:INFO:Finalizing model
2025-10-12 16:02:34,673:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:34,673:INFO:Creating Dashboard logs
2025-10-12 16:02:34,677:INFO:Model: Logistic Regression
2025-10-12 16:02:34,744:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 988, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:02:34,999:INFO:Initializing predict_model()
2025-10-12 16:02:35,000:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E02AF4C0>)
2025-10-12 16:02:35,000:INFO:Checking exceptions
2025-10-12 16:02:35,000:INFO:Preloading libraries
2025-10-12 16:02:35,309:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:02:35,310:INFO:Initializing plot_model()
2025-10-12 16:02:35,310:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpwq4nfg32, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:35,310:INFO:Checking exceptions
2025-10-12 16:02:35,311:INFO:Preloading libraries
2025-10-12 16:02:35,311:INFO:Copying training dataset
2025-10-12 16:02:35,311:INFO:Plot type: auc
2025-10-12 16:02:35,593:INFO:Fitting Model
2025-10-12 16:02:35,593:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:02:35,594:INFO:Scoring test/hold-out set
2025-10-12 16:02:35,609:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpwq4nfg32\AUC.png'
2025-10-12 16:02:35,785:INFO:Visual Rendered Successfully
2025-10-12 16:02:35,932:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:35,945:INFO:Initializing plot_model()
2025-10-12 16:02:35,947:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpwq4nfg32, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:35,947:INFO:Checking exceptions
2025-10-12 16:02:35,947:INFO:Preloading libraries
2025-10-12 16:02:35,948:INFO:Copying training dataset
2025-10-12 16:02:35,948:INFO:Plot type: confusion_matrix
2025-10-12 16:02:36,227:INFO:Fitting Model
2025-10-12 16:02:36,227:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:02:36,227:INFO:Scoring test/hold-out set
2025-10-12 16:02:36,241:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpwq4nfg32\Confusion Matrix.png'
2025-10-12 16:02:36,344:INFO:Visual Rendered Successfully
2025-10-12 16:02:36,525:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:36,548:INFO:Initializing plot_model()
2025-10-12 16:02:36,549:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpwq4nfg32, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:36,549:INFO:Checking exceptions
2025-10-12 16:02:36,551:INFO:Preloading libraries
2025-10-12 16:02:36,551:INFO:Copying training dataset
2025-10-12 16:02:36,551:INFO:Plot type: feature
2025-10-12 16:02:36,710:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpwq4nfg32\Feature Importance.png'
2025-10-12 16:02:36,843:INFO:Visual Rendered Successfully
2025-10-12 16:02:37,016:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:37,033:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:02:37,281:INFO:Uploading results into container
2025-10-12 16:02:37,282:INFO:Uploading model into container now
2025-10-12 16:02:37,289:INFO:_master_model_container: 24
2025-10-12 16:02:37,289:INFO:_display_container: 9
2025-10-12 16:02:37,290:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:02:37,290:INFO:create_model() successfully completed......................................
2025-10-12 16:02:37,447:INFO:Initializing blend_models()
2025-10-12 16:02:37,447:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator_list=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=988, solver='auto',
                tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:02:37,447:INFO:Checking exceptions
2025-10-12 16:02:37,447:INFO:Estimator RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=988, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-12 16:02:37,460:INFO:Importing libraries
2025-10-12 16:02:37,460:INFO:Copying training dataset
2025-10-12 16:02:37,462:INFO:Getting model names
2025-10-12 16:02:37,466:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:37,469:INFO:Initializing create_model()
2025-10-12 16:02:37,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                              random_state=988, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DEFA08E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:37,469:INFO:Checking exceptions
2025-10-12 16:02:37,469:INFO:Importing libraries
2025-10-12 16:02:37,469:INFO:Copying training dataset
2025-10-12 16:02:37,473:INFO:Defining folds
2025-10-12 16:02:37,474:INFO:Declaring metric variables
2025-10-12 16:02:37,477:INFO:Importing untrained model
2025-10-12 16:02:37,477:INFO:Declaring custom model
2025-10-12 16:02:37,481:INFO:Voting Classifier Imported successfully
2025-10-12 16:02:37,487:INFO:Starting cross validation
2025-10-12 16:02:37,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:37,905:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:37,912:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:37,912:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:37,916:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:37,919:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:37,933:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:37,982:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:02:37,990:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:02:37,990:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:02:37,993:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:02:37,996:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:37,997:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:02:38,005:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:38,008:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:38,010:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:02:38,054:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:38,077:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:02:38,081:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:02:38,111:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:02:38,140:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:02:38,161:INFO:Calculating mean and std
2025-10-12 16:02:38,161:INFO:Creating metrics dataframe
2025-10-12 16:02:38,165:INFO:Finalizing model
2025-10-12 16:02:38,320:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:38,335:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:38,351:INFO:Uploading results into container
2025-10-12 16:02:38,352:INFO:Uploading model into container now
2025-10-12 16:02:38,352:INFO:_master_model_container: 25
2025-10-12 16:02:38,352:INFO:_display_container: 10
2025-10-12 16:02:38,355:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                              random_state=988, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:02:38,356:INFO:create_model() successfully completed......................................
2025-10-12 16:02:38,518:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:38,519:INFO:Creating Dashboard logs
2025-10-12 16:02:38,522:INFO:Model: Voting Classifier
2025-10-12 16:02:38,602:INFO:Logged params: {'flatten_transform': True, 'n_jobs': -1, 'verbose': False, 'voting': 'hard', 'weights': None, 'Linear Discriminant Analysis': LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), 'Ridge Classifier': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=988, solver='auto',
                tol=0.0001), 'Logistic Regression__C': 1.0, 'Logistic Regression__class_weight': None, 'Logistic Regression__dual': False, 'Logistic Regression__fit_intercept': True, 'Logistic Regression__intercept_scaling': 1, 'Logistic Regression__l1_ratio': None, 'Logistic Regression__max_iter': 1000, 'Logistic Regression__multi_class': 'auto', 'Logistic Regression__n_jobs': None, 'Logistic Regression__penalty': 'l2', 'Logistic Regression__random_state': 988, 'Logistic Regression__solver': 'lbfgs', 'Logistic Regression__tol': 0.0001, 'Logistic Regression__verbose': 0, 'Logistic Regression__warm_start': False, 'Linear Discriminant Analysis__covariance_estimator': None, 'Linear Discriminant Analysis__n_components': None, 'Linear Discriminant Analysis__priors': None, 'Linear Discriminant Analysis__shrinkage': None, 'Linear Discriminant Analysis__solver': 'svd', 'Linear Discriminant Analysis__store_covariance': False, 'Linear Discriminant Analysis__tol': 0.0001, 'Ridge Classifier__alpha': 1.0, 'Ridge Classifier__class_weight': None, 'Ridge Classifier__copy_X': True, 'Ridge Classifier__fit_intercept': True, 'Ridge Classifier__max_iter': None, 'Ridge Classifier__positive': False, 'Ridge Classifier__random_state': 988, 'Ridge Classifier__solver': 'auto', 'Ridge Classifier__tol': 0.0001, 'Logistic Regression_1__C': 1.0, 'Logistic Regression_1__class_weight': None, 'Logistic Regression_1__dual': False, 'Logistic Regression_1__fit_intercept': True, 'Logistic Regression_1__intercept_scaling': 1, 'Logistic Regression_1__l1_ratio': None, 'Logistic Regression_1__max_iter': 1000, 'Logistic Regression_1__multi_class': 'auto', 'Logistic Regression_1__n_jobs': None, 'Logistic Regression_1__penalty': 'l2', 'Logistic Regression_1__random_state': 988, 'Logistic Regression_1__solver': 'lbfgs', 'Logistic Regression_1__tol': 0.0001, 'Logistic Regression_1__verbose': 0, 'Logistic Regression_1__warm_start': False}
2025-10-12 16:02:38,951:INFO:Initializing predict_model()
2025-10-12 16:02:38,951:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                              random_state=988, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E0385430>)
2025-10-12 16:02:38,951:INFO:Checking exceptions
2025-10-12 16:02:38,951:INFO:Preloading libraries
2025-10-12 16:02:39,317:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:02:39,322:INFO:Initializing plot_model()
2025-10-12 16:02:39,322:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                              random_state=988, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpw2bmr54t, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:39,322:INFO:Checking exceptions
2025-10-12 16:02:39,322:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:02:39,326:INFO:Initializing plot_model()
2025-10-12 16:02:39,326:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                              random_state=988, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpw2bmr54t, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:39,326:INFO:Checking exceptions
2025-10-12 16:02:39,328:INFO:Preloading libraries
2025-10-12 16:02:39,329:INFO:Copying training dataset
2025-10-12 16:02:39,329:INFO:Plot type: confusion_matrix
2025-10-12 16:02:39,662:INFO:Fitting Model
2025-10-12 16:02:39,662:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:02:39,662:INFO:Scoring test/hold-out set
2025-10-12 16:02:39,687:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpw2bmr54t\Confusion Matrix.png'
2025-10-12 16:02:39,774:INFO:Visual Rendered Successfully
2025-10-12 16:02:39,926:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:39,947:INFO:Initializing plot_model()
2025-10-12 16:02:39,947:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                              random_state=988, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpw2bmr54t, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:39,947:INFO:Checking exceptions
2025-10-12 16:02:39,948:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 16:02:39,948:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:02:40,184:INFO:_master_model_container: 25
2025-10-12 16:02:40,184:INFO:_display_container: 10
2025-10-12 16:02:40,187:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                              random_state=988, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=988,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:02:40,187:INFO:blend_models() successfully completed......................................
2025-10-12 16:02:40,336:INFO:Initializing compare_models()
2025-10-12 16:02:40,336:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:02:40,336:INFO:Checking exceptions
2025-10-12 16:02:40,338:INFO:Preparing display monitor
2025-10-12 16:02:40,355:INFO:Initializing Logistic Regression
2025-10-12 16:02:40,355:INFO:Total runtime is 0.0 minutes
2025-10-12 16:02:40,359:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:40,360:INFO:Initializing create_model()
2025-10-12 16:02:40,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:40,360:INFO:Checking exceptions
2025-10-12 16:02:40,360:INFO:Importing libraries
2025-10-12 16:02:40,360:INFO:Copying training dataset
2025-10-12 16:02:40,363:INFO:Defining folds
2025-10-12 16:02:40,363:INFO:Declaring metric variables
2025-10-12 16:02:40,365:INFO:Importing untrained model
2025-10-12 16:02:40,370:INFO:Logistic Regression Imported successfully
2025-10-12 16:02:40,378:INFO:Starting cross validation
2025-10-12 16:02:40,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:40,585:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:40,589:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:40,603:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:40,606:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:40,658:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:40,663:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:40,667:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:40,668:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:40,669:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:40,674:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:02:40,718:INFO:Calculating mean and std
2025-10-12 16:02:40,718:INFO:Creating metrics dataframe
2025-10-12 16:02:40,720:INFO:Uploading results into container
2025-10-12 16:02:40,720:INFO:Uploading model into container now
2025-10-12 16:02:40,720:INFO:_master_model_container: 26
2025-10-12 16:02:40,720:INFO:_display_container: 11
2025-10-12 16:02:40,721:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:02:40,721:INFO:create_model() successfully completed......................................
2025-10-12 16:02:40,868:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:40,868:INFO:Creating metrics dataframe
2025-10-12 16:02:40,873:INFO:Initializing K Neighbors Classifier
2025-10-12 16:02:40,873:INFO:Total runtime is 0.008638608455657958 minutes
2025-10-12 16:02:40,876:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:40,876:INFO:Initializing create_model()
2025-10-12 16:02:40,876:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:40,876:INFO:Checking exceptions
2025-10-12 16:02:40,876:INFO:Importing libraries
2025-10-12 16:02:40,876:INFO:Copying training dataset
2025-10-12 16:02:40,880:INFO:Defining folds
2025-10-12 16:02:40,880:INFO:Declaring metric variables
2025-10-12 16:02:40,883:INFO:Importing untrained model
2025-10-12 16:02:40,885:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:02:40,891:INFO:Starting cross validation
2025-10-12 16:02:40,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:41,138:INFO:Calculating mean and std
2025-10-12 16:02:41,138:INFO:Creating metrics dataframe
2025-10-12 16:02:41,140:INFO:Uploading results into container
2025-10-12 16:02:41,140:INFO:Uploading model into container now
2025-10-12 16:02:41,141:INFO:_master_model_container: 27
2025-10-12 16:02:41,141:INFO:_display_container: 11
2025-10-12 16:02:41,141:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:02:41,141:INFO:create_model() successfully completed......................................
2025-10-12 16:02:41,291:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:41,291:INFO:Creating metrics dataframe
2025-10-12 16:02:41,295:INFO:Initializing Naive Bayes
2025-10-12 16:02:41,295:INFO:Total runtime is 0.015680360794067382 minutes
2025-10-12 16:02:41,299:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:41,299:INFO:Initializing create_model()
2025-10-12 16:02:41,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:41,299:INFO:Checking exceptions
2025-10-12 16:02:41,299:INFO:Importing libraries
2025-10-12 16:02:41,299:INFO:Copying training dataset
2025-10-12 16:02:41,303:INFO:Defining folds
2025-10-12 16:02:41,303:INFO:Declaring metric variables
2025-10-12 16:02:41,306:INFO:Importing untrained model
2025-10-12 16:02:41,310:INFO:Naive Bayes Imported successfully
2025-10-12 16:02:41,319:INFO:Starting cross validation
2025-10-12 16:02:41,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:41,526:INFO:Calculating mean and std
2025-10-12 16:02:41,527:INFO:Creating metrics dataframe
2025-10-12 16:02:41,529:INFO:Uploading results into container
2025-10-12 16:02:41,529:INFO:Uploading model into container now
2025-10-12 16:02:41,530:INFO:_master_model_container: 28
2025-10-12 16:02:41,530:INFO:_display_container: 11
2025-10-12 16:02:41,530:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:02:41,530:INFO:create_model() successfully completed......................................
2025-10-12 16:02:41,702:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:41,702:INFO:Creating metrics dataframe
2025-10-12 16:02:41,709:INFO:Initializing Decision Tree Classifier
2025-10-12 16:02:41,709:INFO:Total runtime is 0.022571146488189697 minutes
2025-10-12 16:02:41,712:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:41,713:INFO:Initializing create_model()
2025-10-12 16:02:41,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:41,713:INFO:Checking exceptions
2025-10-12 16:02:41,713:INFO:Importing libraries
2025-10-12 16:02:41,713:INFO:Copying training dataset
2025-10-12 16:02:41,716:INFO:Defining folds
2025-10-12 16:02:41,717:INFO:Declaring metric variables
2025-10-12 16:02:41,720:INFO:Importing untrained model
2025-10-12 16:02:41,723:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:02:41,729:INFO:Starting cross validation
2025-10-12 16:02:41,731:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:41,881:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:41,893:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:41,899:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:41,902:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:41,909:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:41,918:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:41,918:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:41,920:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:41,923:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:41,923:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:41,928:INFO:Calculating mean and std
2025-10-12 16:02:41,929:INFO:Creating metrics dataframe
2025-10-12 16:02:41,931:INFO:Uploading results into container
2025-10-12 16:02:41,931:INFO:Uploading model into container now
2025-10-12 16:02:41,932:INFO:_master_model_container: 29
2025-10-12 16:02:41,932:INFO:_display_container: 11
2025-10-12 16:02:41,932:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=988, splitter='best')
2025-10-12 16:02:41,932:INFO:create_model() successfully completed......................................
2025-10-12 16:02:42,086:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:42,086:INFO:Creating metrics dataframe
2025-10-12 16:02:42,092:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:02:42,092:INFO:Total runtime is 0.028959643840789796 minutes
2025-10-12 16:02:42,093:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:42,095:INFO:Initializing create_model()
2025-10-12 16:02:42,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:42,095:INFO:Checking exceptions
2025-10-12 16:02:42,095:INFO:Importing libraries
2025-10-12 16:02:42,095:INFO:Copying training dataset
2025-10-12 16:02:42,098:INFO:Defining folds
2025-10-12 16:02:42,098:INFO:Declaring metric variables
2025-10-12 16:02:42,100:INFO:Importing untrained model
2025-10-12 16:02:42,104:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:02:42,110:INFO:Starting cross validation
2025-10-12 16:02:42,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:42,269:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:42,287:INFO:Calculating mean and std
2025-10-12 16:02:42,288:INFO:Creating metrics dataframe
2025-10-12 16:02:42,290:INFO:Uploading results into container
2025-10-12 16:02:42,290:INFO:Uploading model into container now
2025-10-12 16:02:42,291:INFO:_master_model_container: 30
2025-10-12 16:02:42,291:INFO:_display_container: 11
2025-10-12 16:02:42,291:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=988, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:02:42,291:INFO:create_model() successfully completed......................................
2025-10-12 16:02:42,444:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:42,444:INFO:Creating metrics dataframe
2025-10-12 16:02:42,451:INFO:Initializing Ridge Classifier
2025-10-12 16:02:42,451:INFO:Total runtime is 0.03493181467056274 minutes
2025-10-12 16:02:42,455:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:42,455:INFO:Initializing create_model()
2025-10-12 16:02:42,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:42,455:INFO:Checking exceptions
2025-10-12 16:02:42,455:INFO:Importing libraries
2025-10-12 16:02:42,455:INFO:Copying training dataset
2025-10-12 16:02:42,458:INFO:Defining folds
2025-10-12 16:02:42,459:INFO:Declaring metric variables
2025-10-12 16:02:42,461:INFO:Importing untrained model
2025-10-12 16:02:42,465:INFO:Ridge Classifier Imported successfully
2025-10-12 16:02:42,473:INFO:Starting cross validation
2025-10-12 16:02:42,475:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:42,660:INFO:Calculating mean and std
2025-10-12 16:02:42,661:INFO:Creating metrics dataframe
2025-10-12 16:02:42,663:INFO:Uploading results into container
2025-10-12 16:02:42,663:INFO:Uploading model into container now
2025-10-12 16:02:42,663:INFO:_master_model_container: 31
2025-10-12 16:02:42,663:INFO:_display_container: 11
2025-10-12 16:02:42,663:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=988, solver='auto',
                tol=0.0001)
2025-10-12 16:02:42,663:INFO:create_model() successfully completed......................................
2025-10-12 16:02:42,825:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:42,825:INFO:Creating metrics dataframe
2025-10-12 16:02:42,837:INFO:Initializing Random Forest Classifier
2025-10-12 16:02:42,838:INFO:Total runtime is 0.0413904070854187 minutes
2025-10-12 16:02:42,843:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:42,843:INFO:Initializing create_model()
2025-10-12 16:02:42,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:42,843:INFO:Checking exceptions
2025-10-12 16:02:42,843:INFO:Importing libraries
2025-10-12 16:02:42,843:INFO:Copying training dataset
2025-10-12 16:02:42,849:INFO:Defining folds
2025-10-12 16:02:42,849:INFO:Declaring metric variables
2025-10-12 16:02:42,852:INFO:Importing untrained model
2025-10-12 16:02:42,857:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:02:42,862:INFO:Starting cross validation
2025-10-12 16:02:42,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:43,275:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:43,304:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:43,345:INFO:Calculating mean and std
2025-10-12 16:02:43,346:INFO:Creating metrics dataframe
2025-10-12 16:02:43,348:INFO:Uploading results into container
2025-10-12 16:02:43,349:INFO:Uploading model into container now
2025-10-12 16:02:43,349:INFO:_master_model_container: 32
2025-10-12 16:02:43,349:INFO:_display_container: 11
2025-10-12 16:02:43,349:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=988, verbose=0,
                       warm_start=False)
2025-10-12 16:02:43,349:INFO:create_model() successfully completed......................................
2025-10-12 16:02:43,506:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:43,506:INFO:Creating metrics dataframe
2025-10-12 16:02:43,512:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:02:43,512:INFO:Total runtime is 0.05262542168299357 minutes
2025-10-12 16:02:43,516:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:43,517:INFO:Initializing create_model()
2025-10-12 16:02:43,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:43,517:INFO:Checking exceptions
2025-10-12 16:02:43,517:INFO:Importing libraries
2025-10-12 16:02:43,517:INFO:Copying training dataset
2025-10-12 16:02:43,520:INFO:Defining folds
2025-10-12 16:02:43,521:INFO:Declaring metric variables
2025-10-12 16:02:43,525:INFO:Importing untrained model
2025-10-12 16:02:43,529:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:02:43,535:INFO:Starting cross validation
2025-10-12 16:02:43,537:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:43,628:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:02:43,628:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:02:43,629:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:02:43,634:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:02:43,636:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:02:43,637:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:02:43,637:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:02:43,643:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:02:43,650:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:02:43,660:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:02:43,665:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:43,667:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:43,671:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:43,677:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:43,679:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:43,679:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:43,686:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:43,700:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:43,719:INFO:Calculating mean and std
2025-10-12 16:02:43,720:INFO:Creating metrics dataframe
2025-10-12 16:02:43,721:INFO:Uploading results into container
2025-10-12 16:02:43,722:INFO:Uploading model into container now
2025-10-12 16:02:43,722:INFO:_master_model_container: 33
2025-10-12 16:02:43,722:INFO:_display_container: 11
2025-10-12 16:02:43,723:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:02:43,723:INFO:create_model() successfully completed......................................
2025-10-12 16:02:43,869:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:43,870:INFO:Creating metrics dataframe
2025-10-12 16:02:43,876:INFO:Initializing Ada Boost Classifier
2025-10-12 16:02:43,876:INFO:Total runtime is 0.05868529081344605 minutes
2025-10-12 16:02:43,879:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:43,879:INFO:Initializing create_model()
2025-10-12 16:02:43,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:43,879:INFO:Checking exceptions
2025-10-12 16:02:43,879:INFO:Importing libraries
2025-10-12 16:02:43,879:INFO:Copying training dataset
2025-10-12 16:02:43,883:INFO:Defining folds
2025-10-12 16:02:43,884:INFO:Declaring metric variables
2025-10-12 16:02:43,887:INFO:Importing untrained model
2025-10-12 16:02:43,890:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:02:43,895:INFO:Starting cross validation
2025-10-12 16:02:43,897:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:43,988:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:02:43,991:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:02:43,992:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:02:43,993:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:02:43,993:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:02:43,995:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:02:44,000:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:02:44,002:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:02:44,011:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:02:44,015:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:02:44,030:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,032:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,032:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,039:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,041:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,043:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,045:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,047:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,056:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,060:INFO:Calculating mean and std
2025-10-12 16:02:44,061:INFO:Creating metrics dataframe
2025-10-12 16:02:44,063:INFO:Uploading results into container
2025-10-12 16:02:44,063:INFO:Uploading model into container now
2025-10-12 16:02:44,063:INFO:_master_model_container: 34
2025-10-12 16:02:44,063:INFO:_display_container: 11
2025-10-12 16:02:44,065:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=988)
2025-10-12 16:02:44,065:INFO:create_model() successfully completed......................................
2025-10-12 16:02:44,209:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:44,209:INFO:Creating metrics dataframe
2025-10-12 16:02:44,216:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:02:44,216:INFO:Total runtime is 0.06435357332229615 minutes
2025-10-12 16:02:44,219:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:44,219:INFO:Initializing create_model()
2025-10-12 16:02:44,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:44,220:INFO:Checking exceptions
2025-10-12 16:02:44,220:INFO:Importing libraries
2025-10-12 16:02:44,220:INFO:Copying training dataset
2025-10-12 16:02:44,223:INFO:Defining folds
2025-10-12 16:02:44,223:INFO:Declaring metric variables
2025-10-12 16:02:44,227:INFO:Importing untrained model
2025-10-12 16:02:44,229:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:02:44,236:INFO:Starting cross validation
2025-10-12 16:02:44,237:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:44,452:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,455:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,461:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,464:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,465:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,467:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,470:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,472:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,474:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,475:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,480:INFO:Calculating mean and std
2025-10-12 16:02:44,481:INFO:Creating metrics dataframe
2025-10-12 16:02:44,483:INFO:Uploading results into container
2025-10-12 16:02:44,483:INFO:Uploading model into container now
2025-10-12 16:02:44,483:INFO:_master_model_container: 35
2025-10-12 16:02:44,485:INFO:_display_container: 11
2025-10-12 16:02:44,485:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=988, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:02:44,485:INFO:create_model() successfully completed......................................
2025-10-12 16:02:44,627:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:44,627:INFO:Creating metrics dataframe
2025-10-12 16:02:44,632:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:02:44,632:INFO:Total runtime is 0.07128745714823405 minutes
2025-10-12 16:02:44,635:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:44,635:INFO:Initializing create_model()
2025-10-12 16:02:44,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:44,635:INFO:Checking exceptions
2025-10-12 16:02:44,635:INFO:Importing libraries
2025-10-12 16:02:44,635:INFO:Copying training dataset
2025-10-12 16:02:44,640:INFO:Defining folds
2025-10-12 16:02:44,640:INFO:Declaring metric variables
2025-10-12 16:02:44,643:INFO:Importing untrained model
2025-10-12 16:02:44,645:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:02:44,651:INFO:Starting cross validation
2025-10-12 16:02:44,652:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:44,793:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,808:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,810:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,814:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,818:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,818:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,825:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,830:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,832:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,832:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:44,852:INFO:Calculating mean and std
2025-10-12 16:02:44,853:INFO:Creating metrics dataframe
2025-10-12 16:02:44,855:INFO:Uploading results into container
2025-10-12 16:02:44,855:INFO:Uploading model into container now
2025-10-12 16:02:44,855:INFO:_master_model_container: 36
2025-10-12 16:02:44,855:INFO:_display_container: 11
2025-10-12 16:02:44,855:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:02:44,855:INFO:create_model() successfully completed......................................
2025-10-12 16:02:44,998:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:44,998:INFO:Creating metrics dataframe
2025-10-12 16:02:45,005:INFO:Initializing Extra Trees Classifier
2025-10-12 16:02:45,005:INFO:Total runtime is 0.07750092744827271 minutes
2025-10-12 16:02:45,008:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:45,008:INFO:Initializing create_model()
2025-10-12 16:02:45,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:45,008:INFO:Checking exceptions
2025-10-12 16:02:45,008:INFO:Importing libraries
2025-10-12 16:02:45,008:INFO:Copying training dataset
2025-10-12 16:02:45,012:INFO:Defining folds
2025-10-12 16:02:45,012:INFO:Declaring metric variables
2025-10-12 16:02:45,015:INFO:Importing untrained model
2025-10-12 16:02:45,018:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:02:45,022:INFO:Starting cross validation
2025-10-12 16:02:45,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:45,491:INFO:Calculating mean and std
2025-10-12 16:02:45,492:INFO:Creating metrics dataframe
2025-10-12 16:02:45,494:INFO:Uploading results into container
2025-10-12 16:02:45,495:INFO:Uploading model into container now
2025-10-12 16:02:45,496:INFO:_master_model_container: 37
2025-10-12 16:02:45,496:INFO:_display_container: 11
2025-10-12 16:02:45,497:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=988, verbose=0,
                     warm_start=False)
2025-10-12 16:02:45,497:INFO:create_model() successfully completed......................................
2025-10-12 16:02:45,650:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:45,651:INFO:Creating metrics dataframe
2025-10-12 16:02:45,658:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:02:45,658:INFO:Total runtime is 0.0883815328280131 minutes
2025-10-12 16:02:45,661:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:45,661:INFO:Initializing create_model()
2025-10-12 16:02:45,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:45,661:INFO:Checking exceptions
2025-10-12 16:02:45,661:INFO:Importing libraries
2025-10-12 16:02:45,661:INFO:Copying training dataset
2025-10-12 16:02:45,665:INFO:Defining folds
2025-10-12 16:02:45,665:INFO:Declaring metric variables
2025-10-12 16:02:45,668:INFO:Importing untrained model
2025-10-12 16:02:45,672:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:02:45,678:INFO:Starting cross validation
2025-10-12 16:02:45,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:45,856:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:45,869:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:45,870:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:45,905:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:45,905:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:45,905:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:46,045:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:46,102:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:46,128:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:46,131:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:46,145:INFO:Calculating mean and std
2025-10-12 16:02:46,146:INFO:Creating metrics dataframe
2025-10-12 16:02:46,147:INFO:Uploading results into container
2025-10-12 16:02:46,148:INFO:Uploading model into container now
2025-10-12 16:02:46,148:INFO:_master_model_container: 38
2025-10-12 16:02:46,148:INFO:_display_container: 11
2025-10-12 16:02:46,149:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:02:46,149:INFO:create_model() successfully completed......................................
2025-10-12 16:02:46,305:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:46,305:INFO:Creating metrics dataframe
2025-10-12 16:02:46,313:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:02:46,313:INFO:Total runtime is 0.09931121269861858 minutes
2025-10-12 16:02:46,317:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:46,317:INFO:Initializing create_model()
2025-10-12 16:02:46,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:46,317:INFO:Checking exceptions
2025-10-12 16:02:46,317:INFO:Importing libraries
2025-10-12 16:02:46,317:INFO:Copying training dataset
2025-10-12 16:02:46,321:INFO:Defining folds
2025-10-12 16:02:46,321:INFO:Declaring metric variables
2025-10-12 16:02:46,323:INFO:Importing untrained model
2025-10-12 16:02:46,328:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:02:46,332:INFO:Starting cross validation
2025-10-12 16:02:46,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:47,069:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:47,078:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:47,141:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:47,142:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:47,152:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:47,168:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:47,183:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:47,191:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:47,210:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:47,217:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:47,237:INFO:Calculating mean and std
2025-10-12 16:02:47,238:INFO:Creating metrics dataframe
2025-10-12 16:02:47,240:INFO:Uploading results into container
2025-10-12 16:02:47,241:INFO:Uploading model into container now
2025-10-12 16:02:47,242:INFO:_master_model_container: 39
2025-10-12 16:02:47,242:INFO:_display_container: 11
2025-10-12 16:02:47,243:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=988, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:02:47,243:INFO:create_model() successfully completed......................................
2025-10-12 16:02:47,418:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:47,419:INFO:Creating metrics dataframe
2025-10-12 16:02:47,425:INFO:Initializing CatBoost Classifier
2025-10-12 16:02:47,425:INFO:Total runtime is 0.11784646113713583 minutes
2025-10-12 16:02:47,428:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:47,429:INFO:Initializing create_model()
2025-10-12 16:02:47,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:47,429:INFO:Checking exceptions
2025-10-12 16:02:47,429:INFO:Importing libraries
2025-10-12 16:02:47,429:INFO:Copying training dataset
2025-10-12 16:02:47,432:INFO:Defining folds
2025-10-12 16:02:47,432:INFO:Declaring metric variables
2025-10-12 16:02:47,435:INFO:Importing untrained model
2025-10-12 16:02:47,440:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:02:47,446:INFO:Starting cross validation
2025-10-12 16:02:47,447:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:49,443:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:49,445:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:49,446:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:49,450:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:50,338:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:50,340:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:51,253:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:51,270:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:51,281:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:52,078:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:52,082:INFO:Calculating mean and std
2025-10-12 16:02:52,083:INFO:Creating metrics dataframe
2025-10-12 16:02:52,086:INFO:Uploading results into container
2025-10-12 16:02:52,086:INFO:Uploading model into container now
2025-10-12 16:02:52,087:INFO:_master_model_container: 40
2025-10-12 16:02:52,087:INFO:_display_container: 11
2025-10-12 16:02:52,087:INFO:<catboost.core.CatBoostClassifier object at 0x00000265E0186D90>
2025-10-12 16:02:52,087:INFO:create_model() successfully completed......................................
2025-10-12 16:02:52,259:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:52,259:INFO:Creating metrics dataframe
2025-10-12 16:02:52,270:INFO:Initializing Dummy Classifier
2025-10-12 16:02:52,270:INFO:Total runtime is 0.19858819643656414 minutes
2025-10-12 16:02:52,276:INFO:SubProcess create_model() called ==================================
2025-10-12 16:02:52,276:INFO:Initializing create_model()
2025-10-12 16:02:52,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265D1B88820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:52,276:INFO:Checking exceptions
2025-10-12 16:02:52,276:INFO:Importing libraries
2025-10-12 16:02:52,276:INFO:Copying training dataset
2025-10-12 16:02:52,281:INFO:Defining folds
2025-10-12 16:02:52,281:INFO:Declaring metric variables
2025-10-12 16:02:52,286:INFO:Importing untrained model
2025-10-12 16:02:52,289:INFO:Dummy Classifier Imported successfully
2025-10-12 16:02:52,297:INFO:Starting cross validation
2025-10-12 16:02:52,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:02:52,432:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:52,438:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:52,440:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:52,441:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:52,442:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:52,453:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:52,456:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:52,456:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:52,458:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:52,458:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:02:52,470:INFO:Calculating mean and std
2025-10-12 16:02:52,471:INFO:Creating metrics dataframe
2025-10-12 16:02:52,472:INFO:Uploading results into container
2025-10-12 16:02:52,473:INFO:Uploading model into container now
2025-10-12 16:02:52,473:INFO:_master_model_container: 41
2025-10-12 16:02:52,473:INFO:_display_container: 11
2025-10-12 16:02:52,473:INFO:DummyClassifier(constant=None, random_state=988, strategy='prior')
2025-10-12 16:02:52,473:INFO:create_model() successfully completed......................................
2025-10-12 16:02:52,627:INFO:SubProcess create_model() end ==================================
2025-10-12 16:02:52,628:INFO:Creating metrics dataframe
2025-10-12 16:02:52,635:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:02:52,642:INFO:Initializing create_model()
2025-10-12 16:02:52,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:02:52,643:INFO:Checking exceptions
2025-10-12 16:02:52,644:INFO:Importing libraries
2025-10-12 16:02:52,644:INFO:Copying training dataset
2025-10-12 16:02:52,647:INFO:Defining folds
2025-10-12 16:02:52,647:INFO:Declaring metric variables
2025-10-12 16:02:52,647:INFO:Importing untrained model
2025-10-12 16:02:52,647:INFO:Declaring custom model
2025-10-12 16:02:52,647:INFO:Logistic Regression Imported successfully
2025-10-12 16:02:52,648:INFO:Cross validation set to False
2025-10-12 16:02:52,648:INFO:Fitting Model
2025-10-12 16:02:52,749:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:02:52,750:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:02:52,750:INFO:create_model() successfully completed......................................
2025-10-12 16:02:52,907:INFO:Creating Dashboard logs
2025-10-12 16:02:52,911:INFO:Model: Logistic Regression
2025-10-12 16:02:52,976:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 988, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:02:53,241:INFO:Initializing predict_model()
2025-10-12 16:02:53,241:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E01AF790>)
2025-10-12 16:02:53,241:INFO:Checking exceptions
2025-10-12 16:02:53,241:INFO:Preloading libraries
2025-10-12 16:02:53,560:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:02:53,560:INFO:Initializing plot_model()
2025-10-12 16:02:53,560:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp3m3uopwe, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:53,560:INFO:Checking exceptions
2025-10-12 16:02:53,562:INFO:Preloading libraries
2025-10-12 16:02:53,562:INFO:Copying training dataset
2025-10-12 16:02:53,562:INFO:Plot type: auc
2025-10-12 16:02:53,833:INFO:Fitting Model
2025-10-12 16:02:53,835:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:02:53,835:INFO:Scoring test/hold-out set
2025-10-12 16:02:53,848:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp3m3uopwe\AUC.png'
2025-10-12 16:02:54,019:INFO:Visual Rendered Successfully
2025-10-12 16:02:54,165:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:54,185:INFO:Initializing plot_model()
2025-10-12 16:02:54,185:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp3m3uopwe, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:54,185:INFO:Checking exceptions
2025-10-12 16:02:54,186:INFO:Preloading libraries
2025-10-12 16:02:54,187:INFO:Copying training dataset
2025-10-12 16:02:54,187:INFO:Plot type: confusion_matrix
2025-10-12 16:02:54,465:INFO:Fitting Model
2025-10-12 16:02:54,465:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:02:54,466:INFO:Scoring test/hold-out set
2025-10-12 16:02:54,478:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp3m3uopwe\Confusion Matrix.png'
2025-10-12 16:02:54,573:INFO:Visual Rendered Successfully
2025-10-12 16:02:54,720:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:54,745:INFO:Initializing plot_model()
2025-10-12 16:02:54,745:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp3m3uopwe, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, system=False)
2025-10-12 16:02:54,745:INFO:Checking exceptions
2025-10-12 16:02:54,746:INFO:Preloading libraries
2025-10-12 16:02:54,747:INFO:Copying training dataset
2025-10-12 16:02:54,747:INFO:Plot type: feature
2025-10-12 16:02:54,883:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp3m3uopwe\Feature Importance.png'
2025-10-12 16:02:54,991:INFO:Visual Rendered Successfully
2025-10-12 16:02:55,145:INFO:plot_model() successfully completed......................................
2025-10-12 16:02:55,163:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:02:55,392:INFO:Creating Dashboard logs
2025-10-12 16:02:55,395:INFO:Model: Ridge Classifier
2025-10-12 16:02:55,462:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 988, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:02:55,888:INFO:Creating Dashboard logs
2025-10-12 16:02:55,892:INFO:Model: Extra Trees Classifier
2025-10-12 16:02:55,966:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 988, 'verbose': 0, 'warm_start': False}
2025-10-12 16:02:56,437:INFO:Creating Dashboard logs
2025-10-12 16:02:56,443:INFO:Model: Naive Bayes
2025-10-12 16:02:56,520:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:02:56,966:INFO:Creating Dashboard logs
2025-10-12 16:02:56,970:INFO:Model: K Neighbors Classifier
2025-10-12 16:02:57,038:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:02:57,499:INFO:Creating Dashboard logs
2025-10-12 16:02:57,503:INFO:Model: Random Forest Classifier
2025-10-12 16:02:57,568:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 988, 'verbose': 0, 'warm_start': False}
2025-10-12 16:02:58,025:INFO:Creating Dashboard logs
2025-10-12 16:02:58,030:INFO:Model: Decision Tree Classifier
2025-10-12 16:02:58,102:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 988, 'splitter': 'best'}
2025-10-12 16:02:58,510:INFO:Creating Dashboard logs
2025-10-12 16:02:58,513:INFO:Model: Ada Boost Classifier
2025-10-12 16:02:58,581:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 988}
2025-10-12 16:02:58,945:INFO:Creating Dashboard logs
2025-10-12 16:02:58,949:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:02:59,015:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 988, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:02:59,417:INFO:Creating Dashboard logs
2025-10-12 16:02:59,420:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:02:59,496:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:02:59,897:INFO:Creating Dashboard logs
2025-10-12 16:02:59,900:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:02:59,995:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 988, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:03:00,428:INFO:Creating Dashboard logs
2025-10-12 16:03:00,431:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:03:00,500:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 988, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:03:00,891:INFO:Creating Dashboard logs
2025-10-12 16:03:00,893:INFO:Model: CatBoost Classifier
2025-10-12 16:03:00,955:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-10-12 16:03:00,955:INFO:Logged params: {}
2025-10-12 16:03:01,319:INFO:Creating Dashboard logs
2025-10-12 16:03:01,322:INFO:Model: Dummy Classifier
2025-10-12 16:03:01,390:INFO:Logged params: {'constant': None, 'random_state': 988, 'strategy': 'prior'}
2025-10-12 16:03:01,767:INFO:Creating Dashboard logs
2025-10-12 16:03:01,770:INFO:Model: SVM - Linear Kernel
2025-10-12 16:03:01,836:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 988, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:03:02,333:INFO:Creating Dashboard logs
2025-10-12 16:03:02,336:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 16:03:02,406:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:03:02,857:INFO:_master_model_container: 41
2025-10-12 16:03:02,857:INFO:_display_container: 11
2025-10-12 16:03:02,858:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=988, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:03:02,858:INFO:compare_models() successfully completed......................................
2025-10-12 16:03:28,620:INFO:Initializing predict_model()
2025-10-12 16:03:28,620:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=mlflow.pyfunc.loaded_model:
  run_id: 39f894e7d3eb44a99b7896e490c21033
  artifact_path: model
  flavor: mlflow.sklearn
, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E02AFF70>)
2025-10-12 16:03:28,620:INFO:Checking exceptions
2025-10-12 16:03:28,620:INFO:Preloading libraries
2025-10-12 16:03:28,621:INFO:Set up data.
2025-10-12 16:03:28,627:INFO:Set up index.
2025-10-12 16:03:59,182:INFO:Initializing predict_model()
2025-10-12 16:03:59,182:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265DFFBDE80>, estimator=mlflow.pyfunc.loaded_model:
  run_id: 39f894e7d3eb44a99b7896e490c21033
  artifact_path: model
  flavor: mlflow.sklearn
, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E15C94C0>)
2025-10-12 16:03:59,182:INFO:Checking exceptions
2025-10-12 16:03:59,182:INFO:Preloading libraries
2025-10-12 16:03:59,185:INFO:Set up data.
2025-10-12 16:03:59,193:INFO:Set up index.
2025-10-12 16:05:39,610:INFO:PyCaret ClassificationExperiment
2025-10-12 16:05:39,610:INFO:Logging name: titanic_exp_1
2025-10-12 16:05:39,610:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-12 16:05:39,610:INFO:version 3.3.2
2025-10-12 16:05:39,610:INFO:Initializing setup()
2025-10-12 16:05:39,610:INFO:self.USI: bf11
2025-10-12 16:05:39,610:INFO:self._variable_keys: {'fold_generator', 'is_multiclass', 'pipeline', 'y', 'target_param', '_ml_usecase', 'fold_shuffle_param', 'X_train', 'html_param', 'gpu_n_jobs_param', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', 'exp_id', 'data', 'y_test', 'exp_name_log', 'memory', 'y_train', 'X_test', 'seed', 'fix_imbalance', 'n_jobs_param', 'X', 'logging_param', '_available_plots', 'idx'}
2025-10-12 16:05:39,610:INFO:Checking environment
2025-10-12 16:05:39,610:INFO:python_version: 3.9.13
2025-10-12 16:05:39,610:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2025-10-12 16:05:39,610:INFO:machine: AMD64
2025-10-12 16:05:39,610:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-12 16:05:39,610:INFO:Memory: svmem(total=16778072064, available=1150844928, percent=93.1, used=15627227136, free=1150844928)
2025-10-12 16:05:39,610:INFO:Physical Core: 10
2025-10-12 16:05:39,610:INFO:Logical Core: 16
2025-10-12 16:05:39,610:INFO:Checking libraries
2025-10-12 16:05:39,610:INFO:System:
2025-10-12 16:05:39,610:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2025-10-12 16:05:39,610:INFO:executable: c:\Users\david\Programming\MLOps\.venv\Scripts\python.exe
2025-10-12 16:05:39,610:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-12 16:05:39,611:INFO:PyCaret required dependencies:
2025-10-12 16:05:39,611:INFO:                 pip: 25.2
2025-10-12 16:05:39,611:INFO:          setuptools: 80.9.0
2025-10-12 16:05:39,611:INFO:             pycaret: 3.3.2
2025-10-12 16:05:39,611:INFO:             IPython: 8.18.1
2025-10-12 16:05:39,611:INFO:          ipywidgets: 8.1.7
2025-10-12 16:05:39,611:INFO:                tqdm: 4.67.1
2025-10-12 16:05:39,611:INFO:               numpy: 1.26.4
2025-10-12 16:05:39,611:INFO:              pandas: 2.1.4
2025-10-12 16:05:39,611:INFO:              jinja2: 3.1.6
2025-10-12 16:05:39,611:INFO:               scipy: 1.11.4
2025-10-12 16:05:39,611:INFO:              joblib: 1.3.2
2025-10-12 16:05:39,611:INFO:             sklearn: 1.4.2
2025-10-12 16:05:39,611:INFO:                pyod: 2.0.5
2025-10-12 16:05:39,611:INFO:            imblearn: 0.12.4
2025-10-12 16:05:39,611:INFO:   category_encoders: 2.6.4
2025-10-12 16:05:39,611:INFO:            lightgbm: 4.6.0
2025-10-12 16:05:39,611:INFO:               numba: 0.60.0
2025-10-12 16:05:39,611:INFO:            requests: 2.32.5
2025-10-12 16:05:39,611:INFO:          matplotlib: 3.7.5
2025-10-12 16:05:39,611:INFO:          scikitplot: 0.3.7
2025-10-12 16:05:39,611:INFO:         yellowbrick: 1.5
2025-10-12 16:05:39,611:INFO:              plotly: 5.24.1
2025-10-12 16:05:39,611:INFO:    plotly-resampler: Not installed
2025-10-12 16:05:39,611:INFO:             kaleido: 1.1.0
2025-10-12 16:05:39,611:INFO:           schemdraw: 0.15
2025-10-12 16:05:39,611:INFO:         statsmodels: 0.14.5
2025-10-12 16:05:39,611:INFO:              sktime: 0.26.0
2025-10-12 16:05:39,611:INFO:               tbats: 1.1.3
2025-10-12 16:05:39,612:INFO:            pmdarima: 2.0.4
2025-10-12 16:05:39,612:INFO:              psutil: 7.1.0
2025-10-12 16:05:39,612:INFO:          markupsafe: 2.1.5
2025-10-12 16:05:39,612:INFO:             pickle5: Not installed
2025-10-12 16:05:39,612:INFO:         cloudpickle: 3.1.1
2025-10-12 16:05:39,612:INFO:         deprecation: 2.1.0
2025-10-12 16:05:39,612:INFO:              xxhash: 3.6.0
2025-10-12 16:05:39,612:INFO:           wurlitzer: Not installed
2025-10-12 16:05:39,612:INFO:PyCaret optional dependencies:
2025-10-12 16:05:39,612:INFO:                shap: 0.44.1
2025-10-12 16:05:39,612:INFO:           interpret: 0.7.2
2025-10-12 16:05:39,612:INFO:                umap: 0.5.7
2025-10-12 16:05:39,612:INFO:     ydata_profiling: 4.17.0
2025-10-12 16:05:39,612:INFO:  explainerdashboard: 0.5.1
2025-10-12 16:05:39,612:INFO:             autoviz: Not installed
2025-10-12 16:05:39,612:INFO:           fairlearn: 0.7.0
2025-10-12 16:05:39,612:INFO:          deepchecks: Not installed
2025-10-12 16:05:39,612:INFO:             xgboost: 2.1.4
2025-10-12 16:05:39,612:INFO:            catboost: 1.2.8
2025-10-12 16:05:39,612:INFO:              kmodes: 0.12.2
2025-10-12 16:05:39,612:INFO:             mlxtend: 0.23.4
2025-10-12 16:05:39,612:INFO:       statsforecast: 1.5.0
2025-10-12 16:05:39,612:INFO:        tune_sklearn: Not installed
2025-10-12 16:05:39,612:INFO:                 ray: Not installed
2025-10-12 16:05:39,612:INFO:            hyperopt: 0.2.7
2025-10-12 16:05:39,612:INFO:              optuna: 4.5.0
2025-10-12 16:05:39,612:INFO:               skopt: 0.10.2
2025-10-12 16:05:39,612:INFO:              mlflow: 3.1.4
2025-10-12 16:05:39,612:INFO:              gradio: Not installed
2025-10-12 16:05:39,612:INFO:             fastapi: 0.119.0
2025-10-12 16:05:39,612:INFO:             uvicorn: 0.37.0
2025-10-12 16:05:39,612:INFO:              m2cgen: 0.10.0
2025-10-12 16:05:39,612:INFO:           evidently: 0.4.40
2025-10-12 16:05:39,612:INFO:               fugue: 0.8.7
2025-10-12 16:05:39,612:INFO:           streamlit: Not installed
2025-10-12 16:05:39,612:INFO:             prophet: Not installed
2025-10-12 16:05:39,612:INFO:None
2025-10-12 16:05:39,612:INFO:Set up data.
2025-10-12 16:05:39,621:INFO:Set up folding strategy.
2025-10-12 16:05:39,621:INFO:Set up train/test split.
2025-10-12 16:05:39,627:INFO:Set up index.
2025-10-12 16:05:39,627:INFO:Assigning column types.
2025-10-12 16:05:39,631:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-12 16:05:39,661:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:05:39,662:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:05:39,678:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:05:39,680:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:05:39,705:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:05:39,706:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:05:39,722:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:05:39,724:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:05:39,724:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-12 16:05:39,750:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:05:39,766:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:05:39,767:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:05:39,794:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:05:39,809:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:05:39,811:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:05:39,811:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-12 16:05:39,854:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:05:39,856:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:05:39,898:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:05:39,900:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:05:39,901:INFO:Preparing preprocessing pipeline...
2025-10-12 16:05:39,902:INFO:Set up simple imputation.
2025-10-12 16:05:39,904:INFO:Set up encoding of ordinal features.
2025-10-12 16:05:39,904:INFO:Set up encoding of categorical features.
2025-10-12 16:05:39,985:INFO:Finished creating preprocessing pipeline.
2025-10-12 16:05:39,996:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-10-12 16:05:39,996:INFO:Creating final display dataframe.
2025-10-12 16:05:40,252:INFO:Setup _display_container:                     Description            Value
0                    Session id             4451
1                        Target         Survived
2                   Target type           Binary
3           Original data shape        (712, 12)
4        Transformed data shape        (712, 14)
5   Transformed train set shape        (498, 14)
6    Transformed test set shape        (214, 14)
7              Numeric features                6
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name    titanic_exp_1
21                          USI             bf11
2025-10-12 16:05:40,302:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:05:40,304:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:05:40,349:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:05:40,351:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:05:40,352:INFO:Logging experiment in loggers
2025-10-12 16:05:40,452:INFO:SubProcess save_model() called ==================================
2025-10-12 16:05:40,474:INFO:Initializing save_model()
2025-10-12 16:05:40,474:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\david\AppData\Local\Temp\tmpy8e0ro5p\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 16:05:40,474:INFO:Adding model into prep_pipe
2025-10-12 16:05:40,474:WARNING:Only Model saved as it was a pipeline.
2025-10-12 16:05:40,481:INFO:C:\Users\david\AppData\Local\Temp\tmpy8e0ro5p\Transformation Pipeline.pkl saved in current working directory
2025-10-12 16:05:40,491:INFO:Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-10-12 16:05:40,492:INFO:save_model() successfully completed......................................
2025-10-12 16:05:40,646:INFO:SubProcess save_model() end ==================================
2025-10-12 16:05:40,720:INFO:setup() successfully completed in 0.75s...............
2025-10-12 16:05:40,749:INFO:Initializing compare_models()
2025-10-12 16:05:40,749:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:05:40,749:INFO:Checking exceptions
2025-10-12 16:05:40,752:INFO:Preparing display monitor
2025-10-12 16:05:40,770:INFO:Initializing Logistic Regression
2025-10-12 16:05:40,770:INFO:Total runtime is 0.0 minutes
2025-10-12 16:05:40,774:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:40,774:INFO:Initializing create_model()
2025-10-12 16:05:40,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:40,774:INFO:Checking exceptions
2025-10-12 16:05:40,774:INFO:Importing libraries
2025-10-12 16:05:40,774:INFO:Copying training dataset
2025-10-12 16:05:40,778:INFO:Defining folds
2025-10-12 16:05:40,779:INFO:Declaring metric variables
2025-10-12 16:05:40,781:INFO:Importing untrained model
2025-10-12 16:05:40,783:INFO:Logistic Regression Imported successfully
2025-10-12 16:05:40,788:INFO:Starting cross validation
2025-10-12 16:05:40,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:40,965:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:05:40,967:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:05:40,977:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:05:40,982:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:05:40,983:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:05:41,030:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:05:41,034:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:05:41,035:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:05:41,038:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:05:41,084:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:05:41,120:INFO:Calculating mean and std
2025-10-12 16:05:41,120:INFO:Creating metrics dataframe
2025-10-12 16:05:41,122:INFO:Uploading results into container
2025-10-12 16:05:41,122:INFO:Uploading model into container now
2025-10-12 16:05:41,122:INFO:_master_model_container: 1
2025-10-12 16:05:41,122:INFO:_display_container: 2
2025-10-12 16:05:41,122:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:05:41,122:INFO:create_model() successfully completed......................................
2025-10-12 16:05:41,278:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:41,278:INFO:Creating metrics dataframe
2025-10-12 16:05:41,283:INFO:Initializing K Neighbors Classifier
2025-10-12 16:05:41,284:INFO:Total runtime is 0.008568374315897624 minutes
2025-10-12 16:05:41,286:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:41,286:INFO:Initializing create_model()
2025-10-12 16:05:41,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:41,286:INFO:Checking exceptions
2025-10-12 16:05:41,286:INFO:Importing libraries
2025-10-12 16:05:41,287:INFO:Copying training dataset
2025-10-12 16:05:41,289:INFO:Defining folds
2025-10-12 16:05:41,289:INFO:Declaring metric variables
2025-10-12 16:05:41,292:INFO:Importing untrained model
2025-10-12 16:05:41,296:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:05:41,304:INFO:Starting cross validation
2025-10-12 16:05:41,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:41,635:INFO:Calculating mean and std
2025-10-12 16:05:41,635:INFO:Creating metrics dataframe
2025-10-12 16:05:41,636:INFO:Uploading results into container
2025-10-12 16:05:41,637:INFO:Uploading model into container now
2025-10-12 16:05:41,638:INFO:_master_model_container: 2
2025-10-12 16:05:41,638:INFO:_display_container: 2
2025-10-12 16:05:41,638:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:05:41,638:INFO:create_model() successfully completed......................................
2025-10-12 16:05:41,791:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:41,791:INFO:Creating metrics dataframe
2025-10-12 16:05:41,796:INFO:Initializing Naive Bayes
2025-10-12 16:05:41,797:INFO:Total runtime is 0.017119248708089195 minutes
2025-10-12 16:05:41,799:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:41,800:INFO:Initializing create_model()
2025-10-12 16:05:41,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:41,800:INFO:Checking exceptions
2025-10-12 16:05:41,800:INFO:Importing libraries
2025-10-12 16:05:41,800:INFO:Copying training dataset
2025-10-12 16:05:41,804:INFO:Defining folds
2025-10-12 16:05:41,804:INFO:Declaring metric variables
2025-10-12 16:05:41,808:INFO:Importing untrained model
2025-10-12 16:05:41,811:INFO:Naive Bayes Imported successfully
2025-10-12 16:05:41,818:INFO:Starting cross validation
2025-10-12 16:05:41,819:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:41,966:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,008:INFO:Calculating mean and std
2025-10-12 16:05:42,009:INFO:Creating metrics dataframe
2025-10-12 16:05:42,011:INFO:Uploading results into container
2025-10-12 16:05:42,011:INFO:Uploading model into container now
2025-10-12 16:05:42,012:INFO:_master_model_container: 3
2025-10-12 16:05:42,012:INFO:_display_container: 2
2025-10-12 16:05:42,012:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:05:42,012:INFO:create_model() successfully completed......................................
2025-10-12 16:05:42,176:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:42,177:INFO:Creating metrics dataframe
2025-10-12 16:05:42,182:INFO:Initializing Decision Tree Classifier
2025-10-12 16:05:42,182:INFO:Total runtime is 0.023539034525553386 minutes
2025-10-12 16:05:42,186:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:42,186:INFO:Initializing create_model()
2025-10-12 16:05:42,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:42,186:INFO:Checking exceptions
2025-10-12 16:05:42,186:INFO:Importing libraries
2025-10-12 16:05:42,186:INFO:Copying training dataset
2025-10-12 16:05:42,190:INFO:Defining folds
2025-10-12 16:05:42,191:INFO:Declaring metric variables
2025-10-12 16:05:42,194:INFO:Importing untrained model
2025-10-12 16:05:42,197:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:05:42,202:INFO:Starting cross validation
2025-10-12 16:05:42,204:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:42,329:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,332:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,356:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,357:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,362:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,368:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,370:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,374:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,379:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,420:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,424:INFO:Calculating mean and std
2025-10-12 16:05:42,425:INFO:Creating metrics dataframe
2025-10-12 16:05:42,427:INFO:Uploading results into container
2025-10-12 16:05:42,428:INFO:Uploading model into container now
2025-10-12 16:05:42,428:INFO:_master_model_container: 4
2025-10-12 16:05:42,428:INFO:_display_container: 2
2025-10-12 16:05:42,429:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=4451, splitter='best')
2025-10-12 16:05:42,429:INFO:create_model() successfully completed......................................
2025-10-12 16:05:42,609:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:42,609:INFO:Creating metrics dataframe
2025-10-12 16:05:42,614:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:05:42,615:INFO:Total runtime is 0.030752046902974447 minutes
2025-10-12 16:05:42,617:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:42,618:INFO:Initializing create_model()
2025-10-12 16:05:42,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:42,618:INFO:Checking exceptions
2025-10-12 16:05:42,618:INFO:Importing libraries
2025-10-12 16:05:42,618:INFO:Copying training dataset
2025-10-12 16:05:42,621:INFO:Defining folds
2025-10-12 16:05:42,621:INFO:Declaring metric variables
2025-10-12 16:05:42,625:INFO:Importing untrained model
2025-10-12 16:05:42,628:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:05:42,634:INFO:Starting cross validation
2025-10-12 16:05:42,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:42,785:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,785:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,793:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:42,813:INFO:Calculating mean and std
2025-10-12 16:05:42,813:INFO:Creating metrics dataframe
2025-10-12 16:05:42,816:INFO:Uploading results into container
2025-10-12 16:05:42,816:INFO:Uploading model into container now
2025-10-12 16:05:42,816:INFO:_master_model_container: 5
2025-10-12 16:05:42,817:INFO:_display_container: 2
2025-10-12 16:05:42,817:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4451, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:05:42,817:INFO:create_model() successfully completed......................................
2025-10-12 16:05:42,972:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:42,972:INFO:Creating metrics dataframe
2025-10-12 16:05:42,978:INFO:Initializing Ridge Classifier
2025-10-12 16:05:42,978:INFO:Total runtime is 0.036798910299936934 minutes
2025-10-12 16:05:42,981:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:42,981:INFO:Initializing create_model()
2025-10-12 16:05:42,981:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:42,981:INFO:Checking exceptions
2025-10-12 16:05:42,981:INFO:Importing libraries
2025-10-12 16:05:42,981:INFO:Copying training dataset
2025-10-12 16:05:42,984:INFO:Defining folds
2025-10-12 16:05:42,984:INFO:Declaring metric variables
2025-10-12 16:05:42,988:INFO:Importing untrained model
2025-10-12 16:05:42,990:INFO:Ridge Classifier Imported successfully
2025-10-12 16:05:42,997:INFO:Starting cross validation
2025-10-12 16:05:43,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:43,184:INFO:Calculating mean and std
2025-10-12 16:05:43,185:INFO:Creating metrics dataframe
2025-10-12 16:05:43,187:INFO:Uploading results into container
2025-10-12 16:05:43,187:INFO:Uploading model into container now
2025-10-12 16:05:43,188:INFO:_master_model_container: 6
2025-10-12 16:05:43,188:INFO:_display_container: 2
2025-10-12 16:05:43,188:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001)
2025-10-12 16:05:43,188:INFO:create_model() successfully completed......................................
2025-10-12 16:05:43,339:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:43,339:INFO:Creating metrics dataframe
2025-10-12 16:05:43,345:INFO:Initializing Random Forest Classifier
2025-10-12 16:05:43,345:INFO:Total runtime is 0.042913146813710536 minutes
2025-10-12 16:05:43,348:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:43,349:INFO:Initializing create_model()
2025-10-12 16:05:43,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:43,349:INFO:Checking exceptions
2025-10-12 16:05:43,349:INFO:Importing libraries
2025-10-12 16:05:43,349:INFO:Copying training dataset
2025-10-12 16:05:43,352:INFO:Defining folds
2025-10-12 16:05:43,352:INFO:Declaring metric variables
2025-10-12 16:05:43,355:INFO:Importing untrained model
2025-10-12 16:05:43,358:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:05:43,363:INFO:Starting cross validation
2025-10-12 16:05:43,365:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:43,702:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:43,731:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:43,732:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:43,755:INFO:Calculating mean and std
2025-10-12 16:05:43,756:INFO:Creating metrics dataframe
2025-10-12 16:05:43,758:INFO:Uploading results into container
2025-10-12 16:05:43,758:INFO:Uploading model into container now
2025-10-12 16:05:43,759:INFO:_master_model_container: 7
2025-10-12 16:05:43,759:INFO:_display_container: 2
2025-10-12 16:05:43,759:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4451, verbose=0,
                       warm_start=False)
2025-10-12 16:05:43,759:INFO:create_model() successfully completed......................................
2025-10-12 16:05:43,910:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:43,910:INFO:Creating metrics dataframe
2025-10-12 16:05:43,916:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:05:43,916:INFO:Total runtime is 0.052436339855194095 minutes
2025-10-12 16:05:43,919:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:43,919:INFO:Initializing create_model()
2025-10-12 16:05:43,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:43,919:INFO:Checking exceptions
2025-10-12 16:05:43,919:INFO:Importing libraries
2025-10-12 16:05:43,919:INFO:Copying training dataset
2025-10-12 16:05:43,922:INFO:Defining folds
2025-10-12 16:05:43,922:INFO:Declaring metric variables
2025-10-12 16:05:43,926:INFO:Importing untrained model
2025-10-12 16:05:43,929:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:05:43,934:INFO:Starting cross validation
2025-10-12 16:05:43,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:44,024:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:05:44,038:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:05:44,046:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:05:44,046:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:05:44,046:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:05:44,046:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:05:44,047:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:05:44,049:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:05:44,050:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:05:44,057:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:05:44,061:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,081:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,087:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,089:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,090:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,091:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,093:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,097:INFO:Calculating mean and std
2025-10-12 16:05:44,098:INFO:Creating metrics dataframe
2025-10-12 16:05:44,099:INFO:Uploading results into container
2025-10-12 16:05:44,100:INFO:Uploading model into container now
2025-10-12 16:05:44,100:INFO:_master_model_container: 8
2025-10-12 16:05:44,100:INFO:_display_container: 2
2025-10-12 16:05:44,101:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:05:44,101:INFO:create_model() successfully completed......................................
2025-10-12 16:05:44,250:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:44,250:INFO:Creating metrics dataframe
2025-10-12 16:05:44,255:INFO:Initializing Ada Boost Classifier
2025-10-12 16:05:44,255:INFO:Total runtime is 0.05807775656382243 minutes
2025-10-12 16:05:44,258:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:44,259:INFO:Initializing create_model()
2025-10-12 16:05:44,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:44,259:INFO:Checking exceptions
2025-10-12 16:05:44,259:INFO:Importing libraries
2025-10-12 16:05:44,259:INFO:Copying training dataset
2025-10-12 16:05:44,262:INFO:Defining folds
2025-10-12 16:05:44,262:INFO:Declaring metric variables
2025-10-12 16:05:44,266:INFO:Importing untrained model
2025-10-12 16:05:44,268:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:05:44,276:INFO:Starting cross validation
2025-10-12 16:05:44,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:44,350:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:05:44,357:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:05:44,363:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:05:44,363:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:05:44,369:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:05:44,371:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:05:44,372:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:05:44,378:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:05:44,380:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,384:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:05:44,385:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:05:44,391:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,397:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,406:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,409:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,410:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,410:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,414:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,421:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,426:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,440:INFO:Calculating mean and std
2025-10-12 16:05:44,441:INFO:Creating metrics dataframe
2025-10-12 16:05:44,443:INFO:Uploading results into container
2025-10-12 16:05:44,443:INFO:Uploading model into container now
2025-10-12 16:05:44,444:INFO:_master_model_container: 9
2025-10-12 16:05:44,444:INFO:_display_container: 2
2025-10-12 16:05:44,444:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4451)
2025-10-12 16:05:44,444:INFO:create_model() successfully completed......................................
2025-10-12 16:05:44,588:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:44,589:INFO:Creating metrics dataframe
2025-10-12 16:05:44,595:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:05:44,595:INFO:Total runtime is 0.0637471079826355 minutes
2025-10-12 16:05:44,598:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:44,598:INFO:Initializing create_model()
2025-10-12 16:05:44,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:44,598:INFO:Checking exceptions
2025-10-12 16:05:44,599:INFO:Importing libraries
2025-10-12 16:05:44,599:INFO:Copying training dataset
2025-10-12 16:05:44,602:INFO:Defining folds
2025-10-12 16:05:44,603:INFO:Declaring metric variables
2025-10-12 16:05:44,606:INFO:Importing untrained model
2025-10-12 16:05:44,609:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:05:44,614:INFO:Starting cross validation
2025-10-12 16:05:44,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:44,807:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,816:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,819:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,822:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,824:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,826:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,828:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,830:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,832:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,843:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:44,858:INFO:Calculating mean and std
2025-10-12 16:05:44,859:INFO:Creating metrics dataframe
2025-10-12 16:05:44,861:INFO:Uploading results into container
2025-10-12 16:05:44,861:INFO:Uploading model into container now
2025-10-12 16:05:44,862:INFO:_master_model_container: 10
2025-10-12 16:05:44,862:INFO:_display_container: 2
2025-10-12 16:05:44,862:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4451, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:05:44,862:INFO:create_model() successfully completed......................................
2025-10-12 16:05:45,007:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:45,007:INFO:Creating metrics dataframe
2025-10-12 16:05:45,014:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:05:45,014:INFO:Total runtime is 0.07072983980178833 minutes
2025-10-12 16:05:45,016:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:45,016:INFO:Initializing create_model()
2025-10-12 16:05:45,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:45,017:INFO:Checking exceptions
2025-10-12 16:05:45,017:INFO:Importing libraries
2025-10-12 16:05:45,017:INFO:Copying training dataset
2025-10-12 16:05:45,020:INFO:Defining folds
2025-10-12 16:05:45,020:INFO:Declaring metric variables
2025-10-12 16:05:45,023:INFO:Importing untrained model
2025-10-12 16:05:45,026:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:05:45,031:INFO:Starting cross validation
2025-10-12 16:05:45,033:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:45,131:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:45,144:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:45,161:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:45,162:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:45,166:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:45,166:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:45,172:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:45,173:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:45,174:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:45,179:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:45,185:INFO:Calculating mean and std
2025-10-12 16:05:45,186:INFO:Creating metrics dataframe
2025-10-12 16:05:45,187:INFO:Uploading results into container
2025-10-12 16:05:45,188:INFO:Uploading model into container now
2025-10-12 16:05:45,188:INFO:_master_model_container: 11
2025-10-12 16:05:45,188:INFO:_display_container: 2
2025-10-12 16:05:45,189:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:05:45,189:INFO:create_model() successfully completed......................................
2025-10-12 16:05:45,337:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:45,337:INFO:Creating metrics dataframe
2025-10-12 16:05:45,344:INFO:Initializing Extra Trees Classifier
2025-10-12 16:05:45,344:INFO:Total runtime is 0.07623353004455567 minutes
2025-10-12 16:05:45,347:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:45,347:INFO:Initializing create_model()
2025-10-12 16:05:45,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:45,347:INFO:Checking exceptions
2025-10-12 16:05:45,348:INFO:Importing libraries
2025-10-12 16:05:45,348:INFO:Copying training dataset
2025-10-12 16:05:45,351:INFO:Defining folds
2025-10-12 16:05:45,351:INFO:Declaring metric variables
2025-10-12 16:05:45,354:INFO:Importing untrained model
2025-10-12 16:05:45,356:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:05:45,361:INFO:Starting cross validation
2025-10-12 16:05:45,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:45,766:INFO:Calculating mean and std
2025-10-12 16:05:45,767:INFO:Creating metrics dataframe
2025-10-12 16:05:45,768:INFO:Uploading results into container
2025-10-12 16:05:45,769:INFO:Uploading model into container now
2025-10-12 16:05:45,770:INFO:_master_model_container: 12
2025-10-12 16:05:45,770:INFO:_display_container: 2
2025-10-12 16:05:45,770:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4451, verbose=0,
                     warm_start=False)
2025-10-12 16:05:45,770:INFO:create_model() successfully completed......................................
2025-10-12 16:05:45,912:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:45,913:INFO:Creating metrics dataframe
2025-10-12 16:05:45,918:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:05:45,918:INFO:Total runtime is 0.0858091433842977 minutes
2025-10-12 16:05:45,922:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:45,922:INFO:Initializing create_model()
2025-10-12 16:05:45,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:45,922:INFO:Checking exceptions
2025-10-12 16:05:45,922:INFO:Importing libraries
2025-10-12 16:05:45,922:INFO:Copying training dataset
2025-10-12 16:05:45,926:INFO:Defining folds
2025-10-12 16:05:45,926:INFO:Declaring metric variables
2025-10-12 16:05:45,929:INFO:Importing untrained model
2025-10-12 16:05:45,932:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:05:45,938:INFO:Starting cross validation
2025-10-12 16:05:45,939:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:46,069:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:46,075:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:46,102:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:46,103:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:46,117:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:46,122:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:46,124:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:46,125:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:46,125:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:46,227:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:46,231:INFO:Calculating mean and std
2025-10-12 16:05:46,232:INFO:Creating metrics dataframe
2025-10-12 16:05:46,235:INFO:Uploading results into container
2025-10-12 16:05:46,235:INFO:Uploading model into container now
2025-10-12 16:05:46,235:INFO:_master_model_container: 13
2025-10-12 16:05:46,235:INFO:_display_container: 2
2025-10-12 16:05:46,236:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:05:46,236:INFO:create_model() successfully completed......................................
2025-10-12 16:05:46,396:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:46,396:INFO:Creating metrics dataframe
2025-10-12 16:05:46,404:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:05:46,404:INFO:Total runtime is 0.09389947652816773 minutes
2025-10-12 16:05:46,408:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:46,408:INFO:Initializing create_model()
2025-10-12 16:05:46,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:46,408:INFO:Checking exceptions
2025-10-12 16:05:46,408:INFO:Importing libraries
2025-10-12 16:05:46,408:INFO:Copying training dataset
2025-10-12 16:05:46,412:INFO:Defining folds
2025-10-12 16:05:46,412:INFO:Declaring metric variables
2025-10-12 16:05:46,416:INFO:Importing untrained model
2025-10-12 16:05:46,419:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:05:46,424:INFO:Starting cross validation
2025-10-12 16:05:46,425:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:48,222:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:48,252:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:48,269:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:48,290:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:48,290:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:48,306:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:48,324:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:48,337:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:48,345:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:48,350:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:48,359:INFO:Calculating mean and std
2025-10-12 16:05:48,360:INFO:Creating metrics dataframe
2025-10-12 16:05:48,362:INFO:Uploading results into container
2025-10-12 16:05:48,364:INFO:Uploading model into container now
2025-10-12 16:05:48,364:INFO:_master_model_container: 14
2025-10-12 16:05:48,364:INFO:_display_container: 2
2025-10-12 16:05:48,365:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4451, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:05:48,365:INFO:create_model() successfully completed......................................
2025-10-12 16:05:48,524:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:48,524:INFO:Creating metrics dataframe
2025-10-12 16:05:48,531:INFO:Initializing CatBoost Classifier
2025-10-12 16:05:48,531:INFO:Total runtime is 0.1293531854947408 minutes
2025-10-12 16:05:48,534:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:48,535:INFO:Initializing create_model()
2025-10-12 16:05:48,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:48,535:INFO:Checking exceptions
2025-10-12 16:05:48,535:INFO:Importing libraries
2025-10-12 16:05:48,535:INFO:Copying training dataset
2025-10-12 16:05:48,538:INFO:Defining folds
2025-10-12 16:05:48,538:INFO:Declaring metric variables
2025-10-12 16:05:48,542:INFO:Importing untrained model
2025-10-12 16:05:48,545:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:05:48,551:INFO:Starting cross validation
2025-10-12 16:05:48,552:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:50,312:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:50,337:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:50,339:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:50,357:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:51,631:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:51,715:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:51,727:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:51,757:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:51,760:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:52,531:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:52,539:INFO:Calculating mean and std
2025-10-12 16:05:52,540:INFO:Creating metrics dataframe
2025-10-12 16:05:52,541:INFO:Uploading results into container
2025-10-12 16:05:52,542:INFO:Uploading model into container now
2025-10-12 16:05:52,542:INFO:_master_model_container: 15
2025-10-12 16:05:52,544:INFO:_display_container: 2
2025-10-12 16:05:52,544:INFO:<catboost.core.CatBoostClassifier object at 0x00000265E02E1430>
2025-10-12 16:05:52,544:INFO:create_model() successfully completed......................................
2025-10-12 16:05:52,694:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:52,694:INFO:Creating metrics dataframe
2025-10-12 16:05:52,701:INFO:Initializing Dummy Classifier
2025-10-12 16:05:52,701:INFO:Total runtime is 0.19885547955830893 minutes
2025-10-12 16:05:52,705:INFO:SubProcess create_model() called ==================================
2025-10-12 16:05:52,705:INFO:Initializing create_model()
2025-10-12 16:05:52,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DB757B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:52,705:INFO:Checking exceptions
2025-10-12 16:05:52,705:INFO:Importing libraries
2025-10-12 16:05:52,705:INFO:Copying training dataset
2025-10-12 16:05:52,708:INFO:Defining folds
2025-10-12 16:05:52,708:INFO:Declaring metric variables
2025-10-12 16:05:52,712:INFO:Importing untrained model
2025-10-12 16:05:52,716:INFO:Dummy Classifier Imported successfully
2025-10-12 16:05:52,722:INFO:Starting cross validation
2025-10-12 16:05:52,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:05:52,835:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:52,839:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:52,844:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:52,849:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:52,853:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:52,862:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:52,866:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:52,867:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:52,870:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:52,877:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:05:52,896:INFO:Calculating mean and std
2025-10-12 16:05:52,897:INFO:Creating metrics dataframe
2025-10-12 16:05:52,898:INFO:Uploading results into container
2025-10-12 16:05:52,898:INFO:Uploading model into container now
2025-10-12 16:05:52,899:INFO:_master_model_container: 16
2025-10-12 16:05:52,899:INFO:_display_container: 2
2025-10-12 16:05:52,899:INFO:DummyClassifier(constant=None, random_state=4451, strategy='prior')
2025-10-12 16:05:52,899:INFO:create_model() successfully completed......................................
2025-10-12 16:05:53,048:INFO:SubProcess create_model() end ==================================
2025-10-12 16:05:53,048:INFO:Creating metrics dataframe
2025-10-12 16:05:53,056:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:05:53,065:INFO:Initializing create_model()
2025-10-12 16:05:53,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:05:53,065:INFO:Checking exceptions
2025-10-12 16:05:53,067:INFO:Importing libraries
2025-10-12 16:05:53,067:INFO:Copying training dataset
2025-10-12 16:05:53,070:INFO:Defining folds
2025-10-12 16:05:53,070:INFO:Declaring metric variables
2025-10-12 16:05:53,070:INFO:Importing untrained model
2025-10-12 16:05:53,070:INFO:Declaring custom model
2025-10-12 16:05:53,071:INFO:Logistic Regression Imported successfully
2025-10-12 16:05:53,072:INFO:Cross validation set to False
2025-10-12 16:05:53,072:INFO:Fitting Model
2025-10-12 16:05:53,172:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:05:53,173:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:05:53,173:INFO:create_model() successfully completed......................................
2025-10-12 16:05:53,321:INFO:Creating Dashboard logs
2025-10-12 16:05:53,325:INFO:Model: Logistic Regression
2025-10-12 16:05:53,402:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 4451, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:05:53,622:INFO:Initializing predict_model()
2025-10-12 16:05:53,622:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E1652D30>)
2025-10-12 16:05:53,622:INFO:Checking exceptions
2025-10-12 16:05:53,622:INFO:Preloading libraries
2025-10-12 16:05:53,951:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:05:53,951:INFO:Initializing plot_model()
2025-10-12 16:05:53,951:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp7j4_l1zl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:05:53,952:INFO:Checking exceptions
2025-10-12 16:05:53,953:INFO:Preloading libraries
2025-10-12 16:05:53,953:INFO:Copying training dataset
2025-10-12 16:05:53,953:INFO:Plot type: auc
2025-10-12 16:05:54,224:INFO:Fitting Model
2025-10-12 16:05:54,224:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:05:54,224:INFO:Scoring test/hold-out set
2025-10-12 16:05:54,238:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp7j4_l1zl\AUC.png'
2025-10-12 16:05:54,389:INFO:Visual Rendered Successfully
2025-10-12 16:05:54,531:INFO:plot_model() successfully completed......................................
2025-10-12 16:05:54,550:INFO:Initializing plot_model()
2025-10-12 16:05:54,550:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp7j4_l1zl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:05:54,550:INFO:Checking exceptions
2025-10-12 16:05:54,552:INFO:Preloading libraries
2025-10-12 16:05:54,552:INFO:Copying training dataset
2025-10-12 16:05:54,552:INFO:Plot type: confusion_matrix
2025-10-12 16:05:54,825:INFO:Fitting Model
2025-10-12 16:05:54,825:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:05:54,825:INFO:Scoring test/hold-out set
2025-10-12 16:05:54,837:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp7j4_l1zl\Confusion Matrix.png'
2025-10-12 16:05:54,909:INFO:Visual Rendered Successfully
2025-10-12 16:05:55,060:INFO:plot_model() successfully completed......................................
2025-10-12 16:05:55,078:INFO:Initializing plot_model()
2025-10-12 16:05:55,078:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp7j4_l1zl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:05:55,078:INFO:Checking exceptions
2025-10-12 16:05:55,079:INFO:Preloading libraries
2025-10-12 16:05:55,080:INFO:Copying training dataset
2025-10-12 16:05:55,080:INFO:Plot type: feature
2025-10-12 16:05:55,225:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp7j4_l1zl\Feature Importance.png'
2025-10-12 16:05:55,337:INFO:Visual Rendered Successfully
2025-10-12 16:05:55,479:INFO:plot_model() successfully completed......................................
2025-10-12 16:05:55,496:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:05:55,719:INFO:Creating Dashboard logs
2025-10-12 16:05:55,722:INFO:Model: Ridge Classifier
2025-10-12 16:05:55,788:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 4451, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:05:56,251:INFO:Creating Dashboard logs
2025-10-12 16:05:56,254:INFO:Model: Extra Trees Classifier
2025-10-12 16:05:56,317:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 4451, 'verbose': 0, 'warm_start': False}
2025-10-12 16:05:56,798:INFO:Creating Dashboard logs
2025-10-12 16:05:56,801:INFO:Model: Naive Bayes
2025-10-12 16:05:56,869:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:05:57,338:INFO:Creating Dashboard logs
2025-10-12 16:05:57,342:INFO:Model: Random Forest Classifier
2025-10-12 16:05:57,406:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 4451, 'verbose': 0, 'warm_start': False}
2025-10-12 16:05:57,896:INFO:Creating Dashboard logs
2025-10-12 16:05:57,899:INFO:Model: SVM - Linear Kernel
2025-10-12 16:05:57,966:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 4451, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:05:58,476:INFO:Creating Dashboard logs
2025-10-12 16:05:58,479:INFO:Model: K Neighbors Classifier
2025-10-12 16:05:58,555:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:05:59,002:INFO:Creating Dashboard logs
2025-10-12 16:05:59,005:INFO:Model: Decision Tree Classifier
2025-10-12 16:05:59,067:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 4451, 'splitter': 'best'}
2025-10-12 16:05:59,457:INFO:Creating Dashboard logs
2025-10-12 16:05:59,460:INFO:Model: Ada Boost Classifier
2025-10-12 16:05:59,530:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 4451}
2025-10-12 16:05:59,912:INFO:Creating Dashboard logs
2025-10-12 16:05:59,916:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:05:59,980:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 4451, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:06:00,386:INFO:Creating Dashboard logs
2025-10-12 16:06:00,389:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:06:00,452:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:06:00,839:INFO:Creating Dashboard logs
2025-10-12 16:06:00,842:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:06:00,919:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 4451, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:06:01,354:INFO:Creating Dashboard logs
2025-10-12 16:06:01,356:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:06:01,427:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 4451, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:06:01,854:INFO:Creating Dashboard logs
2025-10-12 16:06:01,856:INFO:Model: CatBoost Classifier
2025-10-12 16:06:01,925:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-10-12 16:06:01,925:INFO:Logged params: {}
2025-10-12 16:06:02,332:INFO:Creating Dashboard logs
2025-10-12 16:06:02,336:INFO:Model: Dummy Classifier
2025-10-12 16:06:02,397:INFO:Logged params: {'constant': None, 'random_state': 4451, 'strategy': 'prior'}
2025-10-12 16:06:02,788:INFO:Creating Dashboard logs
2025-10-12 16:06:02,791:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 16:06:02,864:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:06:03,326:INFO:_master_model_container: 16
2025-10-12 16:06:03,326:INFO:_display_container: 2
2025-10-12 16:06:03,326:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:06:03,326:INFO:compare_models() successfully completed......................................
2025-10-12 16:06:03,346:INFO:Initializing finalize_model()
2025-10-12 16:06:03,346:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-12 16:06:03,346:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:06:03,349:INFO:Initializing create_model()
2025-10-12 16:06:03,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:06:03,349:INFO:Checking exceptions
2025-10-12 16:06:03,350:INFO:Importing libraries
2025-10-12 16:06:03,351:INFO:Copying training dataset
2025-10-12 16:06:03,351:INFO:Defining folds
2025-10-12 16:06:03,351:INFO:Declaring metric variables
2025-10-12 16:06:03,351:INFO:Importing untrained model
2025-10-12 16:06:03,351:INFO:Declaring custom model
2025-10-12 16:06:03,352:INFO:Logistic Regression Imported successfully
2025-10-12 16:06:03,352:INFO:Cross validation set to False
2025-10-12 16:06:03,352:INFO:Fitting Model
2025-10-12 16:06:03,860:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:03,871:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=4451,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-10-12 16:06:03,871:INFO:create_model() successfully completed......................................
2025-10-12 16:06:04,017:INFO:Creating Dashboard logs
2025-10-12 16:06:04,017:INFO:Model: Logistic Regression
2025-10-12 16:06:04,089:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 4451, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:06:04,199:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:06:04,210:INFO:Initializing plot_model()
2025-10-12 16:06:04,210:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=4451,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpwrfyb7g8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:04,210:INFO:Checking exceptions
2025-10-12 16:06:04,211:INFO:Preloading libraries
2025-10-12 16:06:04,211:INFO:Copying training dataset
2025-10-12 16:06:04,211:INFO:Plot type: auc
2025-10-12 16:06:04,477:INFO:Fitting Model
2025-10-12 16:06:04,477:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:06:04,477:INFO:Scoring test/hold-out set
2025-10-12 16:06:04,490:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpwrfyb7g8\AUC.png'
2025-10-12 16:06:04,643:INFO:Visual Rendered Successfully
2025-10-12 16:06:04,790:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:04,825:INFO:Initializing plot_model()
2025-10-12 16:06:04,825:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=4451,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpwrfyb7g8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:04,825:INFO:Checking exceptions
2025-10-12 16:06:04,826:INFO:Preloading libraries
2025-10-12 16:06:04,826:INFO:Copying training dataset
2025-10-12 16:06:04,826:INFO:Plot type: confusion_matrix
2025-10-12 16:06:05,090:INFO:Fitting Model
2025-10-12 16:06:05,090:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:06:05,090:INFO:Scoring test/hold-out set
2025-10-12 16:06:05,102:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpwrfyb7g8\Confusion Matrix.png'
2025-10-12 16:06:05,176:INFO:Visual Rendered Successfully
2025-10-12 16:06:05,321:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:05,350:INFO:Initializing plot_model()
2025-10-12 16:06:05,350:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=4451,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpwrfyb7g8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:05,350:INFO:Checking exceptions
2025-10-12 16:06:05,351:INFO:Preloading libraries
2025-10-12 16:06:05,351:INFO:Copying training dataset
2025-10-12 16:06:05,351:INFO:Plot type: feature
2025-10-12 16:06:05,500:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpwrfyb7g8\Feature Importance.png'
2025-10-12 16:06:05,612:INFO:Visual Rendered Successfully
2025-10-12 16:06:05,757:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:05,776:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:06:06,015:INFO:_master_model_container: 16
2025-10-12 16:06:06,015:INFO:_display_container: 2
2025-10-12 16:06:06,027:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=4451,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-10-12 16:06:06,027:INFO:finalize_model() successfully completed......................................
2025-10-12 16:06:06,196:INFO:Initializing save_model()
2025-10-12 16:06:06,196:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=4451,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), model_name=Titanic_modelV1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 16:06:06,196:INFO:Adding model into prep_pipe
2025-10-12 16:06:06,196:WARNING:Only Model saved as it was a pipeline.
2025-10-12 16:06:06,201:INFO:Titanic_modelV1.pkl saved in current working directory
2025-10-12 16:06:06,215:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=4451,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-10-12 16:06:06,215:INFO:save_model() successfully completed......................................
2025-10-12 16:06:06,415:INFO:Initializing tune_model()
2025-10-12 16:06:06,415:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>)
2025-10-12 16:06:06,416:INFO:Checking exceptions
2025-10-12 16:06:06,429:INFO:Copying training dataset
2025-10-12 16:06:06,431:INFO:Checking base model
2025-10-12 16:06:06,431:INFO:Base model : Logistic Regression
2025-10-12 16:06:06,436:INFO:Declaring metric variables
2025-10-12 16:06:06,439:INFO:Defining Hyperparameters
2025-10-12 16:06:06,599:INFO:Tuning with n_jobs=-1
2025-10-12 16:06:06,600:INFO:Initializing RandomizedSearchCV
2025-10-12 16:06:06,859:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:06,866:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:06,867:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:06,870:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:06,887:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:06,911:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:06,937:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:06,977:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,000:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,040:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,070:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,097:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,127:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,142:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,145:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,149:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,151:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,157:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,157:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,252:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,275:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,292:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,335:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,341:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,380:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,408:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,408:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,408:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,409:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,491:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,505:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,578:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,600:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,611:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,620:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,622:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,642:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,647:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,648:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,656:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,668:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,671:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,788:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,794:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,829:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,833:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,892:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,897:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,897:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,908:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,928:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,946:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:07,980:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,086:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,141:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,143:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,157:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,192:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,197:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,210:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,219:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,224:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,268:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,301:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,322:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,337:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,374:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,478:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,495:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,592:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,592:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,610:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,616:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,636:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,671:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,676:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,676:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,829:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,838:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,849:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,864:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,869:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,912:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,919:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,927:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,930:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,951:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,961:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:08,989:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,001:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,041:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 2.941}
2025-10-12 16:06:09,042:INFO:Hyperparameter search completed
2025-10-12 16:06:09,042:INFO:SubProcess create_model() called ==================================
2025-10-12 16:06:09,043:INFO:Initializing create_model()
2025-10-12 16:06:09,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CEAE9640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 2.941})
2025-10-12 16:06:09,043:INFO:Checking exceptions
2025-10-12 16:06:09,043:INFO:Importing libraries
2025-10-12 16:06:09,043:INFO:Copying training dataset
2025-10-12 16:06:09,046:INFO:Defining folds
2025-10-12 16:06:09,046:INFO:Declaring metric variables
2025-10-12 16:06:09,049:INFO:Importing untrained model
2025-10-12 16:06:09,049:INFO:Declaring custom model
2025-10-12 16:06:09,052:INFO:Logistic Regression Imported successfully
2025-10-12 16:06:09,058:INFO:Starting cross validation
2025-10-12 16:06:09,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:06:09,257:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,270:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,280:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,287:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,338:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,339:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,341:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,343:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,346:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,359:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,464:INFO:Calculating mean and std
2025-10-12 16:06:09,465:INFO:Creating metrics dataframe
2025-10-12 16:06:09,470:INFO:Finalizing model
2025-10-12 16:06:09,588:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:09,592:INFO:Uploading results into container
2025-10-12 16:06:09,593:INFO:Uploading model into container now
2025-10-12 16:06:09,594:INFO:_master_model_container: 17
2025-10-12 16:06:09,594:INFO:_display_container: 3
2025-10-12 16:06:09,594:INFO:LogisticRegression(C=2.941, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:06:09,594:INFO:create_model() successfully completed......................................
2025-10-12 16:06:09,767:INFO:SubProcess create_model() end ==================================
2025-10-12 16:06:09,767:INFO:choose_better activated
2025-10-12 16:06:09,771:INFO:SubProcess create_model() called ==================================
2025-10-12 16:06:09,771:INFO:Initializing create_model()
2025-10-12 16:06:09,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:06:09,772:INFO:Checking exceptions
2025-10-12 16:06:09,773:INFO:Importing libraries
2025-10-12 16:06:09,773:INFO:Copying training dataset
2025-10-12 16:06:09,776:INFO:Defining folds
2025-10-12 16:06:09,776:INFO:Declaring metric variables
2025-10-12 16:06:09,776:INFO:Importing untrained model
2025-10-12 16:06:09,776:INFO:Declaring custom model
2025-10-12 16:06:09,776:INFO:Logistic Regression Imported successfully
2025-10-12 16:06:09,777:INFO:Starting cross validation
2025-10-12 16:06:09,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:06:09,967:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,970:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,992:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:09,994:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:10,002:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:10,014:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:10,054:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:10,055:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:10,062:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:10,069:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:10,112:INFO:Calculating mean and std
2025-10-12 16:06:10,112:INFO:Creating metrics dataframe
2025-10-12 16:06:10,114:INFO:Finalizing model
2025-10-12 16:06:10,225:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:10,225:INFO:Uploading results into container
2025-10-12 16:06:10,226:INFO:Uploading model into container now
2025-10-12 16:06:10,226:INFO:_master_model_container: 18
2025-10-12 16:06:10,226:INFO:_display_container: 4
2025-10-12 16:06:10,226:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:06:10,226:INFO:create_model() successfully completed......................................
2025-10-12 16:06:10,381:INFO:SubProcess create_model() end ==================================
2025-10-12 16:06:10,381:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8621
2025-10-12 16:06:10,381:INFO:LogisticRegression(C=2.941, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8684
2025-10-12 16:06:10,382:INFO:LogisticRegression(C=2.941, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-10-12 16:06:10,382:INFO:choose_better completed
2025-10-12 16:06:10,382:INFO:Creating Dashboard logs
2025-10-12 16:06:10,385:INFO:Model: Logistic Regression
2025-10-12 16:06:10,455:INFO:Logged params: {'C': 2.941, 'class_weight': {}, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 4451, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:06:10,727:INFO:Initializing predict_model()
2025-10-12 16:06:10,727:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=2.941, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E02AF1F0>)
2025-10-12 16:06:10,727:INFO:Checking exceptions
2025-10-12 16:06:10,727:INFO:Preloading libraries
2025-10-12 16:06:11,066:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:06:11,066:INFO:Initializing plot_model()
2025-10-12 16:06:11,066:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=2.941, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpx1ajxdf6, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:11,067:INFO:Checking exceptions
2025-10-12 16:06:11,068:INFO:Preloading libraries
2025-10-12 16:06:11,068:INFO:Copying training dataset
2025-10-12 16:06:11,068:INFO:Plot type: auc
2025-10-12 16:06:11,382:INFO:Fitting Model
2025-10-12 16:06:11,383:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:06:11,383:INFO:Scoring test/hold-out set
2025-10-12 16:06:11,397:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpx1ajxdf6\AUC.png'
2025-10-12 16:06:11,577:INFO:Visual Rendered Successfully
2025-10-12 16:06:11,743:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:11,762:INFO:Initializing plot_model()
2025-10-12 16:06:11,762:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=2.941, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpx1ajxdf6, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:11,762:INFO:Checking exceptions
2025-10-12 16:06:11,764:INFO:Preloading libraries
2025-10-12 16:06:11,765:INFO:Copying training dataset
2025-10-12 16:06:11,765:INFO:Plot type: confusion_matrix
2025-10-12 16:06:12,127:INFO:Fitting Model
2025-10-12 16:06:12,128:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:06:12,128:INFO:Scoring test/hold-out set
2025-10-12 16:06:12,141:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpx1ajxdf6\Confusion Matrix.png'
2025-10-12 16:06:12,235:INFO:Visual Rendered Successfully
2025-10-12 16:06:12,419:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:12,439:INFO:Initializing plot_model()
2025-10-12 16:06:12,439:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=2.941, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpx1ajxdf6, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:12,439:INFO:Checking exceptions
2025-10-12 16:06:12,441:INFO:Preloading libraries
2025-10-12 16:06:12,441:INFO:Copying training dataset
2025-10-12 16:06:12,441:INFO:Plot type: feature
2025-10-12 16:06:12,640:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpx1ajxdf6\Feature Importance.png'
2025-10-12 16:06:12,774:INFO:Visual Rendered Successfully
2025-10-12 16:06:12,941:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:12,964:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:06:13,244:INFO:_master_model_container: 18
2025-10-12 16:06:13,244:INFO:_display_container: 3
2025-10-12 16:06:13,244:INFO:LogisticRegression(C=2.941, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:06:13,244:INFO:tune_model() successfully completed......................................
2025-10-12 16:06:13,430:INFO:Initializing tune_model()
2025-10-12 16:06:13,430:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>)
2025-10-12 16:06:13,430:INFO:Checking exceptions
2025-10-12 16:06:13,430:INFO:Soft dependency imported: optuna: 4.5.0
2025-10-12 16:06:13,445:INFO:Copying training dataset
2025-10-12 16:06:13,449:INFO:Checking base model
2025-10-12 16:06:13,450:INFO:Base model : Logistic Regression
2025-10-12 16:06:13,453:INFO:Declaring metric variables
2025-10-12 16:06:13,457:INFO:Defining Hyperparameters
2025-10-12 16:06:13,662:INFO:Tuning with n_jobs=-1
2025-10-12 16:06:13,662:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.

2025-10-12 16:06:13,663:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.

2025-10-12 16:06:13,663:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.

2025-10-12 16:06:13,663:INFO:Initializing optuna.integration.OptunaSearchCV
2025-10-12 16:06:13,664:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.

2025-10-12 16:06:16,251:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:16,285:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:16,334:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:16,380:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:16,406:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:16,597:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:16,629:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:16,770:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:18,358:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:18,869:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:19,098:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:19,205:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:19,322:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:19,331:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:19,479:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:19,572:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:21,525:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:21,554:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:21,780:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:21,969:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:22,004:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:22,042:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:22,315:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:22,512:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:24,282:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:24,316:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:24,516:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:24,609:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:24,892:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:24,977:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:25,176:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:25,284:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:26,918:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:26,927:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:27,210:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:27,298:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:27,674:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:27,779:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:27,788:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:28,115:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:29,679:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:29,769:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:29,815:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:29,818:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:30,347:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:30,387:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:30,666:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:30,759:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:32,178:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:32,205:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:32,444:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:32,500:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:32,797:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:32,860:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:32,876:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:33,189:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:34,344:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:34,588:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:34,591:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:34,711:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:34,982:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:34,985:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:35,214:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:35,272:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:36,346:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:36,616:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:36,623:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:36,688:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:36,992:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:37,151:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:37,185:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:37,416:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:38,449:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:38,633:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:38,722:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:38,736:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:38,828:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:38,864:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:38,900:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:38,932:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:38,956:INFO:best_params: {'actual_estimator__C': 2.9266227555867883, 'actual_estimator__class_weight': 'balanced'}
2025-10-12 16:06:38,957:INFO:Hyperparameter search completed
2025-10-12 16:06:38,957:INFO:SubProcess create_model() called ==================================
2025-10-12 16:06:38,957:INFO:Initializing create_model()
2025-10-12 16:06:38,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DEC74970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'C': 2.9266227555867883, 'class_weight': 'balanced'})
2025-10-12 16:06:38,958:INFO:Checking exceptions
2025-10-12 16:06:38,958:INFO:Importing libraries
2025-10-12 16:06:38,958:INFO:Copying training dataset
2025-10-12 16:06:38,961:INFO:Defining folds
2025-10-12 16:06:38,961:INFO:Declaring metric variables
2025-10-12 16:06:38,964:INFO:Importing untrained model
2025-10-12 16:06:38,965:INFO:Declaring custom model
2025-10-12 16:06:38,967:INFO:Logistic Regression Imported successfully
2025-10-12 16:06:38,972:INFO:Starting cross validation
2025-10-12 16:06:38,974:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:06:39,182:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,187:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,196:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,204:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,216:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,226:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,236:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,239:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,240:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,241:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,296:INFO:Calculating mean and std
2025-10-12 16:06:39,297:INFO:Creating metrics dataframe
2025-10-12 16:06:39,301:INFO:Finalizing model
2025-10-12 16:06:39,413:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:39,417:INFO:Uploading results into container
2025-10-12 16:06:39,418:INFO:Uploading model into container now
2025-10-12 16:06:39,418:INFO:_master_model_container: 19
2025-10-12 16:06:39,418:INFO:_display_container: 4
2025-10-12 16:06:39,419:INFO:LogisticRegression(C=2.9266227555867883, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:06:39,419:INFO:create_model() successfully completed......................................
2025-10-12 16:06:39,567:INFO:SubProcess create_model() end ==================================
2025-10-12 16:06:39,567:INFO:choose_better activated
2025-10-12 16:06:39,570:INFO:SubProcess create_model() called ==================================
2025-10-12 16:06:39,570:INFO:Initializing create_model()
2025-10-12 16:06:39,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:06:39,571:INFO:Checking exceptions
2025-10-12 16:06:39,572:INFO:Importing libraries
2025-10-12 16:06:39,572:INFO:Copying training dataset
2025-10-12 16:06:39,574:INFO:Defining folds
2025-10-12 16:06:39,576:INFO:Declaring metric variables
2025-10-12 16:06:39,576:INFO:Importing untrained model
2025-10-12 16:06:39,576:INFO:Declaring custom model
2025-10-12 16:06:39,576:INFO:Logistic Regression Imported successfully
2025-10-12 16:06:39,576:INFO:Starting cross validation
2025-10-12 16:06:39,577:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:06:39,754:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,774:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,796:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,801:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,804:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,811:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,836:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,842:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,846:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,849:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:39,916:INFO:Calculating mean and std
2025-10-12 16:06:39,916:INFO:Creating metrics dataframe
2025-10-12 16:06:39,918:INFO:Finalizing model
2025-10-12 16:06:40,019:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:40,020:INFO:Uploading results into container
2025-10-12 16:06:40,020:INFO:Uploading model into container now
2025-10-12 16:06:40,021:INFO:_master_model_container: 20
2025-10-12 16:06:40,021:INFO:_display_container: 5
2025-10-12 16:06:40,021:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:06:40,021:INFO:create_model() successfully completed......................................
2025-10-12 16:06:40,165:INFO:SubProcess create_model() end ==================================
2025-10-12 16:06:40,166:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8621
2025-10-12 16:06:40,166:INFO:LogisticRegression(C=2.9266227555867883, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8698
2025-10-12 16:06:40,166:INFO:LogisticRegression(C=2.9266227555867883, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-10-12 16:06:40,166:INFO:choose_better completed
2025-10-12 16:06:40,166:INFO:Creating Dashboard logs
2025-10-12 16:06:40,169:INFO:Model: Logistic Regression
2025-10-12 16:06:40,238:INFO:Logged params: {'C': 2.9266227555867883, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 4451, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:06:40,496:INFO:Initializing predict_model()
2025-10-12 16:06:40,496:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=2.9266227555867883, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DFFB2E50>)
2025-10-12 16:06:40,497:INFO:Checking exceptions
2025-10-12 16:06:40,497:INFO:Preloading libraries
2025-10-12 16:06:40,816:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:06:40,816:INFO:Initializing plot_model()
2025-10-12 16:06:40,816:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=2.9266227555867883, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp6ca_43v5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:40,816:INFO:Checking exceptions
2025-10-12 16:06:40,817:INFO:Preloading libraries
2025-10-12 16:06:40,818:INFO:Copying training dataset
2025-10-12 16:06:40,818:INFO:Plot type: auc
2025-10-12 16:06:41,091:INFO:Fitting Model
2025-10-12 16:06:41,091:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:06:41,091:INFO:Scoring test/hold-out set
2025-10-12 16:06:41,104:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp6ca_43v5\AUC.png'
2025-10-12 16:06:41,264:INFO:Visual Rendered Successfully
2025-10-12 16:06:41,416:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:41,433:INFO:Initializing plot_model()
2025-10-12 16:06:41,433:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=2.9266227555867883, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp6ca_43v5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:41,434:INFO:Checking exceptions
2025-10-12 16:06:41,435:INFO:Preloading libraries
2025-10-12 16:06:41,435:INFO:Copying training dataset
2025-10-12 16:06:41,436:INFO:Plot type: confusion_matrix
2025-10-12 16:06:41,716:INFO:Fitting Model
2025-10-12 16:06:41,716:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:06:41,717:INFO:Scoring test/hold-out set
2025-10-12 16:06:41,729:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp6ca_43v5\Confusion Matrix.png'
2025-10-12 16:06:41,812:INFO:Visual Rendered Successfully
2025-10-12 16:06:41,962:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:41,976:INFO:Initializing plot_model()
2025-10-12 16:06:41,976:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=2.9266227555867883, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp6ca_43v5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:41,976:INFO:Checking exceptions
2025-10-12 16:06:41,978:INFO:Preloading libraries
2025-10-12 16:06:41,978:INFO:Copying training dataset
2025-10-12 16:06:41,978:INFO:Plot type: feature
2025-10-12 16:06:42,134:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp6ca_43v5\Feature Importance.png'
2025-10-12 16:06:42,247:INFO:Visual Rendered Successfully
2025-10-12 16:06:42,398:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:42,415:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:06:42,670:INFO:_master_model_container: 20
2025-10-12 16:06:42,670:INFO:_display_container: 4
2025-10-12 16:06:42,670:INFO:LogisticRegression(C=2.9266227555867883, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:06:42,671:INFO:tune_model() successfully completed......................................
2025-10-12 16:06:42,847:INFO:Initializing ensemble_model()
2025-10-12 16:06:42,847:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), method=Bagging, fold=None, n_estimators=5, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:06:42,848:INFO:Checking exceptions
2025-10-12 16:06:42,861:INFO:Importing libraries
2025-10-12 16:06:42,861:INFO:Copying training dataset
2025-10-12 16:06:42,861:INFO:Checking base model
2025-10-12 16:06:42,861:INFO:Base model : Logistic Regression
2025-10-12 16:06:42,867:INFO:Importing untrained ensembler
2025-10-12 16:06:42,868:INFO:Ensemble method set to Bagging
2025-10-12 16:06:42,868:INFO:SubProcess create_model() called ==================================
2025-10-12 16:06:42,869:INFO:Initializing create_model()
2025-10-12 16:06:42,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=4451,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=4451, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DBBFB7F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:06:42,869:INFO:Checking exceptions
2025-10-12 16:06:42,869:INFO:Importing libraries
2025-10-12 16:06:42,869:INFO:Copying training dataset
2025-10-12 16:06:42,874:INFO:Defining folds
2025-10-12 16:06:42,874:INFO:Declaring metric variables
2025-10-12 16:06:42,877:INFO:Importing untrained model
2025-10-12 16:06:42,878:INFO:Declaring custom model
2025-10-12 16:06:42,881:INFO:Logistic Regression Imported successfully
2025-10-12 16:06:42,889:INFO:Starting cross validation
2025-10-12 16:06:42,890:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:06:43,132:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,139:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,141:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,147:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,186:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,196:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,198:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,220:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,233:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,248:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,248:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,251:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,269:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,272:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,357:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,360:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,362:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,362:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,370:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,372:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,386:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,398:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,416:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,466:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,477:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,489:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,494:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,525:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,535:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,541:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,553:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,558:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,580:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,588:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,606:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,612:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,651:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,670:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,680:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,701:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,710:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,713:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,718:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,770:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,804:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,822:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,826:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,838:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,838:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:43,889:INFO:Calculating mean and std
2025-10-12 16:06:43,890:INFO:Creating metrics dataframe
2025-10-12 16:06:43,894:INFO:Finalizing model
2025-10-12 16:06:44,019:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:44,081:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:44,146:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:44,210:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:44,279:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:44,282:INFO:Uploading results into container
2025-10-12 16:06:44,284:INFO:Uploading model into container now
2025-10-12 16:06:44,284:INFO:_master_model_container: 21
2025-10-12 16:06:44,285:INFO:_display_container: 5
2025-10-12 16:06:44,285:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=4451,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=4451, verbose=0,
                  warm_start=False)
2025-10-12 16:06:44,285:INFO:create_model() successfully completed......................................
2025-10-12 16:06:44,435:INFO:SubProcess create_model() end ==================================
2025-10-12 16:06:44,435:INFO:Creating Dashboard logs
2025-10-12 16:06:44,438:INFO:Model: Logistic Regression
2025-10-12 16:06:44,500:INFO:Logged params: {'bootstrap': True, 'bootstrap_features': False, 'estimator__C': 1.0, 'estimator__class_weight': None, 'estimator__dual': False, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__l1_ratio': None, 'estimator__max_iter': 1000, 'estimator__multi_class': 'auto', 'estimator__n_jobs': None, 'estimator__penalty': 'l2', 'estimator__random_state': 4451, 'estimator__solver': 'lbfgs', 'estimator__tol': 0.0001, 'estimator__verbose': 0, 'estimator__warm_start': False, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 5, 'n_jobs': None, 'oob_score': False, 'random_state': 4451, 'verbose': 0, 'warm_start': False}
2025-10-12 16:06:44,758:INFO:Initializing predict_model()
2025-10-12 16:06:44,758:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=4451,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=4451, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E1D175E0>)
2025-10-12 16:06:44,758:INFO:Checking exceptions
2025-10-12 16:06:44,758:INFO:Preloading libraries
2025-10-12 16:06:45,082:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:06:45,083:INFO:Initializing plot_model()
2025-10-12 16:06:45,083:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=4451,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=4451, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp171aet64, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:45,083:INFO:Checking exceptions
2025-10-12 16:06:45,084:INFO:Preloading libraries
2025-10-12 16:06:45,084:INFO:Copying training dataset
2025-10-12 16:06:45,084:INFO:Plot type: auc
2025-10-12 16:06:45,359:INFO:Fitting Model
2025-10-12 16:06:45,360:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 16:06:45,360:INFO:Scoring test/hold-out set
2025-10-12 16:06:45,377:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp171aet64\AUC.png'
2025-10-12 16:06:45,529:INFO:Visual Rendered Successfully
2025-10-12 16:06:45,676:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:45,696:INFO:Initializing plot_model()
2025-10-12 16:06:45,696:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=4451,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=4451, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp171aet64, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:45,696:INFO:Checking exceptions
2025-10-12 16:06:45,697:INFO:Preloading libraries
2025-10-12 16:06:45,697:INFO:Copying training dataset
2025-10-12 16:06:45,697:INFO:Plot type: confusion_matrix
2025-10-12 16:06:45,975:INFO:Fitting Model
2025-10-12 16:06:45,975:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 16:06:45,976:INFO:Scoring test/hold-out set
2025-10-12 16:06:45,989:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp171aet64\Confusion Matrix.png'
2025-10-12 16:06:46,067:INFO:Visual Rendered Successfully
2025-10-12 16:06:46,212:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:46,234:INFO:Initializing plot_model()
2025-10-12 16:06:46,234:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=4451,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=4451, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp171aet64, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:46,234:INFO:Checking exceptions
2025-10-12 16:06:46,235:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 16:06:46,235:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:06:46,460:INFO:_master_model_container: 21
2025-10-12 16:06:46,460:INFO:_display_container: 5
2025-10-12 16:06:46,461:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=4451,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=4451, verbose=0,
                  warm_start=False)
2025-10-12 16:06:46,461:INFO:ensemble_model() successfully completed......................................
2025-10-12 16:06:46,618:INFO:Initializing predict_model()
2025-10-12 16:06:46,618:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=4451,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=4451, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E004DC10>)
2025-10-12 16:06:46,618:INFO:Checking exceptions
2025-10-12 16:06:46,618:INFO:Preloading libraries
2025-10-12 16:06:46,964:INFO:Initializing create_model()
2025-10-12 16:06:46,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:06:46,965:INFO:Checking exceptions
2025-10-12 16:06:46,976:INFO:Importing libraries
2025-10-12 16:06:46,976:INFO:Copying training dataset
2025-10-12 16:06:46,980:INFO:Defining folds
2025-10-12 16:06:46,980:INFO:Declaring metric variables
2025-10-12 16:06:46,984:INFO:Importing untrained model
2025-10-12 16:06:46,987:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:06:46,992:INFO:Starting cross validation
2025-10-12 16:06:46,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:06:47,131:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:47,141:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:47,149:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:47,151:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:47,155:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:47,159:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:47,172:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:47,189:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:47,192:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:47,195:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:47,212:INFO:Calculating mean and std
2025-10-12 16:06:47,212:INFO:Creating metrics dataframe
2025-10-12 16:06:47,216:INFO:Finalizing model
2025-10-12 16:06:47,265:INFO:Creating Dashboard logs
2025-10-12 16:06:47,267:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:06:47,331:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:06:47,509:INFO:Initializing predict_model()
2025-10-12 16:06:47,509:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E0385AF0>)
2025-10-12 16:06:47,509:INFO:Checking exceptions
2025-10-12 16:06:47,509:INFO:Preloading libraries
2025-10-12 16:06:47,665:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-12 16:06:47,828:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:06:47,828:INFO:Initializing plot_model()
2025-10-12 16:06:47,829:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpmwp1wld2, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:47,829:INFO:Checking exceptions
2025-10-12 16:06:47,830:INFO:Preloading libraries
2025-10-12 16:06:47,830:INFO:Copying training dataset
2025-10-12 16:06:47,830:INFO:Plot type: auc
2025-10-12 16:06:48,117:INFO:Fitting Model
2025-10-12 16:06:48,117:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:06:48,117:INFO:Scoring test/hold-out set
2025-10-12 16:06:48,131:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpmwp1wld2\AUC.png'
2025-10-12 16:06:48,307:INFO:Visual Rendered Successfully
2025-10-12 16:06:48,460:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:48,483:INFO:Initializing plot_model()
2025-10-12 16:06:48,483:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpmwp1wld2, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:48,483:INFO:Checking exceptions
2025-10-12 16:06:48,484:INFO:Preloading libraries
2025-10-12 16:06:48,484:INFO:Copying training dataset
2025-10-12 16:06:48,484:INFO:Plot type: confusion_matrix
2025-10-12 16:06:48,773:INFO:Fitting Model
2025-10-12 16:06:48,773:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:06:48,774:INFO:Scoring test/hold-out set
2025-10-12 16:06:48,788:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpmwp1wld2\Confusion Matrix.png'
2025-10-12 16:06:48,864:INFO:Visual Rendered Successfully
2025-10-12 16:06:49,010:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:49,033:INFO:Initializing plot_model()
2025-10-12 16:06:49,033:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpmwp1wld2, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:49,033:INFO:Checking exceptions
2025-10-12 16:06:49,035:INFO:Preloading libraries
2025-10-12 16:06:49,035:INFO:Copying training dataset
2025-10-12 16:06:49,035:INFO:Plot type: feature
2025-10-12 16:06:49,188:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpmwp1wld2\Feature Importance.png'
2025-10-12 16:06:49,296:INFO:Visual Rendered Successfully
2025-10-12 16:06:49,445:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:49,462:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:06:49,694:INFO:Uploading results into container
2025-10-12 16:06:49,695:INFO:Uploading model into container now
2025-10-12 16:06:49,703:INFO:_master_model_container: 22
2025-10-12 16:06:49,703:INFO:_display_container: 7
2025-10-12 16:06:49,703:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:06:49,703:INFO:create_model() successfully completed......................................
2025-10-12 16:06:49,848:INFO:Initializing create_model()
2025-10-12 16:06:49,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=ridge, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:06:49,849:INFO:Checking exceptions
2025-10-12 16:06:49,858:INFO:Importing libraries
2025-10-12 16:06:49,859:INFO:Copying training dataset
2025-10-12 16:06:49,862:INFO:Defining folds
2025-10-12 16:06:49,862:INFO:Declaring metric variables
2025-10-12 16:06:49,865:INFO:Importing untrained model
2025-10-12 16:06:49,868:INFO:Ridge Classifier Imported successfully
2025-10-12 16:06:49,872:INFO:Starting cross validation
2025-10-12 16:06:49,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:06:50,052:INFO:Calculating mean and std
2025-10-12 16:06:50,053:INFO:Creating metrics dataframe
2025-10-12 16:06:50,057:INFO:Finalizing model
2025-10-12 16:06:50,107:INFO:Creating Dashboard logs
2025-10-12 16:06:50,110:INFO:Model: Ridge Classifier
2025-10-12 16:06:50,174:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 4451, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:06:50,422:INFO:Initializing predict_model()
2025-10-12 16:06:50,424:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E00843A0>)
2025-10-12 16:06:50,424:INFO:Checking exceptions
2025-10-12 16:06:50,424:INFO:Preloading libraries
2025-10-12 16:06:50,742:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:06:50,742:INFO:Initializing plot_model()
2025-10-12 16:06:50,742:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpv1x_ydgt, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:50,742:INFO:Checking exceptions
2025-10-12 16:06:50,743:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:06:50,743:INFO:Initializing plot_model()
2025-10-12 16:06:50,743:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpv1x_ydgt, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:50,743:INFO:Checking exceptions
2025-10-12 16:06:50,744:INFO:Preloading libraries
2025-10-12 16:06:50,744:INFO:Copying training dataset
2025-10-12 16:06:50,744:INFO:Plot type: confusion_matrix
2025-10-12 16:06:51,025:INFO:Fitting Model
2025-10-12 16:06:51,026:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names

2025-10-12 16:06:51,026:INFO:Scoring test/hold-out set
2025-10-12 16:06:51,040:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpv1x_ydgt\Confusion Matrix.png'
2025-10-12 16:06:51,121:INFO:Visual Rendered Successfully
2025-10-12 16:06:51,283:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:51,301:INFO:Initializing plot_model()
2025-10-12 16:06:51,301:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpv1x_ydgt, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:51,301:INFO:Checking exceptions
2025-10-12 16:06:51,303:INFO:Preloading libraries
2025-10-12 16:06:51,303:INFO:Copying training dataset
2025-10-12 16:06:51,303:INFO:Plot type: feature
2025-10-12 16:06:51,461:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpv1x_ydgt\Feature Importance.png'
2025-10-12 16:06:51,584:INFO:Visual Rendered Successfully
2025-10-12 16:06:51,736:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:51,755:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:06:51,992:INFO:Uploading results into container
2025-10-12 16:06:51,994:INFO:Uploading model into container now
2025-10-12 16:06:52,000:INFO:_master_model_container: 23
2025-10-12 16:06:52,001:INFO:_display_container: 8
2025-10-12 16:06:52,001:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001)
2025-10-12 16:06:52,001:INFO:create_model() successfully completed......................................
2025-10-12 16:06:52,150:INFO:Initializing create_model()
2025-10-12 16:06:52,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:06:52,150:INFO:Checking exceptions
2025-10-12 16:06:52,161:INFO:Importing libraries
2025-10-12 16:06:52,161:INFO:Copying training dataset
2025-10-12 16:06:52,165:INFO:Defining folds
2025-10-12 16:06:52,165:INFO:Declaring metric variables
2025-10-12 16:06:52,168:INFO:Importing untrained model
2025-10-12 16:06:52,170:INFO:Logistic Regression Imported successfully
2025-10-12 16:06:52,176:INFO:Starting cross validation
2025-10-12 16:06:52,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:06:52,367:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:52,388:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:52,396:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:52,407:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:52,430:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:52,435:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:52,452:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:52,456:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:52,457:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:52,457:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:52,500:INFO:Calculating mean and std
2025-10-12 16:06:52,500:INFO:Creating metrics dataframe
2025-10-12 16:06:52,505:INFO:Finalizing model
2025-10-12 16:06:52,612:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:06:52,612:INFO:Creating Dashboard logs
2025-10-12 16:06:52,616:INFO:Model: Logistic Regression
2025-10-12 16:06:52,682:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 4451, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:06:52,922:INFO:Initializing predict_model()
2025-10-12 16:06:52,923:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E16704C0>)
2025-10-12 16:06:52,923:INFO:Checking exceptions
2025-10-12 16:06:52,923:INFO:Preloading libraries
2025-10-12 16:06:53,275:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:06:53,276:INFO:Initializing plot_model()
2025-10-12 16:06:53,276:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpftnb_2m4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:53,276:INFO:Checking exceptions
2025-10-12 16:06:53,277:INFO:Preloading libraries
2025-10-12 16:06:53,278:INFO:Copying training dataset
2025-10-12 16:06:53,278:INFO:Plot type: auc
2025-10-12 16:06:53,568:INFO:Fitting Model
2025-10-12 16:06:53,568:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:06:53,568:INFO:Scoring test/hold-out set
2025-10-12 16:06:53,584:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpftnb_2m4\AUC.png'
2025-10-12 16:06:53,748:INFO:Visual Rendered Successfully
2025-10-12 16:06:53,896:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:53,915:INFO:Initializing plot_model()
2025-10-12 16:06:53,915:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpftnb_2m4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:53,915:INFO:Checking exceptions
2025-10-12 16:06:53,916:INFO:Preloading libraries
2025-10-12 16:06:53,916:INFO:Copying training dataset
2025-10-12 16:06:53,916:INFO:Plot type: confusion_matrix
2025-10-12 16:06:54,248:INFO:Fitting Model
2025-10-12 16:06:54,248:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:06:54,249:INFO:Scoring test/hold-out set
2025-10-12 16:06:54,260:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpftnb_2m4\Confusion Matrix.png'
2025-10-12 16:06:54,335:INFO:Visual Rendered Successfully
2025-10-12 16:06:54,482:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:54,503:INFO:Initializing plot_model()
2025-10-12 16:06:54,503:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpftnb_2m4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:54,503:INFO:Checking exceptions
2025-10-12 16:06:54,505:INFO:Preloading libraries
2025-10-12 16:06:54,505:INFO:Copying training dataset
2025-10-12 16:06:54,505:INFO:Plot type: feature
2025-10-12 16:06:54,654:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpftnb_2m4\Feature Importance.png'
2025-10-12 16:06:54,766:INFO:Visual Rendered Successfully
2025-10-12 16:06:54,920:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:54,939:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:06:55,171:INFO:Uploading results into container
2025-10-12 16:06:55,171:INFO:Uploading model into container now
2025-10-12 16:06:55,178:INFO:_master_model_container: 24
2025-10-12 16:06:55,179:INFO:_display_container: 9
2025-10-12 16:06:55,179:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:06:55,179:INFO:create_model() successfully completed......................................
2025-10-12 16:06:55,333:INFO:Initializing blend_models()
2025-10-12 16:06:55,334:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator_list=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:06:55,334:INFO:Checking exceptions
2025-10-12 16:06:55,334:INFO:Estimator RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-12 16:06:55,346:INFO:Importing libraries
2025-10-12 16:06:55,346:INFO:Copying training dataset
2025-10-12 16:06:55,349:INFO:Getting model names
2025-10-12 16:06:55,352:INFO:SubProcess create_model() called ==================================
2025-10-12 16:06:55,354:INFO:Initializing create_model()
2025-10-12 16:06:55,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DECF8910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:06:55,354:INFO:Checking exceptions
2025-10-12 16:06:55,354:INFO:Importing libraries
2025-10-12 16:06:55,354:INFO:Copying training dataset
2025-10-12 16:06:55,358:INFO:Defining folds
2025-10-12 16:06:55,358:INFO:Declaring metric variables
2025-10-12 16:06:55,362:INFO:Importing untrained model
2025-10-12 16:06:55,362:INFO:Declaring custom model
2025-10-12 16:06:55,367:INFO:Voting Classifier Imported successfully
2025-10-12 16:06:55,374:INFO:Starting cross validation
2025-10-12 16:06:55,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:06:55,823:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:55,824:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:55,837:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:55,838:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:55,842:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:55,848:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:55,886:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:06:55,886:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:06:55,889:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:06:55,901:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:06:55,901:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:06:55,902:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:06:55,921:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:55,938:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:55,952:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:55,957:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:55,969:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:06:55,983:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:06:55,996:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:06:56,008:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:06:56,028:INFO:Calculating mean and std
2025-10-12 16:06:56,028:INFO:Creating metrics dataframe
2025-10-12 16:06:56,031:INFO:Finalizing model
2025-10-12 16:06:56,172:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:56,173:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:56,188:INFO:Uploading results into container
2025-10-12 16:06:56,188:INFO:Uploading model into container now
2025-10-12 16:06:56,189:INFO:_master_model_container: 25
2025-10-12 16:06:56,189:INFO:_display_container: 10
2025-10-12 16:06:56,192:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:06:56,192:INFO:create_model() successfully completed......................................
2025-10-12 16:06:56,356:INFO:SubProcess create_model() end ==================================
2025-10-12 16:06:56,357:INFO:Creating Dashboard logs
2025-10-12 16:06:56,361:INFO:Model: Voting Classifier
2025-10-12 16:06:56,442:INFO:Logged params: {'flatten_transform': True, 'n_jobs': -1, 'verbose': False, 'voting': 'hard', 'weights': None, 'Linear Discriminant Analysis': LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), 'Ridge Classifier': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001), 'Logistic Regression__C': 1.0, 'Logistic Regression__class_weight': None, 'Logistic Regression__dual': False, 'Logistic Regression__fit_intercept': True, 'Logistic Regression__intercept_scaling': 1, 'Logistic Regression__l1_ratio': None, 'Logistic Regression__max_iter': 1000, 'Logistic Regression__multi_class': 'auto', 'Logistic Regression__n_jobs': None, 'Logistic Regression__penalty': 'l2', 'Logistic Regression__random_state': 4451, 'Logistic Regression__solver': 'lbfgs', 'Logistic Regression__tol': 0.0001, 'Logistic Regression__verbose': 0, 'Logistic Regression__warm_start': False, 'Linear Discriminant Analysis__covariance_estimator': None, 'Linear Discriminant Analysis__n_components': None, 'Linear Discriminant Analysis__priors': None, 'Linear Discriminant Analysis__shrinkage': None, 'Linear Discriminant Analysis__solver': 'svd', 'Linear Discriminant Analysis__store_covariance': False, 'Linear Discriminant Analysis__tol': 0.0001, 'Ridge Classifier__alpha': 1.0, 'Ridge Classifier__class_weight': None, 'Ridge Classifier__copy_X': True, 'Ridge Classifier__fit_intercept': True, 'Ridge Classifier__max_iter': None, 'Ridge Classifier__positive': False, 'Ridge Classifier__random_state': 4451, 'Ridge Classifier__solver': 'auto', 'Ridge Classifier__tol': 0.0001, 'Logistic Regression_1__C': 1.0, 'Logistic Regression_1__class_weight': None, 'Logistic Regression_1__dual': False, 'Logistic Regression_1__fit_intercept': True, 'Logistic Regression_1__intercept_scaling': 1, 'Logistic Regression_1__l1_ratio': None, 'Logistic Regression_1__max_iter': 1000, 'Logistic Regression_1__multi_class': 'auto', 'Logistic Regression_1__n_jobs': None, 'Logistic Regression_1__penalty': 'l2', 'Logistic Regression_1__random_state': 4451, 'Logistic Regression_1__solver': 'lbfgs', 'Logistic Regression_1__tol': 0.0001, 'Logistic Regression_1__verbose': 0, 'Logistic Regression_1__warm_start': False}
2025-10-12 16:06:56,820:INFO:Initializing predict_model()
2025-10-12 16:06:56,820:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E0084160>)
2025-10-12 16:06:56,820:INFO:Checking exceptions
2025-10-12 16:06:56,820:INFO:Preloading libraries
2025-10-12 16:06:57,196:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:06:57,200:INFO:Initializing plot_model()
2025-10-12 16:06:57,200:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpebeo_f7_, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:57,200:INFO:Checking exceptions
2025-10-12 16:06:57,200:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:06:57,203:INFO:Initializing plot_model()
2025-10-12 16:06:57,203:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpebeo_f7_, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:57,203:INFO:Checking exceptions
2025-10-12 16:06:57,204:INFO:Preloading libraries
2025-10-12 16:06:57,206:INFO:Copying training dataset
2025-10-12 16:06:57,206:INFO:Plot type: confusion_matrix
2025-10-12 16:06:57,515:INFO:Fitting Model
2025-10-12 16:06:57,515:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:06:57,515:INFO:Scoring test/hold-out set
2025-10-12 16:06:57,538:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpebeo_f7_\Confusion Matrix.png'
2025-10-12 16:06:57,623:INFO:Visual Rendered Successfully
2025-10-12 16:06:57,791:INFO:plot_model() successfully completed......................................
2025-10-12 16:06:57,810:INFO:Initializing plot_model()
2025-10-12 16:06:57,810:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpebeo_f7_, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:06:57,810:INFO:Checking exceptions
2025-10-12 16:06:57,811:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 16:06:57,811:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:06:58,052:INFO:_master_model_container: 25
2025-10-12 16:06:58,052:INFO:_display_container: 10
2025-10-12 16:06:58,053:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:06:58,055:INFO:blend_models() successfully completed......................................
2025-10-12 16:06:58,207:INFO:Initializing compare_models()
2025-10-12 16:06:58,208:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:06:58,208:INFO:Checking exceptions
2025-10-12 16:06:58,209:INFO:Preparing display monitor
2025-10-12 16:06:58,225:INFO:Initializing Logistic Regression
2025-10-12 16:06:58,225:INFO:Total runtime is 0.0 minutes
2025-10-12 16:06:58,229:INFO:SubProcess create_model() called ==================================
2025-10-12 16:06:58,229:INFO:Initializing create_model()
2025-10-12 16:06:58,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:06:58,229:INFO:Checking exceptions
2025-10-12 16:06:58,229:INFO:Importing libraries
2025-10-12 16:06:58,229:INFO:Copying training dataset
2025-10-12 16:06:58,234:INFO:Defining folds
2025-10-12 16:06:58,235:INFO:Declaring metric variables
2025-10-12 16:06:58,238:INFO:Importing untrained model
2025-10-12 16:06:58,242:INFO:Logistic Regression Imported successfully
2025-10-12 16:06:58,250:INFO:Starting cross validation
2025-10-12 16:06:58,251:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:06:58,460:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:58,466:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:58,472:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:58,484:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:58,497:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:58,499:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:58,560:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:58,564:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:58,578:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:58,590:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:06:58,627:INFO:Calculating mean and std
2025-10-12 16:06:58,627:INFO:Creating metrics dataframe
2025-10-12 16:06:58,629:INFO:Uploading results into container
2025-10-12 16:06:58,629:INFO:Uploading model into container now
2025-10-12 16:06:58,629:INFO:_master_model_container: 26
2025-10-12 16:06:58,629:INFO:_display_container: 11
2025-10-12 16:06:58,630:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:06:58,630:INFO:create_model() successfully completed......................................
2025-10-12 16:06:58,781:INFO:SubProcess create_model() end ==================================
2025-10-12 16:06:58,781:INFO:Creating metrics dataframe
2025-10-12 16:06:58,786:INFO:Initializing K Neighbors Classifier
2025-10-12 16:06:58,786:INFO:Total runtime is 0.009347474575042725 minutes
2025-10-12 16:06:58,788:INFO:SubProcess create_model() called ==================================
2025-10-12 16:06:58,789:INFO:Initializing create_model()
2025-10-12 16:06:58,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:06:58,789:INFO:Checking exceptions
2025-10-12 16:06:58,789:INFO:Importing libraries
2025-10-12 16:06:58,789:INFO:Copying training dataset
2025-10-12 16:06:58,791:INFO:Defining folds
2025-10-12 16:06:58,792:INFO:Declaring metric variables
2025-10-12 16:06:58,793:INFO:Importing untrained model
2025-10-12 16:06:58,797:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:06:58,801:INFO:Starting cross validation
2025-10-12 16:06:58,804:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:06:59,065:INFO:Calculating mean and std
2025-10-12 16:06:59,066:INFO:Creating metrics dataframe
2025-10-12 16:06:59,067:INFO:Uploading results into container
2025-10-12 16:06:59,068:INFO:Uploading model into container now
2025-10-12 16:06:59,068:INFO:_master_model_container: 27
2025-10-12 16:06:59,069:INFO:_display_container: 11
2025-10-12 16:06:59,069:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:06:59,069:INFO:create_model() successfully completed......................................
2025-10-12 16:06:59,219:INFO:SubProcess create_model() end ==================================
2025-10-12 16:06:59,219:INFO:Creating metrics dataframe
2025-10-12 16:06:59,224:INFO:Initializing Naive Bayes
2025-10-12 16:06:59,224:INFO:Total runtime is 0.016645570596059166 minutes
2025-10-12 16:06:59,227:INFO:SubProcess create_model() called ==================================
2025-10-12 16:06:59,227:INFO:Initializing create_model()
2025-10-12 16:06:59,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:06:59,227:INFO:Checking exceptions
2025-10-12 16:06:59,227:INFO:Importing libraries
2025-10-12 16:06:59,227:INFO:Copying training dataset
2025-10-12 16:06:59,231:INFO:Defining folds
2025-10-12 16:06:59,231:INFO:Declaring metric variables
2025-10-12 16:06:59,234:INFO:Importing untrained model
2025-10-12 16:06:59,237:INFO:Naive Bayes Imported successfully
2025-10-12 16:06:59,242:INFO:Starting cross validation
2025-10-12 16:06:59,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:06:59,407:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:59,423:INFO:Calculating mean and std
2025-10-12 16:06:59,424:INFO:Creating metrics dataframe
2025-10-12 16:06:59,426:INFO:Uploading results into container
2025-10-12 16:06:59,426:INFO:Uploading model into container now
2025-10-12 16:06:59,427:INFO:_master_model_container: 28
2025-10-12 16:06:59,427:INFO:_display_container: 11
2025-10-12 16:06:59,427:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:06:59,427:INFO:create_model() successfully completed......................................
2025-10-12 16:06:59,579:INFO:SubProcess create_model() end ==================================
2025-10-12 16:06:59,579:INFO:Creating metrics dataframe
2025-10-12 16:06:59,585:INFO:Initializing Decision Tree Classifier
2025-10-12 16:06:59,585:INFO:Total runtime is 0.022657716274261476 minutes
2025-10-12 16:06:59,587:INFO:SubProcess create_model() called ==================================
2025-10-12 16:06:59,587:INFO:Initializing create_model()
2025-10-12 16:06:59,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:06:59,588:INFO:Checking exceptions
2025-10-12 16:06:59,588:INFO:Importing libraries
2025-10-12 16:06:59,588:INFO:Copying training dataset
2025-10-12 16:06:59,591:INFO:Defining folds
2025-10-12 16:06:59,591:INFO:Declaring metric variables
2025-10-12 16:06:59,594:INFO:Importing untrained model
2025-10-12 16:06:59,597:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:06:59,602:INFO:Starting cross validation
2025-10-12 16:06:59,603:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:06:59,722:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:59,748:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:59,762:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:59,764:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:59,764:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:59,764:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:59,772:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:59,773:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:59,775:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:59,778:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:06:59,796:INFO:Calculating mean and std
2025-10-12 16:06:59,797:INFO:Creating metrics dataframe
2025-10-12 16:06:59,799:INFO:Uploading results into container
2025-10-12 16:06:59,799:INFO:Uploading model into container now
2025-10-12 16:06:59,800:INFO:_master_model_container: 29
2025-10-12 16:06:59,800:INFO:_display_container: 11
2025-10-12 16:06:59,800:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=4451, splitter='best')
2025-10-12 16:06:59,800:INFO:create_model() successfully completed......................................
2025-10-12 16:06:59,952:INFO:SubProcess create_model() end ==================================
2025-10-12 16:06:59,952:INFO:Creating metrics dataframe
2025-10-12 16:06:59,957:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:06:59,957:INFO:Total runtime is 0.028865393002827963 minutes
2025-10-12 16:06:59,960:INFO:SubProcess create_model() called ==================================
2025-10-12 16:06:59,960:INFO:Initializing create_model()
2025-10-12 16:06:59,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:06:59,960:INFO:Checking exceptions
2025-10-12 16:06:59,960:INFO:Importing libraries
2025-10-12 16:06:59,960:INFO:Copying training dataset
2025-10-12 16:06:59,963:INFO:Defining folds
2025-10-12 16:06:59,963:INFO:Declaring metric variables
2025-10-12 16:06:59,966:INFO:Importing untrained model
2025-10-12 16:06:59,969:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:06:59,975:INFO:Starting cross validation
2025-10-12 16:06:59,976:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:00,107:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:00,142:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:00,146:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:00,171:INFO:Calculating mean and std
2025-10-12 16:07:00,172:INFO:Creating metrics dataframe
2025-10-12 16:07:00,174:INFO:Uploading results into container
2025-10-12 16:07:00,175:INFO:Uploading model into container now
2025-10-12 16:07:00,175:INFO:_master_model_container: 30
2025-10-12 16:07:00,176:INFO:_display_container: 11
2025-10-12 16:07:00,176:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4451, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:07:00,176:INFO:create_model() successfully completed......................................
2025-10-12 16:07:00,326:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:00,327:INFO:Creating metrics dataframe
2025-10-12 16:07:00,333:INFO:Initializing Ridge Classifier
2025-10-12 16:07:00,333:INFO:Total runtime is 0.03513919512430827 minutes
2025-10-12 16:07:00,336:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:00,337:INFO:Initializing create_model()
2025-10-12 16:07:00,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:00,337:INFO:Checking exceptions
2025-10-12 16:07:00,337:INFO:Importing libraries
2025-10-12 16:07:00,337:INFO:Copying training dataset
2025-10-12 16:07:00,340:INFO:Defining folds
2025-10-12 16:07:00,340:INFO:Declaring metric variables
2025-10-12 16:07:00,342:INFO:Importing untrained model
2025-10-12 16:07:00,347:INFO:Ridge Classifier Imported successfully
2025-10-12 16:07:00,351:INFO:Starting cross validation
2025-10-12 16:07:00,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:00,548:INFO:Calculating mean and std
2025-10-12 16:07:00,549:INFO:Creating metrics dataframe
2025-10-12 16:07:00,551:INFO:Uploading results into container
2025-10-12 16:07:00,551:INFO:Uploading model into container now
2025-10-12 16:07:00,552:INFO:_master_model_container: 31
2025-10-12 16:07:00,552:INFO:_display_container: 11
2025-10-12 16:07:00,552:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001)
2025-10-12 16:07:00,552:INFO:create_model() successfully completed......................................
2025-10-12 16:07:00,705:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:00,705:INFO:Creating metrics dataframe
2025-10-12 16:07:00,711:INFO:Initializing Random Forest Classifier
2025-10-12 16:07:00,711:INFO:Total runtime is 0.04142935673395793 minutes
2025-10-12 16:07:00,713:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:00,713:INFO:Initializing create_model()
2025-10-12 16:07:00,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:00,714:INFO:Checking exceptions
2025-10-12 16:07:00,714:INFO:Importing libraries
2025-10-12 16:07:00,714:INFO:Copying training dataset
2025-10-12 16:07:00,717:INFO:Defining folds
2025-10-12 16:07:00,717:INFO:Declaring metric variables
2025-10-12 16:07:00,720:INFO:Importing untrained model
2025-10-12 16:07:00,723:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:07:00,728:INFO:Starting cross validation
2025-10-12 16:07:00,729:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:01,132:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,164:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,164:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,201:INFO:Calculating mean and std
2025-10-12 16:07:01,202:INFO:Creating metrics dataframe
2025-10-12 16:07:01,204:INFO:Uploading results into container
2025-10-12 16:07:01,204:INFO:Uploading model into container now
2025-10-12 16:07:01,204:INFO:_master_model_container: 32
2025-10-12 16:07:01,204:INFO:_display_container: 11
2025-10-12 16:07:01,206:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4451, verbose=0,
                       warm_start=False)
2025-10-12 16:07:01,206:INFO:create_model() successfully completed......................................
2025-10-12 16:07:01,365:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:01,365:INFO:Creating metrics dataframe
2025-10-12 16:07:01,372:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:07:01,372:INFO:Total runtime is 0.05244946877161662 minutes
2025-10-12 16:07:01,375:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:01,376:INFO:Initializing create_model()
2025-10-12 16:07:01,376:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:01,376:INFO:Checking exceptions
2025-10-12 16:07:01,376:INFO:Importing libraries
2025-10-12 16:07:01,376:INFO:Copying training dataset
2025-10-12 16:07:01,379:INFO:Defining folds
2025-10-12 16:07:01,380:INFO:Declaring metric variables
2025-10-12 16:07:01,382:INFO:Importing untrained model
2025-10-12 16:07:01,386:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:07:01,392:INFO:Starting cross validation
2025-10-12 16:07:01,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:01,489:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:01,506:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:01,506:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:01,507:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:01,508:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:01,510:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:01,510:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:01,512:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:01,520:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:01,529:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:01,535:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,550:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,561:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,567:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,568:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,569:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,572:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,591:INFO:Calculating mean and std
2025-10-12 16:07:01,592:INFO:Creating metrics dataframe
2025-10-12 16:07:01,594:INFO:Uploading results into container
2025-10-12 16:07:01,594:INFO:Uploading model into container now
2025-10-12 16:07:01,594:INFO:_master_model_container: 33
2025-10-12 16:07:01,596:INFO:_display_container: 11
2025-10-12 16:07:01,596:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:07:01,596:INFO:create_model() successfully completed......................................
2025-10-12 16:07:01,752:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:01,752:INFO:Creating metrics dataframe
2025-10-12 16:07:01,760:INFO:Initializing Ada Boost Classifier
2025-10-12 16:07:01,760:INFO:Total runtime is 0.05890775918960571 minutes
2025-10-12 16:07:01,763:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:01,763:INFO:Initializing create_model()
2025-10-12 16:07:01,764:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:01,764:INFO:Checking exceptions
2025-10-12 16:07:01,764:INFO:Importing libraries
2025-10-12 16:07:01,764:INFO:Copying training dataset
2025-10-12 16:07:01,767:INFO:Defining folds
2025-10-12 16:07:01,767:INFO:Declaring metric variables
2025-10-12 16:07:01,771:INFO:Importing untrained model
2025-10-12 16:07:01,774:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:07:01,778:INFO:Starting cross validation
2025-10-12 16:07:01,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:01,881:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:01,882:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:01,882:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:01,885:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:01,891:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:01,894:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:01,896:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:01,898:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:01,902:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:01,914:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:01,927:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,929:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,930:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,932:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,936:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,937:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,945:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,949:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,955:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,963:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:01,978:INFO:Calculating mean and std
2025-10-12 16:07:01,979:INFO:Creating metrics dataframe
2025-10-12 16:07:01,981:INFO:Uploading results into container
2025-10-12 16:07:01,981:INFO:Uploading model into container now
2025-10-12 16:07:01,982:INFO:_master_model_container: 34
2025-10-12 16:07:01,982:INFO:_display_container: 11
2025-10-12 16:07:01,982:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4451)
2025-10-12 16:07:01,982:INFO:create_model() successfully completed......................................
2025-10-12 16:07:02,140:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:02,140:INFO:Creating metrics dataframe
2025-10-12 16:07:02,148:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:07:02,148:INFO:Total runtime is 0.06538568337758383 minutes
2025-10-12 16:07:02,151:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:02,152:INFO:Initializing create_model()
2025-10-12 16:07:02,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:02,152:INFO:Checking exceptions
2025-10-12 16:07:02,152:INFO:Importing libraries
2025-10-12 16:07:02,152:INFO:Copying training dataset
2025-10-12 16:07:02,161:INFO:Defining folds
2025-10-12 16:07:02,161:INFO:Declaring metric variables
2025-10-12 16:07:02,164:INFO:Importing untrained model
2025-10-12 16:07:02,169:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:07:02,177:INFO:Starting cross validation
2025-10-12 16:07:02,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:02,437:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,438:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,440:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,449:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,469:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,472:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,476:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,480:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,483:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,528:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,536:INFO:Calculating mean and std
2025-10-12 16:07:02,537:INFO:Creating metrics dataframe
2025-10-12 16:07:02,539:INFO:Uploading results into container
2025-10-12 16:07:02,539:INFO:Uploading model into container now
2025-10-12 16:07:02,540:INFO:_master_model_container: 35
2025-10-12 16:07:02,540:INFO:_display_container: 11
2025-10-12 16:07:02,540:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4451, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:07:02,540:INFO:create_model() successfully completed......................................
2025-10-12 16:07:02,702:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:02,702:INFO:Creating metrics dataframe
2025-10-12 16:07:02,712:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:07:02,712:INFO:Total runtime is 0.0747846523920695 minutes
2025-10-12 16:07:02,718:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:02,718:INFO:Initializing create_model()
2025-10-12 16:07:02,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:02,719:INFO:Checking exceptions
2025-10-12 16:07:02,720:INFO:Importing libraries
2025-10-12 16:07:02,720:INFO:Copying training dataset
2025-10-12 16:07:02,725:INFO:Defining folds
2025-10-12 16:07:02,725:INFO:Declaring metric variables
2025-10-12 16:07:02,734:INFO:Importing untrained model
2025-10-12 16:07:02,740:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:07:02,750:INFO:Starting cross validation
2025-10-12 16:07:02,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:02,899:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,906:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,908:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,920:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,923:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,925:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,926:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,946:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,954:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,955:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:02,968:INFO:Calculating mean and std
2025-10-12 16:07:02,969:INFO:Creating metrics dataframe
2025-10-12 16:07:02,971:INFO:Uploading results into container
2025-10-12 16:07:02,972:INFO:Uploading model into container now
2025-10-12 16:07:02,972:INFO:_master_model_container: 36
2025-10-12 16:07:02,972:INFO:_display_container: 11
2025-10-12 16:07:02,972:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:07:02,973:INFO:create_model() successfully completed......................................
2025-10-12 16:07:03,137:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:03,137:INFO:Creating metrics dataframe
2025-10-12 16:07:03,144:INFO:Initializing Extra Trees Classifier
2025-10-12 16:07:03,144:INFO:Total runtime is 0.08199022610982258 minutes
2025-10-12 16:07:03,147:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:03,147:INFO:Initializing create_model()
2025-10-12 16:07:03,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:03,147:INFO:Checking exceptions
2025-10-12 16:07:03,147:INFO:Importing libraries
2025-10-12 16:07:03,147:INFO:Copying training dataset
2025-10-12 16:07:03,151:INFO:Defining folds
2025-10-12 16:07:03,151:INFO:Declaring metric variables
2025-10-12 16:07:03,156:INFO:Importing untrained model
2025-10-12 16:07:03,162:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:07:03,169:INFO:Starting cross validation
2025-10-12 16:07:03,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:03,598:INFO:Calculating mean and std
2025-10-12 16:07:03,599:INFO:Creating metrics dataframe
2025-10-12 16:07:03,600:INFO:Uploading results into container
2025-10-12 16:07:03,601:INFO:Uploading model into container now
2025-10-12 16:07:03,602:INFO:_master_model_container: 37
2025-10-12 16:07:03,602:INFO:_display_container: 11
2025-10-12 16:07:03,602:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4451, verbose=0,
                     warm_start=False)
2025-10-12 16:07:03,602:INFO:create_model() successfully completed......................................
2025-10-12 16:07:03,752:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:03,753:INFO:Creating metrics dataframe
2025-10-12 16:07:03,759:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:07:03,759:INFO:Total runtime is 0.09223737319310506 minutes
2025-10-12 16:07:03,762:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:03,763:INFO:Initializing create_model()
2025-10-12 16:07:03,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:03,763:INFO:Checking exceptions
2025-10-12 16:07:03,763:INFO:Importing libraries
2025-10-12 16:07:03,763:INFO:Copying training dataset
2025-10-12 16:07:03,767:INFO:Defining folds
2025-10-12 16:07:03,767:INFO:Declaring metric variables
2025-10-12 16:07:03,770:INFO:Importing untrained model
2025-10-12 16:07:03,773:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:07:03,779:INFO:Starting cross validation
2025-10-12 16:07:03,781:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:03,922:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:03,950:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:03,968:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:03,976:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:03,978:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:03,985:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:03,989:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:03,992:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:03,998:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:04,134:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:04,153:INFO:Calculating mean and std
2025-10-12 16:07:04,154:INFO:Creating metrics dataframe
2025-10-12 16:07:04,156:INFO:Uploading results into container
2025-10-12 16:07:04,156:INFO:Uploading model into container now
2025-10-12 16:07:04,157:INFO:_master_model_container: 38
2025-10-12 16:07:04,157:INFO:_display_container: 11
2025-10-12 16:07:04,157:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:07:04,157:INFO:create_model() successfully completed......................................
2025-10-12 16:07:04,308:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:04,308:INFO:Creating metrics dataframe
2025-10-12 16:07:04,314:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:07:04,314:INFO:Total runtime is 0.10149078369140624 minutes
2025-10-12 16:07:04,318:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:04,318:INFO:Initializing create_model()
2025-10-12 16:07:04,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:04,318:INFO:Checking exceptions
2025-10-12 16:07:04,318:INFO:Importing libraries
2025-10-12 16:07:04,318:INFO:Copying training dataset
2025-10-12 16:07:04,321:INFO:Defining folds
2025-10-12 16:07:04,322:INFO:Declaring metric variables
2025-10-12 16:07:04,326:INFO:Importing untrained model
2025-10-12 16:07:04,329:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:07:04,337:INFO:Starting cross validation
2025-10-12 16:07:04,339:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:05,119:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:05,167:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:05,178:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:05,196:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:05,230:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:05,244:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:05,252:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:05,253:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:05,268:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:05,300:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:05,315:INFO:Calculating mean and std
2025-10-12 16:07:05,316:INFO:Creating metrics dataframe
2025-10-12 16:07:05,319:INFO:Uploading results into container
2025-10-12 16:07:05,319:INFO:Uploading model into container now
2025-10-12 16:07:05,319:INFO:_master_model_container: 39
2025-10-12 16:07:05,319:INFO:_display_container: 11
2025-10-12 16:07:05,320:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4451, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:07:05,321:INFO:create_model() successfully completed......................................
2025-10-12 16:07:05,494:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:05,495:INFO:Creating metrics dataframe
2025-10-12 16:07:05,504:INFO:Initializing CatBoost Classifier
2025-10-12 16:07:05,504:INFO:Total runtime is 0.12132242123285929 minutes
2025-10-12 16:07:05,507:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:05,508:INFO:Initializing create_model()
2025-10-12 16:07:05,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:05,508:INFO:Checking exceptions
2025-10-12 16:07:05,508:INFO:Importing libraries
2025-10-12 16:07:05,508:INFO:Copying training dataset
2025-10-12 16:07:05,512:INFO:Defining folds
2025-10-12 16:07:05,512:INFO:Declaring metric variables
2025-10-12 16:07:05,515:INFO:Importing untrained model
2025-10-12 16:07:05,518:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:07:05,523:INFO:Starting cross validation
2025-10-12 16:07:05,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:07,518:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:07,522:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:07,522:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:07,524:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:07,549:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:07,576:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:09,432:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:09,462:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:10,293:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:10,312:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:10,325:INFO:Calculating mean and std
2025-10-12 16:07:10,326:INFO:Creating metrics dataframe
2025-10-12 16:07:10,328:INFO:Uploading results into container
2025-10-12 16:07:10,329:INFO:Uploading model into container now
2025-10-12 16:07:10,329:INFO:_master_model_container: 40
2025-10-12 16:07:10,329:INFO:_display_container: 11
2025-10-12 16:07:10,329:INFO:<catboost.core.CatBoostClassifier object at 0x00000265E1CBBA90>
2025-10-12 16:07:10,330:INFO:create_model() successfully completed......................................
2025-10-12 16:07:10,490:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:10,491:INFO:Creating metrics dataframe
2025-10-12 16:07:10,498:INFO:Initializing Dummy Classifier
2025-10-12 16:07:10,498:INFO:Total runtime is 0.20454641183217365 minutes
2025-10-12 16:07:10,502:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:10,502:INFO:Initializing create_model()
2025-10-12 16:07:10,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E015EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:10,502:INFO:Checking exceptions
2025-10-12 16:07:10,502:INFO:Importing libraries
2025-10-12 16:07:10,502:INFO:Copying training dataset
2025-10-12 16:07:10,505:INFO:Defining folds
2025-10-12 16:07:10,506:INFO:Declaring metric variables
2025-10-12 16:07:10,509:INFO:Importing untrained model
2025-10-12 16:07:10,511:INFO:Dummy Classifier Imported successfully
2025-10-12 16:07:10,517:INFO:Starting cross validation
2025-10-12 16:07:10,519:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:10,645:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:10,676:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:10,682:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:10,682:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:10,694:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:10,698:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:10,698:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:10,701:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:10,702:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:10,716:INFO:Calculating mean and std
2025-10-12 16:07:10,717:INFO:Creating metrics dataframe
2025-10-12 16:07:10,718:INFO:Uploading results into container
2025-10-12 16:07:10,719:INFO:Uploading model into container now
2025-10-12 16:07:10,719:INFO:_master_model_container: 41
2025-10-12 16:07:10,719:INFO:_display_container: 11
2025-10-12 16:07:10,719:INFO:DummyClassifier(constant=None, random_state=4451, strategy='prior')
2025-10-12 16:07:10,720:INFO:create_model() successfully completed......................................
2025-10-12 16:07:10,879:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:10,880:INFO:Creating metrics dataframe
2025-10-12 16:07:10,888:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:07:10,896:INFO:Initializing create_model()
2025-10-12 16:07:10,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:10,896:INFO:Checking exceptions
2025-10-12 16:07:10,898:INFO:Importing libraries
2025-10-12 16:07:10,898:INFO:Copying training dataset
2025-10-12 16:07:10,901:INFO:Defining folds
2025-10-12 16:07:10,901:INFO:Declaring metric variables
2025-10-12 16:07:10,901:INFO:Importing untrained model
2025-10-12 16:07:10,901:INFO:Declaring custom model
2025-10-12 16:07:10,902:INFO:Logistic Regression Imported successfully
2025-10-12 16:07:10,902:INFO:Cross validation set to False
2025-10-12 16:07:10,904:INFO:Fitting Model
2025-10-12 16:07:11,029:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:07:11,029:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:07:11,029:INFO:create_model() successfully completed......................................
2025-10-12 16:07:11,199:INFO:Creating Dashboard logs
2025-10-12 16:07:11,204:INFO:Model: Logistic Regression
2025-10-12 16:07:11,279:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 4451, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:07:11,517:INFO:Initializing predict_model()
2025-10-12 16:07:11,517:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E02F2670>)
2025-10-12 16:07:11,517:INFO:Checking exceptions
2025-10-12 16:07:11,518:INFO:Preloading libraries
2025-10-12 16:07:11,851:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:07:11,851:INFO:Initializing plot_model()
2025-10-12 16:07:11,851:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpdldlrd8z, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:11,852:INFO:Checking exceptions
2025-10-12 16:07:11,853:INFO:Preloading libraries
2025-10-12 16:07:11,853:INFO:Copying training dataset
2025-10-12 16:07:11,853:INFO:Plot type: auc
2025-10-12 16:07:12,142:INFO:Fitting Model
2025-10-12 16:07:12,142:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:07:12,143:INFO:Scoring test/hold-out set
2025-10-12 16:07:12,159:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpdldlrd8z\AUC.png'
2025-10-12 16:07:12,329:INFO:Visual Rendered Successfully
2025-10-12 16:07:12,489:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:12,512:INFO:Initializing plot_model()
2025-10-12 16:07:12,512:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpdldlrd8z, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:12,512:INFO:Checking exceptions
2025-10-12 16:07:12,514:INFO:Preloading libraries
2025-10-12 16:07:12,514:INFO:Copying training dataset
2025-10-12 16:07:12,514:INFO:Plot type: confusion_matrix
2025-10-12 16:07:12,811:INFO:Fitting Model
2025-10-12 16:07:12,812:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:07:12,812:INFO:Scoring test/hold-out set
2025-10-12 16:07:12,841:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpdldlrd8z\Confusion Matrix.png'
2025-10-12 16:07:12,931:INFO:Visual Rendered Successfully
2025-10-12 16:07:13,090:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:13,109:INFO:Initializing plot_model()
2025-10-12 16:07:13,109:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpdldlrd8z, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:13,109:INFO:Checking exceptions
2025-10-12 16:07:13,111:INFO:Preloading libraries
2025-10-12 16:07:13,111:INFO:Copying training dataset
2025-10-12 16:07:13,111:INFO:Plot type: feature
2025-10-12 16:07:13,268:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpdldlrd8z\Feature Importance.png'
2025-10-12 16:07:13,384:INFO:Visual Rendered Successfully
2025-10-12 16:07:13,552:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:13,571:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:07:13,801:INFO:Creating Dashboard logs
2025-10-12 16:07:13,803:INFO:Model: Ridge Classifier
2025-10-12 16:07:13,867:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 4451, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:07:14,323:INFO:Creating Dashboard logs
2025-10-12 16:07:14,327:INFO:Model: Extra Trees Classifier
2025-10-12 16:07:14,390:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 4451, 'verbose': 0, 'warm_start': False}
2025-10-12 16:07:14,857:INFO:Creating Dashboard logs
2025-10-12 16:07:14,860:INFO:Model: Naive Bayes
2025-10-12 16:07:14,929:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:07:15,371:INFO:Creating Dashboard logs
2025-10-12 16:07:15,373:INFO:Model: Random Forest Classifier
2025-10-12 16:07:15,443:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 4451, 'verbose': 0, 'warm_start': False}
2025-10-12 16:07:15,895:INFO:Creating Dashboard logs
2025-10-12 16:07:15,897:INFO:Model: SVM - Linear Kernel
2025-10-12 16:07:15,981:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 4451, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:07:16,463:INFO:Creating Dashboard logs
2025-10-12 16:07:16,467:INFO:Model: K Neighbors Classifier
2025-10-12 16:07:16,527:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:07:16,980:INFO:Creating Dashboard logs
2025-10-12 16:07:16,983:INFO:Model: Decision Tree Classifier
2025-10-12 16:07:17,056:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 4451, 'splitter': 'best'}
2025-10-12 16:07:17,456:INFO:Creating Dashboard logs
2025-10-12 16:07:17,458:INFO:Model: Ada Boost Classifier
2025-10-12 16:07:17,532:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 4451}
2025-10-12 16:07:17,941:INFO:Creating Dashboard logs
2025-10-12 16:07:17,944:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:07:18,014:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 4451, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:07:18,468:INFO:Creating Dashboard logs
2025-10-12 16:07:18,472:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:07:18,541:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:07:18,953:INFO:Creating Dashboard logs
2025-10-12 16:07:18,956:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:07:19,021:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 4451, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:07:19,509:INFO:Creating Dashboard logs
2025-10-12 16:07:19,512:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:07:19,586:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 4451, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:07:20,026:INFO:Creating Dashboard logs
2025-10-12 16:07:20,029:INFO:Model: CatBoost Classifier
2025-10-12 16:07:20,093:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-10-12 16:07:20,093:INFO:Logged params: {}
2025-10-12 16:07:20,476:INFO:Creating Dashboard logs
2025-10-12 16:07:20,478:INFO:Model: Dummy Classifier
2025-10-12 16:07:27,393:INFO:Initializing create_model()
2025-10-12 16:07:27,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:27,394:INFO:Checking exceptions
2025-10-12 16:07:27,408:INFO:Importing libraries
2025-10-12 16:07:27,408:INFO:Copying training dataset
2025-10-12 16:07:27,412:INFO:Defining folds
2025-10-12 16:07:27,412:INFO:Declaring metric variables
2025-10-12 16:07:27,415:INFO:Importing untrained model
2025-10-12 16:07:27,419:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:07:27,424:INFO:Starting cross validation
2025-10-12 16:07:27,425:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:27,558:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:27,571:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:27,579:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:27,586:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:27,589:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:27,592:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:27,596:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:27,598:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:27,600:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:27,600:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:27,613:INFO:Calculating mean and std
2025-10-12 16:07:27,613:INFO:Creating metrics dataframe
2025-10-12 16:07:27,618:INFO:Finalizing model
2025-10-12 16:07:27,668:INFO:Creating Dashboard logs
2025-10-12 16:07:27,671:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:07:27,742:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:07:27,947:INFO:Initializing predict_model()
2025-10-12 16:07:27,947:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E2634CA0>)
2025-10-12 16:07:27,947:INFO:Checking exceptions
2025-10-12 16:07:27,947:INFO:Preloading libraries
2025-10-12 16:07:28,118:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-12 16:07:28,334:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:07:28,336:INFO:Initializing plot_model()
2025-10-12 16:07:28,336:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpaau6cogj, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:28,336:INFO:Checking exceptions
2025-10-12 16:07:28,337:INFO:Preloading libraries
2025-10-12 16:07:28,338:INFO:Copying training dataset
2025-10-12 16:07:28,338:INFO:Plot type: auc
2025-10-12 16:07:28,623:INFO:Fitting Model
2025-10-12 16:07:28,624:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:07:28,624:INFO:Scoring test/hold-out set
2025-10-12 16:07:28,641:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpaau6cogj\AUC.png'
2025-10-12 16:07:28,839:INFO:Visual Rendered Successfully
2025-10-12 16:07:29,006:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:29,022:INFO:Initializing plot_model()
2025-10-12 16:07:29,022:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpaau6cogj, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:29,022:INFO:Checking exceptions
2025-10-12 16:07:29,023:INFO:Preloading libraries
2025-10-12 16:07:29,023:INFO:Copying training dataset
2025-10-12 16:07:29,023:INFO:Plot type: confusion_matrix
2025-10-12 16:07:29,299:INFO:Fitting Model
2025-10-12 16:07:29,299:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:07:29,299:INFO:Scoring test/hold-out set
2025-10-12 16:07:29,312:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpaau6cogj\Confusion Matrix.png'
2025-10-12 16:07:29,389:INFO:Visual Rendered Successfully
2025-10-12 16:07:29,552:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:29,569:INFO:Initializing plot_model()
2025-10-12 16:07:29,569:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpaau6cogj, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:29,569:INFO:Checking exceptions
2025-10-12 16:07:29,571:INFO:Preloading libraries
2025-10-12 16:07:29,571:INFO:Copying training dataset
2025-10-12 16:07:29,571:INFO:Plot type: feature
2025-10-12 16:07:29,730:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpaau6cogj\Feature Importance.png'
2025-10-12 16:07:29,858:INFO:Visual Rendered Successfully
2025-10-12 16:07:30,022:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:30,039:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:07:30,284:INFO:Uploading results into container
2025-10-12 16:07:30,285:INFO:Uploading model into container now
2025-10-12 16:07:30,293:INFO:_master_model_container: 42
2025-10-12 16:07:30,293:INFO:_display_container: 11
2025-10-12 16:07:30,293:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:07:30,293:INFO:create_model() successfully completed......................................
2025-10-12 16:07:30,457:INFO:Initializing create_model()
2025-10-12 16:07:30,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=ridge, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:30,457:INFO:Checking exceptions
2025-10-12 16:07:30,467:INFO:Importing libraries
2025-10-12 16:07:30,467:INFO:Copying training dataset
2025-10-12 16:07:30,471:INFO:Defining folds
2025-10-12 16:07:30,471:INFO:Declaring metric variables
2025-10-12 16:07:30,473:INFO:Importing untrained model
2025-10-12 16:07:30,477:INFO:Ridge Classifier Imported successfully
2025-10-12 16:07:30,482:INFO:Starting cross validation
2025-10-12 16:07:30,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:30,718:INFO:Calculating mean and std
2025-10-12 16:07:30,718:INFO:Creating metrics dataframe
2025-10-12 16:07:30,722:INFO:Finalizing model
2025-10-12 16:07:30,775:INFO:Creating Dashboard logs
2025-10-12 16:07:30,778:INFO:Model: Ridge Classifier
2025-10-12 16:07:30,848:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 4451, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:07:31,082:INFO:Initializing predict_model()
2025-10-12 16:07:31,082:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E0294B80>)
2025-10-12 16:07:31,082:INFO:Checking exceptions
2025-10-12 16:07:31,082:INFO:Preloading libraries
2025-10-12 16:07:31,412:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:07:31,412:INFO:Initializing plot_model()
2025-10-12 16:07:31,412:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpscdzh9s1, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:31,412:INFO:Checking exceptions
2025-10-12 16:07:31,413:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:07:31,413:INFO:Initializing plot_model()
2025-10-12 16:07:31,413:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpscdzh9s1, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:31,413:INFO:Checking exceptions
2025-10-12 16:07:31,414:INFO:Preloading libraries
2025-10-12 16:07:31,414:INFO:Copying training dataset
2025-10-12 16:07:31,414:INFO:Plot type: confusion_matrix
2025-10-12 16:07:31,714:INFO:Fitting Model
2025-10-12 16:07:31,714:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names

2025-10-12 16:07:31,714:INFO:Scoring test/hold-out set
2025-10-12 16:07:31,727:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpscdzh9s1\Confusion Matrix.png'
2025-10-12 16:07:31,820:INFO:Visual Rendered Successfully
2025-10-12 16:07:31,986:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:32,011:INFO:Initializing plot_model()
2025-10-12 16:07:32,011:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpscdzh9s1, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:32,011:INFO:Checking exceptions
2025-10-12 16:07:32,012:INFO:Preloading libraries
2025-10-12 16:07:32,013:INFO:Copying training dataset
2025-10-12 16:07:32,013:INFO:Plot type: feature
2025-10-12 16:07:32,176:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpscdzh9s1\Feature Importance.png'
2025-10-12 16:07:32,295:INFO:Visual Rendered Successfully
2025-10-12 16:07:32,458:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:32,480:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:07:32,729:INFO:Uploading results into container
2025-10-12 16:07:32,729:INFO:Uploading model into container now
2025-10-12 16:07:32,738:INFO:_master_model_container: 43
2025-10-12 16:07:32,738:INFO:_display_container: 12
2025-10-12 16:07:32,738:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001)
2025-10-12 16:07:32,738:INFO:create_model() successfully completed......................................
2025-10-12 16:07:32,905:INFO:Initializing create_model()
2025-10-12 16:07:32,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:32,905:INFO:Checking exceptions
2025-10-12 16:07:32,916:INFO:Importing libraries
2025-10-12 16:07:32,916:INFO:Copying training dataset
2025-10-12 16:07:32,919:INFO:Defining folds
2025-10-12 16:07:32,919:INFO:Declaring metric variables
2025-10-12 16:07:32,922:INFO:Importing untrained model
2025-10-12 16:07:32,925:INFO:Logistic Regression Imported successfully
2025-10-12 16:07:32,933:INFO:Starting cross validation
2025-10-12 16:07:32,934:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:33,132:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:33,144:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:33,163:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:33,173:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:33,177:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:33,202:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:33,204:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:33,207:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:33,217:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:33,224:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:33,306:INFO:Calculating mean and std
2025-10-12 16:07:33,306:INFO:Creating metrics dataframe
2025-10-12 16:07:33,310:INFO:Finalizing model
2025-10-12 16:07:33,421:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:07:33,422:INFO:Creating Dashboard logs
2025-10-12 16:07:33,424:INFO:Model: Logistic Regression
2025-10-12 16:07:33,498:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 4451, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:07:33,732:INFO:Initializing predict_model()
2025-10-12 16:07:33,732:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E0293AF0>)
2025-10-12 16:07:33,732:INFO:Checking exceptions
2025-10-12 16:07:33,732:INFO:Preloading libraries
2025-10-12 16:07:34,056:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:07:34,056:INFO:Initializing plot_model()
2025-10-12 16:07:34,056:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpi3quf4oy, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:34,056:INFO:Checking exceptions
2025-10-12 16:07:34,058:INFO:Preloading libraries
2025-10-12 16:07:34,058:INFO:Copying training dataset
2025-10-12 16:07:34,058:INFO:Plot type: auc
2025-10-12 16:07:34,374:INFO:Fitting Model
2025-10-12 16:07:34,374:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:07:34,374:INFO:Scoring test/hold-out set
2025-10-12 16:07:34,389:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpi3quf4oy\AUC.png'
2025-10-12 16:07:34,545:INFO:Visual Rendered Successfully
2025-10-12 16:07:34,703:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:34,724:INFO:Initializing plot_model()
2025-10-12 16:07:34,725:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpi3quf4oy, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:34,725:INFO:Checking exceptions
2025-10-12 16:07:34,726:INFO:Preloading libraries
2025-10-12 16:07:34,726:INFO:Copying training dataset
2025-10-12 16:07:34,726:INFO:Plot type: confusion_matrix
2025-10-12 16:07:35,005:INFO:Fitting Model
2025-10-12 16:07:35,005:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:07:35,005:INFO:Scoring test/hold-out set
2025-10-12 16:07:35,018:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpi3quf4oy\Confusion Matrix.png'
2025-10-12 16:07:35,096:INFO:Visual Rendered Successfully
2025-10-12 16:07:35,259:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:35,276:INFO:Initializing plot_model()
2025-10-12 16:07:35,276:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpi3quf4oy, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:35,276:INFO:Checking exceptions
2025-10-12 16:07:35,278:INFO:Preloading libraries
2025-10-12 16:07:35,278:INFO:Copying training dataset
2025-10-12 16:07:35,278:INFO:Plot type: feature
2025-10-12 16:07:35,432:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpi3quf4oy\Feature Importance.png'
2025-10-12 16:07:35,568:INFO:Visual Rendered Successfully
2025-10-12 16:07:35,730:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:35,749:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:07:35,989:INFO:Uploading results into container
2025-10-12 16:07:35,990:INFO:Uploading model into container now
2025-10-12 16:07:35,997:INFO:_master_model_container: 44
2025-10-12 16:07:35,997:INFO:_display_container: 13
2025-10-12 16:07:35,997:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:07:35,998:INFO:create_model() successfully completed......................................
2025-10-12 16:07:36,167:INFO:Initializing blend_models()
2025-10-12 16:07:36,167:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator_list=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:07:36,167:INFO:Checking exceptions
2025-10-12 16:07:36,167:INFO:Estimator RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-12 16:07:36,178:INFO:Importing libraries
2025-10-12 16:07:36,179:INFO:Copying training dataset
2025-10-12 16:07:36,181:INFO:Getting model names
2025-10-12 16:07:36,184:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:36,188:INFO:Initializing create_model()
2025-10-12 16:07:36,188:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DBDF9DF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:36,188:INFO:Checking exceptions
2025-10-12 16:07:36,188:INFO:Importing libraries
2025-10-12 16:07:36,188:INFO:Copying training dataset
2025-10-12 16:07:36,192:INFO:Defining folds
2025-10-12 16:07:36,192:INFO:Declaring metric variables
2025-10-12 16:07:36,195:INFO:Importing untrained model
2025-10-12 16:07:36,196:INFO:Declaring custom model
2025-10-12 16:07:36,199:INFO:Voting Classifier Imported successfully
2025-10-12 16:07:36,206:INFO:Starting cross validation
2025-10-12 16:07:36,208:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:36,639:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:36,653:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:36,657:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:36,660:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:36,661:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:36,662:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:36,673:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:36,709:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:07:36,722:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:07:36,729:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:07:36,744:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:07:36,847:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:36,850:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:36,896:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:36,896:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:07:36,897:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:07:36,934:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:07:36,956:INFO:Calculating mean and std
2025-10-12 16:07:36,957:INFO:Creating metrics dataframe
2025-10-12 16:07:36,961:INFO:Finalizing model
2025-10-12 16:07:37,087:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:37,102:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:37,116:INFO:Uploading results into container
2025-10-12 16:07:37,116:INFO:Uploading model into container now
2025-10-12 16:07:37,117:INFO:_master_model_container: 45
2025-10-12 16:07:37,117:INFO:_display_container: 14
2025-10-12 16:07:37,120:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:07:37,120:INFO:create_model() successfully completed......................................
2025-10-12 16:07:37,302:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:37,302:INFO:Creating Dashboard logs
2025-10-12 16:07:37,307:INFO:Model: Voting Classifier
2025-10-12 16:07:37,390:INFO:Logged params: {'flatten_transform': True, 'n_jobs': -1, 'verbose': False, 'voting': 'hard', 'weights': None, 'Linear Discriminant Analysis': LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), 'Ridge Classifier': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001), 'Logistic Regression__C': 1.0, 'Logistic Regression__class_weight': None, 'Logistic Regression__dual': False, 'Logistic Regression__fit_intercept': True, 'Logistic Regression__intercept_scaling': 1, 'Logistic Regression__l1_ratio': None, 'Logistic Regression__max_iter': 1000, 'Logistic Regression__multi_class': 'auto', 'Logistic Regression__n_jobs': None, 'Logistic Regression__penalty': 'l2', 'Logistic Regression__random_state': 4451, 'Logistic Regression__solver': 'lbfgs', 'Logistic Regression__tol': 0.0001, 'Logistic Regression__verbose': 0, 'Logistic Regression__warm_start': False, 'Linear Discriminant Analysis__covariance_estimator': None, 'Linear Discriminant Analysis__n_components': None, 'Linear Discriminant Analysis__priors': None, 'Linear Discriminant Analysis__shrinkage': None, 'Linear Discriminant Analysis__solver': 'svd', 'Linear Discriminant Analysis__store_covariance': False, 'Linear Discriminant Analysis__tol': 0.0001, 'Ridge Classifier__alpha': 1.0, 'Ridge Classifier__class_weight': None, 'Ridge Classifier__copy_X': True, 'Ridge Classifier__fit_intercept': True, 'Ridge Classifier__max_iter': None, 'Ridge Classifier__positive': False, 'Ridge Classifier__random_state': 4451, 'Ridge Classifier__solver': 'auto', 'Ridge Classifier__tol': 0.0001, 'Logistic Regression_1__C': 1.0, 'Logistic Regression_1__class_weight': None, 'Logistic Regression_1__dual': False, 'Logistic Regression_1__fit_intercept': True, 'Logistic Regression_1__intercept_scaling': 1, 'Logistic Regression_1__l1_ratio': None, 'Logistic Regression_1__max_iter': 1000, 'Logistic Regression_1__multi_class': 'auto', 'Logistic Regression_1__n_jobs': None, 'Logistic Regression_1__penalty': 'l2', 'Logistic Regression_1__random_state': 4451, 'Logistic Regression_1__solver': 'lbfgs', 'Logistic Regression_1__tol': 0.0001, 'Logistic Regression_1__verbose': 0, 'Logistic Regression_1__warm_start': False}
2025-10-12 16:07:37,771:INFO:Initializing predict_model()
2025-10-12 16:07:37,771:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E02F2C10>)
2025-10-12 16:07:37,771:INFO:Checking exceptions
2025-10-12 16:07:37,771:INFO:Preloading libraries
2025-10-12 16:07:38,162:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:07:38,164:INFO:Initializing plot_model()
2025-10-12 16:07:38,164:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmprfr19pzd, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:38,166:INFO:Checking exceptions
2025-10-12 16:07:38,166:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:07:38,168:INFO:Initializing plot_model()
2025-10-12 16:07:38,168:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmprfr19pzd, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:38,168:INFO:Checking exceptions
2025-10-12 16:07:38,171:INFO:Preloading libraries
2025-10-12 16:07:38,171:INFO:Copying training dataset
2025-10-12 16:07:38,172:INFO:Plot type: confusion_matrix
2025-10-12 16:07:38,473:INFO:Fitting Model
2025-10-12 16:07:38,474:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:07:38,474:INFO:Scoring test/hold-out set
2025-10-12 16:07:38,492:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmprfr19pzd\Confusion Matrix.png'
2025-10-12 16:07:38,577:INFO:Visual Rendered Successfully
2025-10-12 16:07:38,747:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:38,769:INFO:Initializing plot_model()
2025-10-12 16:07:38,769:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmprfr19pzd, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:38,769:INFO:Checking exceptions
2025-10-12 16:07:38,770:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 16:07:38,770:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:07:39,023:INFO:_master_model_container: 45
2025-10-12 16:07:39,023:INFO:_display_container: 14
2025-10-12 16:07:39,025:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(cova...
                                              tol=0.0001)),
                             ('Logistic Regression_1',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=4451,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:07:39,025:INFO:blend_models() successfully completed......................................
2025-10-12 16:07:39,192:INFO:Initializing compare_models()
2025-10-12 16:07:39,192:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:07:39,192:INFO:Checking exceptions
2025-10-12 16:07:39,193:INFO:Preparing display monitor
2025-10-12 16:07:39,209:INFO:Initializing Logistic Regression
2025-10-12 16:07:39,209:INFO:Total runtime is 0.0 minutes
2025-10-12 16:07:39,212:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:39,213:INFO:Initializing create_model()
2025-10-12 16:07:39,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:39,213:INFO:Checking exceptions
2025-10-12 16:07:39,213:INFO:Importing libraries
2025-10-12 16:07:39,213:INFO:Copying training dataset
2025-10-12 16:07:39,216:INFO:Defining folds
2025-10-12 16:07:39,216:INFO:Declaring metric variables
2025-10-12 16:07:39,220:INFO:Importing untrained model
2025-10-12 16:07:39,225:INFO:Logistic Regression Imported successfully
2025-10-12 16:07:39,230:INFO:Starting cross validation
2025-10-12 16:07:39,231:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:39,433:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:39,436:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:39,446:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:39,452:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:39,453:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:39,510:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:39,510:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:39,523:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:39,525:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:39,530:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-12 16:07:39,578:INFO:Calculating mean and std
2025-10-12 16:07:39,578:INFO:Creating metrics dataframe
2025-10-12 16:07:39,580:INFO:Uploading results into container
2025-10-12 16:07:39,580:INFO:Uploading model into container now
2025-10-12 16:07:39,581:INFO:_master_model_container: 46
2025-10-12 16:07:39,581:INFO:_display_container: 15
2025-10-12 16:07:39,581:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:07:39,581:INFO:create_model() successfully completed......................................
2025-10-12 16:07:39,762:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:39,762:INFO:Creating metrics dataframe
2025-10-12 16:07:39,768:INFO:Initializing K Neighbors Classifier
2025-10-12 16:07:39,768:INFO:Total runtime is 0.009304976463317871 minutes
2025-10-12 16:07:39,771:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:39,771:INFO:Initializing create_model()
2025-10-12 16:07:39,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:39,772:INFO:Checking exceptions
2025-10-12 16:07:39,772:INFO:Importing libraries
2025-10-12 16:07:39,772:INFO:Copying training dataset
2025-10-12 16:07:39,776:INFO:Defining folds
2025-10-12 16:07:39,776:INFO:Declaring metric variables
2025-10-12 16:07:39,778:INFO:Importing untrained model
2025-10-12 16:07:39,781:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:07:39,787:INFO:Starting cross validation
2025-10-12 16:07:39,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:40,122:INFO:Calculating mean and std
2025-10-12 16:07:40,122:INFO:Creating metrics dataframe
2025-10-12 16:07:40,123:INFO:Uploading results into container
2025-10-12 16:07:40,124:INFO:Uploading model into container now
2025-10-12 16:07:40,124:INFO:_master_model_container: 47
2025-10-12 16:07:40,124:INFO:_display_container: 15
2025-10-12 16:07:40,124:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:07:40,124:INFO:create_model() successfully completed......................................
2025-10-12 16:07:40,287:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:40,287:INFO:Creating metrics dataframe
2025-10-12 16:07:40,292:INFO:Initializing Naive Bayes
2025-10-12 16:07:40,292:INFO:Total runtime is 0.018037474155426024 minutes
2025-10-12 16:07:40,296:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:40,296:INFO:Initializing create_model()
2025-10-12 16:07:40,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:40,296:INFO:Checking exceptions
2025-10-12 16:07:40,296:INFO:Importing libraries
2025-10-12 16:07:40,296:INFO:Copying training dataset
2025-10-12 16:07:40,299:INFO:Defining folds
2025-10-12 16:07:40,299:INFO:Declaring metric variables
2025-10-12 16:07:40,302:INFO:Importing untrained model
2025-10-12 16:07:40,306:INFO:Naive Bayes Imported successfully
2025-10-12 16:07:40,311:INFO:Starting cross validation
2025-10-12 16:07:40,312:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:40,477:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:40,493:INFO:Calculating mean and std
2025-10-12 16:07:40,494:INFO:Creating metrics dataframe
2025-10-12 16:07:40,496:INFO:Uploading results into container
2025-10-12 16:07:40,497:INFO:Uploading model into container now
2025-10-12 16:07:40,497:INFO:_master_model_container: 48
2025-10-12 16:07:40,497:INFO:_display_container: 15
2025-10-12 16:07:40,498:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:07:40,498:INFO:create_model() successfully completed......................................
2025-10-12 16:07:40,663:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:40,663:INFO:Creating metrics dataframe
2025-10-12 16:07:40,668:INFO:Initializing Decision Tree Classifier
2025-10-12 16:07:40,669:INFO:Total runtime is 0.024320673942565915 minutes
2025-10-12 16:07:40,671:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:40,672:INFO:Initializing create_model()
2025-10-12 16:07:40,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:40,672:INFO:Checking exceptions
2025-10-12 16:07:40,672:INFO:Importing libraries
2025-10-12 16:07:40,672:INFO:Copying training dataset
2025-10-12 16:07:40,675:INFO:Defining folds
2025-10-12 16:07:40,675:INFO:Declaring metric variables
2025-10-12 16:07:40,678:INFO:Importing untrained model
2025-10-12 16:07:40,680:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:07:40,686:INFO:Starting cross validation
2025-10-12 16:07:40,688:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:40,807:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:40,825:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:40,841:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:40,842:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:40,843:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:40,846:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:40,856:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:40,858:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:40,862:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:40,865:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:40,884:INFO:Calculating mean and std
2025-10-12 16:07:40,885:INFO:Creating metrics dataframe
2025-10-12 16:07:40,887:INFO:Uploading results into container
2025-10-12 16:07:40,887:INFO:Uploading model into container now
2025-10-12 16:07:40,888:INFO:_master_model_container: 49
2025-10-12 16:07:40,888:INFO:_display_container: 15
2025-10-12 16:07:40,888:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=4451, splitter='best')
2025-10-12 16:07:40,888:INFO:create_model() successfully completed......................................
2025-10-12 16:07:41,054:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:41,054:INFO:Creating metrics dataframe
2025-10-12 16:07:41,062:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:07:41,062:INFO:Total runtime is 0.030872082710266112 minutes
2025-10-12 16:07:41,065:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:41,065:INFO:Initializing create_model()
2025-10-12 16:07:41,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:41,065:INFO:Checking exceptions
2025-10-12 16:07:41,065:INFO:Importing libraries
2025-10-12 16:07:41,065:INFO:Copying training dataset
2025-10-12 16:07:41,070:INFO:Defining folds
2025-10-12 16:07:41,070:INFO:Declaring metric variables
2025-10-12 16:07:41,075:INFO:Importing untrained model
2025-10-12 16:07:41,078:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:07:41,085:INFO:Starting cross validation
2025-10-12 16:07:41,087:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:41,237:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:41,273:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:41,279:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:41,291:INFO:Calculating mean and std
2025-10-12 16:07:41,292:INFO:Creating metrics dataframe
2025-10-12 16:07:41,293:INFO:Uploading results into container
2025-10-12 16:07:41,294:INFO:Uploading model into container now
2025-10-12 16:07:41,295:INFO:_master_model_container: 50
2025-10-12 16:07:41,295:INFO:_display_container: 15
2025-10-12 16:07:41,295:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4451, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:07:41,295:INFO:create_model() successfully completed......................................
2025-10-12 16:07:41,463:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:41,464:INFO:Creating metrics dataframe
2025-10-12 16:07:41,470:INFO:Initializing Ridge Classifier
2025-10-12 16:07:41,470:INFO:Total runtime is 0.03768466313680013 minutes
2025-10-12 16:07:41,473:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:41,473:INFO:Initializing create_model()
2025-10-12 16:07:41,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:41,473:INFO:Checking exceptions
2025-10-12 16:07:41,473:INFO:Importing libraries
2025-10-12 16:07:41,473:INFO:Copying training dataset
2025-10-12 16:07:41,477:INFO:Defining folds
2025-10-12 16:07:41,477:INFO:Declaring metric variables
2025-10-12 16:07:41,479:INFO:Importing untrained model
2025-10-12 16:07:41,484:INFO:Ridge Classifier Imported successfully
2025-10-12 16:07:41,489:INFO:Starting cross validation
2025-10-12 16:07:41,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:41,696:INFO:Calculating mean and std
2025-10-12 16:07:41,697:INFO:Creating metrics dataframe
2025-10-12 16:07:41,698:INFO:Uploading results into container
2025-10-12 16:07:41,699:INFO:Uploading model into container now
2025-10-12 16:07:41,699:INFO:_master_model_container: 51
2025-10-12 16:07:41,699:INFO:_display_container: 15
2025-10-12 16:07:41,701:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4451, solver='auto',
                tol=0.0001)
2025-10-12 16:07:41,701:INFO:create_model() successfully completed......................................
2025-10-12 16:07:41,879:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:41,879:INFO:Creating metrics dataframe
2025-10-12 16:07:41,884:INFO:Initializing Random Forest Classifier
2025-10-12 16:07:41,884:INFO:Total runtime is 0.04457909266153971 minutes
2025-10-12 16:07:41,888:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:41,889:INFO:Initializing create_model()
2025-10-12 16:07:41,889:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:41,889:INFO:Checking exceptions
2025-10-12 16:07:41,889:INFO:Importing libraries
2025-10-12 16:07:41,889:INFO:Copying training dataset
2025-10-12 16:07:41,892:INFO:Defining folds
2025-10-12 16:07:41,892:INFO:Declaring metric variables
2025-10-12 16:07:41,896:INFO:Importing untrained model
2025-10-12 16:07:41,899:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:07:41,906:INFO:Starting cross validation
2025-10-12 16:07:41,907:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:42,342:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:42,357:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:42,372:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:42,456:INFO:Calculating mean and std
2025-10-12 16:07:42,457:INFO:Creating metrics dataframe
2025-10-12 16:07:42,459:INFO:Uploading results into container
2025-10-12 16:07:42,459:INFO:Uploading model into container now
2025-10-12 16:07:42,459:INFO:_master_model_container: 52
2025-10-12 16:07:42,460:INFO:_display_container: 15
2025-10-12 16:07:42,460:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4451, verbose=0,
                       warm_start=False)
2025-10-12 16:07:42,460:INFO:create_model() successfully completed......................................
2025-10-12 16:07:42,639:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:42,639:INFO:Creating metrics dataframe
2025-10-12 16:07:42,646:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:07:42,646:INFO:Total runtime is 0.05726999044418335 minutes
2025-10-12 16:07:42,648:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:42,649:INFO:Initializing create_model()
2025-10-12 16:07:42,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:42,649:INFO:Checking exceptions
2025-10-12 16:07:42,649:INFO:Importing libraries
2025-10-12 16:07:42,649:INFO:Copying training dataset
2025-10-12 16:07:42,653:INFO:Defining folds
2025-10-12 16:07:42,653:INFO:Declaring metric variables
2025-10-12 16:07:42,657:INFO:Importing untrained model
2025-10-12 16:07:42,660:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:07:42,667:INFO:Starting cross validation
2025-10-12 16:07:42,669:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:42,782:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:42,784:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:42,800:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:42,802:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:42,809:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:42,812:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:42,826:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:42,828:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:42,830:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:42,832:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:42,832:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:42,834:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-12 16:07:42,847:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:42,873:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:42,873:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:42,874:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:42,876:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:42,891:INFO:Calculating mean and std
2025-10-12 16:07:42,892:INFO:Creating metrics dataframe
2025-10-12 16:07:42,894:INFO:Uploading results into container
2025-10-12 16:07:42,894:INFO:Uploading model into container now
2025-10-12 16:07:42,894:INFO:_master_model_container: 53
2025-10-12 16:07:42,894:INFO:_display_container: 15
2025-10-12 16:07:42,896:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:07:42,896:INFO:create_model() successfully completed......................................
2025-10-12 16:07:43,073:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:43,074:INFO:Creating metrics dataframe
2025-10-12 16:07:43,080:INFO:Initializing Ada Boost Classifier
2025-10-12 16:07:43,081:INFO:Total runtime is 0.06453040440877279 minutes
2025-10-12 16:07:43,084:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:43,084:INFO:Initializing create_model()
2025-10-12 16:07:43,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:43,084:INFO:Checking exceptions
2025-10-12 16:07:43,084:INFO:Importing libraries
2025-10-12 16:07:43,084:INFO:Copying training dataset
2025-10-12 16:07:43,089:INFO:Defining folds
2025-10-12 16:07:43,089:INFO:Declaring metric variables
2025-10-12 16:07:43,092:INFO:Importing untrained model
2025-10-12 16:07:43,097:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:07:43,103:INFO:Starting cross validation
2025-10-12 16:07:43,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:43,210:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:43,227:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:43,229:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:43,235:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:43,239:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:43,241:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:43,249:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:43,258:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:43,259:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,274:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:43,275:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:07:43,277:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,279:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,284:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,287:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,313:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,314:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,318:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,326:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,327:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,341:INFO:Calculating mean and std
2025-10-12 16:07:43,342:INFO:Creating metrics dataframe
2025-10-12 16:07:43,345:INFO:Uploading results into container
2025-10-12 16:07:43,346:INFO:Uploading model into container now
2025-10-12 16:07:43,346:INFO:_master_model_container: 54
2025-10-12 16:07:43,346:INFO:_display_container: 15
2025-10-12 16:07:43,347:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4451)
2025-10-12 16:07:43,347:INFO:create_model() successfully completed......................................
2025-10-12 16:07:43,530:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:43,530:INFO:Creating metrics dataframe
2025-10-12 16:07:43,537:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:07:43,538:INFO:Total runtime is 0.07213840484619141 minutes
2025-10-12 16:07:43,541:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:43,541:INFO:Initializing create_model()
2025-10-12 16:07:43,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:43,541:INFO:Checking exceptions
2025-10-12 16:07:43,541:INFO:Importing libraries
2025-10-12 16:07:43,541:INFO:Copying training dataset
2025-10-12 16:07:43,546:INFO:Defining folds
2025-10-12 16:07:43,546:INFO:Declaring metric variables
2025-10-12 16:07:43,550:INFO:Importing untrained model
2025-10-12 16:07:43,553:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:07:43,558:INFO:Starting cross validation
2025-10-12 16:07:43,560:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:43,787:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,791:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,812:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,821:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,841:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,855:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,856:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,856:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,857:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,860:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:43,873:INFO:Calculating mean and std
2025-10-12 16:07:43,874:INFO:Creating metrics dataframe
2025-10-12 16:07:43,876:INFO:Uploading results into container
2025-10-12 16:07:43,877:INFO:Uploading model into container now
2025-10-12 16:07:43,878:INFO:_master_model_container: 55
2025-10-12 16:07:43,878:INFO:_display_container: 15
2025-10-12 16:07:43,878:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4451, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:07:43,878:INFO:create_model() successfully completed......................................
2025-10-12 16:07:44,060:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:44,060:INFO:Creating metrics dataframe
2025-10-12 16:07:44,067:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:07:44,067:INFO:Total runtime is 0.08096448580423991 minutes
2025-10-12 16:07:44,070:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:44,071:INFO:Initializing create_model()
2025-10-12 16:07:44,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:44,071:INFO:Checking exceptions
2025-10-12 16:07:44,071:INFO:Importing libraries
2025-10-12 16:07:44,071:INFO:Copying training dataset
2025-10-12 16:07:44,076:INFO:Defining folds
2025-10-12 16:07:44,076:INFO:Declaring metric variables
2025-10-12 16:07:44,080:INFO:Importing untrained model
2025-10-12 16:07:44,083:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:07:44,090:INFO:Starting cross validation
2025-10-12 16:07:44,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:44,229:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:44,254:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:44,262:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:44,264:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:44,265:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:44,266:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:44,267:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:44,270:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:44,272:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:44,272:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:44,292:INFO:Calculating mean and std
2025-10-12 16:07:44,294:INFO:Creating metrics dataframe
2025-10-12 16:07:44,295:INFO:Uploading results into container
2025-10-12 16:07:44,296:INFO:Uploading model into container now
2025-10-12 16:07:44,296:INFO:_master_model_container: 56
2025-10-12 16:07:44,296:INFO:_display_container: 15
2025-10-12 16:07:44,296:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:07:44,296:INFO:create_model() successfully completed......................................
2025-10-12 16:07:44,475:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:44,475:INFO:Creating metrics dataframe
2025-10-12 16:07:44,483:INFO:Initializing Extra Trees Classifier
2025-10-12 16:07:44,483:INFO:Total runtime is 0.08789679606755575 minutes
2025-10-12 16:07:44,486:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:44,486:INFO:Initializing create_model()
2025-10-12 16:07:44,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:44,486:INFO:Checking exceptions
2025-10-12 16:07:44,487:INFO:Importing libraries
2025-10-12 16:07:44,487:INFO:Copying training dataset
2025-10-12 16:07:44,490:INFO:Defining folds
2025-10-12 16:07:44,490:INFO:Declaring metric variables
2025-10-12 16:07:44,493:INFO:Importing untrained model
2025-10-12 16:07:44,497:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:07:44,502:INFO:Starting cross validation
2025-10-12 16:07:44,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:45,023:INFO:Calculating mean and std
2025-10-12 16:07:45,024:INFO:Creating metrics dataframe
2025-10-12 16:07:45,026:INFO:Uploading results into container
2025-10-12 16:07:45,027:INFO:Uploading model into container now
2025-10-12 16:07:45,027:INFO:_master_model_container: 57
2025-10-12 16:07:45,027:INFO:_display_container: 15
2025-10-12 16:07:45,028:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4451, verbose=0,
                     warm_start=False)
2025-10-12 16:07:45,028:INFO:create_model() successfully completed......................................
2025-10-12 16:07:45,188:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:45,188:INFO:Creating metrics dataframe
2025-10-12 16:07:45,195:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:07:45,195:INFO:Total runtime is 0.09976460138956707 minutes
2025-10-12 16:07:45,199:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:45,199:INFO:Initializing create_model()
2025-10-12 16:07:45,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:45,199:INFO:Checking exceptions
2025-10-12 16:07:45,199:INFO:Importing libraries
2025-10-12 16:07:45,199:INFO:Copying training dataset
2025-10-12 16:07:45,203:INFO:Defining folds
2025-10-12 16:07:45,203:INFO:Declaring metric variables
2025-10-12 16:07:45,208:INFO:Importing untrained model
2025-10-12 16:07:45,211:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:07:45,218:INFO:Starting cross validation
2025-10-12 16:07:45,219:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:45,378:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:45,398:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:45,402:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:45,410:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:45,411:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:45,411:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:45,424:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:45,428:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:45,428:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:45,429:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:45,443:INFO:Calculating mean and std
2025-10-12 16:07:45,444:INFO:Creating metrics dataframe
2025-10-12 16:07:45,447:INFO:Uploading results into container
2025-10-12 16:07:45,447:INFO:Uploading model into container now
2025-10-12 16:07:45,448:INFO:_master_model_container: 58
2025-10-12 16:07:45,448:INFO:_display_container: 15
2025-10-12 16:07:45,448:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:07:45,448:INFO:create_model() successfully completed......................................
2025-10-12 16:07:45,621:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:45,622:INFO:Creating metrics dataframe
2025-10-12 16:07:45,632:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:07:45,632:INFO:Total runtime is 0.10703795750935874 minutes
2025-10-12 16:07:45,636:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:45,637:INFO:Initializing create_model()
2025-10-12 16:07:45,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:45,637:INFO:Checking exceptions
2025-10-12 16:07:45,637:INFO:Importing libraries
2025-10-12 16:07:45,637:INFO:Copying training dataset
2025-10-12 16:07:45,641:INFO:Defining folds
2025-10-12 16:07:45,641:INFO:Declaring metric variables
2025-10-12 16:07:45,646:INFO:Importing untrained model
2025-10-12 16:07:45,651:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:07:45,659:INFO:Starting cross validation
2025-10-12 16:07:45,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:47,454:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:47,514:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:47,541:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:47,546:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:47,549:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:47,588:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:47,598:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:47,598:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:47,622:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:47,640:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:47,659:INFO:Calculating mean and std
2025-10-12 16:07:47,661:INFO:Creating metrics dataframe
2025-10-12 16:07:47,663:INFO:Uploading results into container
2025-10-12 16:07:47,664:INFO:Uploading model into container now
2025-10-12 16:07:47,664:INFO:_master_model_container: 59
2025-10-12 16:07:47,665:INFO:_display_container: 15
2025-10-12 16:07:47,666:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4451, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:07:47,666:INFO:create_model() successfully completed......................................
2025-10-12 16:07:47,872:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:47,872:INFO:Creating metrics dataframe
2025-10-12 16:07:47,881:INFO:Initializing CatBoost Classifier
2025-10-12 16:07:47,881:INFO:Total runtime is 0.1445228417714437 minutes
2025-10-12 16:07:47,885:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:47,887:INFO:Initializing create_model()
2025-10-12 16:07:47,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:47,887:INFO:Checking exceptions
2025-10-12 16:07:47,887:INFO:Importing libraries
2025-10-12 16:07:47,887:INFO:Copying training dataset
2025-10-12 16:07:47,891:INFO:Defining folds
2025-10-12 16:07:47,891:INFO:Declaring metric variables
2025-10-12 16:07:47,896:INFO:Importing untrained model
2025-10-12 16:07:47,901:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:07:47,906:INFO:Starting cross validation
2025-10-12 16:07:47,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:49,975:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:49,976:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:49,976:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:49,976:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:49,978:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:49,990:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:51,852:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:51,858:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:51,887:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:51,893:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:51,907:INFO:Calculating mean and std
2025-10-12 16:07:51,908:INFO:Creating metrics dataframe
2025-10-12 16:07:51,910:INFO:Uploading results into container
2025-10-12 16:07:51,910:INFO:Uploading model into container now
2025-10-12 16:07:51,910:INFO:_master_model_container: 60
2025-10-12 16:07:51,911:INFO:_display_container: 15
2025-10-12 16:07:51,911:INFO:<catboost.core.CatBoostClassifier object at 0x00000265E018A760>
2025-10-12 16:07:51,911:INFO:create_model() successfully completed......................................
2025-10-12 16:07:52,078:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:52,078:INFO:Creating metrics dataframe
2025-10-12 16:07:52,086:INFO:Initializing Dummy Classifier
2025-10-12 16:07:52,086:INFO:Total runtime is 0.21460459232330326 minutes
2025-10-12 16:07:52,089:INFO:SubProcess create_model() called ==================================
2025-10-12 16:07:52,089:INFO:Initializing create_model()
2025-10-12 16:07:52,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E0152BE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:52,089:INFO:Checking exceptions
2025-10-12 16:07:52,090:INFO:Importing libraries
2025-10-12 16:07:52,090:INFO:Copying training dataset
2025-10-12 16:07:52,093:INFO:Defining folds
2025-10-12 16:07:52,093:INFO:Declaring metric variables
2025-10-12 16:07:52,096:INFO:Importing untrained model
2025-10-12 16:07:52,099:INFO:Dummy Classifier Imported successfully
2025-10-12 16:07:52,105:INFO:Starting cross validation
2025-10-12 16:07:52,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:07:52,246:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:52,261:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:52,268:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:52,270:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:52,272:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:52,282:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:52,282:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:52,287:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:52,287:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:52,290:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:07:52,310:INFO:Calculating mean and std
2025-10-12 16:07:52,311:INFO:Creating metrics dataframe
2025-10-12 16:07:52,313:INFO:Uploading results into container
2025-10-12 16:07:52,314:INFO:Uploading model into container now
2025-10-12 16:07:52,314:INFO:_master_model_container: 61
2025-10-12 16:07:52,314:INFO:_display_container: 15
2025-10-12 16:07:52,315:INFO:DummyClassifier(constant=None, random_state=4451, strategy='prior')
2025-10-12 16:07:52,315:INFO:create_model() successfully completed......................................
2025-10-12 16:07:52,493:INFO:SubProcess create_model() end ==================================
2025-10-12 16:07:52,494:INFO:Creating metrics dataframe
2025-10-12 16:07:52,502:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:07:52,510:INFO:Initializing create_model()
2025-10-12 16:07:52,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:07:52,511:INFO:Checking exceptions
2025-10-12 16:07:52,512:INFO:Importing libraries
2025-10-12 16:07:52,512:INFO:Copying training dataset
2025-10-12 16:07:52,514:INFO:Defining folds
2025-10-12 16:07:52,514:INFO:Declaring metric variables
2025-10-12 16:07:52,516:INFO:Importing untrained model
2025-10-12 16:07:52,516:INFO:Declaring custom model
2025-10-12 16:07:52,516:INFO:Logistic Regression Imported successfully
2025-10-12 16:07:52,517:INFO:Cross validation set to False
2025-10-12 16:07:52,517:INFO:Fitting Model
2025-10-12 16:07:52,650:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-12 16:07:52,651:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:07:52,651:INFO:create_model() successfully completed......................................
2025-10-12 16:07:52,846:INFO:Creating Dashboard logs
2025-10-12 16:07:52,849:INFO:Model: Logistic Regression
2025-10-12 16:07:52,942:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 4451, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:07:53,232:INFO:Initializing predict_model()
2025-10-12 16:07:53,233:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E0588280>)
2025-10-12 16:07:53,233:INFO:Checking exceptions
2025-10-12 16:07:53,233:INFO:Preloading libraries
2025-10-12 16:07:53,577:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:07:53,577:INFO:Initializing plot_model()
2025-10-12 16:07:53,577:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpp0dxm0og, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:53,577:INFO:Checking exceptions
2025-10-12 16:07:53,579:INFO:Preloading libraries
2025-10-12 16:07:53,579:INFO:Copying training dataset
2025-10-12 16:07:53,579:INFO:Plot type: auc
2025-10-12 16:07:53,914:INFO:Fitting Model
2025-10-12 16:07:53,915:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:07:53,915:INFO:Scoring test/hold-out set
2025-10-12 16:07:53,929:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpp0dxm0og\AUC.png'
2025-10-12 16:07:54,136:INFO:Visual Rendered Successfully
2025-10-12 16:07:54,312:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:54,346:INFO:Initializing plot_model()
2025-10-12 16:07:54,346:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpp0dxm0og, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:54,346:INFO:Checking exceptions
2025-10-12 16:07:54,347:INFO:Preloading libraries
2025-10-12 16:07:54,347:INFO:Copying training dataset
2025-10-12 16:07:54,347:INFO:Plot type: confusion_matrix
2025-10-12 16:07:54,673:INFO:Fitting Model
2025-10-12 16:07:54,673:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:07:54,673:INFO:Scoring test/hold-out set
2025-10-12 16:07:54,691:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpp0dxm0og\Confusion Matrix.png'
2025-10-12 16:07:54,781:INFO:Visual Rendered Successfully
2025-10-12 16:07:54,964:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:54,985:INFO:Initializing plot_model()
2025-10-12 16:07:54,985:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpp0dxm0og, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, system=False)
2025-10-12 16:07:54,985:INFO:Checking exceptions
2025-10-12 16:07:54,986:INFO:Preloading libraries
2025-10-12 16:07:54,986:INFO:Copying training dataset
2025-10-12 16:07:54,986:INFO:Plot type: feature
2025-10-12 16:07:55,144:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpp0dxm0og\Feature Importance.png'
2025-10-12 16:07:55,269:INFO:Visual Rendered Successfully
2025-10-12 16:07:55,430:INFO:plot_model() successfully completed......................................
2025-10-12 16:07:55,450:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:07:55,701:INFO:Creating Dashboard logs
2025-10-12 16:07:55,704:INFO:Model: Ridge Classifier
2025-10-12 16:07:55,775:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 4451, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:07:56,257:INFO:Creating Dashboard logs
2025-10-12 16:07:56,259:INFO:Model: Extra Trees Classifier
2025-10-12 16:07:56,331:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 4451, 'verbose': 0, 'warm_start': False}
2025-10-12 16:07:56,799:INFO:Creating Dashboard logs
2025-10-12 16:07:56,802:INFO:Model: Naive Bayes
2025-10-12 16:07:56,875:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:07:57,351:INFO:Creating Dashboard logs
2025-10-12 16:07:57,354:INFO:Model: Random Forest Classifier
2025-10-12 16:07:57,420:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 4451, 'verbose': 0, 'warm_start': False}
2025-10-12 16:07:57,935:INFO:Creating Dashboard logs
2025-10-12 16:07:57,938:INFO:Model: SVM - Linear Kernel
2025-10-12 16:07:58,022:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 4451, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:07:58,516:INFO:Creating Dashboard logs
2025-10-12 16:07:58,519:INFO:Model: K Neighbors Classifier
2025-10-12 16:07:58,599:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:07:59,092:INFO:Creating Dashboard logs
2025-10-12 16:07:59,094:INFO:Model: Decision Tree Classifier
2025-10-12 16:07:59,166:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 4451, 'splitter': 'best'}
2025-10-12 16:07:59,586:INFO:Creating Dashboard logs
2025-10-12 16:07:59,589:INFO:Model: Ada Boost Classifier
2025-10-12 16:07:59,659:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 4451}
2025-10-12 16:08:00,070:INFO:Creating Dashboard logs
2025-10-12 16:08:00,072:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:08:00,144:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 4451, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:08:00,567:INFO:Creating Dashboard logs
2025-10-12 16:08:00,569:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:08:00,638:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:08:01,040:INFO:Creating Dashboard logs
2025-10-12 16:08:01,043:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:08:01,111:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 4451, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:08:01,581:INFO:Creating Dashboard logs
2025-10-12 16:08:01,584:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:08:01,649:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 4451, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:08:02,077:INFO:Creating Dashboard logs
2025-10-12 16:08:02,080:INFO:Model: CatBoost Classifier
2025-10-12 16:08:02,148:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-10-12 16:08:02,148:INFO:Logged params: {}
2025-10-12 16:08:02,546:INFO:Creating Dashboard logs
2025-10-12 16:08:02,549:INFO:Model: Dummy Classifier
2025-10-12 16:08:02,622:INFO:Logged params: {'constant': None, 'random_state': 4451, 'strategy': 'prior'}
2025-10-12 16:08:03,060:INFO:Creating Dashboard logs
2025-10-12 16:08:03,063:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 16:08:03,158:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:08:03,624:INFO:_master_model_container: 61
2025-10-12 16:08:03,624:INFO:_display_container: 15
2025-10-12 16:08:03,625:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:08:03,625:INFO:compare_models() successfully completed......................................
2025-10-12 16:08:16,836:INFO:Initializing predict_model()
2025-10-12 16:08:16,837:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=mlflow.pyfunc.loaded_model:
  run_id: 39f894e7d3eb44a99b7896e490c21033
  artifact_path: model
  flavor: mlflow.sklearn
, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E1D1D280>)
2025-10-12 16:08:16,837:INFO:Checking exceptions
2025-10-12 16:08:16,837:INFO:Preloading libraries
2025-10-12 16:08:16,838:INFO:Set up data.
2025-10-12 16:08:16,844:INFO:Set up index.
2025-10-12 16:09:52,502:INFO:Initializing predict_model()
2025-10-12 16:09:52,502:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299F10>, estimator=mlflow.pyfunc.loaded_model:
  run_id: 39f894e7d3eb44a99b7896e490c21033
  artifact_path: model
  flavor: mlflow.sklearn
, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E201DA60>)
2025-10-12 16:09:52,502:INFO:Checking exceptions
2025-10-12 16:09:52,502:INFO:Preloading libraries
2025-10-12 16:09:52,505:INFO:Set up data.
2025-10-12 16:09:52,511:INFO:Set up index.
2025-10-12 16:18:18,013:INFO:PyCaret ClassificationExperiment
2025-10-12 16:18:18,013:INFO:Logging name: titanic_exp_1
2025-10-12 16:18:18,013:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-12 16:18:18,013:INFO:version 3.3.2
2025-10-12 16:18:18,013:INFO:Initializing setup()
2025-10-12 16:18:18,013:INFO:self.USI: 290d
2025-10-12 16:18:18,013:INFO:self._variable_keys: {'fold_generator', 'is_multiclass', 'pipeline', 'y', 'target_param', '_ml_usecase', 'fold_shuffle_param', 'X_train', 'html_param', 'gpu_n_jobs_param', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', 'exp_id', 'data', 'y_test', 'exp_name_log', 'memory', 'y_train', 'X_test', 'seed', 'fix_imbalance', 'n_jobs_param', 'X', 'logging_param', '_available_plots', 'idx'}
2025-10-12 16:18:18,013:INFO:Checking environment
2025-10-12 16:18:18,013:INFO:python_version: 3.9.13
2025-10-12 16:18:18,013:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2025-10-12 16:18:18,013:INFO:machine: AMD64
2025-10-12 16:18:18,013:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-12 16:18:18,013:INFO:Memory: svmem(total=16778072064, available=5290893312, percent=68.5, used=11487178752, free=5290893312)
2025-10-12 16:18:18,013:INFO:Physical Core: 10
2025-10-12 16:18:18,013:INFO:Logical Core: 16
2025-10-12 16:18:18,013:INFO:Checking libraries
2025-10-12 16:18:18,013:INFO:System:
2025-10-12 16:18:18,013:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2025-10-12 16:18:18,013:INFO:executable: c:\Users\david\Programming\MLOps\.venv\Scripts\python.exe
2025-10-12 16:18:18,014:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-12 16:18:18,014:INFO:PyCaret required dependencies:
2025-10-12 16:18:18,014:INFO:                 pip: 25.2
2025-10-12 16:18:18,014:INFO:          setuptools: 80.9.0
2025-10-12 16:18:18,014:INFO:             pycaret: 3.3.2
2025-10-12 16:18:18,014:INFO:             IPython: 8.18.1
2025-10-12 16:18:18,014:INFO:          ipywidgets: 8.1.7
2025-10-12 16:18:18,014:INFO:                tqdm: 4.67.1
2025-10-12 16:18:18,014:INFO:               numpy: 1.26.4
2025-10-12 16:18:18,014:INFO:              pandas: 2.1.4
2025-10-12 16:18:18,014:INFO:              jinja2: 3.1.6
2025-10-12 16:18:18,014:INFO:               scipy: 1.11.4
2025-10-12 16:18:18,014:INFO:              joblib: 1.3.2
2025-10-12 16:18:18,014:INFO:             sklearn: 1.4.2
2025-10-12 16:18:18,014:INFO:                pyod: 2.0.5
2025-10-12 16:18:18,014:INFO:            imblearn: 0.12.4
2025-10-12 16:18:18,014:INFO:   category_encoders: 2.6.4
2025-10-12 16:18:18,014:INFO:            lightgbm: 4.6.0
2025-10-12 16:18:18,014:INFO:               numba: 0.60.0
2025-10-12 16:18:18,014:INFO:            requests: 2.32.5
2025-10-12 16:18:18,014:INFO:          matplotlib: 3.7.5
2025-10-12 16:18:18,014:INFO:          scikitplot: 0.3.7
2025-10-12 16:18:18,014:INFO:         yellowbrick: 1.5
2025-10-12 16:18:18,014:INFO:              plotly: 5.24.1
2025-10-12 16:18:18,014:INFO:    plotly-resampler: Not installed
2025-10-12 16:18:18,014:INFO:             kaleido: 1.1.0
2025-10-12 16:18:18,014:INFO:           schemdraw: 0.15
2025-10-12 16:18:18,014:INFO:         statsmodels: 0.14.5
2025-10-12 16:18:18,014:INFO:              sktime: 0.26.0
2025-10-12 16:18:18,015:INFO:               tbats: 1.1.3
2025-10-12 16:18:18,015:INFO:            pmdarima: 2.0.4
2025-10-12 16:18:18,015:INFO:              psutil: 7.1.0
2025-10-12 16:18:18,015:INFO:          markupsafe: 2.1.5
2025-10-12 16:18:18,015:INFO:             pickle5: Not installed
2025-10-12 16:18:18,015:INFO:         cloudpickle: 3.1.1
2025-10-12 16:18:18,015:INFO:         deprecation: 2.1.0
2025-10-12 16:18:18,015:INFO:              xxhash: 3.6.0
2025-10-12 16:18:18,015:INFO:           wurlitzer: Not installed
2025-10-12 16:18:18,015:INFO:PyCaret optional dependencies:
2025-10-12 16:18:18,015:INFO:                shap: 0.44.1
2025-10-12 16:18:18,015:INFO:           interpret: 0.7.2
2025-10-12 16:18:18,015:INFO:                umap: 0.5.7
2025-10-12 16:18:18,015:INFO:     ydata_profiling: 4.17.0
2025-10-12 16:18:18,015:INFO:  explainerdashboard: 0.5.1
2025-10-12 16:18:18,015:INFO:             autoviz: Not installed
2025-10-12 16:18:18,015:INFO:           fairlearn: 0.7.0
2025-10-12 16:18:18,015:INFO:          deepchecks: Not installed
2025-10-12 16:18:18,015:INFO:             xgboost: 2.1.4
2025-10-12 16:18:18,015:INFO:            catboost: 1.2.8
2025-10-12 16:18:18,015:INFO:              kmodes: 0.12.2
2025-10-12 16:18:18,015:INFO:             mlxtend: 0.23.4
2025-10-12 16:18:18,015:INFO:       statsforecast: 1.5.0
2025-10-12 16:18:18,015:INFO:        tune_sklearn: Not installed
2025-10-12 16:18:18,015:INFO:                 ray: Not installed
2025-10-12 16:18:18,015:INFO:            hyperopt: 0.2.7
2025-10-12 16:18:18,015:INFO:              optuna: 4.5.0
2025-10-12 16:18:18,015:INFO:               skopt: 0.10.2
2025-10-12 16:18:18,015:INFO:              mlflow: 3.1.4
2025-10-12 16:18:18,015:INFO:              gradio: Not installed
2025-10-12 16:18:18,015:INFO:             fastapi: 0.119.0
2025-10-12 16:18:18,015:INFO:             uvicorn: 0.37.0
2025-10-12 16:18:18,015:INFO:              m2cgen: 0.10.0
2025-10-12 16:18:18,015:INFO:           evidently: 0.4.40
2025-10-12 16:18:18,015:INFO:               fugue: 0.8.7
2025-10-12 16:18:18,015:INFO:           streamlit: Not installed
2025-10-12 16:18:18,015:INFO:             prophet: Not installed
2025-10-12 16:18:18,015:INFO:None
2025-10-12 16:18:18,015:INFO:Set up data.
2025-10-12 16:18:18,020:INFO:Set up folding strategy.
2025-10-12 16:18:18,020:INFO:Set up train/test split.
2025-10-12 16:18:18,022:INFO:Set up index.
2025-10-12 16:18:18,023:INFO:Assigning column types.
2025-10-12 16:18:18,026:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-12 16:18:18,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:18:18,052:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:18:18,067:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:18:18,068:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:18:18,094:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:18:18,095:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:18:18,113:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:18:18,115:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:18:18,115:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-12 16:18:18,144:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:18:18,164:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:18:18,165:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:18:18,193:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:18:18,209:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:18:18,212:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:18:18,213:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-12 16:18:18,264:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:18:18,267:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:18:18,323:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:18:18,325:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:18:18,326:INFO:Preparing preprocessing pipeline...
2025-10-12 16:18:18,327:INFO:Set up simple imputation.
2025-10-12 16:18:18,339:INFO:Finished creating preprocessing pipeline.
2025-10-12 16:18:18,341:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-12 16:18:18,341:INFO:Creating final display dataframe.
2025-10-12 16:18:18,379:INFO:Setup _display_container:                     Description            Value
0                    Session id             6951
1                        Target         Survived
2                   Target type           Binary
3           Original data shape         (712, 7)
4        Transformed data shape         (712, 7)
5   Transformed train set shape         (498, 7)
6    Transformed test set shape         (214, 7)
7              Numeric features                6
8                    Preprocess             True
9               Imputation type           simple
10           Numeric imputation             mean
11       Categorical imputation             mode
12               Fold Generator  StratifiedKFold
13                  Fold Number               10
14                     CPU Jobs               -1
15                      Use GPU            False
16               Log Experiment     MlflowLogger
17              Experiment Name    titanic_exp_1
18                          USI             290d
2025-10-12 16:18:18,426:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:18:18,427:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:18:18,470:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:18:18,471:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:18:18,472:INFO:Logging experiment in loggers
2025-10-12 16:18:18,607:INFO:SubProcess save_model() called ==================================
2025-10-12 16:18:18,613:INFO:Initializing save_model()
2025-10-12 16:18:18,613:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\david\AppData\Local\Temp\tmpcfemtrc0\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 16:18:18,613:INFO:Adding model into prep_pipe
2025-10-12 16:18:18,613:WARNING:Only Model saved as it was a pipeline.
2025-10-12 16:18:18,614:INFO:C:\Users\david\AppData\Local\Temp\tmpcfemtrc0\Transformation Pipeline.pkl saved in current working directory
2025-10-12 16:18:18,616:INFO:Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-12 16:18:18,616:INFO:save_model() successfully completed......................................
2025-10-12 16:18:18,805:INFO:SubProcess save_model() end ==================================
2025-10-12 16:18:18,943:INFO:setup() successfully completed in 0.46s...............
2025-10-12 16:18:24,499:INFO:Initializing compare_models()
2025-10-12 16:18:24,501:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:18:24,501:INFO:Checking exceptions
2025-10-12 16:18:24,503:INFO:Preparing display monitor
2025-10-12 16:18:24,525:INFO:Initializing Logistic Regression
2025-10-12 16:18:24,525:INFO:Total runtime is 0.0 minutes
2025-10-12 16:18:24,528:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:24,529:INFO:Initializing create_model()
2025-10-12 16:18:24,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:24,529:INFO:Checking exceptions
2025-10-12 16:18:24,529:INFO:Importing libraries
2025-10-12 16:18:24,529:INFO:Copying training dataset
2025-10-12 16:18:24,532:INFO:Defining folds
2025-10-12 16:18:24,532:INFO:Declaring metric variables
2025-10-12 16:18:24,535:INFO:Importing untrained model
2025-10-12 16:18:24,539:INFO:Logistic Regression Imported successfully
2025-10-12 16:18:24,544:INFO:Starting cross validation
2025-10-12 16:18:24,544:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:32,181:INFO:Calculating mean and std
2025-10-12 16:18:32,184:INFO:Creating metrics dataframe
2025-10-12 16:18:32,188:INFO:Uploading results into container
2025-10-12 16:18:32,189:INFO:Uploading model into container now
2025-10-12 16:18:32,191:INFO:_master_model_container: 1
2025-10-12 16:18:32,191:INFO:_display_container: 2
2025-10-12 16:18:32,191:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6951, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:18:32,192:INFO:create_model() successfully completed......................................
2025-10-12 16:18:32,421:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:32,421:INFO:Creating metrics dataframe
2025-10-12 16:18:32,426:INFO:Initializing K Neighbors Classifier
2025-10-12 16:18:32,426:INFO:Total runtime is 0.1316801110903422 minutes
2025-10-12 16:18:32,428:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:32,429:INFO:Initializing create_model()
2025-10-12 16:18:32,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:32,429:INFO:Checking exceptions
2025-10-12 16:18:32,429:INFO:Importing libraries
2025-10-12 16:18:32,429:INFO:Copying training dataset
2025-10-12 16:18:32,432:INFO:Defining folds
2025-10-12 16:18:32,432:INFO:Declaring metric variables
2025-10-12 16:18:32,435:INFO:Importing untrained model
2025-10-12 16:18:32,439:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:18:32,444:INFO:Starting cross validation
2025-10-12 16:18:32,445:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:36,325:INFO:Calculating mean and std
2025-10-12 16:18:36,326:INFO:Creating metrics dataframe
2025-10-12 16:18:36,329:INFO:Uploading results into container
2025-10-12 16:18:36,330:INFO:Uploading model into container now
2025-10-12 16:18:36,330:INFO:_master_model_container: 2
2025-10-12 16:18:36,330:INFO:_display_container: 2
2025-10-12 16:18:36,331:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:18:36,331:INFO:create_model() successfully completed......................................
2025-10-12 16:18:36,525:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:36,525:INFO:Creating metrics dataframe
2025-10-12 16:18:36,530:INFO:Initializing Naive Bayes
2025-10-12 16:18:36,530:INFO:Total runtime is 0.2000866413116455 minutes
2025-10-12 16:18:36,534:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:36,534:INFO:Initializing create_model()
2025-10-12 16:18:36,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:36,534:INFO:Checking exceptions
2025-10-12 16:18:36,535:INFO:Importing libraries
2025-10-12 16:18:36,535:INFO:Copying training dataset
2025-10-12 16:18:36,538:INFO:Defining folds
2025-10-12 16:18:36,539:INFO:Declaring metric variables
2025-10-12 16:18:36,542:INFO:Importing untrained model
2025-10-12 16:18:36,545:INFO:Naive Bayes Imported successfully
2025-10-12 16:18:36,550:INFO:Starting cross validation
2025-10-12 16:18:36,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:36,617:INFO:Calculating mean and std
2025-10-12 16:18:36,617:INFO:Creating metrics dataframe
2025-10-12 16:18:36,620:INFO:Uploading results into container
2025-10-12 16:18:36,621:INFO:Uploading model into container now
2025-10-12 16:18:36,621:INFO:_master_model_container: 3
2025-10-12 16:18:36,621:INFO:_display_container: 2
2025-10-12 16:18:36,621:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:18:36,621:INFO:create_model() successfully completed......................................
2025-10-12 16:18:36,793:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:36,793:INFO:Creating metrics dataframe
2025-10-12 16:18:36,799:INFO:Initializing Decision Tree Classifier
2025-10-12 16:18:36,799:INFO:Total runtime is 0.20456163485844928 minutes
2025-10-12 16:18:36,803:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:36,803:INFO:Initializing create_model()
2025-10-12 16:18:36,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:36,803:INFO:Checking exceptions
2025-10-12 16:18:36,803:INFO:Importing libraries
2025-10-12 16:18:36,803:INFO:Copying training dataset
2025-10-12 16:18:36,806:INFO:Defining folds
2025-10-12 16:18:36,807:INFO:Declaring metric variables
2025-10-12 16:18:36,810:INFO:Importing untrained model
2025-10-12 16:18:36,814:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:18:36,819:INFO:Starting cross validation
2025-10-12 16:18:36,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:36,879:INFO:Calculating mean and std
2025-10-12 16:18:36,880:INFO:Creating metrics dataframe
2025-10-12 16:18:36,881:INFO:Uploading results into container
2025-10-12 16:18:36,881:INFO:Uploading model into container now
2025-10-12 16:18:36,881:INFO:_master_model_container: 4
2025-10-12 16:18:36,881:INFO:_display_container: 2
2025-10-12 16:18:36,881:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6951, splitter='best')
2025-10-12 16:18:36,881:INFO:create_model() successfully completed......................................
2025-10-12 16:18:37,058:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:37,058:INFO:Creating metrics dataframe
2025-10-12 16:18:37,064:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:18:37,064:INFO:Total runtime is 0.20898388624191283 minutes
2025-10-12 16:18:37,067:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:37,067:INFO:Initializing create_model()
2025-10-12 16:18:37,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:37,067:INFO:Checking exceptions
2025-10-12 16:18:37,067:INFO:Importing libraries
2025-10-12 16:18:37,068:INFO:Copying training dataset
2025-10-12 16:18:37,071:INFO:Defining folds
2025-10-12 16:18:37,072:INFO:Declaring metric variables
2025-10-12 16:18:37,074:INFO:Importing untrained model
2025-10-12 16:18:37,077:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:18:37,083:INFO:Starting cross validation
2025-10-12 16:18:37,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:37,129:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:18:37,130:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:18:37,143:INFO:Calculating mean and std
2025-10-12 16:18:37,143:INFO:Creating metrics dataframe
2025-10-12 16:18:37,146:INFO:Uploading results into container
2025-10-12 16:18:37,146:INFO:Uploading model into container now
2025-10-12 16:18:37,146:INFO:_master_model_container: 5
2025-10-12 16:18:37,146:INFO:_display_container: 2
2025-10-12 16:18:37,147:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6951, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:18:37,147:INFO:create_model() successfully completed......................................
2025-10-12 16:18:37,318:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:37,318:INFO:Creating metrics dataframe
2025-10-12 16:18:37,326:INFO:Initializing Ridge Classifier
2025-10-12 16:18:37,326:INFO:Total runtime is 0.21335172653198242 minutes
2025-10-12 16:18:37,329:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:37,329:INFO:Initializing create_model()
2025-10-12 16:18:37,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:37,329:INFO:Checking exceptions
2025-10-12 16:18:37,329:INFO:Importing libraries
2025-10-12 16:18:37,329:INFO:Copying training dataset
2025-10-12 16:18:37,333:INFO:Defining folds
2025-10-12 16:18:37,333:INFO:Declaring metric variables
2025-10-12 16:18:37,337:INFO:Importing untrained model
2025-10-12 16:18:37,341:INFO:Ridge Classifier Imported successfully
2025-10-12 16:18:37,345:INFO:Starting cross validation
2025-10-12 16:18:37,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:37,408:INFO:Calculating mean and std
2025-10-12 16:18:37,409:INFO:Creating metrics dataframe
2025-10-12 16:18:37,410:INFO:Uploading results into container
2025-10-12 16:18:37,410:INFO:Uploading model into container now
2025-10-12 16:18:37,411:INFO:_master_model_container: 6
2025-10-12 16:18:37,411:INFO:_display_container: 2
2025-10-12 16:18:37,411:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001)
2025-10-12 16:18:37,411:INFO:create_model() successfully completed......................................
2025-10-12 16:18:37,579:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:37,579:INFO:Creating metrics dataframe
2025-10-12 16:18:37,584:INFO:Initializing Random Forest Classifier
2025-10-12 16:18:37,584:INFO:Total runtime is 0.2176488955815633 minutes
2025-10-12 16:18:37,588:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:37,588:INFO:Initializing create_model()
2025-10-12 16:18:37,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:37,588:INFO:Checking exceptions
2025-10-12 16:18:37,588:INFO:Importing libraries
2025-10-12 16:18:37,588:INFO:Copying training dataset
2025-10-12 16:18:37,591:INFO:Defining folds
2025-10-12 16:18:37,591:INFO:Declaring metric variables
2025-10-12 16:18:37,594:INFO:Importing untrained model
2025-10-12 16:18:37,597:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:18:37,603:INFO:Starting cross validation
2025-10-12 16:18:37,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:37,905:INFO:Calculating mean and std
2025-10-12 16:18:37,906:INFO:Creating metrics dataframe
2025-10-12 16:18:37,908:INFO:Uploading results into container
2025-10-12 16:18:37,908:INFO:Uploading model into container now
2025-10-12 16:18:37,909:INFO:_master_model_container: 7
2025-10-12 16:18:37,909:INFO:_display_container: 2
2025-10-12 16:18:37,909:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6951, verbose=0,
                       warm_start=False)
2025-10-12 16:18:37,909:INFO:create_model() successfully completed......................................
2025-10-12 16:18:38,076:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:38,076:INFO:Creating metrics dataframe
2025-10-12 16:18:38,083:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:18:38,084:INFO:Total runtime is 0.22598075071970622 minutes
2025-10-12 16:18:38,087:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:38,088:INFO:Initializing create_model()
2025-10-12 16:18:38,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:38,088:INFO:Checking exceptions
2025-10-12 16:18:38,088:INFO:Importing libraries
2025-10-12 16:18:38,088:INFO:Copying training dataset
2025-10-12 16:18:38,091:INFO:Defining folds
2025-10-12 16:18:38,091:INFO:Declaring metric variables
2025-10-12 16:18:38,094:INFO:Importing untrained model
2025-10-12 16:18:38,099:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:18:38,105:INFO:Starting cross validation
2025-10-12 16:18:38,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:38,169:INFO:Calculating mean and std
2025-10-12 16:18:38,170:INFO:Creating metrics dataframe
2025-10-12 16:18:38,171:INFO:Uploading results into container
2025-10-12 16:18:38,171:INFO:Uploading model into container now
2025-10-12 16:18:38,171:INFO:_master_model_container: 8
2025-10-12 16:18:38,171:INFO:_display_container: 2
2025-10-12 16:18:38,171:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:18:38,171:INFO:create_model() successfully completed......................................
2025-10-12 16:18:38,345:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:38,345:INFO:Creating metrics dataframe
2025-10-12 16:18:38,353:INFO:Initializing Ada Boost Classifier
2025-10-12 16:18:38,353:INFO:Total runtime is 0.23046051263809203 minutes
2025-10-12 16:18:38,357:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:38,358:INFO:Initializing create_model()
2025-10-12 16:18:38,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:38,358:INFO:Checking exceptions
2025-10-12 16:18:38,358:INFO:Importing libraries
2025-10-12 16:18:38,358:INFO:Copying training dataset
2025-10-12 16:18:38,361:INFO:Defining folds
2025-10-12 16:18:38,361:INFO:Declaring metric variables
2025-10-12 16:18:38,366:INFO:Importing untrained model
2025-10-12 16:18:38,369:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:18:38,375:INFO:Starting cross validation
2025-10-12 16:18:38,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:38,391:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:18:38,391:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:18:38,394:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:18:38,396:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:18:38,397:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:18:38,399:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:18:38,400:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:18:38,400:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:18:38,404:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:18:38,407:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:18:38,531:INFO:Calculating mean and std
2025-10-12 16:18:38,531:INFO:Creating metrics dataframe
2025-10-12 16:18:38,534:INFO:Uploading results into container
2025-10-12 16:18:38,534:INFO:Uploading model into container now
2025-10-12 16:18:38,535:INFO:_master_model_container: 9
2025-10-12 16:18:38,535:INFO:_display_container: 2
2025-10-12 16:18:38,535:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6951)
2025-10-12 16:18:38,535:INFO:create_model() successfully completed......................................
2025-10-12 16:18:38,706:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:38,706:INFO:Creating metrics dataframe
2025-10-12 16:18:38,713:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:18:38,713:INFO:Total runtime is 0.23646790981292723 minutes
2025-10-12 16:18:38,716:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:38,716:INFO:Initializing create_model()
2025-10-12 16:18:38,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:38,716:INFO:Checking exceptions
2025-10-12 16:18:38,716:INFO:Importing libraries
2025-10-12 16:18:38,716:INFO:Copying training dataset
2025-10-12 16:18:38,720:INFO:Defining folds
2025-10-12 16:18:38,720:INFO:Declaring metric variables
2025-10-12 16:18:38,724:INFO:Importing untrained model
2025-10-12 16:18:38,727:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:18:38,733:INFO:Starting cross validation
2025-10-12 16:18:38,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:38,917:INFO:Calculating mean and std
2025-10-12 16:18:38,919:INFO:Creating metrics dataframe
2025-10-12 16:18:38,920:INFO:Uploading results into container
2025-10-12 16:18:38,921:INFO:Uploading model into container now
2025-10-12 16:18:38,921:INFO:_master_model_container: 10
2025-10-12 16:18:38,921:INFO:_display_container: 2
2025-10-12 16:18:38,922:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:18:38,922:INFO:create_model() successfully completed......................................
2025-10-12 16:18:39,081:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:39,081:INFO:Creating metrics dataframe
2025-10-12 16:18:39,087:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:18:39,087:INFO:Total runtime is 0.24270365635553995 minutes
2025-10-12 16:18:39,091:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:39,091:INFO:Initializing create_model()
2025-10-12 16:18:39,091:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:39,091:INFO:Checking exceptions
2025-10-12 16:18:39,091:INFO:Importing libraries
2025-10-12 16:18:39,091:INFO:Copying training dataset
2025-10-12 16:18:39,095:INFO:Defining folds
2025-10-12 16:18:39,095:INFO:Declaring metric variables
2025-10-12 16:18:39,098:INFO:Importing untrained model
2025-10-12 16:18:39,102:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:18:39,109:INFO:Starting cross validation
2025-10-12 16:18:39,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:39,181:INFO:Calculating mean and std
2025-10-12 16:18:39,181:INFO:Creating metrics dataframe
2025-10-12 16:18:39,183:INFO:Uploading results into container
2025-10-12 16:18:39,183:INFO:Uploading model into container now
2025-10-12 16:18:39,183:INFO:_master_model_container: 11
2025-10-12 16:18:39,183:INFO:_display_container: 2
2025-10-12 16:18:39,183:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:18:39,183:INFO:create_model() successfully completed......................................
2025-10-12 16:18:39,337:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:39,338:INFO:Creating metrics dataframe
2025-10-12 16:18:39,345:INFO:Initializing Extra Trees Classifier
2025-10-12 16:18:39,345:INFO:Total runtime is 0.2469937006632487 minutes
2025-10-12 16:18:39,348:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:39,348:INFO:Initializing create_model()
2025-10-12 16:18:39,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:39,348:INFO:Checking exceptions
2025-10-12 16:18:39,348:INFO:Importing libraries
2025-10-12 16:18:39,348:INFO:Copying training dataset
2025-10-12 16:18:39,352:INFO:Defining folds
2025-10-12 16:18:39,352:INFO:Declaring metric variables
2025-10-12 16:18:39,355:INFO:Importing untrained model
2025-10-12 16:18:39,358:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:18:39,365:INFO:Starting cross validation
2025-10-12 16:18:39,366:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:39,632:INFO:Calculating mean and std
2025-10-12 16:18:39,633:INFO:Creating metrics dataframe
2025-10-12 16:18:39,635:INFO:Uploading results into container
2025-10-12 16:18:39,635:INFO:Uploading model into container now
2025-10-12 16:18:39,635:INFO:_master_model_container: 12
2025-10-12 16:18:39,636:INFO:_display_container: 2
2025-10-12 16:18:39,636:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6951, verbose=0,
                     warm_start=False)
2025-10-12 16:18:39,636:INFO:create_model() successfully completed......................................
2025-10-12 16:18:39,797:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:39,797:INFO:Creating metrics dataframe
2025-10-12 16:18:39,805:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:18:39,805:INFO:Total runtime is 0.2546613335609436 minutes
2025-10-12 16:18:39,807:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:39,808:INFO:Initializing create_model()
2025-10-12 16:18:39,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:39,808:INFO:Checking exceptions
2025-10-12 16:18:39,808:INFO:Importing libraries
2025-10-12 16:18:39,808:INFO:Copying training dataset
2025-10-12 16:18:39,810:INFO:Defining folds
2025-10-12 16:18:39,811:INFO:Declaring metric variables
2025-10-12 16:18:39,813:INFO:Importing untrained model
2025-10-12 16:18:39,816:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:18:39,824:INFO:Starting cross validation
2025-10-12 16:18:39,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:40,399:INFO:Calculating mean and std
2025-10-12 16:18:40,401:INFO:Creating metrics dataframe
2025-10-12 16:18:40,403:INFO:Uploading results into container
2025-10-12 16:18:40,403:INFO:Uploading model into container now
2025-10-12 16:18:40,403:INFO:_master_model_container: 13
2025-10-12 16:18:40,403:INFO:_display_container: 2
2025-10-12 16:18:40,404:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:18:40,404:INFO:create_model() successfully completed......................................
2025-10-12 16:18:40,588:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:40,588:INFO:Creating metrics dataframe
2025-10-12 16:18:40,597:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:18:40,597:INFO:Total runtime is 0.267862069606781 minutes
2025-10-12 16:18:40,599:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:40,600:INFO:Initializing create_model()
2025-10-12 16:18:40,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:40,600:INFO:Checking exceptions
2025-10-12 16:18:40,600:INFO:Importing libraries
2025-10-12 16:18:40,600:INFO:Copying training dataset
2025-10-12 16:18:40,604:INFO:Defining folds
2025-10-12 16:18:40,604:INFO:Declaring metric variables
2025-10-12 16:18:40,608:INFO:Importing untrained model
2025-10-12 16:18:40,611:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:18:40,617:INFO:Starting cross validation
2025-10-12 16:18:40,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:41,521:INFO:Calculating mean and std
2025-10-12 16:18:41,524:INFO:Creating metrics dataframe
2025-10-12 16:18:41,526:INFO:Uploading results into container
2025-10-12 16:18:41,527:INFO:Uploading model into container now
2025-10-12 16:18:41,528:INFO:_master_model_container: 14
2025-10-12 16:18:41,528:INFO:_display_container: 2
2025-10-12 16:18:41,529:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6951, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:18:41,529:INFO:create_model() successfully completed......................................
2025-10-12 16:18:41,723:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:41,724:INFO:Creating metrics dataframe
2025-10-12 16:18:41,732:INFO:Initializing CatBoost Classifier
2025-10-12 16:18:41,732:INFO:Total runtime is 0.28678828477859497 minutes
2025-10-12 16:18:41,737:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:41,737:INFO:Initializing create_model()
2025-10-12 16:18:41,737:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:41,737:INFO:Checking exceptions
2025-10-12 16:18:41,737:INFO:Importing libraries
2025-10-12 16:18:41,737:INFO:Copying training dataset
2025-10-12 16:18:41,741:INFO:Defining folds
2025-10-12 16:18:41,741:INFO:Declaring metric variables
2025-10-12 16:18:41,743:INFO:Importing untrained model
2025-10-12 16:18:41,746:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:18:41,753:INFO:Starting cross validation
2025-10-12 16:18:41,753:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:45,815:INFO:Calculating mean and std
2025-10-12 16:18:45,816:INFO:Creating metrics dataframe
2025-10-12 16:18:45,818:INFO:Uploading results into container
2025-10-12 16:18:45,819:INFO:Uploading model into container now
2025-10-12 16:18:45,819:INFO:_master_model_container: 15
2025-10-12 16:18:45,819:INFO:_display_container: 2
2025-10-12 16:18:45,820:INFO:<catboost.core.CatBoostClassifier object at 0x00000265DEDDBE80>
2025-10-12 16:18:45,820:INFO:create_model() successfully completed......................................
2025-10-12 16:18:46,006:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:46,006:INFO:Creating metrics dataframe
2025-10-12 16:18:46,013:INFO:Initializing Dummy Classifier
2025-10-12 16:18:46,013:INFO:Total runtime is 0.3581346074740092 minutes
2025-10-12 16:18:46,016:INFO:SubProcess create_model() called ==================================
2025-10-12 16:18:46,016:INFO:Initializing create_model()
2025-10-12 16:18:46,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265CED50B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:46,016:INFO:Checking exceptions
2025-10-12 16:18:46,016:INFO:Importing libraries
2025-10-12 16:18:46,016:INFO:Copying training dataset
2025-10-12 16:18:46,019:INFO:Defining folds
2025-10-12 16:18:46,019:INFO:Declaring metric variables
2025-10-12 16:18:46,023:INFO:Importing untrained model
2025-10-12 16:18:46,025:INFO:Dummy Classifier Imported successfully
2025-10-12 16:18:46,031:INFO:Starting cross validation
2025-10-12 16:18:46,033:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:18:46,065:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:18:46,065:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:18:46,067:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:18:46,067:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:18:46,069:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:18:46,070:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:18:46,070:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:18:46,070:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:18:46,074:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:18:46,074:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:18:46,091:INFO:Calculating mean and std
2025-10-12 16:18:46,092:INFO:Creating metrics dataframe
2025-10-12 16:18:46,093:INFO:Uploading results into container
2025-10-12 16:18:46,093:INFO:Uploading model into container now
2025-10-12 16:18:46,094:INFO:_master_model_container: 16
2025-10-12 16:18:46,094:INFO:_display_container: 2
2025-10-12 16:18:46,094:INFO:DummyClassifier(constant=None, random_state=6951, strategy='prior')
2025-10-12 16:18:46,094:INFO:create_model() successfully completed......................................
2025-10-12 16:18:46,256:INFO:SubProcess create_model() end ==================================
2025-10-12 16:18:46,256:INFO:Creating metrics dataframe
2025-10-12 16:18:46,264:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:18:46,273:INFO:Initializing create_model()
2025-10-12 16:18:46,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:46,273:INFO:Checking exceptions
2025-10-12 16:18:46,274:INFO:Importing libraries
2025-10-12 16:18:46,274:INFO:Copying training dataset
2025-10-12 16:18:46,276:INFO:Defining folds
2025-10-12 16:18:46,276:INFO:Declaring metric variables
2025-10-12 16:18:46,276:INFO:Importing untrained model
2025-10-12 16:18:46,277:INFO:Declaring custom model
2025-10-12 16:18:46,277:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:18:46,277:INFO:Cross validation set to False
2025-10-12 16:18:46,277:INFO:Fitting Model
2025-10-12 16:18:46,364:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:18:46,364:INFO:create_model() successfully completed......................................
2025-10-12 16:18:46,541:INFO:Creating Dashboard logs
2025-10-12 16:18:46,550:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:18:46,629:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 6951, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:18:46,881:INFO:Initializing predict_model()
2025-10-12 16:18:46,881:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E0330B80>)
2025-10-12 16:18:46,881:INFO:Checking exceptions
2025-10-12 16:18:46,881:INFO:Preloading libraries
2025-10-12 16:18:47,112:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:18:47,112:INFO:Initializing plot_model()
2025-10-12 16:18:47,114:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpcfh2uoyc, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:18:47,114:INFO:Checking exceptions
2025-10-12 16:18:47,116:INFO:Preloading libraries
2025-10-12 16:18:47,121:INFO:Copying training dataset
2025-10-12 16:18:47,121:INFO:Plot type: auc
2025-10-12 16:18:47,162:INFO:Fitting Model
2025-10-12 16:18:47,163:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:18:47,163:INFO:Scoring test/hold-out set
2025-10-12 16:18:47,179:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpcfh2uoyc\AUC.png'
2025-10-12 16:18:47,354:INFO:Visual Rendered Successfully
2025-10-12 16:18:47,523:INFO:plot_model() successfully completed......................................
2025-10-12 16:18:47,539:INFO:Initializing plot_model()
2025-10-12 16:18:47,539:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpcfh2uoyc, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:18:47,539:INFO:Checking exceptions
2025-10-12 16:18:47,540:INFO:Preloading libraries
2025-10-12 16:18:47,545:INFO:Copying training dataset
2025-10-12 16:18:47,545:INFO:Plot type: confusion_matrix
2025-10-12 16:18:47,590:INFO:Fitting Model
2025-10-12 16:18:47,590:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:18:47,590:INFO:Scoring test/hold-out set
2025-10-12 16:18:47,605:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpcfh2uoyc\Confusion Matrix.png'
2025-10-12 16:18:47,691:INFO:Visual Rendered Successfully
2025-10-12 16:18:47,852:INFO:plot_model() successfully completed......................................
2025-10-12 16:18:47,872:INFO:Initializing plot_model()
2025-10-12 16:18:47,872:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpcfh2uoyc, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:18:47,873:INFO:Checking exceptions
2025-10-12 16:18:47,874:INFO:Preloading libraries
2025-10-12 16:18:47,878:INFO:Copying training dataset
2025-10-12 16:18:47,878:INFO:Plot type: feature
2025-10-12 16:18:47,878:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:18:47,901:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpcfh2uoyc\Feature Importance.png'
2025-10-12 16:18:47,996:INFO:Visual Rendered Successfully
2025-10-12 16:18:48,160:INFO:plot_model() successfully completed......................................
2025-10-12 16:18:48,175:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:18:48,445:INFO:Creating Dashboard logs
2025-10-12 16:18:48,449:INFO:Model: Ada Boost Classifier
2025-10-12 16:18:48,517:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 6951}
2025-10-12 16:18:48,990:INFO:Creating Dashboard logs
2025-10-12 16:18:48,992:INFO:Model: CatBoost Classifier
2025-10-12 16:18:49,075:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-10-12 16:18:49,075:INFO:Logged params: {}
2025-10-12 16:18:49,525:INFO:Creating Dashboard logs
2025-10-12 16:18:49,528:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:18:49,599:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6951, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:18:50,130:INFO:Creating Dashboard logs
2025-10-12 16:18:50,133:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 16:18:50,199:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:18:50,660:INFO:Creating Dashboard logs
2025-10-12 16:18:50,664:INFO:Model: Logistic Regression
2025-10-12 16:18:50,749:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 6951, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:18:51,237:INFO:Creating Dashboard logs
2025-10-12 16:18:51,240:INFO:Model: Ridge Classifier
2025-10-12 16:18:51,311:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 6951, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:18:51,794:INFO:Creating Dashboard logs
2025-10-12 16:18:51,796:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:18:51,871:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:18:52,348:INFO:Creating Dashboard logs
2025-10-12 16:18:52,351:INFO:Model: Extra Trees Classifier
2025-10-12 16:18:52,420:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6951, 'verbose': 0, 'warm_start': False}
2025-10-12 16:18:52,916:INFO:Creating Dashboard logs
2025-10-12 16:18:52,919:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:18:53,009:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 6951, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:18:53,524:INFO:Creating Dashboard logs
2025-10-12 16:18:53,526:INFO:Model: Random Forest Classifier
2025-10-12 16:18:53,590:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6951, 'verbose': 0, 'warm_start': False}
2025-10-12 16:18:54,069:INFO:Creating Dashboard logs
2025-10-12 16:18:54,073:INFO:Model: Naive Bayes
2025-10-12 16:18:54,143:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:18:54,601:INFO:Creating Dashboard logs
2025-10-12 16:18:54,604:INFO:Model: Decision Tree Classifier
2025-10-12 16:18:54,672:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 6951, 'splitter': 'best'}
2025-10-12 16:18:55,131:INFO:Creating Dashboard logs
2025-10-12 16:18:55,133:INFO:Model: K Neighbors Classifier
2025-10-12 16:18:55,199:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:18:55,654:INFO:Creating Dashboard logs
2025-10-12 16:18:55,657:INFO:Model: SVM - Linear Kernel
2025-10-12 16:18:55,723:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 6951, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:18:56,206:INFO:Creating Dashboard logs
2025-10-12 16:18:56,208:INFO:Model: Dummy Classifier
2025-10-12 16:18:56,284:INFO:Logged params: {'constant': None, 'random_state': 6951, 'strategy': 'prior'}
2025-10-12 16:18:56,714:INFO:_master_model_container: 16
2025-10-12 16:18:56,714:INFO:_display_container: 2
2025-10-12 16:18:56,715:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:18:56,715:INFO:compare_models() successfully completed......................................
2025-10-12 16:18:56,733:INFO:Initializing finalize_model()
2025-10-12 16:18:56,733:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-12 16:18:56,733:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:18:56,737:INFO:Initializing create_model()
2025-10-12 16:18:56,737:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:18:56,737:INFO:Checking exceptions
2025-10-12 16:18:56,738:INFO:Importing libraries
2025-10-12 16:18:56,739:INFO:Copying training dataset
2025-10-12 16:18:56,739:INFO:Defining folds
2025-10-12 16:18:56,739:INFO:Declaring metric variables
2025-10-12 16:18:56,739:INFO:Importing untrained model
2025-10-12 16:18:56,739:INFO:Declaring custom model
2025-10-12 16:18:56,740:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:18:56,740:INFO:Cross validation set to False
2025-10-12 16:18:56,740:INFO:Fitting Model
2025-10-12 16:18:56,843:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, incl...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=6951, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-10-12 16:18:56,843:INFO:create_model() successfully completed......................................
2025-10-12 16:18:57,017:INFO:Creating Dashboard logs
2025-10-12 16:18:57,018:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:18:57,091:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 6951, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:18:57,220:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:18:57,224:INFO:Initializing plot_model()
2025-10-12 16:18:57,224:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, incl...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=6951, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpbjd1fz5r, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:18:57,224:INFO:Checking exceptions
2025-10-12 16:18:57,226:INFO:Preloading libraries
2025-10-12 16:18:57,231:INFO:Copying training dataset
2025-10-12 16:18:57,231:INFO:Plot type: auc
2025-10-12 16:18:57,271:INFO:Fitting Model
2025-10-12 16:18:57,271:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:18:57,272:INFO:Scoring test/hold-out set
2025-10-12 16:18:57,287:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpbjd1fz5r\AUC.png'
2025-10-12 16:18:57,468:INFO:Visual Rendered Successfully
2025-10-12 16:18:57,630:INFO:plot_model() successfully completed......................................
2025-10-12 16:18:57,676:INFO:Initializing plot_model()
2025-10-12 16:18:57,676:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, incl...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=6951, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpbjd1fz5r, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:18:57,676:INFO:Checking exceptions
2025-10-12 16:18:57,678:INFO:Preloading libraries
2025-10-12 16:18:57,681:INFO:Copying training dataset
2025-10-12 16:18:57,681:INFO:Plot type: confusion_matrix
2025-10-12 16:18:57,721:INFO:Fitting Model
2025-10-12 16:18:57,721:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:18:57,721:INFO:Scoring test/hold-out set
2025-10-12 16:18:57,735:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpbjd1fz5r\Confusion Matrix.png'
2025-10-12 16:18:57,813:INFO:Visual Rendered Successfully
2025-10-12 16:18:57,974:INFO:plot_model() successfully completed......................................
2025-10-12 16:18:57,993:INFO:Initializing plot_model()
2025-10-12 16:18:57,993:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, incl...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=6951, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpbjd1fz5r, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:18:57,993:INFO:Checking exceptions
2025-10-12 16:18:57,995:INFO:Preloading libraries
2025-10-12 16:18:57,999:INFO:Copying training dataset
2025-10-12 16:18:57,999:INFO:Plot type: feature
2025-10-12 16:18:57,999:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:18:58,021:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpbjd1fz5r\Feature Importance.png'
2025-10-12 16:18:58,108:INFO:Visual Rendered Successfully
2025-10-12 16:18:58,268:INFO:plot_model() successfully completed......................................
2025-10-12 16:18:58,286:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:18:58,526:INFO:_master_model_container: 16
2025-10-12 16:18:58,526:INFO:_display_container: 2
2025-10-12 16:18:58,529:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, incl...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=6951, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-10-12 16:18:58,529:INFO:finalize_model() successfully completed......................................
2025-10-12 16:18:58,698:INFO:Initializing save_model()
2025-10-12 16:18:58,698:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, incl...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=6951, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=Titanic_modelV1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 16:18:58,698:INFO:Adding model into prep_pipe
2025-10-12 16:18:58,698:WARNING:Only Model saved as it was a pipeline.
2025-10-12 16:18:58,718:INFO:Titanic_modelV1.pkl saved in current working directory
2025-10-12 16:18:58,721:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, incl...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=6951, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-10-12 16:18:58,721:INFO:save_model() successfully completed......................................
2025-10-12 16:18:58,901:INFO:Initializing tune_model()
2025-10-12 16:18:58,901:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>)
2025-10-12 16:18:58,901:INFO:Checking exceptions
2025-10-12 16:18:58,914:INFO:Copying training dataset
2025-10-12 16:18:58,916:INFO:Checking base model
2025-10-12 16:18:58,916:INFO:Base model : Gradient Boosting Classifier
2025-10-12 16:18:58,919:INFO:Declaring metric variables
2025-10-12 16:18:58,922:INFO:Defining Hyperparameters
2025-10-12 16:18:59,081:INFO:Tuning with n_jobs=-1
2025-10-12 16:18:59,081:INFO:Initializing RandomizedSearchCV
2025-10-12 16:19:01,789:INFO:best_params: {'actual_estimator__subsample': 1.0, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.01}
2025-10-12 16:19:01,790:INFO:Hyperparameter search completed
2025-10-12 16:19:01,790:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:01,790:INFO:Initializing create_model()
2025-10-12 16:19:01,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DBD6C700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 1.0, 'n_estimators': 250, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.2, 'max_features': 'log2', 'max_depth': 10, 'learning_rate': 0.01})
2025-10-12 16:19:01,790:INFO:Checking exceptions
2025-10-12 16:19:01,790:INFO:Importing libraries
2025-10-12 16:19:01,791:INFO:Copying training dataset
2025-10-12 16:19:01,797:INFO:Defining folds
2025-10-12 16:19:01,797:INFO:Declaring metric variables
2025-10-12 16:19:01,804:INFO:Importing untrained model
2025-10-12 16:19:01,804:INFO:Declaring custom model
2025-10-12 16:19:01,810:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:19:01,820:INFO:Starting cross validation
2025-10-12 16:19:01,821:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:02,350:INFO:Calculating mean and std
2025-10-12 16:19:02,351:INFO:Creating metrics dataframe
2025-10-12 16:19:02,356:INFO:Finalizing model
2025-10-12 16:19:02,606:INFO:Uploading results into container
2025-10-12 16:19:02,606:INFO:Uploading model into container now
2025-10-12 16:19:02,607:INFO:_master_model_container: 17
2025-10-12 16:19:02,607:INFO:_display_container: 3
2025-10-12 16:19:02,607:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=10,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=5,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=250, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:19:02,608:INFO:create_model() successfully completed......................................
2025-10-12 16:19:02,778:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:02,779:INFO:choose_better activated
2025-10-12 16:19:02,781:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:02,781:INFO:Initializing create_model()
2025-10-12 16:19:02,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:02,783:INFO:Checking exceptions
2025-10-12 16:19:02,784:INFO:Importing libraries
2025-10-12 16:19:02,784:INFO:Copying training dataset
2025-10-12 16:19:02,787:INFO:Defining folds
2025-10-12 16:19:02,787:INFO:Declaring metric variables
2025-10-12 16:19:02,787:INFO:Importing untrained model
2025-10-12 16:19:02,787:INFO:Declaring custom model
2025-10-12 16:19:02,788:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:19:02,788:INFO:Starting cross validation
2025-10-12 16:19:02,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:03,004:INFO:Calculating mean and std
2025-10-12 16:19:03,004:INFO:Creating metrics dataframe
2025-10-12 16:19:03,006:INFO:Finalizing model
2025-10-12 16:19:03,091:INFO:Uploading results into container
2025-10-12 16:19:03,091:INFO:Uploading model into container now
2025-10-12 16:19:03,092:INFO:_master_model_container: 18
2025-10-12 16:19:03,092:INFO:_display_container: 4
2025-10-12 16:19:03,092:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:19:03,092:INFO:create_model() successfully completed......................................
2025-10-12 16:19:03,261:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:03,261:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8816
2025-10-12 16:19:03,262:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=10,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=5,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=250, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8755
2025-10-12 16:19:03,262:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-12 16:19:03,262:INFO:choose_better completed
2025-10-12 16:19:03,262:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-12 16:19:03,263:INFO:Creating Dashboard logs
2025-10-12 16:19:03,266:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:19:03,339:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 6951, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:19:03,623:INFO:Initializing predict_model()
2025-10-12 16:19:03,623:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DD9371F0>)
2025-10-12 16:19:03,623:INFO:Checking exceptions
2025-10-12 16:19:03,623:INFO:Preloading libraries
2025-10-12 16:19:03,884:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:19:03,885:INFO:Initializing plot_model()
2025-10-12 16:19:03,885:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpjfdh_bnn, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:03,885:INFO:Checking exceptions
2025-10-12 16:19:03,886:INFO:Preloading libraries
2025-10-12 16:19:03,892:INFO:Copying training dataset
2025-10-12 16:19:03,892:INFO:Plot type: auc
2025-10-12 16:19:03,934:INFO:Fitting Model
2025-10-12 16:19:03,934:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:19:03,934:INFO:Scoring test/hold-out set
2025-10-12 16:19:03,952:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpjfdh_bnn\AUC.png'
2025-10-12 16:19:04,136:INFO:Visual Rendered Successfully
2025-10-12 16:19:04,302:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:04,318:INFO:Initializing plot_model()
2025-10-12 16:19:04,318:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpjfdh_bnn, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:04,318:INFO:Checking exceptions
2025-10-12 16:19:04,320:INFO:Preloading libraries
2025-10-12 16:19:04,324:INFO:Copying training dataset
2025-10-12 16:19:04,325:INFO:Plot type: confusion_matrix
2025-10-12 16:19:04,370:INFO:Fitting Model
2025-10-12 16:19:04,371:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:19:04,371:INFO:Scoring test/hold-out set
2025-10-12 16:19:04,384:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpjfdh_bnn\Confusion Matrix.png'
2025-10-12 16:19:04,468:INFO:Visual Rendered Successfully
2025-10-12 16:19:04,635:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:04,657:INFO:Initializing plot_model()
2025-10-12 16:19:04,657:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpjfdh_bnn, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:04,657:INFO:Checking exceptions
2025-10-12 16:19:04,658:INFO:Preloading libraries
2025-10-12 16:19:04,664:INFO:Copying training dataset
2025-10-12 16:19:04,664:INFO:Plot type: feature
2025-10-12 16:19:04,664:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:19:04,689:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpjfdh_bnn\Feature Importance.png'
2025-10-12 16:19:04,778:INFO:Visual Rendered Successfully
2025-10-12 16:19:04,951:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:04,969:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:19:05,265:INFO:_master_model_container: 18
2025-10-12 16:19:05,265:INFO:_display_container: 3
2025-10-12 16:19:05,266:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:19:05,266:INFO:tune_model() successfully completed......................................
2025-10-12 16:19:05,455:INFO:Initializing tune_model()
2025-10-12 16:19:05,455:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>)
2025-10-12 16:19:05,456:INFO:Checking exceptions
2025-10-12 16:19:05,456:INFO:Soft dependency imported: optuna: 4.5.0
2025-10-12 16:19:05,471:INFO:Copying training dataset
2025-10-12 16:19:05,475:INFO:Checking base model
2025-10-12 16:19:05,475:INFO:Base model : Gradient Boosting Classifier
2025-10-12 16:19:05,480:INFO:Declaring metric variables
2025-10-12 16:19:05,484:INFO:Defining Hyperparameters
2025-10-12 16:19:05,678:INFO:Tuning with n_jobs=-1
2025-10-12 16:19:05,679:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.

2025-10-12 16:19:05,679:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.

2025-10-12 16:19:05,679:INFO:Initializing optuna.integration.OptunaSearchCV
2025-10-12 16:19:05,679:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.

2025-10-12 16:19:35,575:INFO:best_params: {'actual_estimator__n_estimators': 137, 'actual_estimator__learning_rate': 0.023548057466832556, 'actual_estimator__subsample': 0.6866338145323752, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__max_depth': 9, 'actual_estimator__min_impurity_decrease': 0.3461415719933991, 'actual_estimator__max_features': 0.6013946763596008}
2025-10-12 16:19:35,576:INFO:Hyperparameter search completed
2025-10-12 16:19:35,576:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:35,577:INFO:Initializing create_model()
2025-10-12 16:19:35,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E20FB220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 137, 'learning_rate': 0.023548057466832556, 'subsample': 0.6866338145323752, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_depth': 9, 'min_impurity_decrease': 0.3461415719933991, 'max_features': 0.6013946763596008})
2025-10-12 16:19:35,577:INFO:Checking exceptions
2025-10-12 16:19:35,577:INFO:Importing libraries
2025-10-12 16:19:35,577:INFO:Copying training dataset
2025-10-12 16:19:35,580:INFO:Defining folds
2025-10-12 16:19:35,580:INFO:Declaring metric variables
2025-10-12 16:19:35,584:INFO:Importing untrained model
2025-10-12 16:19:35,585:INFO:Declaring custom model
2025-10-12 16:19:35,591:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:19:35,601:INFO:Starting cross validation
2025-10-12 16:19:35,602:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:35,869:INFO:Calculating mean and std
2025-10-12 16:19:35,870:INFO:Creating metrics dataframe
2025-10-12 16:19:35,875:INFO:Finalizing model
2025-10-12 16:19:35,980:INFO:Uploading results into container
2025-10-12 16:19:35,980:INFO:Uploading model into container now
2025-10-12 16:19:35,981:INFO:_master_model_container: 19
2025-10-12 16:19:35,981:INFO:_display_container: 4
2025-10-12 16:19:35,981:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.023548057466832556, loss='log_loss',
                           max_depth=9, max_features=0.6013946763596008,
                           max_leaf_nodes=None,
                           min_impurity_decrease=0.3461415719933991,
                           min_samples_leaf=5, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=137,
                           n_iter_no_change=None, random_state=6951,
                           subsample=0.6866338145323752, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:19:35,981:INFO:create_model() successfully completed......................................
2025-10-12 16:19:36,147:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:36,147:INFO:choose_better activated
2025-10-12 16:19:36,151:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:36,151:INFO:Initializing create_model()
2025-10-12 16:19:36,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:36,151:INFO:Checking exceptions
2025-10-12 16:19:36,153:INFO:Importing libraries
2025-10-12 16:19:36,153:INFO:Copying training dataset
2025-10-12 16:19:36,155:INFO:Defining folds
2025-10-12 16:19:36,155:INFO:Declaring metric variables
2025-10-12 16:19:36,156:INFO:Importing untrained model
2025-10-12 16:19:36,156:INFO:Declaring custom model
2025-10-12 16:19:36,156:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:19:36,156:INFO:Starting cross validation
2025-10-12 16:19:36,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:36,370:INFO:Calculating mean and std
2025-10-12 16:19:36,370:INFO:Creating metrics dataframe
2025-10-12 16:19:36,371:INFO:Finalizing model
2025-10-12 16:19:36,455:INFO:Uploading results into container
2025-10-12 16:19:36,455:INFO:Uploading model into container now
2025-10-12 16:19:36,456:INFO:_master_model_container: 20
2025-10-12 16:19:36,456:INFO:_display_container: 5
2025-10-12 16:19:36,456:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:19:36,456:INFO:create_model() successfully completed......................................
2025-10-12 16:19:36,624:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:36,625:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8816
2025-10-12 16:19:36,625:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.023548057466832556, loss='log_loss',
                           max_depth=9, max_features=0.6013946763596008,
                           max_leaf_nodes=None,
                           min_impurity_decrease=0.3461415719933991,
                           min_samples_leaf=5, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=137,
                           n_iter_no_change=None, random_state=6951,
                           subsample=0.6866338145323752, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8765
2025-10-12 16:19:36,626:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-12 16:19:36,626:INFO:choose_better completed
2025-10-12 16:19:36,626:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-12 16:19:36,626:INFO:Creating Dashboard logs
2025-10-12 16:19:36,630:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:19:36,706:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 6951, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:19:36,977:INFO:Initializing predict_model()
2025-10-12 16:19:36,977:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E02AB430>)
2025-10-12 16:19:36,977:INFO:Checking exceptions
2025-10-12 16:19:36,977:INFO:Preloading libraries
2025-10-12 16:19:37,180:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:19:37,180:INFO:Initializing plot_model()
2025-10-12 16:19:37,180:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpuhnew204, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:37,180:INFO:Checking exceptions
2025-10-12 16:19:37,182:INFO:Preloading libraries
2025-10-12 16:19:37,185:INFO:Copying training dataset
2025-10-12 16:19:37,185:INFO:Plot type: auc
2025-10-12 16:19:37,226:INFO:Fitting Model
2025-10-12 16:19:37,227:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:19:37,227:INFO:Scoring test/hold-out set
2025-10-12 16:19:37,244:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpuhnew204\AUC.png'
2025-10-12 16:19:37,405:INFO:Visual Rendered Successfully
2025-10-12 16:19:37,569:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:37,586:INFO:Initializing plot_model()
2025-10-12 16:19:37,586:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpuhnew204, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:37,586:INFO:Checking exceptions
2025-10-12 16:19:37,587:INFO:Preloading libraries
2025-10-12 16:19:37,591:INFO:Copying training dataset
2025-10-12 16:19:37,591:INFO:Plot type: confusion_matrix
2025-10-12 16:19:37,631:INFO:Fitting Model
2025-10-12 16:19:37,631:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:19:37,632:INFO:Scoring test/hold-out set
2025-10-12 16:19:37,645:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpuhnew204\Confusion Matrix.png'
2025-10-12 16:19:37,751:INFO:Visual Rendered Successfully
2025-10-12 16:19:37,922:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:37,947:INFO:Initializing plot_model()
2025-10-12 16:19:37,947:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpuhnew204, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:37,947:INFO:Checking exceptions
2025-10-12 16:19:37,949:INFO:Preloading libraries
2025-10-12 16:19:37,953:INFO:Copying training dataset
2025-10-12 16:19:37,953:INFO:Plot type: feature
2025-10-12 16:19:37,953:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:19:37,977:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpuhnew204\Feature Importance.png'
2025-10-12 16:19:38,062:INFO:Visual Rendered Successfully
2025-10-12 16:19:38,244:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:38,259:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:19:38,524:INFO:_master_model_container: 20
2025-10-12 16:19:38,524:INFO:_display_container: 4
2025-10-12 16:19:38,524:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:19:38,524:INFO:tune_model() successfully completed......................................
2025-10-12 16:19:38,705:INFO:Initializing ensemble_model()
2025-10-12 16:19:38,705:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), method=Bagging, fold=None, n_estimators=5, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:19:38,705:INFO:Checking exceptions
2025-10-12 16:19:38,718:INFO:Importing libraries
2025-10-12 16:19:38,718:INFO:Copying training dataset
2025-10-12 16:19:38,718:INFO:Checking base model
2025-10-12 16:19:38,718:INFO:Base model : Gradient Boosting Classifier
2025-10-12 16:19:38,725:INFO:Importing untrained ensembler
2025-10-12 16:19:38,725:INFO:Ensemble method set to Bagging
2025-10-12 16:19:38,725:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:38,726:INFO:Initializing create_model()
2025-10-12 16:19:38,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=6951,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=6951, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E22F08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:38,727:INFO:Checking exceptions
2025-10-12 16:19:38,727:INFO:Importing libraries
2025-10-12 16:19:38,727:INFO:Copying training dataset
2025-10-12 16:19:38,730:INFO:Defining folds
2025-10-12 16:19:38,730:INFO:Declaring metric variables
2025-10-12 16:19:38,734:INFO:Importing untrained model
2025-10-12 16:19:38,734:INFO:Declaring custom model
2025-10-12 16:19:38,739:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:19:38,747:INFO:Starting cross validation
2025-10-12 16:19:38,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:39,533:INFO:Calculating mean and std
2025-10-12 16:19:39,533:INFO:Creating metrics dataframe
2025-10-12 16:19:39,537:INFO:Finalizing model
2025-10-12 16:19:39,937:INFO:Uploading results into container
2025-10-12 16:19:39,937:INFO:Uploading model into container now
2025-10-12 16:19:39,938:INFO:_master_model_container: 21
2025-10-12 16:19:39,938:INFO:_display_container: 5
2025-10-12 16:19:39,939:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=6951,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=6951, verbose=0,
                  warm_start=False)
2025-10-12 16:19:39,939:INFO:create_model() successfully completed......................................
2025-10-12 16:19:40,096:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:40,096:INFO:Creating Dashboard logs
2025-10-12 16:19:40,099:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:19:40,165:INFO:Logged params: {'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__criterion': 'friedman_mse', 'estimator__init': None, 'estimator__learning_rate': 0.1, 'estimator__loss': 'log_loss', 'estimator__max_depth': 3, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_iter_no_change': None, 'estimator__random_state': 6951, 'estimator__subsample': 1.0, 'estimator__tol': 0.0001, 'estimator__validation_fraction': 0.1, 'estimator__verbose': 0, 'estimator__warm_start': False, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 5, 'n_jobs': None, 'oob_score': False, 'random_state': 6951, 'verbose': 0, 'warm_start': False}
2025-10-12 16:19:40,471:INFO:Initializing predict_model()
2025-10-12 16:19:40,471:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=6951,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=6951, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DD937670>)
2025-10-12 16:19:40,471:INFO:Checking exceptions
2025-10-12 16:19:40,471:INFO:Preloading libraries
2025-10-12 16:19:40,684:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:19:40,685:INFO:Initializing plot_model()
2025-10-12 16:19:40,685:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=6951,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=6951, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpd5rxfn3x, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:40,685:INFO:Checking exceptions
2025-10-12 16:19:40,686:INFO:Preloading libraries
2025-10-12 16:19:40,707:INFO:Copying training dataset
2025-10-12 16:19:40,707:INFO:Plot type: auc
2025-10-12 16:19:40,748:INFO:Fitting Model
2025-10-12 16:19:40,748:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 16:19:40,748:INFO:Scoring test/hold-out set
2025-10-12 16:19:40,769:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpd5rxfn3x\AUC.png'
2025-10-12 16:19:40,926:INFO:Visual Rendered Successfully
2025-10-12 16:19:41,088:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:41,105:INFO:Initializing plot_model()
2025-10-12 16:19:41,105:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=6951,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=6951, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpd5rxfn3x, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:41,105:INFO:Checking exceptions
2025-10-12 16:19:41,106:INFO:Preloading libraries
2025-10-12 16:19:41,129:INFO:Copying training dataset
2025-10-12 16:19:41,129:INFO:Plot type: confusion_matrix
2025-10-12 16:19:41,172:INFO:Fitting Model
2025-10-12 16:19:41,172:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 16:19:41,172:INFO:Scoring test/hold-out set
2025-10-12 16:19:41,192:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpd5rxfn3x\Confusion Matrix.png'
2025-10-12 16:19:41,279:INFO:Visual Rendered Successfully
2025-10-12 16:19:41,447:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:41,472:INFO:Initializing plot_model()
2025-10-12 16:19:41,473:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=6951,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=6951, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpd5rxfn3x, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:41,473:INFO:Checking exceptions
2025-10-12 16:19:41,473:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 16:19:41,473:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:19:41,739:INFO:_master_model_container: 21
2025-10-12 16:19:41,739:INFO:_display_container: 5
2025-10-12 16:19:41,740:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=6951,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=6951, verbose=0,
                  warm_start=False)
2025-10-12 16:19:41,740:INFO:ensemble_model() successfully completed......................................
2025-10-12 16:19:41,903:INFO:Initializing predict_model()
2025-10-12 16:19:41,903:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=6951,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=6951, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E20D0F70>)
2025-10-12 16:19:41,903:INFO:Checking exceptions
2025-10-12 16:19:41,903:INFO:Preloading libraries
2025-10-12 16:19:42,134:INFO:Initializing create_model()
2025-10-12 16:19:42,135:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:42,135:INFO:Checking exceptions
2025-10-12 16:19:42,147:INFO:Importing libraries
2025-10-12 16:19:42,148:INFO:Copying training dataset
2025-10-12 16:19:42,151:INFO:Defining folds
2025-10-12 16:19:42,151:INFO:Declaring metric variables
2025-10-12 16:19:42,154:INFO:Importing untrained model
2025-10-12 16:19:42,158:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:19:42,162:INFO:Starting cross validation
2025-10-12 16:19:42,163:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:42,213:INFO:Calculating mean and std
2025-10-12 16:19:42,213:INFO:Creating metrics dataframe
2025-10-12 16:19:42,217:INFO:Finalizing model
2025-10-12 16:19:42,223:INFO:Creating Dashboard logs
2025-10-12 16:19:42,226:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:19:42,301:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:19:42,517:INFO:Initializing predict_model()
2025-10-12 16:19:42,517:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E023B9D0>)
2025-10-12 16:19:42,517:INFO:Checking exceptions
2025-10-12 16:19:42,517:INFO:Preloading libraries
2025-10-12 16:19:42,731:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:19:42,732:INFO:Initializing plot_model()
2025-10-12 16:19:42,732:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpy9w8l_o_, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:42,732:INFO:Checking exceptions
2025-10-12 16:19:42,733:INFO:Preloading libraries
2025-10-12 16:19:42,734:INFO:Copying training dataset
2025-10-12 16:19:42,734:INFO:Plot type: auc
2025-10-12 16:19:42,774:INFO:Fitting Model
2025-10-12 16:19:42,774:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:19:42,775:INFO:Scoring test/hold-out set
2025-10-12 16:19:42,788:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpy9w8l_o_\AUC.png'
2025-10-12 16:19:42,956:INFO:Visual Rendered Successfully
2025-10-12 16:19:43,131:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:43,150:INFO:Initializing plot_model()
2025-10-12 16:19:43,150:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpy9w8l_o_, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:43,150:INFO:Checking exceptions
2025-10-12 16:19:43,151:INFO:Preloading libraries
2025-10-12 16:19:43,151:INFO:Copying training dataset
2025-10-12 16:19:43,151:INFO:Plot type: confusion_matrix
2025-10-12 16:19:43,191:INFO:Fitting Model
2025-10-12 16:19:43,193:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:19:43,193:INFO:Scoring test/hold-out set
2025-10-12 16:19:43,205:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpy9w8l_o_\Confusion Matrix.png'
2025-10-12 16:19:43,304:INFO:Visual Rendered Successfully
2025-10-12 16:19:43,464:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:43,481:INFO:Initializing plot_model()
2025-10-12 16:19:43,482:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpy9w8l_o_, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:43,482:INFO:Checking exceptions
2025-10-12 16:19:43,483:INFO:Preloading libraries
2025-10-12 16:19:43,483:INFO:Copying training dataset
2025-10-12 16:19:43,483:INFO:Plot type: feature
2025-10-12 16:19:43,516:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpy9w8l_o_\Feature Importance.png'
2025-10-12 16:19:43,629:INFO:Visual Rendered Successfully
2025-10-12 16:19:43,802:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:43,816:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:19:44,063:INFO:Uploading results into container
2025-10-12 16:19:44,064:INFO:Uploading model into container now
2025-10-12 16:19:44,071:INFO:_master_model_container: 22
2025-10-12 16:19:44,071:INFO:_display_container: 7
2025-10-12 16:19:44,071:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:19:44,071:INFO:create_model() successfully completed......................................
2025-10-12 16:19:44,232:INFO:Initializing create_model()
2025-10-12 16:19:44,232:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=ridge, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:44,232:INFO:Checking exceptions
2025-10-12 16:19:44,243:INFO:Importing libraries
2025-10-12 16:19:44,243:INFO:Copying training dataset
2025-10-12 16:19:44,246:INFO:Defining folds
2025-10-12 16:19:44,247:INFO:Declaring metric variables
2025-10-12 16:19:44,249:INFO:Importing untrained model
2025-10-12 16:19:44,252:INFO:Ridge Classifier Imported successfully
2025-10-12 16:19:44,258:INFO:Starting cross validation
2025-10-12 16:19:44,259:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:44,310:INFO:Calculating mean and std
2025-10-12 16:19:44,310:INFO:Creating metrics dataframe
2025-10-12 16:19:44,315:INFO:Finalizing model
2025-10-12 16:19:44,321:INFO:Creating Dashboard logs
2025-10-12 16:19:44,325:INFO:Model: Ridge Classifier
2025-10-12 16:19:44,414:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 6951, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:19:44,642:INFO:Initializing predict_model()
2025-10-12 16:19:44,642:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E06AEA60>)
2025-10-12 16:19:44,642:INFO:Checking exceptions
2025-10-12 16:19:44,642:INFO:Preloading libraries
2025-10-12 16:19:44,852:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:19:44,852:INFO:Initializing plot_model()
2025-10-12 16:19:44,852:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp42n25h_5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:44,852:INFO:Checking exceptions
2025-10-12 16:19:44,852:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:19:44,852:INFO:Initializing plot_model()
2025-10-12 16:19:44,852:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp42n25h_5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:44,852:INFO:Checking exceptions
2025-10-12 16:19:44,854:INFO:Preloading libraries
2025-10-12 16:19:44,854:INFO:Copying training dataset
2025-10-12 16:19:44,855:INFO:Plot type: confusion_matrix
2025-10-12 16:19:44,895:INFO:Fitting Model
2025-10-12 16:19:44,895:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names

2025-10-12 16:19:44,895:INFO:Scoring test/hold-out set
2025-10-12 16:19:44,907:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp42n25h_5\Confusion Matrix.png'
2025-10-12 16:19:44,983:INFO:Visual Rendered Successfully
2025-10-12 16:19:45,146:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:45,162:INFO:Initializing plot_model()
2025-10-12 16:19:45,162:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp42n25h_5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:45,162:INFO:Checking exceptions
2025-10-12 16:19:45,163:INFO:Preloading libraries
2025-10-12 16:19:45,163:INFO:Copying training dataset
2025-10-12 16:19:45,163:INFO:Plot type: feature
2025-10-12 16:19:45,195:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp42n25h_5\Feature Importance.png'
2025-10-12 16:19:45,284:INFO:Visual Rendered Successfully
2025-10-12 16:19:45,460:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:45,483:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:19:45,739:INFO:Uploading results into container
2025-10-12 16:19:45,740:INFO:Uploading model into container now
2025-10-12 16:19:45,747:INFO:_master_model_container: 23
2025-10-12 16:19:45,748:INFO:_display_container: 8
2025-10-12 16:19:45,748:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001)
2025-10-12 16:19:45,748:INFO:create_model() successfully completed......................................
2025-10-12 16:19:45,912:INFO:Initializing create_model()
2025-10-12 16:19:45,912:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:45,912:INFO:Checking exceptions
2025-10-12 16:19:45,921:INFO:Importing libraries
2025-10-12 16:19:45,921:INFO:Copying training dataset
2025-10-12 16:19:45,926:INFO:Defining folds
2025-10-12 16:19:45,926:INFO:Declaring metric variables
2025-10-12 16:19:45,928:INFO:Importing untrained model
2025-10-12 16:19:45,931:INFO:Logistic Regression Imported successfully
2025-10-12 16:19:45,937:INFO:Starting cross validation
2025-10-12 16:19:45,938:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:46,016:INFO:Calculating mean and std
2025-10-12 16:19:46,017:INFO:Creating metrics dataframe
2025-10-12 16:19:46,021:INFO:Finalizing model
2025-10-12 16:19:46,032:INFO:Creating Dashboard logs
2025-10-12 16:19:46,036:INFO:Model: Logistic Regression
2025-10-12 16:19:46,105:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 6951, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:19:46,328:INFO:Initializing predict_model()
2025-10-12 16:19:46,328:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6951, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E25C71F0>)
2025-10-12 16:19:46,328:INFO:Checking exceptions
2025-10-12 16:19:46,328:INFO:Preloading libraries
2025-10-12 16:19:46,551:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:19:46,551:INFO:Initializing plot_model()
2025-10-12 16:19:46,551:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6951, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp1gcf09e4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:46,552:INFO:Checking exceptions
2025-10-12 16:19:46,553:INFO:Preloading libraries
2025-10-12 16:19:46,553:INFO:Copying training dataset
2025-10-12 16:19:46,553:INFO:Plot type: auc
2025-10-12 16:19:46,598:INFO:Fitting Model
2025-10-12 16:19:46,599:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:19:46,599:INFO:Scoring test/hold-out set
2025-10-12 16:19:46,613:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp1gcf09e4\AUC.png'
2025-10-12 16:19:46,778:INFO:Visual Rendered Successfully
2025-10-12 16:19:46,955:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:46,974:INFO:Initializing plot_model()
2025-10-12 16:19:46,974:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6951, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp1gcf09e4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:46,974:INFO:Checking exceptions
2025-10-12 16:19:46,975:INFO:Preloading libraries
2025-10-12 16:19:46,975:INFO:Copying training dataset
2025-10-12 16:19:46,975:INFO:Plot type: confusion_matrix
2025-10-12 16:19:47,017:INFO:Fitting Model
2025-10-12 16:19:47,017:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names

2025-10-12 16:19:47,018:INFO:Scoring test/hold-out set
2025-10-12 16:19:47,031:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp1gcf09e4\Confusion Matrix.png'
2025-10-12 16:19:47,117:INFO:Visual Rendered Successfully
2025-10-12 16:19:47,289:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:47,309:INFO:Initializing plot_model()
2025-10-12 16:19:47,309:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6951, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp1gcf09e4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:47,309:INFO:Checking exceptions
2025-10-12 16:19:47,311:INFO:Preloading libraries
2025-10-12 16:19:47,311:INFO:Copying training dataset
2025-10-12 16:19:47,311:INFO:Plot type: feature
2025-10-12 16:19:47,343:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp1gcf09e4\Feature Importance.png'
2025-10-12 16:19:47,431:INFO:Visual Rendered Successfully
2025-10-12 16:19:47,593:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:47,608:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:19:47,855:INFO:Uploading results into container
2025-10-12 16:19:47,856:INFO:Uploading model into container now
2025-10-12 16:19:47,863:INFO:_master_model_container: 24
2025-10-12 16:19:47,863:INFO:_display_container: 9
2025-10-12 16:19:47,864:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6951, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:19:47,864:INFO:create_model() successfully completed......................................
2025-10-12 16:19:48,038:INFO:Initializing blend_models()
2025-10-12 16:19:48,038:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6951, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:19:48,038:INFO:Checking exceptions
2025-10-12 16:19:48,038:INFO:Estimator RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-12 16:19:48,050:INFO:Importing libraries
2025-10-12 16:19:48,051:INFO:Copying training dataset
2025-10-12 16:19:48,054:INFO:Getting model names
2025-10-12 16:19:48,058:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:48,061:INFO:Initializing create_model()
2025-10-12 16:19:48,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              random_state=6951, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6951,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DD823280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:48,061:INFO:Checking exceptions
2025-10-12 16:19:48,061:INFO:Importing libraries
2025-10-12 16:19:48,061:INFO:Copying training dataset
2025-10-12 16:19:48,065:INFO:Defining folds
2025-10-12 16:19:48,065:INFO:Declaring metric variables
2025-10-12 16:19:48,068:INFO:Importing untrained model
2025-10-12 16:19:48,068:INFO:Declaring custom model
2025-10-12 16:19:48,072:INFO:Voting Classifier Imported successfully
2025-10-12 16:19:48,080:INFO:Starting cross validation
2025-10-12 16:19:48,080:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:48,304:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:19:48,304:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:19:48,304:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:19:48,304:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:19:48,305:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:19:48,306:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:19:48,319:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:19:48,331:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:19:48,331:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:19:48,333:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:19:48,351:INFO:Calculating mean and std
2025-10-12 16:19:48,351:INFO:Creating metrics dataframe
2025-10-12 16:19:48,355:INFO:Finalizing model
2025-10-12 16:19:48,447:INFO:Uploading results into container
2025-10-12 16:19:48,448:INFO:Uploading model into container now
2025-10-12 16:19:48,448:INFO:_master_model_container: 25
2025-10-12 16:19:48,448:INFO:_display_container: 10
2025-10-12 16:19:48,451:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              random_state=6951, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6951,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:19:48,451:INFO:create_model() successfully completed......................................
2025-10-12 16:19:48,617:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:48,617:INFO:Creating Dashboard logs
2025-10-12 16:19:48,620:INFO:Model: Voting Classifier
2025-10-12 16:19:48,701:INFO:Logged params: {'flatten_transform': True, 'n_jobs': -1, 'verbose': False, 'voting': 'hard', 'weights': None, 'Linear Discriminant Analysis': LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), 'Ridge Classifier': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001), 'Gradient Boosting Classifier__ccp_alpha': 0.0, 'Gradient Boosting Classifier__criterion': 'friedman_mse', 'Gradient Boosting Classifier__init': None, 'Gradient Boosting Classifier__learning_rate': 0.1, 'Gradient Boosting Classifier__loss': 'log_loss', 'Gradient Boosting Classifier__max_depth': 3, 'Gradient Boosting Classifier__max_features': None, 'Gradient Boosting Classifier__max_leaf_nodes': None, 'Gradient Boosting Classifier__min_impurity_decrease': 0.0, 'Gradient Boosting Classifier__min_samples_leaf': 1, 'Gradient Boosting Classifier__min_samples_split': 2, 'Gradient Boosting Classifier__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Classifier__n_estimators': 100, 'Gradient Boosting Classifier__n_iter_no_change': None, 'Gradient Boosting Classifier__random_state': 6951, 'Gradient Boosting Classifier__subsample': 1.0, 'Gradient Boosting Classifier__tol': 0.0001, 'Gradient Boosting Classifier__validation_fraction': 0.1, 'Gradient Boosting Classifier__verbose': 0, 'Gradient Boosting Classifier__warm_start': False, 'Linear Discriminant Analysis__covariance_estimator': None, 'Linear Discriminant Analysis__n_components': None, 'Linear Discriminant Analysis__priors': None, 'Linear Discriminant Analysis__shrinkage': None, 'Linear Discriminant Analysis__solver': 'svd', 'Linear Discriminant Analysis__store_covariance': False, 'Linear Discriminant Analysis__tol': 0.0001, 'Ridge Classifier__alpha': 1.0, 'Ridge Classifier__class_weight': None, 'Ridge Classifier__copy_X': True, 'Ridge Classifier__fit_intercept': True, 'Ridge Classifier__max_iter': None, 'Ridge Classifier__positive': False, 'Ridge Classifier__random_state': 6951, 'Ridge Classifier__solver': 'auto', 'Ridge Classifier__tol': 0.0001, 'Logistic Regression__C': 1.0, 'Logistic Regression__class_weight': None, 'Logistic Regression__dual': False, 'Logistic Regression__fit_intercept': True, 'Logistic Regression__intercept_scaling': 1, 'Logistic Regression__l1_ratio': None, 'Logistic Regression__max_iter': 1000, 'Logistic Regression__multi_class': 'auto', 'Logistic Regression__n_jobs': None, 'Logistic Regression__penalty': 'l2', 'Logistic Regression__random_state': 6951, 'Logistic Regression__solver': 'lbfgs', 'Logistic Regression__tol': 0.0001, 'Logistic Regression__verbose': 0, 'Logistic Regression__warm_start': False}
2025-10-12 16:19:49,056:INFO:Initializing predict_model()
2025-10-12 16:19:49,056:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              random_state=6951, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6951,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E2A19A60>)
2025-10-12 16:19:49,056:INFO:Checking exceptions
2025-10-12 16:19:49,056:INFO:Preloading libraries
2025-10-12 16:19:49,283:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:19:49,286:INFO:Initializing plot_model()
2025-10-12 16:19:49,286:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              random_state=6951, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6951,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpk_7ss7na, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:49,286:INFO:Checking exceptions
2025-10-12 16:19:49,287:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:19:49,289:INFO:Initializing plot_model()
2025-10-12 16:19:49,289:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              random_state=6951, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6951,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpk_7ss7na, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:49,289:INFO:Checking exceptions
2025-10-12 16:19:49,291:INFO:Preloading libraries
2025-10-12 16:19:49,296:INFO:Copying training dataset
2025-10-12 16:19:49,296:INFO:Plot type: confusion_matrix
2025-10-12 16:19:49,336:INFO:Fitting Model
2025-10-12 16:19:49,336:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:19:49,337:INFO:Scoring test/hold-out set
2025-10-12 16:19:49,360:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpk_7ss7na\Confusion Matrix.png'
2025-10-12 16:19:49,434:INFO:Visual Rendered Successfully
2025-10-12 16:19:49,594:INFO:plot_model() successfully completed......................................
2025-10-12 16:19:49,615:INFO:Initializing plot_model()
2025-10-12 16:19:49,615:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              random_state=6951, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6951,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpk_7ss7na, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:19:49,615:INFO:Checking exceptions
2025-10-12 16:19:49,615:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 16:19:49,616:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:19:49,870:INFO:_master_model_container: 25
2025-10-12 16:19:49,870:INFO:_display_container: 10
2025-10-12 16:19:49,872:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              random_state=6951, solver='auto',
                                              tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6951,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:19:49,872:INFO:blend_models() successfully completed......................................
2025-10-12 16:19:50,042:INFO:Initializing compare_models()
2025-10-12 16:19:50,042:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:19:50,042:INFO:Checking exceptions
2025-10-12 16:19:50,043:INFO:Preparing display monitor
2025-10-12 16:19:50,060:INFO:Initializing Logistic Regression
2025-10-12 16:19:50,060:INFO:Total runtime is 0.0 minutes
2025-10-12 16:19:50,062:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:50,062:INFO:Initializing create_model()
2025-10-12 16:19:50,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:50,063:INFO:Checking exceptions
2025-10-12 16:19:50,063:INFO:Importing libraries
2025-10-12 16:19:50,063:INFO:Copying training dataset
2025-10-12 16:19:50,066:INFO:Defining folds
2025-10-12 16:19:50,067:INFO:Declaring metric variables
2025-10-12 16:19:50,070:INFO:Importing untrained model
2025-10-12 16:19:50,073:INFO:Logistic Regression Imported successfully
2025-10-12 16:19:50,081:INFO:Starting cross validation
2025-10-12 16:19:50,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:50,162:INFO:Calculating mean and std
2025-10-12 16:19:50,162:INFO:Creating metrics dataframe
2025-10-12 16:19:50,164:INFO:Uploading results into container
2025-10-12 16:19:50,164:INFO:Uploading model into container now
2025-10-12 16:19:50,165:INFO:_master_model_container: 26
2025-10-12 16:19:50,165:INFO:_display_container: 11
2025-10-12 16:19:50,165:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6951, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:19:50,165:INFO:create_model() successfully completed......................................
2025-10-12 16:19:50,328:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:50,329:INFO:Creating metrics dataframe
2025-10-12 16:19:50,333:INFO:Initializing K Neighbors Classifier
2025-10-12 16:19:50,333:INFO:Total runtime is 0.004554975032806397 minutes
2025-10-12 16:19:50,336:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:50,336:INFO:Initializing create_model()
2025-10-12 16:19:50,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:50,336:INFO:Checking exceptions
2025-10-12 16:19:50,336:INFO:Importing libraries
2025-10-12 16:19:50,336:INFO:Copying training dataset
2025-10-12 16:19:50,338:INFO:Defining folds
2025-10-12 16:19:50,338:INFO:Declaring metric variables
2025-10-12 16:19:50,341:INFO:Importing untrained model
2025-10-12 16:19:50,343:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:19:50,348:INFO:Starting cross validation
2025-10-12 16:19:50,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:50,471:INFO:Calculating mean and std
2025-10-12 16:19:50,472:INFO:Creating metrics dataframe
2025-10-12 16:19:50,474:INFO:Uploading results into container
2025-10-12 16:19:50,474:INFO:Uploading model into container now
2025-10-12 16:19:50,474:INFO:_master_model_container: 27
2025-10-12 16:19:50,474:INFO:_display_container: 11
2025-10-12 16:19:50,474:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:19:50,474:INFO:create_model() successfully completed......................................
2025-10-12 16:19:50,639:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:50,639:INFO:Creating metrics dataframe
2025-10-12 16:19:50,646:INFO:Initializing Naive Bayes
2025-10-12 16:19:50,646:INFO:Total runtime is 0.00976095199584961 minutes
2025-10-12 16:19:50,649:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:50,649:INFO:Initializing create_model()
2025-10-12 16:19:50,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:50,650:INFO:Checking exceptions
2025-10-12 16:19:50,650:INFO:Importing libraries
2025-10-12 16:19:50,650:INFO:Copying training dataset
2025-10-12 16:19:50,652:INFO:Defining folds
2025-10-12 16:19:50,652:INFO:Declaring metric variables
2025-10-12 16:19:50,654:INFO:Importing untrained model
2025-10-12 16:19:50,656:INFO:Naive Bayes Imported successfully
2025-10-12 16:19:50,663:INFO:Starting cross validation
2025-10-12 16:19:50,664:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:50,719:INFO:Calculating mean and std
2025-10-12 16:19:50,719:INFO:Creating metrics dataframe
2025-10-12 16:19:50,721:INFO:Uploading results into container
2025-10-12 16:19:50,721:INFO:Uploading model into container now
2025-10-12 16:19:50,721:INFO:_master_model_container: 28
2025-10-12 16:19:50,721:INFO:_display_container: 11
2025-10-12 16:19:50,722:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:19:50,722:INFO:create_model() successfully completed......................................
2025-10-12 16:19:50,887:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:50,887:INFO:Creating metrics dataframe
2025-10-12 16:19:50,894:INFO:Initializing Decision Tree Classifier
2025-10-12 16:19:50,894:INFO:Total runtime is 0.013899004459381104 minutes
2025-10-12 16:19:50,897:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:50,897:INFO:Initializing create_model()
2025-10-12 16:19:50,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:50,898:INFO:Checking exceptions
2025-10-12 16:19:50,898:INFO:Importing libraries
2025-10-12 16:19:50,898:INFO:Copying training dataset
2025-10-12 16:19:50,900:INFO:Defining folds
2025-10-12 16:19:50,900:INFO:Declaring metric variables
2025-10-12 16:19:50,903:INFO:Importing untrained model
2025-10-12 16:19:50,907:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:19:50,913:INFO:Starting cross validation
2025-10-12 16:19:50,914:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:50,982:INFO:Calculating mean and std
2025-10-12 16:19:50,982:INFO:Creating metrics dataframe
2025-10-12 16:19:50,984:INFO:Uploading results into container
2025-10-12 16:19:50,984:INFO:Uploading model into container now
2025-10-12 16:19:50,984:INFO:_master_model_container: 29
2025-10-12 16:19:50,984:INFO:_display_container: 11
2025-10-12 16:19:50,985:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6951, splitter='best')
2025-10-12 16:19:50,985:INFO:create_model() successfully completed......................................
2025-10-12 16:19:51,174:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:51,174:INFO:Creating metrics dataframe
2025-10-12 16:19:51,180:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:19:51,180:INFO:Total runtime is 0.018666104475657145 minutes
2025-10-12 16:19:51,183:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:51,183:INFO:Initializing create_model()
2025-10-12 16:19:51,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:51,183:INFO:Checking exceptions
2025-10-12 16:19:51,183:INFO:Importing libraries
2025-10-12 16:19:51,183:INFO:Copying training dataset
2025-10-12 16:19:51,187:INFO:Defining folds
2025-10-12 16:19:51,187:INFO:Declaring metric variables
2025-10-12 16:19:51,190:INFO:Importing untrained model
2025-10-12 16:19:51,195:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:19:51,202:INFO:Starting cross validation
2025-10-12 16:19:51,204:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:51,251:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:19:51,251:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:19:51,262:INFO:Calculating mean and std
2025-10-12 16:19:51,262:INFO:Creating metrics dataframe
2025-10-12 16:19:51,264:INFO:Uploading results into container
2025-10-12 16:19:51,264:INFO:Uploading model into container now
2025-10-12 16:19:51,265:INFO:_master_model_container: 30
2025-10-12 16:19:51,265:INFO:_display_container: 11
2025-10-12 16:19:51,265:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6951, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:19:51,265:INFO:create_model() successfully completed......................................
2025-10-12 16:19:51,436:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:51,436:INFO:Creating metrics dataframe
2025-10-12 16:19:51,441:INFO:Initializing Ridge Classifier
2025-10-12 16:19:51,442:INFO:Total runtime is 0.023042774200439452 minutes
2025-10-12 16:19:51,445:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:51,445:INFO:Initializing create_model()
2025-10-12 16:19:51,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:51,445:INFO:Checking exceptions
2025-10-12 16:19:51,445:INFO:Importing libraries
2025-10-12 16:19:51,445:INFO:Copying training dataset
2025-10-12 16:19:51,448:INFO:Defining folds
2025-10-12 16:19:51,448:INFO:Declaring metric variables
2025-10-12 16:19:51,451:INFO:Importing untrained model
2025-10-12 16:19:51,455:INFO:Ridge Classifier Imported successfully
2025-10-12 16:19:51,462:INFO:Starting cross validation
2025-10-12 16:19:51,463:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:51,528:INFO:Calculating mean and std
2025-10-12 16:19:51,528:INFO:Creating metrics dataframe
2025-10-12 16:19:51,530:INFO:Uploading results into container
2025-10-12 16:19:51,530:INFO:Uploading model into container now
2025-10-12 16:19:51,531:INFO:_master_model_container: 31
2025-10-12 16:19:51,531:INFO:_display_container: 11
2025-10-12 16:19:51,531:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001)
2025-10-12 16:19:51,531:INFO:create_model() successfully completed......................................
2025-10-12 16:19:51,706:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:51,706:INFO:Creating metrics dataframe
2025-10-12 16:19:51,714:INFO:Initializing Random Forest Classifier
2025-10-12 16:19:51,714:INFO:Total runtime is 0.02756680647532145 minutes
2025-10-12 16:19:51,716:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:51,717:INFO:Initializing create_model()
2025-10-12 16:19:51,717:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:51,717:INFO:Checking exceptions
2025-10-12 16:19:51,717:INFO:Importing libraries
2025-10-12 16:19:51,717:INFO:Copying training dataset
2025-10-12 16:19:51,720:INFO:Defining folds
2025-10-12 16:19:51,720:INFO:Declaring metric variables
2025-10-12 16:19:51,723:INFO:Importing untrained model
2025-10-12 16:19:51,726:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:19:51,731:INFO:Starting cross validation
2025-10-12 16:19:51,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:52,102:INFO:Calculating mean and std
2025-10-12 16:19:52,104:INFO:Creating metrics dataframe
2025-10-12 16:19:52,105:INFO:Uploading results into container
2025-10-12 16:19:52,106:INFO:Uploading model into container now
2025-10-12 16:19:52,106:INFO:_master_model_container: 32
2025-10-12 16:19:52,106:INFO:_display_container: 11
2025-10-12 16:19:52,107:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6951, verbose=0,
                       warm_start=False)
2025-10-12 16:19:52,107:INFO:create_model() successfully completed......................................
2025-10-12 16:19:52,284:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:52,284:INFO:Creating metrics dataframe
2025-10-12 16:19:52,292:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:19:52,292:INFO:Total runtime is 0.03719675938288371 minutes
2025-10-12 16:19:52,295:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:52,295:INFO:Initializing create_model()
2025-10-12 16:19:52,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:52,295:INFO:Checking exceptions
2025-10-12 16:19:52,296:INFO:Importing libraries
2025-10-12 16:19:52,296:INFO:Copying training dataset
2025-10-12 16:19:52,300:INFO:Defining folds
2025-10-12 16:19:52,300:INFO:Declaring metric variables
2025-10-12 16:19:52,305:INFO:Importing untrained model
2025-10-12 16:19:52,308:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:19:52,318:INFO:Starting cross validation
2025-10-12 16:19:52,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:52,395:INFO:Calculating mean and std
2025-10-12 16:19:52,396:INFO:Creating metrics dataframe
2025-10-12 16:19:52,397:INFO:Uploading results into container
2025-10-12 16:19:52,398:INFO:Uploading model into container now
2025-10-12 16:19:52,398:INFO:_master_model_container: 33
2025-10-12 16:19:52,398:INFO:_display_container: 11
2025-10-12 16:19:52,398:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:19:52,398:INFO:create_model() successfully completed......................................
2025-10-12 16:19:52,578:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:52,578:INFO:Creating metrics dataframe
2025-10-12 16:19:52,585:INFO:Initializing Ada Boost Classifier
2025-10-12 16:19:52,585:INFO:Total runtime is 0.04208724896113078 minutes
2025-10-12 16:19:52,588:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:52,588:INFO:Initializing create_model()
2025-10-12 16:19:52,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:52,589:INFO:Checking exceptions
2025-10-12 16:19:52,589:INFO:Importing libraries
2025-10-12 16:19:52,589:INFO:Copying training dataset
2025-10-12 16:19:52,591:INFO:Defining folds
2025-10-12 16:19:52,592:INFO:Declaring metric variables
2025-10-12 16:19:52,594:INFO:Importing untrained model
2025-10-12 16:19:52,598:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:19:52,603:INFO:Starting cross validation
2025-10-12 16:19:52,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:52,620:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:19:52,623:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:19:52,624:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:19:52,626:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:19:52,628:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:19:52,629:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:19:52,632:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:19:52,634:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:19:52,636:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:19:52,638:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:19:52,799:INFO:Calculating mean and std
2025-10-12 16:19:52,800:INFO:Creating metrics dataframe
2025-10-12 16:19:52,803:INFO:Uploading results into container
2025-10-12 16:19:52,803:INFO:Uploading model into container now
2025-10-12 16:19:52,803:INFO:_master_model_container: 34
2025-10-12 16:19:52,803:INFO:_display_container: 11
2025-10-12 16:19:52,804:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6951)
2025-10-12 16:19:52,804:INFO:create_model() successfully completed......................................
2025-10-12 16:19:52,969:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:52,970:INFO:Creating metrics dataframe
2025-10-12 16:19:52,975:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:19:52,976:INFO:Total runtime is 0.04860521952311198 minutes
2025-10-12 16:19:52,978:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:52,979:INFO:Initializing create_model()
2025-10-12 16:19:52,979:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:52,979:INFO:Checking exceptions
2025-10-12 16:19:52,979:INFO:Importing libraries
2025-10-12 16:19:52,979:INFO:Copying training dataset
2025-10-12 16:19:52,983:INFO:Defining folds
2025-10-12 16:19:52,983:INFO:Declaring metric variables
2025-10-12 16:19:52,985:INFO:Importing untrained model
2025-10-12 16:19:52,988:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:19:52,995:INFO:Starting cross validation
2025-10-12 16:19:52,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:53,201:INFO:Calculating mean and std
2025-10-12 16:19:53,202:INFO:Creating metrics dataframe
2025-10-12 16:19:53,204:INFO:Uploading results into container
2025-10-12 16:19:53,204:INFO:Uploading model into container now
2025-10-12 16:19:53,205:INFO:_master_model_container: 35
2025-10-12 16:19:53,205:INFO:_display_container: 11
2025-10-12 16:19:53,205:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:19:53,205:INFO:create_model() successfully completed......................................
2025-10-12 16:19:53,368:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:53,368:INFO:Creating metrics dataframe
2025-10-12 16:19:53,375:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:19:53,375:INFO:Total runtime is 0.05525870720545451 minutes
2025-10-12 16:19:53,377:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:53,378:INFO:Initializing create_model()
2025-10-12 16:19:53,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:53,378:INFO:Checking exceptions
2025-10-12 16:19:53,378:INFO:Importing libraries
2025-10-12 16:19:53,378:INFO:Copying training dataset
2025-10-12 16:19:53,381:INFO:Defining folds
2025-10-12 16:19:53,381:INFO:Declaring metric variables
2025-10-12 16:19:53,385:INFO:Importing untrained model
2025-10-12 16:19:53,387:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:19:53,393:INFO:Starting cross validation
2025-10-12 16:19:53,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:53,452:INFO:Calculating mean and std
2025-10-12 16:19:53,452:INFO:Creating metrics dataframe
2025-10-12 16:19:53,454:INFO:Uploading results into container
2025-10-12 16:19:53,455:INFO:Uploading model into container now
2025-10-12 16:19:53,455:INFO:_master_model_container: 36
2025-10-12 16:19:53,455:INFO:_display_container: 11
2025-10-12 16:19:53,455:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:19:53,455:INFO:create_model() successfully completed......................................
2025-10-12 16:19:53,617:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:53,617:INFO:Creating metrics dataframe
2025-10-12 16:19:53,624:INFO:Initializing Extra Trees Classifier
2025-10-12 16:19:53,624:INFO:Total runtime is 0.059396950403849284 minutes
2025-10-12 16:19:53,627:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:53,627:INFO:Initializing create_model()
2025-10-12 16:19:53,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:53,628:INFO:Checking exceptions
2025-10-12 16:19:53,628:INFO:Importing libraries
2025-10-12 16:19:53,628:INFO:Copying training dataset
2025-10-12 16:19:53,630:INFO:Defining folds
2025-10-12 16:19:53,631:INFO:Declaring metric variables
2025-10-12 16:19:53,635:INFO:Importing untrained model
2025-10-12 16:19:53,637:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:19:53,644:INFO:Starting cross validation
2025-10-12 16:19:53,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:53,934:INFO:Calculating mean and std
2025-10-12 16:19:53,935:INFO:Creating metrics dataframe
2025-10-12 16:19:53,937:INFO:Uploading results into container
2025-10-12 16:19:53,937:INFO:Uploading model into container now
2025-10-12 16:19:53,938:INFO:_master_model_container: 37
2025-10-12 16:19:53,938:INFO:_display_container: 11
2025-10-12 16:19:53,938:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6951, verbose=0,
                     warm_start=False)
2025-10-12 16:19:53,938:INFO:create_model() successfully completed......................................
2025-10-12 16:19:54,114:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:54,114:INFO:Creating metrics dataframe
2025-10-12 16:19:54,121:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:19:54,121:INFO:Total runtime is 0.06768964529037476 minutes
2025-10-12 16:19:54,124:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:54,124:INFO:Initializing create_model()
2025-10-12 16:19:54,124:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:54,124:INFO:Checking exceptions
2025-10-12 16:19:54,124:INFO:Importing libraries
2025-10-12 16:19:54,124:INFO:Copying training dataset
2025-10-12 16:19:54,127:INFO:Defining folds
2025-10-12 16:19:54,127:INFO:Declaring metric variables
2025-10-12 16:19:54,130:INFO:Importing untrained model
2025-10-12 16:19:54,134:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:19:54,139:INFO:Starting cross validation
2025-10-12 16:19:54,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:54,553:INFO:Calculating mean and std
2025-10-12 16:19:54,554:INFO:Creating metrics dataframe
2025-10-12 16:19:54,555:INFO:Uploading results into container
2025-10-12 16:19:54,555:INFO:Uploading model into container now
2025-10-12 16:19:54,556:INFO:_master_model_container: 38
2025-10-12 16:19:54,556:INFO:_display_container: 11
2025-10-12 16:19:54,556:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:19:54,556:INFO:create_model() successfully completed......................................
2025-10-12 16:19:54,716:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:54,717:INFO:Creating metrics dataframe
2025-10-12 16:19:54,724:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:19:54,724:INFO:Total runtime is 0.07772932052612305 minutes
2025-10-12 16:19:54,726:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:54,727:INFO:Initializing create_model()
2025-10-12 16:19:54,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:54,727:INFO:Checking exceptions
2025-10-12 16:19:54,727:INFO:Importing libraries
2025-10-12 16:19:54,727:INFO:Copying training dataset
2025-10-12 16:19:54,730:INFO:Defining folds
2025-10-12 16:19:54,730:INFO:Declaring metric variables
2025-10-12 16:19:54,734:INFO:Importing untrained model
2025-10-12 16:19:54,736:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:19:54,741:INFO:Starting cross validation
2025-10-12 16:19:54,742:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:19:56,461:INFO:Calculating mean and std
2025-10-12 16:19:56,462:INFO:Creating metrics dataframe
2025-10-12 16:19:56,465:INFO:Uploading results into container
2025-10-12 16:19:56,465:INFO:Uploading model into container now
2025-10-12 16:19:56,467:INFO:_master_model_container: 39
2025-10-12 16:19:56,467:INFO:_display_container: 11
2025-10-12 16:19:56,468:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6951, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:19:56,468:INFO:create_model() successfully completed......................................
2025-10-12 16:19:56,651:INFO:SubProcess create_model() end ==================================
2025-10-12 16:19:56,651:INFO:Creating metrics dataframe
2025-10-12 16:19:56,659:INFO:Initializing CatBoost Classifier
2025-10-12 16:19:56,659:INFO:Total runtime is 0.10998355150222779 minutes
2025-10-12 16:19:56,662:INFO:SubProcess create_model() called ==================================
2025-10-12 16:19:56,662:INFO:Initializing create_model()
2025-10-12 16:19:56,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:19:56,662:INFO:Checking exceptions
2025-10-12 16:19:56,662:INFO:Importing libraries
2025-10-12 16:19:56,662:INFO:Copying training dataset
2025-10-12 16:19:56,665:INFO:Defining folds
2025-10-12 16:19:56,665:INFO:Declaring metric variables
2025-10-12 16:19:56,669:INFO:Importing untrained model
2025-10-12 16:19:56,671:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:19:56,677:INFO:Starting cross validation
2025-10-12 16:19:56,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:20:00,758:INFO:Calculating mean and std
2025-10-12 16:20:00,759:INFO:Creating metrics dataframe
2025-10-12 16:20:00,761:INFO:Uploading results into container
2025-10-12 16:20:00,761:INFO:Uploading model into container now
2025-10-12 16:20:00,761:INFO:_master_model_container: 40
2025-10-12 16:20:00,761:INFO:_display_container: 11
2025-10-12 16:20:00,761:INFO:<catboost.core.CatBoostClassifier object at 0x00000265E00511F0>
2025-10-12 16:20:00,762:INFO:create_model() successfully completed......................................
2025-10-12 16:20:00,928:INFO:SubProcess create_model() end ==================================
2025-10-12 16:20:00,928:INFO:Creating metrics dataframe
2025-10-12 16:20:00,936:INFO:Initializing Dummy Classifier
2025-10-12 16:20:00,936:INFO:Total runtime is 0.18127605120340984 minutes
2025-10-12 16:20:00,939:INFO:SubProcess create_model() called ==================================
2025-10-12 16:20:00,940:INFO:Initializing create_model()
2025-10-12 16:20:00,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265DFFC2FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:20:00,940:INFO:Checking exceptions
2025-10-12 16:20:00,940:INFO:Importing libraries
2025-10-12 16:20:00,940:INFO:Copying training dataset
2025-10-12 16:20:00,944:INFO:Defining folds
2025-10-12 16:20:00,944:INFO:Declaring metric variables
2025-10-12 16:20:00,947:INFO:Importing untrained model
2025-10-12 16:20:00,950:INFO:Dummy Classifier Imported successfully
2025-10-12 16:20:00,956:INFO:Starting cross validation
2025-10-12 16:20:00,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:20:00,986:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:20:00,990:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:20:00,992:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:20:00,992:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:20:00,993:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:20:00,995:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:20:00,998:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:20:01,002:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:20:01,003:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:20:01,004:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:20:01,023:INFO:Calculating mean and std
2025-10-12 16:20:01,023:INFO:Creating metrics dataframe
2025-10-12 16:20:01,026:INFO:Uploading results into container
2025-10-12 16:20:01,027:INFO:Uploading model into container now
2025-10-12 16:20:01,028:INFO:_master_model_container: 41
2025-10-12 16:20:01,028:INFO:_display_container: 11
2025-10-12 16:20:01,028:INFO:DummyClassifier(constant=None, random_state=6951, strategy='prior')
2025-10-12 16:20:01,028:INFO:create_model() successfully completed......................................
2025-10-12 16:20:01,203:INFO:SubProcess create_model() end ==================================
2025-10-12 16:20:01,203:INFO:Creating metrics dataframe
2025-10-12 16:20:01,211:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:20:01,219:INFO:Initializing create_model()
2025-10-12 16:20:01,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:20:01,220:INFO:Checking exceptions
2025-10-12 16:20:01,221:INFO:Importing libraries
2025-10-12 16:20:01,221:INFO:Copying training dataset
2025-10-12 16:20:01,225:INFO:Defining folds
2025-10-12 16:20:01,225:INFO:Declaring metric variables
2025-10-12 16:20:01,225:INFO:Importing untrained model
2025-10-12 16:20:01,225:INFO:Declaring custom model
2025-10-12 16:20:01,226:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:20:01,226:INFO:Cross validation set to False
2025-10-12 16:20:01,226:INFO:Fitting Model
2025-10-12 16:20:01,314:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:20:01,314:INFO:create_model() successfully completed......................................
2025-10-12 16:20:01,486:INFO:Creating Dashboard logs
2025-10-12 16:20:01,489:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:20:01,555:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 6951, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:20:01,789:INFO:Initializing predict_model()
2025-10-12 16:20:01,789:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E00DEC10>)
2025-10-12 16:20:01,789:INFO:Checking exceptions
2025-10-12 16:20:01,789:INFO:Preloading libraries
2025-10-12 16:20:01,997:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:20:01,997:INFO:Initializing plot_model()
2025-10-12 16:20:01,997:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp9zmmtl8c, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:20:01,997:INFO:Checking exceptions
2025-10-12 16:20:01,999:INFO:Preloading libraries
2025-10-12 16:20:02,003:INFO:Copying training dataset
2025-10-12 16:20:02,003:INFO:Plot type: auc
2025-10-12 16:20:02,043:INFO:Fitting Model
2025-10-12 16:20:02,043:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:20:02,044:INFO:Scoring test/hold-out set
2025-10-12 16:20:02,059:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp9zmmtl8c\AUC.png'
2025-10-12 16:20:02,227:INFO:Visual Rendered Successfully
2025-10-12 16:20:02,392:INFO:plot_model() successfully completed......................................
2025-10-12 16:20:02,411:INFO:Initializing plot_model()
2025-10-12 16:20:02,411:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp9zmmtl8c, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:20:02,411:INFO:Checking exceptions
2025-10-12 16:20:02,413:INFO:Preloading libraries
2025-10-12 16:20:02,417:INFO:Copying training dataset
2025-10-12 16:20:02,417:INFO:Plot type: confusion_matrix
2025-10-12 16:20:02,458:INFO:Fitting Model
2025-10-12 16:20:02,458:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:20:02,458:INFO:Scoring test/hold-out set
2025-10-12 16:20:02,473:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp9zmmtl8c\Confusion Matrix.png'
2025-10-12 16:20:02,563:INFO:Visual Rendered Successfully
2025-10-12 16:20:02,725:INFO:plot_model() successfully completed......................................
2025-10-12 16:20:02,745:INFO:Initializing plot_model()
2025-10-12 16:20:02,745:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp9zmmtl8c, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:20:02,745:INFO:Checking exceptions
2025-10-12 16:20:02,747:INFO:Preloading libraries
2025-10-12 16:20:02,750:INFO:Copying training dataset
2025-10-12 16:20:02,750:INFO:Plot type: feature
2025-10-12 16:20:02,750:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:20:02,774:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp9zmmtl8c\Feature Importance.png'
2025-10-12 16:20:02,861:INFO:Visual Rendered Successfully
2025-10-12 16:20:03,028:INFO:plot_model() successfully completed......................................
2025-10-12 16:20:03,049:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:20:03,286:INFO:Creating Dashboard logs
2025-10-12 16:20:03,289:INFO:Model: Ada Boost Classifier
2025-10-12 16:20:03,361:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 6951}
2025-10-12 16:20:03,785:INFO:Creating Dashboard logs
2025-10-12 16:20:03,788:INFO:Model: CatBoost Classifier
2025-10-12 16:20:03,854:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-10-12 16:20:03,854:INFO:Logged params: {}
2025-10-12 16:20:04,261:INFO:Creating Dashboard logs
2025-10-12 16:20:04,263:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:20:04,329:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6951, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:20:04,773:INFO:Creating Dashboard logs
2025-10-12 16:20:04,775:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 16:20:04,836:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:20:05,256:INFO:Creating Dashboard logs
2025-10-12 16:20:05,260:INFO:Model: Logistic Regression
2025-10-12 16:20:05,324:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 6951, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:20:05,777:INFO:Creating Dashboard logs
2025-10-12 16:20:05,780:INFO:Model: Ridge Classifier
2025-10-12 16:20:05,851:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 6951, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:20:06,293:INFO:Creating Dashboard logs
2025-10-12 16:20:06,296:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:20:06,361:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:20:06,792:INFO:Creating Dashboard logs
2025-10-12 16:20:06,794:INFO:Model: Extra Trees Classifier
2025-10-12 16:20:06,862:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6951, 'verbose': 0, 'warm_start': False}
2025-10-12 16:20:07,362:INFO:Creating Dashboard logs
2025-10-12 16:20:07,365:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:20:07,444:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 6951, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:20:07,939:INFO:Creating Dashboard logs
2025-10-12 16:20:07,941:INFO:Model: Random Forest Classifier
2025-10-12 16:20:08,010:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6951, 'verbose': 0, 'warm_start': False}
2025-10-12 16:20:08,435:INFO:Creating Dashboard logs
2025-10-12 16:20:08,438:INFO:Model: Naive Bayes
2025-10-12 16:20:08,511:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:20:08,953:INFO:Creating Dashboard logs
2025-10-12 16:20:08,956:INFO:Model: Decision Tree Classifier
2025-10-12 16:20:09,026:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 6951, 'splitter': 'best'}
2025-10-12 16:20:09,459:INFO:Creating Dashboard logs
2025-10-12 16:20:09,463:INFO:Model: K Neighbors Classifier
2025-10-12 16:20:09,531:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:20:09,965:INFO:Creating Dashboard logs
2025-10-12 16:20:09,968:INFO:Model: SVM - Linear Kernel
2025-10-12 16:20:10,024:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 6951, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:20:10,490:INFO:Creating Dashboard logs
2025-10-12 16:20:10,493:INFO:Model: Dummy Classifier
2025-10-12 16:20:10,561:INFO:Logged params: {'constant': None, 'random_state': 6951, 'strategy': 'prior'}
2025-10-12 16:20:10,953:INFO:_master_model_container: 41
2025-10-12 16:20:10,953:INFO:_display_container: 11
2025-10-12 16:20:10,953:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:20:10,953:INFO:compare_models() successfully completed......................................
2025-10-12 16:20:13,840:INFO:Initializing predict_model()
2025-10-12 16:20:13,840:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=mlflow.pyfunc.loaded_model:
  run_id: 39f894e7d3eb44a99b7896e490c21033
  artifact_path: model
  flavor: mlflow.sklearn
, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E014DDC0>)
2025-10-12 16:20:13,840:INFO:Checking exceptions
2025-10-12 16:20:13,841:INFO:Preloading libraries
2025-10-12 16:20:13,843:INFO:Set up data.
2025-10-12 16:20:13,846:INFO:Set up index.
2025-10-12 16:20:50,352:INFO:Initializing create_model()
2025-10-12 16:20:50,352:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:20:50,353:INFO:Checking exceptions
2025-10-12 16:20:50,365:INFO:Importing libraries
2025-10-12 16:20:50,366:INFO:Copying training dataset
2025-10-12 16:20:50,368:INFO:Defining folds
2025-10-12 16:20:50,368:INFO:Declaring metric variables
2025-10-12 16:20:50,371:INFO:Importing untrained model
2025-10-12 16:20:50,373:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:20:50,380:INFO:Starting cross validation
2025-10-12 16:20:50,380:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:20:50,453:INFO:Calculating mean and std
2025-10-12 16:20:50,453:INFO:Creating metrics dataframe
2025-10-12 16:20:50,458:INFO:Finalizing model
2025-10-12 16:20:50,463:INFO:Creating Dashboard logs
2025-10-12 16:20:50,466:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:20:50,527:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:20:50,731:INFO:Initializing predict_model()
2025-10-12 16:20:50,731:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E2675790>)
2025-10-12 16:20:50,731:INFO:Checking exceptions
2025-10-12 16:20:50,731:INFO:Preloading libraries
2025-10-12 16:20:50,956:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:20:50,956:INFO:Initializing plot_model()
2025-10-12 16:20:50,956:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpagzoin1p, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:20:50,956:INFO:Checking exceptions
2025-10-12 16:20:50,957:INFO:Preloading libraries
2025-10-12 16:20:50,957:INFO:Copying training dataset
2025-10-12 16:20:50,957:INFO:Plot type: auc
2025-10-12 16:20:51,001:INFO:Fitting Model
2025-10-12 16:20:51,001:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:20:51,001:INFO:Scoring test/hold-out set
2025-10-12 16:20:51,013:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpagzoin1p\AUC.png'
2025-10-12 16:20:51,172:INFO:Visual Rendered Successfully
2025-10-12 16:20:51,335:INFO:plot_model() successfully completed......................................
2025-10-12 16:20:51,351:INFO:Initializing plot_model()
2025-10-12 16:20:51,351:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpagzoin1p, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:20:51,351:INFO:Checking exceptions
2025-10-12 16:20:51,352:INFO:Preloading libraries
2025-10-12 16:20:51,352:INFO:Copying training dataset
2025-10-12 16:20:51,352:INFO:Plot type: confusion_matrix
2025-10-12 16:20:51,393:INFO:Fitting Model
2025-10-12 16:20:51,393:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:20:51,393:INFO:Scoring test/hold-out set
2025-10-12 16:20:51,405:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpagzoin1p\Confusion Matrix.png'
2025-10-12 16:20:51,483:INFO:Visual Rendered Successfully
2025-10-12 16:20:51,659:INFO:plot_model() successfully completed......................................
2025-10-12 16:20:51,675:INFO:Initializing plot_model()
2025-10-12 16:20:51,675:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpagzoin1p, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:20:51,675:INFO:Checking exceptions
2025-10-12 16:20:51,676:INFO:Preloading libraries
2025-10-12 16:20:51,677:INFO:Copying training dataset
2025-10-12 16:20:51,677:INFO:Plot type: feature
2025-10-12 16:20:51,713:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpagzoin1p\Feature Importance.png'
2025-10-12 16:20:51,807:INFO:Visual Rendered Successfully
2025-10-12 16:20:51,983:INFO:plot_model() successfully completed......................................
2025-10-12 16:20:51,996:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:20:52,231:INFO:Uploading results into container
2025-10-12 16:20:52,231:INFO:Uploading model into container now
2025-10-12 16:20:52,239:INFO:_master_model_container: 42
2025-10-12 16:20:52,240:INFO:_display_container: 12
2025-10-12 16:20:52,240:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:20:52,240:INFO:create_model() successfully completed......................................
2025-10-12 16:20:52,401:INFO:Initializing create_model()
2025-10-12 16:20:52,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=ridge, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:20:52,402:INFO:Checking exceptions
2025-10-12 16:20:52,412:INFO:Importing libraries
2025-10-12 16:20:52,412:INFO:Copying training dataset
2025-10-12 16:20:52,415:INFO:Defining folds
2025-10-12 16:20:52,415:INFO:Declaring metric variables
2025-10-12 16:20:52,417:INFO:Importing untrained model
2025-10-12 16:20:52,420:INFO:Ridge Classifier Imported successfully
2025-10-12 16:20:52,430:INFO:Starting cross validation
2025-10-12 16:20:52,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:20:52,515:INFO:Calculating mean and std
2025-10-12 16:20:52,515:INFO:Creating metrics dataframe
2025-10-12 16:20:52,519:INFO:Finalizing model
2025-10-12 16:20:52,524:INFO:Creating Dashboard logs
2025-10-12 16:20:52,527:INFO:Model: Ridge Classifier
2025-10-12 16:20:52,613:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 6951, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:20:52,828:INFO:Initializing predict_model()
2025-10-12 16:20:52,828:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E244D430>)
2025-10-12 16:20:52,828:INFO:Checking exceptions
2025-10-12 16:20:52,828:INFO:Preloading libraries
2025-10-12 16:20:53,055:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:20:53,055:INFO:Initializing plot_model()
2025-10-12 16:20:53,055:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpq65s_o68, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:20:53,055:INFO:Checking exceptions
2025-10-12 16:20:53,055:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:20:53,056:INFO:Initializing plot_model()
2025-10-12 16:20:53,056:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpq65s_o68, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:20:53,056:INFO:Checking exceptions
2025-10-12 16:20:53,056:INFO:Preloading libraries
2025-10-12 16:20:53,056:INFO:Copying training dataset
2025-10-12 16:20:53,056:INFO:Plot type: confusion_matrix
2025-10-12 16:20:53,096:INFO:Fitting Model
2025-10-12 16:20:53,096:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names

2025-10-12 16:20:53,096:INFO:Scoring test/hold-out set
2025-10-12 16:20:53,108:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpq65s_o68\Confusion Matrix.png'
2025-10-12 16:20:53,186:INFO:Visual Rendered Successfully
2025-10-12 16:20:53,346:INFO:plot_model() successfully completed......................................
2025-10-12 16:20:53,363:INFO:Initializing plot_model()
2025-10-12 16:20:53,363:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpq65s_o68, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:20:53,363:INFO:Checking exceptions
2025-10-12 16:20:53,364:INFO:Preloading libraries
2025-10-12 16:20:53,364:INFO:Copying training dataset
2025-10-12 16:20:53,365:INFO:Plot type: feature
2025-10-12 16:20:53,398:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpq65s_o68\Feature Importance.png'
2025-10-12 16:20:53,488:INFO:Visual Rendered Successfully
2025-10-12 16:20:53,652:INFO:plot_model() successfully completed......................................
2025-10-12 16:20:53,670:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:20:53,900:INFO:Uploading results into container
2025-10-12 16:20:53,901:INFO:Uploading model into container now
2025-10-12 16:20:53,908:INFO:_master_model_container: 43
2025-10-12 16:20:53,908:INFO:_display_container: 13
2025-10-12 16:20:53,909:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001)
2025-10-12 16:20:53,909:INFO:create_model() successfully completed......................................
2025-10-12 16:20:54,072:INFO:Initializing create_model()
2025-10-12 16:20:54,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:20:54,072:INFO:Checking exceptions
2025-10-12 16:20:54,082:INFO:Importing libraries
2025-10-12 16:20:54,082:INFO:Copying training dataset
2025-10-12 16:20:54,085:INFO:Defining folds
2025-10-12 16:20:54,085:INFO:Declaring metric variables
2025-10-12 16:20:54,088:INFO:Importing untrained model
2025-10-12 16:20:54,091:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:20:54,100:INFO:Starting cross validation
2025-10-12 16:20:54,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:20:54,299:INFO:Calculating mean and std
2025-10-12 16:20:54,299:INFO:Creating metrics dataframe
2025-10-12 16:20:54,303:INFO:Finalizing model
2025-10-12 16:20:54,379:INFO:Creating Dashboard logs
2025-10-12 16:20:54,382:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:20:54,460:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 6951, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:20:54,722:INFO:Initializing predict_model()
2025-10-12 16:20:54,722:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E244D040>)
2025-10-12 16:20:54,722:INFO:Checking exceptions
2025-10-12 16:20:54,722:INFO:Preloading libraries
2025-10-12 16:20:54,946:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:20:54,947:INFO:Initializing plot_model()
2025-10-12 16:20:54,947:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp23fphjh5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:20:54,947:INFO:Checking exceptions
2025-10-12 16:20:54,948:INFO:Preloading libraries
2025-10-12 16:20:54,952:INFO:Copying training dataset
2025-10-12 16:20:54,952:INFO:Plot type: auc
2025-10-12 16:20:54,990:INFO:Fitting Model
2025-10-12 16:20:54,990:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:20:54,991:INFO:Scoring test/hold-out set
2025-10-12 16:20:55,006:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp23fphjh5\AUC.png'
2025-10-12 16:20:55,164:INFO:Visual Rendered Successfully
2025-10-12 16:20:55,328:INFO:plot_model() successfully completed......................................
2025-10-12 16:20:55,346:INFO:Initializing plot_model()
2025-10-12 16:20:55,346:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp23fphjh5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:20:55,346:INFO:Checking exceptions
2025-10-12 16:20:55,348:INFO:Preloading libraries
2025-10-12 16:20:55,352:INFO:Copying training dataset
2025-10-12 16:20:55,352:INFO:Plot type: confusion_matrix
2025-10-12 16:20:55,393:INFO:Fitting Model
2025-10-12 16:20:55,393:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:20:55,393:INFO:Scoring test/hold-out set
2025-10-12 16:20:55,408:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp23fphjh5\Confusion Matrix.png'
2025-10-12 16:20:55,488:INFO:Visual Rendered Successfully
2025-10-12 16:20:55,653:INFO:plot_model() successfully completed......................................
2025-10-12 16:20:55,673:INFO:Initializing plot_model()
2025-10-12 16:20:55,673:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp23fphjh5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, system=False)
2025-10-12 16:20:55,673:INFO:Checking exceptions
2025-10-12 16:20:55,676:INFO:Preloading libraries
2025-10-12 16:20:55,680:INFO:Copying training dataset
2025-10-12 16:20:55,680:INFO:Plot type: feature
2025-10-12 16:20:55,680:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:20:55,719:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp23fphjh5\Feature Importance.png'
2025-10-12 16:20:55,813:INFO:Visual Rendered Successfully
2025-10-12 16:20:55,976:INFO:plot_model() successfully completed......................................
2025-10-12 16:20:55,994:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:20:56,235:INFO:Uploading results into container
2025-10-12 16:20:56,235:INFO:Uploading model into container now
2025-10-12 16:20:56,242:INFO:_master_model_container: 44
2025-10-12 16:20:56,242:INFO:_display_container: 14
2025-10-12 16:20:56,243:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:20:56,243:INFO:create_model() successfully completed......................................
2025-10-12 16:20:56,409:INFO:Initializing blend_models()
2025-10-12 16:20:56,409:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator_list=[mlflow.pyfunc.loaded_model:
  run_id: 39f894e7d3eb44a99b7896e490c21033
  artifact_path: model
  flavor: mlflow.sklearn
, LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6951, solver='auto',
                tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6951, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:20:56,409:INFO:Checking exceptions
2025-10-12 16:21:28,180:INFO:Initializing predict_model()
2025-10-12 16:21:28,180:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265E0299DC0>, estimator=mlflow.pyfunc.loaded_model:
  run_id: 39f894e7d3eb44a99b7896e490c21033
  artifact_path: model
  flavor: mlflow.sklearn
, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265E20AFF70>)
2025-10-12 16:21:28,180:INFO:Checking exceptions
2025-10-12 16:21:28,180:INFO:Preloading libraries
2025-10-12 16:21:28,181:INFO:Set up data.
2025-10-12 16:21:28,184:INFO:Set up index.
2025-10-12 16:22:41,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 16:22:41,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 16:22:41,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 16:22:41,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 16:22:42,799:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\mlflow\utils\requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources  # noqa: TID251

2025-10-12 16:24:45,022:INFO:PyCaret ClassificationExperiment
2025-10-12 16:24:45,022:INFO:Logging name: titanic_exp_1
2025-10-12 16:24:45,022:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-12 16:24:45,022:INFO:version 3.3.2
2025-10-12 16:24:45,022:INFO:Initializing setup()
2025-10-12 16:24:45,022:INFO:self.USI: 4eea
2025-10-12 16:24:45,022:INFO:self._variable_keys: {'data', 'y_train', 'memory', 'log_plots_param', 'is_multiclass', '_ml_usecase', 'exp_id', 'fold_groups_param', 'seed', 'gpu_n_jobs_param', 'target_param', 'y', 'n_jobs_param', 'exp_name_log', 'html_param', 'fold_generator', 'X_test', 'X_train', '_available_plots', 'gpu_param', 'fold_shuffle_param', 'idx', 'logging_param', 'X', 'fix_imbalance', 'pipeline', 'y_test', 'USI'}
2025-10-12 16:24:45,022:INFO:Checking environment
2025-10-12 16:24:45,022:INFO:python_version: 3.9.13
2025-10-12 16:24:45,022:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2025-10-12 16:24:45,022:INFO:machine: AMD64
2025-10-12 16:24:45,022:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-12 16:24:45,022:INFO:Memory: svmem(total=16778072064, available=5989089280, percent=64.3, used=10788982784, free=5989089280)
2025-10-12 16:24:45,022:INFO:Physical Core: 10
2025-10-12 16:24:45,022:INFO:Logical Core: 16
2025-10-12 16:24:45,022:INFO:Checking libraries
2025-10-12 16:24:45,022:INFO:System:
2025-10-12 16:24:45,022:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2025-10-12 16:24:45,022:INFO:executable: c:\Users\david\Programming\MLOps\.venv\Scripts\python.exe
2025-10-12 16:24:45,022:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-12 16:24:45,022:INFO:PyCaret required dependencies:
2025-10-12 16:24:45,762:INFO:                 pip: 25.2
2025-10-12 16:24:45,764:INFO:          setuptools: 80.9.0
2025-10-12 16:24:45,764:INFO:             pycaret: 3.3.2
2025-10-12 16:24:45,764:INFO:             IPython: 8.18.1
2025-10-12 16:24:45,764:INFO:          ipywidgets: 8.1.7
2025-10-12 16:24:45,764:INFO:                tqdm: 4.67.1
2025-10-12 16:24:45,764:INFO:               numpy: 1.26.4
2025-10-12 16:24:45,764:INFO:              pandas: 2.1.4
2025-10-12 16:24:45,764:INFO:              jinja2: 3.1.6
2025-10-12 16:24:45,764:INFO:               scipy: 1.11.4
2025-10-12 16:24:45,764:INFO:              joblib: 1.3.2
2025-10-12 16:24:45,764:INFO:             sklearn: 1.4.2
2025-10-12 16:24:45,764:INFO:                pyod: 2.0.5
2025-10-12 16:24:45,764:INFO:            imblearn: 0.12.4
2025-10-12 16:24:45,764:INFO:   category_encoders: 2.6.4
2025-10-12 16:24:45,764:INFO:            lightgbm: 4.6.0
2025-10-12 16:24:45,764:INFO:               numba: 0.60.0
2025-10-12 16:24:45,764:INFO:            requests: 2.32.5
2025-10-12 16:24:45,764:INFO:          matplotlib: 3.7.5
2025-10-12 16:24:45,764:INFO:          scikitplot: 0.3.7
2025-10-12 16:24:45,764:INFO:         yellowbrick: 1.5
2025-10-12 16:24:45,764:INFO:              plotly: 5.24.1
2025-10-12 16:24:45,764:INFO:    plotly-resampler: Not installed
2025-10-12 16:24:45,764:INFO:             kaleido: 1.1.0
2025-10-12 16:24:45,764:INFO:           schemdraw: 0.15
2025-10-12 16:24:45,764:INFO:         statsmodels: 0.14.5
2025-10-12 16:24:45,764:INFO:              sktime: 0.26.0
2025-10-12 16:24:45,764:INFO:               tbats: 1.1.3
2025-10-12 16:24:45,764:INFO:            pmdarima: 2.0.4
2025-10-12 16:24:45,764:INFO:              psutil: 7.1.0
2025-10-12 16:24:45,764:INFO:          markupsafe: 2.1.5
2025-10-12 16:24:45,764:INFO:             pickle5: Not installed
2025-10-12 16:24:45,764:INFO:         cloudpickle: 3.1.1
2025-10-12 16:24:45,764:INFO:         deprecation: 2.1.0
2025-10-12 16:24:45,764:INFO:              xxhash: 3.6.0
2025-10-12 16:24:45,764:INFO:           wurlitzer: Not installed
2025-10-12 16:24:45,764:INFO:PyCaret optional dependencies:
2025-10-12 16:24:47,666:INFO:                shap: 0.44.1
2025-10-12 16:24:47,666:INFO:           interpret: 0.7.2
2025-10-12 16:24:47,666:INFO:                umap: 0.5.7
2025-10-12 16:24:47,666:INFO:     ydata_profiling: 4.17.0
2025-10-12 16:24:47,666:INFO:  explainerdashboard: 0.5.1
2025-10-12 16:24:47,666:INFO:             autoviz: Not installed
2025-10-12 16:24:47,666:INFO:           fairlearn: 0.7.0
2025-10-12 16:24:47,666:INFO:          deepchecks: Not installed
2025-10-12 16:24:47,666:INFO:             xgboost: 2.1.4
2025-10-12 16:24:47,666:INFO:            catboost: 1.2.8
2025-10-12 16:24:47,666:INFO:              kmodes: 0.12.2
2025-10-12 16:24:47,666:INFO:             mlxtend: 0.23.4
2025-10-12 16:24:47,666:INFO:       statsforecast: 1.5.0
2025-10-12 16:24:47,666:INFO:        tune_sklearn: Not installed
2025-10-12 16:24:47,666:INFO:                 ray: Not installed
2025-10-12 16:24:47,666:INFO:            hyperopt: 0.2.7
2025-10-12 16:24:47,666:INFO:              optuna: 4.5.0
2025-10-12 16:24:47,666:INFO:               skopt: 0.10.2
2025-10-12 16:24:47,666:INFO:              mlflow: 3.1.4
2025-10-12 16:24:47,666:INFO:              gradio: Not installed
2025-10-12 16:24:47,666:INFO:             fastapi: 0.119.0
2025-10-12 16:24:47,666:INFO:             uvicorn: 0.37.0
2025-10-12 16:24:47,666:INFO:              m2cgen: 0.10.0
2025-10-12 16:24:47,666:INFO:           evidently: 0.4.40
2025-10-12 16:24:47,666:INFO:               fugue: 0.8.7
2025-10-12 16:24:47,666:INFO:           streamlit: Not installed
2025-10-12 16:24:47,666:INFO:             prophet: Not installed
2025-10-12 16:24:47,666:INFO:None
2025-10-12 16:24:47,666:INFO:Set up data.
2025-10-12 16:24:47,669:INFO:Set up folding strategy.
2025-10-12 16:24:47,670:INFO:Set up train/test split.
2025-10-12 16:24:47,671:INFO:Set up index.
2025-10-12 16:24:47,671:INFO:Assigning column types.
2025-10-12 16:24:47,674:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-12 16:24:47,699:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:24:47,702:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:24:47,726:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:24:47,728:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:24:47,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:24:47,778:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:24:47,794:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:24:47,796:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:24:47,797:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-12 16:24:47,823:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:24:47,840:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:24:47,842:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:24:47,869:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:24:47,885:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:24:47,886:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:24:47,887:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-12 16:24:47,929:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:24:47,932:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:24:47,975:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:24:47,977:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:24:47,979:INFO:Preparing preprocessing pipeline...
2025-10-12 16:24:47,980:INFO:Set up simple imputation.
2025-10-12 16:24:47,994:INFO:Finished creating preprocessing pipeline.
2025-10-12 16:24:47,998:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-12 16:24:47,999:INFO:Creating final display dataframe.
2025-10-12 16:24:48,038:INFO:Setup _display_container:                     Description            Value
0                    Session id             8866
1                        Target         Survived
2                   Target type           Binary
3           Original data shape         (712, 8)
4        Transformed data shape         (712, 8)
5   Transformed train set shape         (498, 8)
6    Transformed test set shape         (214, 8)
7              Numeric features                7
8                    Preprocess             True
9               Imputation type           simple
10           Numeric imputation             mean
11       Categorical imputation             mode
12               Fold Generator  StratifiedKFold
13                  Fold Number               10
14                     CPU Jobs               -1
15                      Use GPU            False
16               Log Experiment     MlflowLogger
17              Experiment Name    titanic_exp_1
18                          USI             4eea
2025-10-12 16:24:48,088:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:24:48,089:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:24:48,133:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:24:48,134:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:24:48,135:INFO:Logging experiment in loggers
2025-10-12 16:24:48,411:INFO:SubProcess save_model() called ==================================
2025-10-12 16:24:48,415:INFO:Initializing save_model()
2025-10-12 16:24:48,415:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\david\AppData\Local\Temp\tmpo0_m6ali\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 16:24:48,415:INFO:Adding model into prep_pipe
2025-10-12 16:24:48,415:WARNING:Only Model saved as it was a pipeline.
2025-10-12 16:24:48,417:INFO:C:\Users\david\AppData\Local\Temp\tmpo0_m6ali\Transformation Pipeline.pkl saved in current working directory
2025-10-12 16:24:48,419:INFO:Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-12 16:24:48,419:INFO:save_model() successfully completed......................................
2025-10-12 16:24:48,511:INFO:SubProcess save_model() end ==================================
2025-10-12 16:24:48,652:INFO:setup() successfully completed in 3.12s...............
2025-10-12 16:24:48,679:INFO:Initializing compare_models()
2025-10-12 16:24:48,679:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:24:48,679:INFO:Checking exceptions
2025-10-12 16:24:48,681:INFO:Preparing display monitor
2025-10-12 16:24:48,701:INFO:Initializing Logistic Regression
2025-10-12 16:24:48,701:INFO:Total runtime is 0.0 minutes
2025-10-12 16:24:48,705:INFO:SubProcess create_model() called ==================================
2025-10-12 16:24:48,706:INFO:Initializing create_model()
2025-10-12 16:24:48,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:24:48,706:INFO:Checking exceptions
2025-10-12 16:24:48,706:INFO:Importing libraries
2025-10-12 16:24:48,706:INFO:Copying training dataset
2025-10-12 16:24:48,708:INFO:Defining folds
2025-10-12 16:24:48,708:INFO:Declaring metric variables
2025-10-12 16:24:48,711:INFO:Importing untrained model
2025-10-12 16:24:48,716:INFO:Logistic Regression Imported successfully
2025-10-12 16:24:48,724:INFO:Starting cross validation
2025-10-12 16:24:48,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:24:54,842:INFO:Calculating mean and std
2025-10-12 16:24:54,844:INFO:Creating metrics dataframe
2025-10-12 16:24:54,846:INFO:Uploading results into container
2025-10-12 16:24:54,847:INFO:Uploading model into container now
2025-10-12 16:24:54,848:INFO:_master_model_container: 1
2025-10-12 16:24:54,848:INFO:_display_container: 2
2025-10-12 16:24:54,849:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8866, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:24:54,849:INFO:create_model() successfully completed......................................
2025-10-12 16:24:54,962:INFO:SubProcess create_model() end ==================================
2025-10-12 16:24:54,962:INFO:Creating metrics dataframe
2025-10-12 16:24:54,968:INFO:Initializing K Neighbors Classifier
2025-10-12 16:24:54,968:INFO:Total runtime is 0.10444584290186563 minutes
2025-10-12 16:24:54,970:INFO:SubProcess create_model() called ==================================
2025-10-12 16:24:54,970:INFO:Initializing create_model()
2025-10-12 16:24:54,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:24:54,971:INFO:Checking exceptions
2025-10-12 16:24:54,971:INFO:Importing libraries
2025-10-12 16:24:54,971:INFO:Copying training dataset
2025-10-12 16:24:54,973:INFO:Defining folds
2025-10-12 16:24:54,973:INFO:Declaring metric variables
2025-10-12 16:24:54,977:INFO:Importing untrained model
2025-10-12 16:24:54,979:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:24:54,984:INFO:Starting cross validation
2025-10-12 16:24:54,985:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:24:58,971:INFO:Calculating mean and std
2025-10-12 16:24:58,974:INFO:Creating metrics dataframe
2025-10-12 16:24:58,977:INFO:Uploading results into container
2025-10-12 16:24:58,978:INFO:Uploading model into container now
2025-10-12 16:24:58,979:INFO:_master_model_container: 2
2025-10-12 16:24:58,979:INFO:_display_container: 2
2025-10-12 16:24:58,979:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:24:58,979:INFO:create_model() successfully completed......................................
2025-10-12 16:24:59,094:INFO:SubProcess create_model() end ==================================
2025-10-12 16:24:59,094:INFO:Creating metrics dataframe
2025-10-12 16:24:59,105:INFO:Initializing Naive Bayes
2025-10-12 16:24:59,105:INFO:Total runtime is 0.17339030504226682 minutes
2025-10-12 16:24:59,110:INFO:SubProcess create_model() called ==================================
2025-10-12 16:24:59,111:INFO:Initializing create_model()
2025-10-12 16:24:59,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:24:59,111:INFO:Checking exceptions
2025-10-12 16:24:59,111:INFO:Importing libraries
2025-10-12 16:24:59,111:INFO:Copying training dataset
2025-10-12 16:24:59,115:INFO:Defining folds
2025-10-12 16:24:59,115:INFO:Declaring metric variables
2025-10-12 16:24:59,119:INFO:Importing untrained model
2025-10-12 16:24:59,125:INFO:Naive Bayes Imported successfully
2025-10-12 16:24:59,131:INFO:Starting cross validation
2025-10-12 16:24:59,132:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:24:59,189:INFO:Calculating mean and std
2025-10-12 16:24:59,190:INFO:Creating metrics dataframe
2025-10-12 16:24:59,191:INFO:Uploading results into container
2025-10-12 16:24:59,191:INFO:Uploading model into container now
2025-10-12 16:24:59,192:INFO:_master_model_container: 3
2025-10-12 16:24:59,192:INFO:_display_container: 2
2025-10-12 16:24:59,192:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:24:59,192:INFO:create_model() successfully completed......................................
2025-10-12 16:24:59,288:INFO:SubProcess create_model() end ==================================
2025-10-12 16:24:59,288:INFO:Creating metrics dataframe
2025-10-12 16:24:59,294:INFO:Initializing Decision Tree Classifier
2025-10-12 16:24:59,294:INFO:Total runtime is 0.1765438715616862 minutes
2025-10-12 16:24:59,297:INFO:SubProcess create_model() called ==================================
2025-10-12 16:24:59,297:INFO:Initializing create_model()
2025-10-12 16:24:59,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:24:59,298:INFO:Checking exceptions
2025-10-12 16:24:59,298:INFO:Importing libraries
2025-10-12 16:24:59,298:INFO:Copying training dataset
2025-10-12 16:24:59,302:INFO:Defining folds
2025-10-12 16:24:59,302:INFO:Declaring metric variables
2025-10-12 16:24:59,307:INFO:Importing untrained model
2025-10-12 16:24:59,311:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:24:59,318:INFO:Starting cross validation
2025-10-12 16:24:59,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:24:59,391:INFO:Calculating mean and std
2025-10-12 16:24:59,392:INFO:Creating metrics dataframe
2025-10-12 16:24:59,394:INFO:Uploading results into container
2025-10-12 16:24:59,394:INFO:Uploading model into container now
2025-10-12 16:24:59,394:INFO:_master_model_container: 4
2025-10-12 16:24:59,394:INFO:_display_container: 2
2025-10-12 16:24:59,395:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8866, splitter='best')
2025-10-12 16:24:59,395:INFO:create_model() successfully completed......................................
2025-10-12 16:24:59,495:INFO:SubProcess create_model() end ==================================
2025-10-12 16:24:59,495:INFO:Creating metrics dataframe
2025-10-12 16:24:59,500:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:24:59,500:INFO:Total runtime is 0.17997821966807045 minutes
2025-10-12 16:24:59,503:INFO:SubProcess create_model() called ==================================
2025-10-12 16:24:59,504:INFO:Initializing create_model()
2025-10-12 16:24:59,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:24:59,504:INFO:Checking exceptions
2025-10-12 16:24:59,504:INFO:Importing libraries
2025-10-12 16:24:59,504:INFO:Copying training dataset
2025-10-12 16:24:59,507:INFO:Defining folds
2025-10-12 16:24:59,507:INFO:Declaring metric variables
2025-10-12 16:24:59,510:INFO:Importing untrained model
2025-10-12 16:24:59,513:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:24:59,518:INFO:Starting cross validation
2025-10-12 16:24:59,519:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:24:59,554:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:24:59,579:INFO:Calculating mean and std
2025-10-12 16:24:59,579:INFO:Creating metrics dataframe
2025-10-12 16:24:59,581:INFO:Uploading results into container
2025-10-12 16:24:59,581:INFO:Uploading model into container now
2025-10-12 16:24:59,582:INFO:_master_model_container: 5
2025-10-12 16:24:59,582:INFO:_display_container: 2
2025-10-12 16:24:59,582:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8866, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:24:59,582:INFO:create_model() successfully completed......................................
2025-10-12 16:24:59,677:INFO:SubProcess create_model() end ==================================
2025-10-12 16:24:59,677:INFO:Creating metrics dataframe
2025-10-12 16:24:59,682:INFO:Initializing Ridge Classifier
2025-10-12 16:24:59,682:INFO:Total runtime is 0.18301249742507933 minutes
2025-10-12 16:24:59,685:INFO:SubProcess create_model() called ==================================
2025-10-12 16:24:59,685:INFO:Initializing create_model()
2025-10-12 16:24:59,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:24:59,686:INFO:Checking exceptions
2025-10-12 16:24:59,686:INFO:Importing libraries
2025-10-12 16:24:59,686:INFO:Copying training dataset
2025-10-12 16:24:59,689:INFO:Defining folds
2025-10-12 16:24:59,690:INFO:Declaring metric variables
2025-10-12 16:24:59,694:INFO:Importing untrained model
2025-10-12 16:24:59,698:INFO:Ridge Classifier Imported successfully
2025-10-12 16:24:59,704:INFO:Starting cross validation
2025-10-12 16:24:59,705:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:24:59,765:INFO:Calculating mean and std
2025-10-12 16:24:59,765:INFO:Creating metrics dataframe
2025-10-12 16:24:59,767:INFO:Uploading results into container
2025-10-12 16:24:59,767:INFO:Uploading model into container now
2025-10-12 16:24:59,768:INFO:_master_model_container: 6
2025-10-12 16:24:59,768:INFO:_display_container: 2
2025-10-12 16:24:59,768:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8866, solver='auto',
                tol=0.0001)
2025-10-12 16:24:59,768:INFO:create_model() successfully completed......................................
2025-10-12 16:24:59,866:INFO:SubProcess create_model() end ==================================
2025-10-12 16:24:59,866:INFO:Creating metrics dataframe
2025-10-12 16:24:59,872:INFO:Initializing Random Forest Classifier
2025-10-12 16:24:59,872:INFO:Total runtime is 0.18618018627166746 minutes
2025-10-12 16:24:59,875:INFO:SubProcess create_model() called ==================================
2025-10-12 16:24:59,876:INFO:Initializing create_model()
2025-10-12 16:24:59,876:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:24:59,876:INFO:Checking exceptions
2025-10-12 16:24:59,876:INFO:Importing libraries
2025-10-12 16:24:59,876:INFO:Copying training dataset
2025-10-12 16:24:59,879:INFO:Defining folds
2025-10-12 16:24:59,879:INFO:Declaring metric variables
2025-10-12 16:24:59,882:INFO:Importing untrained model
2025-10-12 16:24:59,886:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:24:59,892:INFO:Starting cross validation
2025-10-12 16:24:59,894:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:00,218:INFO:Calculating mean and std
2025-10-12 16:25:00,219:INFO:Creating metrics dataframe
2025-10-12 16:25:00,220:INFO:Uploading results into container
2025-10-12 16:25:00,220:INFO:Uploading model into container now
2025-10-12 16:25:00,220:INFO:_master_model_container: 7
2025-10-12 16:25:00,221:INFO:_display_container: 2
2025-10-12 16:25:00,221:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8866, verbose=0,
                       warm_start=False)
2025-10-12 16:25:00,221:INFO:create_model() successfully completed......................................
2025-10-12 16:25:00,318:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:00,318:INFO:Creating metrics dataframe
2025-10-12 16:25:00,324:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:25:00,324:INFO:Total runtime is 0.19371867179870603 minutes
2025-10-12 16:25:00,327:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:00,328:INFO:Initializing create_model()
2025-10-12 16:25:00,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:00,328:INFO:Checking exceptions
2025-10-12 16:25:00,328:INFO:Importing libraries
2025-10-12 16:25:00,328:INFO:Copying training dataset
2025-10-12 16:25:00,334:INFO:Defining folds
2025-10-12 16:25:00,335:INFO:Declaring metric variables
2025-10-12 16:25:00,338:INFO:Importing untrained model
2025-10-12 16:25:00,340:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:25:00,347:INFO:Starting cross validation
2025-10-12 16:25:00,348:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:00,419:INFO:Calculating mean and std
2025-10-12 16:25:00,419:INFO:Creating metrics dataframe
2025-10-12 16:25:00,421:INFO:Uploading results into container
2025-10-12 16:25:00,421:INFO:Uploading model into container now
2025-10-12 16:25:00,421:INFO:_master_model_container: 8
2025-10-12 16:25:00,421:INFO:_display_container: 2
2025-10-12 16:25:00,421:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:25:00,421:INFO:create_model() successfully completed......................................
2025-10-12 16:25:00,520:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:00,520:INFO:Creating metrics dataframe
2025-10-12 16:25:00,525:INFO:Initializing Ada Boost Classifier
2025-10-12 16:25:00,526:INFO:Total runtime is 0.19708515803019203 minutes
2025-10-12 16:25:00,528:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:00,528:INFO:Initializing create_model()
2025-10-12 16:25:00,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:00,529:INFO:Checking exceptions
2025-10-12 16:25:00,529:INFO:Importing libraries
2025-10-12 16:25:00,529:INFO:Copying training dataset
2025-10-12 16:25:00,533:INFO:Defining folds
2025-10-12 16:25:00,533:INFO:Declaring metric variables
2025-10-12 16:25:00,537:INFO:Importing untrained model
2025-10-12 16:25:00,540:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:25:00,545:INFO:Starting cross validation
2025-10-12 16:25:00,546:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:00,561:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:25:00,565:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:25:00,565:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:25:00,566:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:25:00,570:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:25:00,571:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:25:00,572:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:25:00,575:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:25:00,576:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:25:00,579:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:25:00,701:INFO:Calculating mean and std
2025-10-12 16:25:00,703:INFO:Creating metrics dataframe
2025-10-12 16:25:00,704:INFO:Uploading results into container
2025-10-12 16:25:00,704:INFO:Uploading model into container now
2025-10-12 16:25:00,705:INFO:_master_model_container: 9
2025-10-12 16:25:00,705:INFO:_display_container: 2
2025-10-12 16:25:00,706:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8866)
2025-10-12 16:25:00,706:INFO:create_model() successfully completed......................................
2025-10-12 16:25:00,800:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:00,801:INFO:Creating metrics dataframe
2025-10-12 16:25:00,807:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:25:00,807:INFO:Total runtime is 0.20175591309865312 minutes
2025-10-12 16:25:00,810:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:00,811:INFO:Initializing create_model()
2025-10-12 16:25:00,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:00,811:INFO:Checking exceptions
2025-10-12 16:25:00,811:INFO:Importing libraries
2025-10-12 16:25:00,811:INFO:Copying training dataset
2025-10-12 16:25:00,814:INFO:Defining folds
2025-10-12 16:25:00,814:INFO:Declaring metric variables
2025-10-12 16:25:00,818:INFO:Importing untrained model
2025-10-12 16:25:00,822:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:25:00,828:INFO:Starting cross validation
2025-10-12 16:25:00,829:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:01,031:INFO:Calculating mean and std
2025-10-12 16:25:01,033:INFO:Creating metrics dataframe
2025-10-12 16:25:01,034:INFO:Uploading results into container
2025-10-12 16:25:01,034:INFO:Uploading model into container now
2025-10-12 16:25:01,034:INFO:_master_model_container: 10
2025-10-12 16:25:01,035:INFO:_display_container: 2
2025-10-12 16:25:01,035:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:25:01,035:INFO:create_model() successfully completed......................................
2025-10-12 16:25:01,129:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:01,129:INFO:Creating metrics dataframe
2025-10-12 16:25:01,136:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:25:01,137:INFO:Total runtime is 0.20726050138473506 minutes
2025-10-12 16:25:01,139:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:01,140:INFO:Initializing create_model()
2025-10-12 16:25:01,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:01,140:INFO:Checking exceptions
2025-10-12 16:25:01,140:INFO:Importing libraries
2025-10-12 16:25:01,140:INFO:Copying training dataset
2025-10-12 16:25:01,143:INFO:Defining folds
2025-10-12 16:25:01,143:INFO:Declaring metric variables
2025-10-12 16:25:01,145:INFO:Importing untrained model
2025-10-12 16:25:01,149:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:25:01,156:INFO:Starting cross validation
2025-10-12 16:25:01,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:01,217:INFO:Calculating mean and std
2025-10-12 16:25:01,217:INFO:Creating metrics dataframe
2025-10-12 16:25:01,219:INFO:Uploading results into container
2025-10-12 16:25:01,219:INFO:Uploading model into container now
2025-10-12 16:25:01,219:INFO:_master_model_container: 11
2025-10-12 16:25:01,219:INFO:_display_container: 2
2025-10-12 16:25:01,219:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:25:01,220:INFO:create_model() successfully completed......................................
2025-10-12 16:25:01,315:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:01,315:INFO:Creating metrics dataframe
2025-10-12 16:25:01,321:INFO:Initializing Extra Trees Classifier
2025-10-12 16:25:01,321:INFO:Total runtime is 0.21032854715983068 minutes
2025-10-12 16:25:01,325:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:01,325:INFO:Initializing create_model()
2025-10-12 16:25:01,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:01,326:INFO:Checking exceptions
2025-10-12 16:25:01,326:INFO:Importing libraries
2025-10-12 16:25:01,326:INFO:Copying training dataset
2025-10-12 16:25:01,334:INFO:Defining folds
2025-10-12 16:25:01,334:INFO:Declaring metric variables
2025-10-12 16:25:01,338:INFO:Importing untrained model
2025-10-12 16:25:01,341:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:25:01,346:INFO:Starting cross validation
2025-10-12 16:25:01,347:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:01,589:INFO:Calculating mean and std
2025-10-12 16:25:01,590:INFO:Creating metrics dataframe
2025-10-12 16:25:01,591:INFO:Uploading results into container
2025-10-12 16:25:01,591:INFO:Uploading model into container now
2025-10-12 16:25:01,592:INFO:_master_model_container: 12
2025-10-12 16:25:01,592:INFO:_display_container: 2
2025-10-12 16:25:01,592:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8866, verbose=0,
                     warm_start=False)
2025-10-12 16:25:01,592:INFO:create_model() successfully completed......................................
2025-10-12 16:25:01,690:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:01,690:INFO:Creating metrics dataframe
2025-10-12 16:25:01,697:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:25:01,698:INFO:Total runtime is 0.21660532951354974 minutes
2025-10-12 16:25:01,701:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:01,701:INFO:Initializing create_model()
2025-10-12 16:25:01,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:01,701:INFO:Checking exceptions
2025-10-12 16:25:01,701:INFO:Importing libraries
2025-10-12 16:25:01,701:INFO:Copying training dataset
2025-10-12 16:25:01,704:INFO:Defining folds
2025-10-12 16:25:01,705:INFO:Declaring metric variables
2025-10-12 16:25:01,708:INFO:Importing untrained model
2025-10-12 16:25:01,712:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:25:01,718:INFO:Starting cross validation
2025-10-12 16:25:01,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:02,276:INFO:Calculating mean and std
2025-10-12 16:25:02,277:INFO:Creating metrics dataframe
2025-10-12 16:25:02,278:INFO:Uploading results into container
2025-10-12 16:25:02,279:INFO:Uploading model into container now
2025-10-12 16:25:02,279:INFO:_master_model_container: 13
2025-10-12 16:25:02,279:INFO:_display_container: 2
2025-10-12 16:25:02,280:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:25:02,280:INFO:create_model() successfully completed......................................
2025-10-12 16:25:02,374:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:02,374:INFO:Creating metrics dataframe
2025-10-12 16:25:02,382:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:25:02,382:INFO:Total runtime is 0.2280166586240132 minutes
2025-10-12 16:25:02,386:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:02,386:INFO:Initializing create_model()
2025-10-12 16:25:02,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:02,387:INFO:Checking exceptions
2025-10-12 16:25:02,387:INFO:Importing libraries
2025-10-12 16:25:02,387:INFO:Copying training dataset
2025-10-12 16:25:02,391:INFO:Defining folds
2025-10-12 16:25:02,391:INFO:Declaring metric variables
2025-10-12 16:25:02,394:INFO:Importing untrained model
2025-10-12 16:25:02,398:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:25:02,404:INFO:Starting cross validation
2025-10-12 16:25:02,405:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:03,812:INFO:Calculating mean and std
2025-10-12 16:25:03,814:INFO:Creating metrics dataframe
2025-10-12 16:25:03,816:INFO:Uploading results into container
2025-10-12 16:25:03,817:INFO:Uploading model into container now
2025-10-12 16:25:03,818:INFO:_master_model_container: 14
2025-10-12 16:25:03,818:INFO:_display_container: 2
2025-10-12 16:25:03,819:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8866, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:25:03,819:INFO:create_model() successfully completed......................................
2025-10-12 16:25:03,945:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:03,945:INFO:Creating metrics dataframe
2025-10-12 16:25:03,951:INFO:Initializing CatBoost Classifier
2025-10-12 16:25:03,951:INFO:Total runtime is 0.25415731668472286 minutes
2025-10-12 16:25:03,954:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:03,955:INFO:Initializing create_model()
2025-10-12 16:25:03,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:03,955:INFO:Checking exceptions
2025-10-12 16:25:03,955:INFO:Importing libraries
2025-10-12 16:25:03,955:INFO:Copying training dataset
2025-10-12 16:25:03,958:INFO:Defining folds
2025-10-12 16:25:03,958:INFO:Declaring metric variables
2025-10-12 16:25:03,961:INFO:Importing untrained model
2025-10-12 16:25:03,964:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:25:03,970:INFO:Starting cross validation
2025-10-12 16:25:03,972:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:07,742:INFO:Calculating mean and std
2025-10-12 16:25:07,744:INFO:Creating metrics dataframe
2025-10-12 16:25:07,746:INFO:Uploading results into container
2025-10-12 16:25:07,746:INFO:Uploading model into container now
2025-10-12 16:25:07,747:INFO:_master_model_container: 15
2025-10-12 16:25:07,747:INFO:_display_container: 2
2025-10-12 16:25:07,747:INFO:<catboost.core.CatBoostClassifier object at 0x00000279D3F17C40>
2025-10-12 16:25:07,747:INFO:create_model() successfully completed......................................
2025-10-12 16:25:07,848:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:07,848:INFO:Creating metrics dataframe
2025-10-12 16:25:07,856:INFO:Initializing Dummy Classifier
2025-10-12 16:25:07,856:INFO:Total runtime is 0.31924534638722735 minutes
2025-10-12 16:25:07,860:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:07,860:INFO:Initializing create_model()
2025-10-12 16:25:07,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3F74DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:07,860:INFO:Checking exceptions
2025-10-12 16:25:07,860:INFO:Importing libraries
2025-10-12 16:25:07,861:INFO:Copying training dataset
2025-10-12 16:25:07,864:INFO:Defining folds
2025-10-12 16:25:07,864:INFO:Declaring metric variables
2025-10-12 16:25:07,868:INFO:Importing untrained model
2025-10-12 16:25:07,870:INFO:Dummy Classifier Imported successfully
2025-10-12 16:25:07,875:INFO:Starting cross validation
2025-10-12 16:25:07,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:07,901:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:07,904:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:07,904:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:07,905:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:07,908:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:07,909:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:07,915:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:07,915:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:07,918:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:07,928:INFO:Calculating mean and std
2025-10-12 16:25:07,928:INFO:Creating metrics dataframe
2025-10-12 16:25:07,929:INFO:Uploading results into container
2025-10-12 16:25:07,931:INFO:Uploading model into container now
2025-10-12 16:25:07,931:INFO:_master_model_container: 16
2025-10-12 16:25:07,931:INFO:_display_container: 2
2025-10-12 16:25:07,931:INFO:DummyClassifier(constant=None, random_state=8866, strategy='prior')
2025-10-12 16:25:07,931:INFO:create_model() successfully completed......................................
2025-10-12 16:25:08,026:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:08,026:INFO:Creating metrics dataframe
2025-10-12 16:25:08,034:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:25:08,041:INFO:Initializing create_model()
2025-10-12 16:25:08,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:08,041:INFO:Checking exceptions
2025-10-12 16:25:08,042:INFO:Importing libraries
2025-10-12 16:25:08,042:INFO:Copying training dataset
2025-10-12 16:25:08,045:INFO:Defining folds
2025-10-12 16:25:08,045:INFO:Declaring metric variables
2025-10-12 16:25:08,046:INFO:Importing untrained model
2025-10-12 16:25:08,046:INFO:Declaring custom model
2025-10-12 16:25:08,046:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:25:08,047:INFO:Cross validation set to False
2025-10-12 16:25:08,047:INFO:Fitting Model
2025-10-12 16:25:08,127:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:25:08,127:INFO:create_model() successfully completed......................................
2025-10-12 16:25:08,229:INFO:Creating Dashboard logs
2025-10-12 16:25:08,234:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:25:08,301:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8866, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:25:08,560:INFO:Initializing predict_model()
2025-10-12 16:25:08,560:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000279D3F8F8B0>)
2025-10-12 16:25:08,560:INFO:Checking exceptions
2025-10-12 16:25:08,560:INFO:Preloading libraries
2025-10-12 16:25:08,714:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:25:08,714:INFO:Initializing plot_model()
2025-10-12 16:25:08,714:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpph6cf_l8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:08,714:INFO:Checking exceptions
2025-10-12 16:25:08,716:INFO:Preloading libraries
2025-10-12 16:25:08,720:INFO:Copying training dataset
2025-10-12 16:25:08,720:INFO:Plot type: auc
2025-10-12 16:25:08,758:INFO:Fitting Model
2025-10-12 16:25:08,759:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:25:08,759:INFO:Scoring test/hold-out set
2025-10-12 16:25:08,777:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpph6cf_l8\AUC.png'
2025-10-12 16:25:08,967:INFO:Visual Rendered Successfully
2025-10-12 16:25:09,061:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:09,080:INFO:Initializing plot_model()
2025-10-12 16:25:09,080:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpph6cf_l8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:09,080:INFO:Checking exceptions
2025-10-12 16:25:09,081:INFO:Preloading libraries
2025-10-12 16:25:09,086:INFO:Copying training dataset
2025-10-12 16:25:09,086:INFO:Plot type: confusion_matrix
2025-10-12 16:25:09,125:INFO:Fitting Model
2025-10-12 16:25:09,125:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:25:09,125:INFO:Scoring test/hold-out set
2025-10-12 16:25:09,140:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpph6cf_l8\Confusion Matrix.png'
2025-10-12 16:25:09,219:INFO:Visual Rendered Successfully
2025-10-12 16:25:09,320:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:09,339:INFO:Initializing plot_model()
2025-10-12 16:25:09,339:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpph6cf_l8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:09,339:INFO:Checking exceptions
2025-10-12 16:25:09,340:INFO:Preloading libraries
2025-10-12 16:25:09,344:INFO:Copying training dataset
2025-10-12 16:25:09,345:INFO:Plot type: feature
2025-10-12 16:25:09,345:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:25:09,373:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpph6cf_l8\Feature Importance.png'
2025-10-12 16:25:09,488:INFO:Visual Rendered Successfully
2025-10-12 16:25:09,584:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:09,601:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:25:09,602:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml

2025-10-12 16:25:11,640:INFO:Creating Dashboard logs
2025-10-12 16:25:11,642:INFO:Model: CatBoost Classifier
2025-10-12 16:25:11,711:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-10-12 16:25:11,712:INFO:Logged params: {}
2025-10-12 16:25:12,101:INFO:Creating Dashboard logs
2025-10-12 16:25:12,104:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:25:12,176:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 8866, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:25:12,610:INFO:Creating Dashboard logs
2025-10-12 16:25:12,612:INFO:Model: Ada Boost Classifier
2025-10-12 16:25:12,678:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 8866}
2025-10-12 16:25:13,056:INFO:Creating Dashboard logs
2025-10-12 16:25:13,059:INFO:Model: Random Forest Classifier
2025-10-12 16:25:13,127:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8866, 'verbose': 0, 'warm_start': False}
2025-10-12 16:25:13,523:INFO:Creating Dashboard logs
2025-10-12 16:25:13,526:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 16:25:13,600:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:25:13,999:INFO:Creating Dashboard logs
2025-10-12 16:25:14,002:INFO:Model: Ridge Classifier
2025-10-12 16:25:14,084:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 8866, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:25:14,502:INFO:Creating Dashboard logs
2025-10-12 16:25:14,505:INFO:Model: Extra Trees Classifier
2025-10-12 16:25:14,576:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8866, 'verbose': 0, 'warm_start': False}
2025-10-12 16:25:14,969:INFO:Creating Dashboard logs
2025-10-12 16:25:14,972:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:25:15,047:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 8866, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:25:15,504:INFO:Creating Dashboard logs
2025-10-12 16:25:15,506:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:25:15,578:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:25:15,982:INFO:Creating Dashboard logs
2025-10-12 16:25:15,986:INFO:Model: Logistic Regression
2025-10-12 16:25:16,054:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 8866, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:25:16,460:INFO:Creating Dashboard logs
2025-10-12 16:25:16,462:INFO:Model: Naive Bayes
2025-10-12 16:25:16,538:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:25:16,939:INFO:Creating Dashboard logs
2025-10-12 16:25:16,943:INFO:Model: Decision Tree Classifier
2025-10-12 16:25:17,011:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 8866, 'splitter': 'best'}
2025-10-12 16:25:17,429:INFO:Creating Dashboard logs
2025-10-12 16:25:17,431:INFO:Model: K Neighbors Classifier
2025-10-12 16:25:17,492:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:25:17,896:INFO:Creating Dashboard logs
2025-10-12 16:25:17,900:INFO:Model: SVM - Linear Kernel
2025-10-12 16:25:17,970:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 8866, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:25:18,369:INFO:Creating Dashboard logs
2025-10-12 16:25:18,372:INFO:Model: Dummy Classifier
2025-10-12 16:25:18,436:INFO:Logged params: {'constant': None, 'random_state': 8866, 'strategy': 'prior'}
2025-10-12 16:25:18,771:INFO:_master_model_container: 16
2025-10-12 16:25:18,771:INFO:_display_container: 2
2025-10-12 16:25:18,771:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:25:18,772:INFO:compare_models() successfully completed......................................
2025-10-12 16:25:18,802:INFO:Initializing finalize_model()
2025-10-12 16:25:18,802:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-12 16:25:18,803:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:25:18,805:INFO:Initializing create_model()
2025-10-12 16:25:18,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:18,806:INFO:Checking exceptions
2025-10-12 16:25:18,808:INFO:Importing libraries
2025-10-12 16:25:18,808:INFO:Copying training dataset
2025-10-12 16:25:18,808:INFO:Defining folds
2025-10-12 16:25:18,808:INFO:Declaring metric variables
2025-10-12 16:25:18,808:INFO:Importing untrained model
2025-10-12 16:25:18,808:INFO:Declaring custom model
2025-10-12 16:25:18,809:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:25:18,809:INFO:Cross validation set to False
2025-10-12 16:25:18,809:INFO:Fitting Model
2025-10-12 16:25:18,954:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=8866, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-10-12 16:25:18,954:INFO:create_model() successfully completed......................................
2025-10-12 16:25:19,049:INFO:Creating Dashboard logs
2025-10-12 16:25:19,049:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:25:19,123:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8866, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:25:19,247:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:25:19,249:INFO:Initializing plot_model()
2025-10-12 16:25:19,249:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=8866, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp0nnwj6z2, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:19,249:INFO:Checking exceptions
2025-10-12 16:25:19,250:INFO:Preloading libraries
2025-10-12 16:25:19,255:INFO:Copying training dataset
2025-10-12 16:25:19,255:INFO:Plot type: auc
2025-10-12 16:25:19,299:INFO:Fitting Model
2025-10-12 16:25:19,299:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:25:19,300:INFO:Scoring test/hold-out set
2025-10-12 16:25:19,317:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp0nnwj6z2\AUC.png'
2025-10-12 16:25:19,488:INFO:Visual Rendered Successfully
2025-10-12 16:25:19,581:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:19,612:INFO:Initializing plot_model()
2025-10-12 16:25:19,612:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=8866, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp0nnwj6z2, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:19,612:INFO:Checking exceptions
2025-10-12 16:25:19,614:INFO:Preloading libraries
2025-10-12 16:25:19,617:INFO:Copying training dataset
2025-10-12 16:25:19,617:INFO:Plot type: confusion_matrix
2025-10-12 16:25:19,659:INFO:Fitting Model
2025-10-12 16:25:19,659:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:25:19,659:INFO:Scoring test/hold-out set
2025-10-12 16:25:19,672:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp0nnwj6z2\Confusion Matrix.png'
2025-10-12 16:25:19,751:INFO:Visual Rendered Successfully
2025-10-12 16:25:19,848:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:19,867:INFO:Initializing plot_model()
2025-10-12 16:25:19,867:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=8866, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp0nnwj6z2, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:19,868:INFO:Checking exceptions
2025-10-12 16:25:19,869:INFO:Preloading libraries
2025-10-12 16:25:19,875:INFO:Copying training dataset
2025-10-12 16:25:19,875:INFO:Plot type: feature
2025-10-12 16:25:19,875:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:25:19,900:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp0nnwj6z2\Feature Importance.png'
2025-10-12 16:25:19,985:INFO:Visual Rendered Successfully
2025-10-12 16:25:20,082:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:20,099:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:25:20,275:INFO:_master_model_container: 16
2025-10-12 16:25:20,275:INFO:_display_container: 2
2025-10-12 16:25:20,277:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=8866, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-10-12 16:25:20,277:INFO:finalize_model() successfully completed......................................
2025-10-12 16:25:20,376:INFO:Initializing save_model()
2025-10-12 16:25:20,376:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=8866, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=Titanic_modelV1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 16:25:20,376:INFO:Adding model into prep_pipe
2025-10-12 16:25:20,376:WARNING:Only Model saved as it was a pipeline.
2025-10-12 16:25:20,382:INFO:Titanic_modelV1.pkl saved in current working directory
2025-10-12 16:25:20,384:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=8866, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-10-12 16:25:20,384:INFO:save_model() successfully completed......................................
2025-10-12 16:25:20,505:INFO:Initializing tune_model()
2025-10-12 16:25:20,505:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>)
2025-10-12 16:25:20,505:INFO:Checking exceptions
2025-10-12 16:25:20,518:INFO:Copying training dataset
2025-10-12 16:25:20,520:INFO:Checking base model
2025-10-12 16:25:20,521:INFO:Base model : Gradient Boosting Classifier
2025-10-12 16:25:20,524:INFO:Declaring metric variables
2025-10-12 16:25:20,526:INFO:Defining Hyperparameters
2025-10-12 16:25:20,626:INFO:Tuning with n_jobs=-1
2025-10-12 16:25:20,626:INFO:Initializing RandomizedSearchCV
2025-10-12 16:25:23,004:INFO:best_params: {'actual_estimator__subsample': 0.95, 'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 4, 'actual_estimator__learning_rate': 0.001}
2025-10-12 16:25:23,005:INFO:Hyperparameter search completed
2025-10-12 16:25:23,005:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:23,005:INFO:Initializing create_model()
2025-10-12 16:25:23,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D3AEE670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.95, 'n_estimators': 160, 'min_samples_split': 10, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.1, 'max_features': 'log2', 'max_depth': 4, 'learning_rate': 0.001})
2025-10-12 16:25:23,006:INFO:Checking exceptions
2025-10-12 16:25:23,006:INFO:Importing libraries
2025-10-12 16:25:23,006:INFO:Copying training dataset
2025-10-12 16:25:23,009:INFO:Defining folds
2025-10-12 16:25:23,009:INFO:Declaring metric variables
2025-10-12 16:25:23,012:INFO:Importing untrained model
2025-10-12 16:25:23,012:INFO:Declaring custom model
2025-10-12 16:25:23,015:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:25:23,020:INFO:Starting cross validation
2025-10-12 16:25:23,021:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:23,259:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:23,266:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:23,269:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:23,269:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:23,278:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:23,331:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:23,337:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:23,340:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:23,345:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:23,348:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:23,359:INFO:Calculating mean and std
2025-10-12 16:25:23,360:INFO:Creating metrics dataframe
2025-10-12 16:25:23,365:INFO:Finalizing model
2025-10-12 16:25:23,511:INFO:Uploading results into container
2025-10-12 16:25:23,512:INFO:Uploading model into container now
2025-10-12 16:25:23,512:INFO:_master_model_container: 17
2025-10-12 16:25:23,512:INFO:_display_container: 3
2025-10-12 16:25:23,512:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=4,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.1, min_samples_leaf=3,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8866, subsample=0.95, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:25:23,512:INFO:create_model() successfully completed......................................
2025-10-12 16:25:23,614:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:23,614:INFO:choose_better activated
2025-10-12 16:25:23,617:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:23,617:INFO:Initializing create_model()
2025-10-12 16:25:23,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:23,617:INFO:Checking exceptions
2025-10-12 16:25:23,619:INFO:Importing libraries
2025-10-12 16:25:23,619:INFO:Copying training dataset
2025-10-12 16:25:23,621:INFO:Defining folds
2025-10-12 16:25:23,621:INFO:Declaring metric variables
2025-10-12 16:25:23,621:INFO:Importing untrained model
2025-10-12 16:25:23,621:INFO:Declaring custom model
2025-10-12 16:25:23,623:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:25:23,623:INFO:Starting cross validation
2025-10-12 16:25:23,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:23,844:INFO:Calculating mean and std
2025-10-12 16:25:23,844:INFO:Creating metrics dataframe
2025-10-12 16:25:23,846:INFO:Finalizing model
2025-10-12 16:25:23,935:INFO:Uploading results into container
2025-10-12 16:25:23,936:INFO:Uploading model into container now
2025-10-12 16:25:23,936:INFO:_master_model_container: 18
2025-10-12 16:25:23,936:INFO:_display_container: 4
2025-10-12 16:25:23,937:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:25:23,937:INFO:create_model() successfully completed......................................
2025-10-12 16:25:24,051:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:24,052:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8759
2025-10-12 16:25:24,052:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=4,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.1, min_samples_leaf=3,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8866, subsample=0.95, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8566
2025-10-12 16:25:24,052:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-12 16:25:24,052:INFO:choose_better completed
2025-10-12 16:25:24,052:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-12 16:25:24,054:INFO:Creating Dashboard logs
2025-10-12 16:25:24,057:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:25:24,136:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8866, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:25:24,350:INFO:Initializing predict_model()
2025-10-12 16:25:24,350:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000279D4682790>)
2025-10-12 16:25:24,350:INFO:Checking exceptions
2025-10-12 16:25:24,350:INFO:Preloading libraries
2025-10-12 16:25:24,511:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:25:24,511:INFO:Initializing plot_model()
2025-10-12 16:25:24,511:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp0xi0awhu, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:24,512:INFO:Checking exceptions
2025-10-12 16:25:24,512:INFO:Preloading libraries
2025-10-12 16:25:24,517:INFO:Copying training dataset
2025-10-12 16:25:24,517:INFO:Plot type: auc
2025-10-12 16:25:24,565:INFO:Fitting Model
2025-10-12 16:25:24,565:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:25:24,565:INFO:Scoring test/hold-out set
2025-10-12 16:25:24,580:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp0xi0awhu\AUC.png'
2025-10-12 16:25:24,746:INFO:Visual Rendered Successfully
2025-10-12 16:25:24,844:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:24,861:INFO:Initializing plot_model()
2025-10-12 16:25:24,861:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp0xi0awhu, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:24,861:INFO:Checking exceptions
2025-10-12 16:25:24,862:INFO:Preloading libraries
2025-10-12 16:25:24,867:INFO:Copying training dataset
2025-10-12 16:25:24,867:INFO:Plot type: confusion_matrix
2025-10-12 16:25:24,912:INFO:Fitting Model
2025-10-12 16:25:24,913:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:25:24,913:INFO:Scoring test/hold-out set
2025-10-12 16:25:24,929:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp0xi0awhu\Confusion Matrix.png'
2025-10-12 16:25:25,015:INFO:Visual Rendered Successfully
2025-10-12 16:25:25,116:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:25,135:INFO:Initializing plot_model()
2025-10-12 16:25:25,135:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp0xi0awhu, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:25,135:INFO:Checking exceptions
2025-10-12 16:25:25,137:INFO:Preloading libraries
2025-10-12 16:25:25,141:INFO:Copying training dataset
2025-10-12 16:25:25,141:INFO:Plot type: feature
2025-10-12 16:25:25,141:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:25:25,172:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp0xi0awhu\Feature Importance.png'
2025-10-12 16:25:25,281:INFO:Visual Rendered Successfully
2025-10-12 16:25:25,380:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:25,396:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:25:25,625:INFO:_master_model_container: 18
2025-10-12 16:25:25,625:INFO:_display_container: 3
2025-10-12 16:25:25,626:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:25:25,626:INFO:tune_model() successfully completed......................................
2025-10-12 16:25:25,758:INFO:Initializing tune_model()
2025-10-12 16:25:25,758:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>)
2025-10-12 16:25:25,758:INFO:Checking exceptions
2025-10-12 16:25:25,758:INFO:Soft dependency imported: optuna: 4.5.0
2025-10-12 16:25:25,895:INFO:Copying training dataset
2025-10-12 16:25:25,900:INFO:Checking base model
2025-10-12 16:25:25,900:INFO:Base model : Gradient Boosting Classifier
2025-10-12 16:25:25,904:INFO:Declaring metric variables
2025-10-12 16:25:25,909:INFO:Defining Hyperparameters
2025-10-12 16:25:26,025:INFO:Tuning with n_jobs=-1
2025-10-12 16:25:26,025:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.

2025-10-12 16:25:26,025:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.

2025-10-12 16:25:26,026:INFO:Initializing optuna.integration.OptunaSearchCV
2025-10-12 16:25:26,041:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.

2025-10-12 16:25:46,819:INFO:best_params: {'actual_estimator__n_estimators': 70, 'actual_estimator__learning_rate': 3.7663381860222148e-06, 'actual_estimator__subsample': 0.6544559995736583, 'actual_estimator__min_samples_split': 8, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__max_depth': 5, 'actual_estimator__min_impurity_decrease': 3.4876047559336756e-09, 'actual_estimator__max_features': 0.9039431353683158}
2025-10-12 16:25:46,821:INFO:Hyperparameter search completed
2025-10-12 16:25:46,821:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:46,822:INFO:Initializing create_model()
2025-10-12 16:25:46,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D416B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 70, 'learning_rate': 3.7663381860222148e-06, 'subsample': 0.6544559995736583, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_depth': 5, 'min_impurity_decrease': 3.4876047559336756e-09, 'max_features': 0.9039431353683158})
2025-10-12 16:25:46,822:INFO:Checking exceptions
2025-10-12 16:25:46,822:INFO:Importing libraries
2025-10-12 16:25:46,822:INFO:Copying training dataset
2025-10-12 16:25:46,825:INFO:Defining folds
2025-10-12 16:25:46,826:INFO:Declaring metric variables
2025-10-12 16:25:46,828:INFO:Importing untrained model
2025-10-12 16:25:46,828:INFO:Declaring custom model
2025-10-12 16:25:46,831:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:25:46,837:INFO:Starting cross validation
2025-10-12 16:25:46,837:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:46,988:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:47,004:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:47,006:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:47,006:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:47,008:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:47,013:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:47,015:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:47,020:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:47,020:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:47,031:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:25:47,044:INFO:Calculating mean and std
2025-10-12 16:25:47,045:INFO:Creating metrics dataframe
2025-10-12 16:25:47,049:INFO:Finalizing model
2025-10-12 16:25:47,129:INFO:Uploading results into container
2025-10-12 16:25:47,129:INFO:Uploading model into container now
2025-10-12 16:25:47,131:INFO:_master_model_container: 19
2025-10-12 16:25:47,131:INFO:_display_container: 4
2025-10-12 16:25:47,131:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=3.7663381860222148e-06,
                           loss='log_loss', max_depth=5,
                           max_features=0.9039431353683158, max_leaf_nodes=None,
                           min_impurity_decrease=3.4876047559336756e-09,
                           min_samples_leaf=4, min_samples_split=8,
                           min_weight_fraction_leaf=0.0, n_estimators=70,
                           n_iter_no_change=None, random_state=8866,
                           subsample=0.6544559995736583, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:25:47,131:INFO:create_model() successfully completed......................................
2025-10-12 16:25:47,238:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:47,238:INFO:choose_better activated
2025-10-12 16:25:47,241:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:47,241:INFO:Initializing create_model()
2025-10-12 16:25:47,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:47,241:INFO:Checking exceptions
2025-10-12 16:25:47,243:INFO:Importing libraries
2025-10-12 16:25:47,243:INFO:Copying training dataset
2025-10-12 16:25:47,245:INFO:Defining folds
2025-10-12 16:25:47,245:INFO:Declaring metric variables
2025-10-12 16:25:47,246:INFO:Importing untrained model
2025-10-12 16:25:47,246:INFO:Declaring custom model
2025-10-12 16:25:47,246:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:25:47,246:INFO:Starting cross validation
2025-10-12 16:25:47,247:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:47,467:INFO:Calculating mean and std
2025-10-12 16:25:47,467:INFO:Creating metrics dataframe
2025-10-12 16:25:47,469:INFO:Finalizing model
2025-10-12 16:25:47,548:INFO:Uploading results into container
2025-10-12 16:25:47,548:INFO:Uploading model into container now
2025-10-12 16:25:47,549:INFO:_master_model_container: 20
2025-10-12 16:25:47,549:INFO:_display_container: 5
2025-10-12 16:25:47,549:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:25:47,549:INFO:create_model() successfully completed......................................
2025-10-12 16:25:47,647:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:47,648:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8759
2025-10-12 16:25:47,648:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=3.7663381860222148e-06,
                           loss='log_loss', max_depth=5,
                           max_features=0.9039431353683158, max_leaf_nodes=None,
                           min_impurity_decrease=3.4876047559336756e-09,
                           min_samples_leaf=4, min_samples_split=8,
                           min_weight_fraction_leaf=0.0, n_estimators=70,
                           n_iter_no_change=None, random_state=8866,
                           subsample=0.6544559995736583, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8581
2025-10-12 16:25:47,648:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-12 16:25:47,648:INFO:choose_better completed
2025-10-12 16:25:47,649:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-12 16:25:47,649:INFO:Creating Dashboard logs
2025-10-12 16:25:47,651:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:25:47,755:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8866, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:25:47,990:INFO:Initializing predict_model()
2025-10-12 16:25:47,991:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000279C72344C0>)
2025-10-12 16:25:47,991:INFO:Checking exceptions
2025-10-12 16:25:47,991:INFO:Preloading libraries
2025-10-12 16:25:48,126:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:25:48,127:INFO:Initializing plot_model()
2025-10-12 16:25:48,127:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpru2ztg9k, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:48,127:INFO:Checking exceptions
2025-10-12 16:25:48,128:INFO:Preloading libraries
2025-10-12 16:25:48,133:INFO:Copying training dataset
2025-10-12 16:25:48,133:INFO:Plot type: auc
2025-10-12 16:25:48,178:INFO:Fitting Model
2025-10-12 16:25:48,178:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:25:48,178:INFO:Scoring test/hold-out set
2025-10-12 16:25:48,194:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpru2ztg9k\AUC.png'
2025-10-12 16:25:48,352:INFO:Visual Rendered Successfully
2025-10-12 16:25:48,462:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:48,482:INFO:Initializing plot_model()
2025-10-12 16:25:48,482:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpru2ztg9k, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:48,482:INFO:Checking exceptions
2025-10-12 16:25:48,484:INFO:Preloading libraries
2025-10-12 16:25:48,488:INFO:Copying training dataset
2025-10-12 16:25:48,488:INFO:Plot type: confusion_matrix
2025-10-12 16:25:48,542:INFO:Fitting Model
2025-10-12 16:25:48,542:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:25:48,544:INFO:Scoring test/hold-out set
2025-10-12 16:25:48,563:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpru2ztg9k\Confusion Matrix.png'
2025-10-12 16:25:48,661:INFO:Visual Rendered Successfully
2025-10-12 16:25:48,774:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:48,787:INFO:Initializing plot_model()
2025-10-12 16:25:48,787:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpru2ztg9k, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:48,787:INFO:Checking exceptions
2025-10-12 16:25:48,789:INFO:Preloading libraries
2025-10-12 16:25:48,794:INFO:Copying training dataset
2025-10-12 16:25:48,794:INFO:Plot type: feature
2025-10-12 16:25:48,795:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:25:48,822:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpru2ztg9k\Feature Importance.png'
2025-10-12 16:25:48,933:INFO:Visual Rendered Successfully
2025-10-12 16:25:49,039:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:49,055:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:25:49,261:INFO:_master_model_container: 20
2025-10-12 16:25:49,261:INFO:_display_container: 4
2025-10-12 16:25:49,261:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:25:49,261:INFO:tune_model() successfully completed......................................
2025-10-12 16:25:49,391:INFO:Initializing ensemble_model()
2025-10-12 16:25:49,391:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), method=Bagging, fold=None, n_estimators=5, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:25:49,391:INFO:Checking exceptions
2025-10-12 16:25:49,406:INFO:Importing libraries
2025-10-12 16:25:49,407:INFO:Copying training dataset
2025-10-12 16:25:49,407:INFO:Checking base model
2025-10-12 16:25:49,407:INFO:Base model : Gradient Boosting Classifier
2025-10-12 16:25:49,415:INFO:Importing untrained ensembler
2025-10-12 16:25:49,415:INFO:Ensemble method set to Bagging
2025-10-12 16:25:49,416:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:49,417:INFO:Initializing create_model()
2025-10-12 16:25:49,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=8866,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=8866, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279CA373520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:49,418:INFO:Checking exceptions
2025-10-12 16:25:49,418:INFO:Importing libraries
2025-10-12 16:25:49,418:INFO:Copying training dataset
2025-10-12 16:25:49,421:INFO:Defining folds
2025-10-12 16:25:49,421:INFO:Declaring metric variables
2025-10-12 16:25:49,424:INFO:Importing untrained model
2025-10-12 16:25:49,424:INFO:Declaring custom model
2025-10-12 16:25:49,429:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:25:49,436:INFO:Starting cross validation
2025-10-12 16:25:49,437:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:50,281:INFO:Calculating mean and std
2025-10-12 16:25:50,281:INFO:Creating metrics dataframe
2025-10-12 16:25:50,285:INFO:Finalizing model
2025-10-12 16:25:50,750:INFO:Uploading results into container
2025-10-12 16:25:50,752:INFO:Uploading model into container now
2025-10-12 16:25:50,752:INFO:_master_model_container: 21
2025-10-12 16:25:50,752:INFO:_display_container: 5
2025-10-12 16:25:50,754:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=8866,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=8866, verbose=0,
                  warm_start=False)
2025-10-12 16:25:50,754:INFO:create_model() successfully completed......................................
2025-10-12 16:25:50,855:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:50,855:INFO:Creating Dashboard logs
2025-10-12 16:25:50,858:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:25:50,929:INFO:Logged params: {'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__criterion': 'friedman_mse', 'estimator__init': None, 'estimator__learning_rate': 0.1, 'estimator__loss': 'log_loss', 'estimator__max_depth': 3, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_iter_no_change': None, 'estimator__random_state': 8866, 'estimator__subsample': 1.0, 'estimator__tol': 0.0001, 'estimator__validation_fraction': 0.1, 'estimator__verbose': 0, 'estimator__warm_start': False, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 5, 'n_jobs': None, 'oob_score': False, 'random_state': 8866, 'verbose': 0, 'warm_start': False}
2025-10-12 16:25:51,217:INFO:Initializing predict_model()
2025-10-12 16:25:51,217:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=8866,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=8866, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000279C724A430>)
2025-10-12 16:25:51,217:INFO:Checking exceptions
2025-10-12 16:25:51,217:INFO:Preloading libraries
2025-10-12 16:25:51,380:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:25:51,381:INFO:Initializing plot_model()
2025-10-12 16:25:51,381:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=8866,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=8866, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp3vyc0va5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:51,381:INFO:Checking exceptions
2025-10-12 16:25:51,382:INFO:Preloading libraries
2025-10-12 16:25:51,404:INFO:Copying training dataset
2025-10-12 16:25:51,404:INFO:Plot type: auc
2025-10-12 16:25:51,446:INFO:Fitting Model
2025-10-12 16:25:51,446:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 16:25:51,447:INFO:Scoring test/hold-out set
2025-10-12 16:25:51,465:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp3vyc0va5\AUC.png'
2025-10-12 16:25:51,624:INFO:Visual Rendered Successfully
2025-10-12 16:25:51,725:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:51,745:INFO:Initializing plot_model()
2025-10-12 16:25:51,745:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=8866,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=8866, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp3vyc0va5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:51,745:INFO:Checking exceptions
2025-10-12 16:25:51,746:INFO:Preloading libraries
2025-10-12 16:25:51,766:INFO:Copying training dataset
2025-10-12 16:25:51,766:INFO:Plot type: confusion_matrix
2025-10-12 16:25:51,811:INFO:Fitting Model
2025-10-12 16:25:51,811:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 16:25:51,811:INFO:Scoring test/hold-out set
2025-10-12 16:25:51,831:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp3vyc0va5\Confusion Matrix.png'
2025-10-12 16:25:51,911:INFO:Visual Rendered Successfully
2025-10-12 16:25:52,011:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:52,026:INFO:Initializing plot_model()
2025-10-12 16:25:52,026:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=8866,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=8866, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp3vyc0va5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:52,026:INFO:Checking exceptions
2025-10-12 16:25:52,027:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 16:25:52,028:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:25:52,223:INFO:_master_model_container: 21
2025-10-12 16:25:52,223:INFO:_display_container: 5
2025-10-12 16:25:52,224:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=8866,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=8866, verbose=0,
                  warm_start=False)
2025-10-12 16:25:52,225:INFO:ensemble_model() successfully completed......................................
2025-10-12 16:25:52,325:INFO:Initializing predict_model()
2025-10-12 16:25:52,325:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=8866,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=8866, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000279D3F23CA0>)
2025-10-12 16:25:52,325:INFO:Checking exceptions
2025-10-12 16:25:52,325:INFO:Preloading libraries
2025-10-12 16:25:52,502:INFO:Initializing create_model()
2025-10-12 16:25:52,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:52,502:INFO:Checking exceptions
2025-10-12 16:25:52,514:INFO:Importing libraries
2025-10-12 16:25:52,514:INFO:Copying training dataset
2025-10-12 16:25:52,518:INFO:Defining folds
2025-10-12 16:25:52,518:INFO:Declaring metric variables
2025-10-12 16:25:52,521:INFO:Importing untrained model
2025-10-12 16:25:52,524:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:25:52,529:INFO:Starting cross validation
2025-10-12 16:25:52,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:52,594:INFO:Calculating mean and std
2025-10-12 16:25:52,594:INFO:Creating metrics dataframe
2025-10-12 16:25:52,599:INFO:Finalizing model
2025-10-12 16:25:52,606:INFO:Creating Dashboard logs
2025-10-12 16:25:52,608:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:25:52,679:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:25:52,921:INFO:Initializing predict_model()
2025-10-12 16:25:52,922:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000279C72D2C10>)
2025-10-12 16:25:52,922:INFO:Checking exceptions
2025-10-12 16:25:52,922:INFO:Preloading libraries
2025-10-12 16:25:53,092:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:25:53,092:INFO:Initializing plot_model()
2025-10-12 16:25:53,092:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp7gu7zhod, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:53,092:INFO:Checking exceptions
2025-10-12 16:25:53,094:INFO:Preloading libraries
2025-10-12 16:25:53,094:INFO:Copying training dataset
2025-10-12 16:25:53,094:INFO:Plot type: auc
2025-10-12 16:25:53,139:INFO:Fitting Model
2025-10-12 16:25:53,140:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:25:53,140:INFO:Scoring test/hold-out set
2025-10-12 16:25:53,154:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp7gu7zhod\AUC.png'
2025-10-12 16:25:53,325:INFO:Visual Rendered Successfully
2025-10-12 16:25:53,427:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:53,438:INFO:Initializing plot_model()
2025-10-12 16:25:53,438:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp7gu7zhod, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:53,438:INFO:Checking exceptions
2025-10-12 16:25:53,439:INFO:Preloading libraries
2025-10-12 16:25:53,439:INFO:Copying training dataset
2025-10-12 16:25:53,439:INFO:Plot type: confusion_matrix
2025-10-12 16:25:53,483:INFO:Fitting Model
2025-10-12 16:25:53,483:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:25:53,484:INFO:Scoring test/hold-out set
2025-10-12 16:25:53,498:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp7gu7zhod\Confusion Matrix.png'
2025-10-12 16:25:53,580:INFO:Visual Rendered Successfully
2025-10-12 16:25:53,681:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:53,698:INFO:Initializing plot_model()
2025-10-12 16:25:53,698:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp7gu7zhod, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:53,698:INFO:Checking exceptions
2025-10-12 16:25:53,699:INFO:Preloading libraries
2025-10-12 16:25:53,699:INFO:Copying training dataset
2025-10-12 16:25:53,700:INFO:Plot type: feature
2025-10-12 16:25:53,734:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp7gu7zhod\Feature Importance.png'
2025-10-12 16:25:53,829:INFO:Visual Rendered Successfully
2025-10-12 16:25:53,937:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:53,954:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:25:54,129:INFO:Uploading results into container
2025-10-12 16:25:54,131:INFO:Uploading model into container now
2025-10-12 16:25:54,138:INFO:_master_model_container: 22
2025-10-12 16:25:54,139:INFO:_display_container: 7
2025-10-12 16:25:54,139:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:25:54,139:INFO:create_model() successfully completed......................................
2025-10-12 16:25:54,237:INFO:Initializing create_model()
2025-10-12 16:25:54,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=ridge, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:54,237:INFO:Checking exceptions
2025-10-12 16:25:54,247:INFO:Importing libraries
2025-10-12 16:25:54,248:INFO:Copying training dataset
2025-10-12 16:25:54,250:INFO:Defining folds
2025-10-12 16:25:54,250:INFO:Declaring metric variables
2025-10-12 16:25:54,252:INFO:Importing untrained model
2025-10-12 16:25:54,256:INFO:Ridge Classifier Imported successfully
2025-10-12 16:25:54,263:INFO:Starting cross validation
2025-10-12 16:25:54,264:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:54,324:INFO:Calculating mean and std
2025-10-12 16:25:54,324:INFO:Creating metrics dataframe
2025-10-12 16:25:54,330:INFO:Finalizing model
2025-10-12 16:25:54,338:INFO:Creating Dashboard logs
2025-10-12 16:25:54,340:INFO:Model: Ridge Classifier
2025-10-12 16:25:54,408:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 8866, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:25:54,698:INFO:Initializing predict_model()
2025-10-12 16:25:54,698:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8866, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000279C7238E50>)
2025-10-12 16:25:54,698:INFO:Checking exceptions
2025-10-12 16:25:54,698:INFO:Preloading libraries
2025-10-12 16:25:54,872:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:25:54,872:INFO:Initializing plot_model()
2025-10-12 16:25:54,872:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8866, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpcp9aggei, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:54,872:INFO:Checking exceptions
2025-10-12 16:25:54,874:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:25:54,874:INFO:Initializing plot_model()
2025-10-12 16:25:54,874:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8866, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpcp9aggei, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:54,874:INFO:Checking exceptions
2025-10-12 16:25:54,875:INFO:Preloading libraries
2025-10-12 16:25:54,876:INFO:Copying training dataset
2025-10-12 16:25:54,876:INFO:Plot type: confusion_matrix
2025-10-12 16:25:54,922:INFO:Fitting Model
2025-10-12 16:25:54,922:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names

2025-10-12 16:25:54,924:INFO:Scoring test/hold-out set
2025-10-12 16:25:54,937:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpcp9aggei\Confusion Matrix.png'
2025-10-12 16:25:55,012:INFO:Visual Rendered Successfully
2025-10-12 16:25:55,114:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:55,126:INFO:Initializing plot_model()
2025-10-12 16:25:55,126:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8866, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpcp9aggei, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:55,126:INFO:Checking exceptions
2025-10-12 16:25:55,128:INFO:Preloading libraries
2025-10-12 16:25:55,128:INFO:Copying training dataset
2025-10-12 16:25:55,128:INFO:Plot type: feature
2025-10-12 16:25:55,167:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpcp9aggei\Feature Importance.png'
2025-10-12 16:25:55,255:INFO:Visual Rendered Successfully
2025-10-12 16:25:55,356:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:55,374:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:25:55,546:INFO:Uploading results into container
2025-10-12 16:25:55,547:INFO:Uploading model into container now
2025-10-12 16:25:55,553:INFO:_master_model_container: 23
2025-10-12 16:25:55,553:INFO:_display_container: 8
2025-10-12 16:25:55,553:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8866, solver='auto',
                tol=0.0001)
2025-10-12 16:25:55,553:INFO:create_model() successfully completed......................................
2025-10-12 16:25:55,661:INFO:Initializing create_model()
2025-10-12 16:25:55,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:55,661:INFO:Checking exceptions
2025-10-12 16:25:55,672:INFO:Importing libraries
2025-10-12 16:25:55,674:INFO:Copying training dataset
2025-10-12 16:25:55,677:INFO:Defining folds
2025-10-12 16:25:55,677:INFO:Declaring metric variables
2025-10-12 16:25:55,680:INFO:Importing untrained model
2025-10-12 16:25:55,685:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:25:55,692:INFO:Starting cross validation
2025-10-12 16:25:55,693:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:55,900:INFO:Calculating mean and std
2025-10-12 16:25:55,901:INFO:Creating metrics dataframe
2025-10-12 16:25:55,906:INFO:Finalizing model
2025-10-12 16:25:55,979:INFO:Creating Dashboard logs
2025-10-12 16:25:55,982:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:25:56,066:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8866, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:25:56,309:INFO:Initializing predict_model()
2025-10-12 16:25:56,309:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000279C7238A60>)
2025-10-12 16:25:56,309:INFO:Checking exceptions
2025-10-12 16:25:56,309:INFO:Preloading libraries
2025-10-12 16:25:56,448:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:25:56,448:INFO:Initializing plot_model()
2025-10-12 16:25:56,448:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp4mxpy9rb, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:56,448:INFO:Checking exceptions
2025-10-12 16:25:56,450:INFO:Preloading libraries
2025-10-12 16:25:56,454:INFO:Copying training dataset
2025-10-12 16:25:56,454:INFO:Plot type: auc
2025-10-12 16:25:56,494:INFO:Fitting Model
2025-10-12 16:25:56,495:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:25:56,495:INFO:Scoring test/hold-out set
2025-10-12 16:25:56,509:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp4mxpy9rb\AUC.png'
2025-10-12 16:25:56,675:INFO:Visual Rendered Successfully
2025-10-12 16:25:56,773:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:56,791:INFO:Initializing plot_model()
2025-10-12 16:25:56,792:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp4mxpy9rb, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:56,792:INFO:Checking exceptions
2025-10-12 16:25:56,794:INFO:Preloading libraries
2025-10-12 16:25:56,798:INFO:Copying training dataset
2025-10-12 16:25:56,798:INFO:Plot type: confusion_matrix
2025-10-12 16:25:56,839:INFO:Fitting Model
2025-10-12 16:25:56,839:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:25:56,839:INFO:Scoring test/hold-out set
2025-10-12 16:25:56,858:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp4mxpy9rb\Confusion Matrix.png'
2025-10-12 16:25:56,959:INFO:Visual Rendered Successfully
2025-10-12 16:25:57,058:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:57,076:INFO:Initializing plot_model()
2025-10-12 16:25:57,076:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp4mxpy9rb, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:57,076:INFO:Checking exceptions
2025-10-12 16:25:57,078:INFO:Preloading libraries
2025-10-12 16:25:57,081:INFO:Copying training dataset
2025-10-12 16:25:57,081:INFO:Plot type: feature
2025-10-12 16:25:57,082:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:25:57,106:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp4mxpy9rb\Feature Importance.png'
2025-10-12 16:25:57,212:INFO:Visual Rendered Successfully
2025-10-12 16:25:57,314:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:57,332:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:25:57,520:INFO:Uploading results into container
2025-10-12 16:25:57,521:INFO:Uploading model into container now
2025-10-12 16:25:57,534:INFO:_master_model_container: 24
2025-10-12 16:25:57,535:INFO:_display_container: 9
2025-10-12 16:25:57,535:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:25:57,536:INFO:create_model() successfully completed......................................
2025-10-12 16:25:57,642:INFO:Initializing blend_models()
2025-10-12 16:25:57,642:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8866, solver='auto',
                tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:25:57,642:INFO:Checking exceptions
2025-10-12 16:25:57,642:INFO:Estimator RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8866, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-12 16:25:57,652:INFO:Importing libraries
2025-10-12 16:25:57,652:INFO:Copying training dataset
2025-10-12 16:25:57,657:INFO:Getting model names
2025-10-12 16:25:57,659:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:57,663:INFO:Initializing create_model()
2025-10-12 16:25:57,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=8866,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279D4610FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:57,664:INFO:Checking exceptions
2025-10-12 16:25:57,664:INFO:Importing libraries
2025-10-12 16:25:57,664:INFO:Copying training dataset
2025-10-12 16:25:57,667:INFO:Defining folds
2025-10-12 16:25:57,667:INFO:Declaring metric variables
2025-10-12 16:25:57,670:INFO:Importing untrained model
2025-10-12 16:25:57,670:INFO:Declaring custom model
2025-10-12 16:25:57,674:INFO:Voting Classifier Imported successfully
2025-10-12 16:25:57,680:INFO:Starting cross validation
2025-10-12 16:25:57,681:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:57,979:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:25:57,979:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:25:57,979:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:25:57,997:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:25:57,997:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:25:57,998:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:25:58,023:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:25:58,023:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:25:58,023:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:25:58,023:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:25:58,043:INFO:Calculating mean and std
2025-10-12 16:25:58,043:INFO:Creating metrics dataframe
2025-10-12 16:25:58,047:INFO:Finalizing model
2025-10-12 16:25:58,155:INFO:Uploading results into container
2025-10-12 16:25:58,166:INFO:Uploading model into container now
2025-10-12 16:25:58,166:INFO:_master_model_container: 25
2025-10-12 16:25:58,167:INFO:_display_container: 10
2025-10-12 16:25:58,169:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=8866,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:25:58,169:INFO:create_model() successfully completed......................................
2025-10-12 16:25:58,268:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:58,269:INFO:Creating Dashboard logs
2025-10-12 16:25:58,272:INFO:Model: Voting Classifier
2025-10-12 16:25:58,359:INFO:Logged params: {'flatten_transform': True, 'n_jobs': -1, 'verbose': False, 'voting': 'hard', 'weights': None, 'Linear Discriminant Analysis': LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), 'Ridge Classifier': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8866, solver='auto',
                tol=0.0001), 'Gradient Boosting Classifier__ccp_alpha': 0.0, 'Gradient Boosting Classifier__criterion': 'friedman_mse', 'Gradient Boosting Classifier__init': None, 'Gradient Boosting Classifier__learning_rate': 0.1, 'Gradient Boosting Classifier__loss': 'log_loss', 'Gradient Boosting Classifier__max_depth': 3, 'Gradient Boosting Classifier__max_features': None, 'Gradient Boosting Classifier__max_leaf_nodes': None, 'Gradient Boosting Classifier__min_impurity_decrease': 0.0, 'Gradient Boosting Classifier__min_samples_leaf': 1, 'Gradient Boosting Classifier__min_samples_split': 2, 'Gradient Boosting Classifier__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Classifier__n_estimators': 100, 'Gradient Boosting Classifier__n_iter_no_change': None, 'Gradient Boosting Classifier__random_state': 8866, 'Gradient Boosting Classifier__subsample': 1.0, 'Gradient Boosting Classifier__tol': 0.0001, 'Gradient Boosting Classifier__validation_fraction': 0.1, 'Gradient Boosting Classifier__verbose': 0, 'Gradient Boosting Classifier__warm_start': False, 'Linear Discriminant Analysis__covariance_estimator': None, 'Linear Discriminant Analysis__n_components': None, 'Linear Discriminant Analysis__priors': None, 'Linear Discriminant Analysis__shrinkage': None, 'Linear Discriminant Analysis__solver': 'svd', 'Linear Discriminant Analysis__store_covariance': False, 'Linear Discriminant Analysis__tol': 0.0001, 'Ridge Classifier__alpha': 1.0, 'Ridge Classifier__class_weight': None, 'Ridge Classifier__copy_X': True, 'Ridge Classifier__fit_intercept': True, 'Ridge Classifier__max_iter': None, 'Ridge Classifier__positive': False, 'Ridge Classifier__random_state': 8866, 'Ridge Classifier__solver': 'auto', 'Ridge Classifier__tol': 0.0001, 'Gradient Boosting Classifier_1__ccp_alpha': 0.0, 'Gradient Boosting Classifier_1__criterion': 'friedman_mse', 'Gradient Boosting Classifier_1__init': None, 'Gradient Boosting Classifier_1__learning_rate': 0.1, 'Gradient Boosting Classifier_1__loss': 'log_loss', 'Gradient Boosting Classifier_1__max_depth': 3, 'Gradient Boosting Classifier_1__max_features': None, 'Gradient Boosting Classifier_1__max_leaf_nodes': None, 'Gradient Boosting Classifier_1__min_impurity_decrease': 0.0, 'Gradient Boosting Classifier_1__min_samples_leaf': 1, 'Gradient Boosting Classifier_1__min_samples_split': 2, 'Gradient Boosting Classifier_1__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Classifier_1__n_estimators': 100, 'Gradient Boosting Classifier_1__n_iter_no_change': None, 'Gradient Boosting Classifier_1__random_state': 8866, 'Gradient Boosting Classifier_1__subsample': 1.0, 'Gradient Boosting Classifier_1__tol': 0.0001, 'Gradient Boosting Classifier_1__validation_fraction': 0.1, 'Gradient Boosting Classifier_1__verbose': 0, 'Gradient Boosting Classifier_1__warm_start': False}
2025-10-12 16:25:58,715:INFO:Initializing predict_model()
2025-10-12 16:25:58,715:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=8866,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000279C72D2550>)
2025-10-12 16:25:58,715:INFO:Checking exceptions
2025-10-12 16:25:58,715:INFO:Preloading libraries
2025-10-12 16:25:58,869:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:25:58,871:INFO:Initializing plot_model()
2025-10-12 16:25:58,871:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=8866,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmptd33gvi7, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:58,871:INFO:Checking exceptions
2025-10-12 16:25:58,872:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:25:58,875:INFO:Initializing plot_model()
2025-10-12 16:25:58,875:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=8866,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmptd33gvi7, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:58,875:INFO:Checking exceptions
2025-10-12 16:25:58,876:INFO:Preloading libraries
2025-10-12 16:25:58,884:INFO:Copying training dataset
2025-10-12 16:25:58,884:INFO:Plot type: confusion_matrix
2025-10-12 16:25:58,926:INFO:Fitting Model
2025-10-12 16:25:58,926:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:25:58,926:INFO:Scoring test/hold-out set
2025-10-12 16:25:58,945:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmptd33gvi7\Confusion Matrix.png'
2025-10-12 16:25:59,019:INFO:Visual Rendered Successfully
2025-10-12 16:25:59,119:INFO:plot_model() successfully completed......................................
2025-10-12 16:25:59,141:INFO:Initializing plot_model()
2025-10-12 16:25:59,141:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=8866,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmptd33gvi7, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:25:59,141:INFO:Checking exceptions
2025-10-12 16:25:59,141:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 16:25:59,141:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:25:59,334:INFO:_master_model_container: 25
2025-10-12 16:25:59,334:INFO:_display_container: 10
2025-10-12 16:25:59,337:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=8866,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:25:59,337:INFO:blend_models() successfully completed......................................
2025-10-12 16:25:59,436:INFO:Initializing compare_models()
2025-10-12 16:25:59,436:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:25:59,436:INFO:Checking exceptions
2025-10-12 16:25:59,437:INFO:Preparing display monitor
2025-10-12 16:25:59,456:INFO:Initializing Logistic Regression
2025-10-12 16:25:59,457:INFO:Total runtime is 0.0 minutes
2025-10-12 16:25:59,459:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:59,459:INFO:Initializing create_model()
2025-10-12 16:25:59,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:59,461:INFO:Checking exceptions
2025-10-12 16:25:59,461:INFO:Importing libraries
2025-10-12 16:25:59,461:INFO:Copying training dataset
2025-10-12 16:25:59,462:INFO:Defining folds
2025-10-12 16:25:59,462:INFO:Declaring metric variables
2025-10-12 16:25:59,466:INFO:Importing untrained model
2025-10-12 16:25:59,470:INFO:Logistic Regression Imported successfully
2025-10-12 16:25:59,476:INFO:Starting cross validation
2025-10-12 16:25:59,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:59,553:INFO:Calculating mean and std
2025-10-12 16:25:59,553:INFO:Creating metrics dataframe
2025-10-12 16:25:59,555:INFO:Uploading results into container
2025-10-12 16:25:59,555:INFO:Uploading model into container now
2025-10-12 16:25:59,555:INFO:_master_model_container: 26
2025-10-12 16:25:59,555:INFO:_display_container: 11
2025-10-12 16:25:59,557:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8866, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:25:59,557:INFO:create_model() successfully completed......................................
2025-10-12 16:25:59,652:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:59,652:INFO:Creating metrics dataframe
2025-10-12 16:25:59,658:INFO:Initializing K Neighbors Classifier
2025-10-12 16:25:59,658:INFO:Total runtime is 0.003378268082936605 minutes
2025-10-12 16:25:59,659:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:59,661:INFO:Initializing create_model()
2025-10-12 16:25:59,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:59,661:INFO:Checking exceptions
2025-10-12 16:25:59,661:INFO:Importing libraries
2025-10-12 16:25:59,661:INFO:Copying training dataset
2025-10-12 16:25:59,663:INFO:Defining folds
2025-10-12 16:25:59,663:INFO:Declaring metric variables
2025-10-12 16:25:59,666:INFO:Importing untrained model
2025-10-12 16:25:59,668:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:25:59,676:INFO:Starting cross validation
2025-10-12 16:25:59,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:25:59,818:INFO:Calculating mean and std
2025-10-12 16:25:59,819:INFO:Creating metrics dataframe
2025-10-12 16:25:59,820:INFO:Uploading results into container
2025-10-12 16:25:59,821:INFO:Uploading model into container now
2025-10-12 16:25:59,821:INFO:_master_model_container: 27
2025-10-12 16:25:59,821:INFO:_display_container: 11
2025-10-12 16:25:59,821:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:25:59,821:INFO:create_model() successfully completed......................................
2025-10-12 16:25:59,921:INFO:SubProcess create_model() end ==================================
2025-10-12 16:25:59,921:INFO:Creating metrics dataframe
2025-10-12 16:25:59,925:INFO:Initializing Naive Bayes
2025-10-12 16:25:59,925:INFO:Total runtime is 0.007831180095672607 minutes
2025-10-12 16:25:59,928:INFO:SubProcess create_model() called ==================================
2025-10-12 16:25:59,929:INFO:Initializing create_model()
2025-10-12 16:25:59,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:25:59,929:INFO:Checking exceptions
2025-10-12 16:25:59,929:INFO:Importing libraries
2025-10-12 16:25:59,929:INFO:Copying training dataset
2025-10-12 16:25:59,933:INFO:Defining folds
2025-10-12 16:25:59,933:INFO:Declaring metric variables
2025-10-12 16:25:59,935:INFO:Importing untrained model
2025-10-12 16:25:59,937:INFO:Naive Bayes Imported successfully
2025-10-12 16:25:59,942:INFO:Starting cross validation
2025-10-12 16:25:59,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:00,006:INFO:Calculating mean and std
2025-10-12 16:26:00,007:INFO:Creating metrics dataframe
2025-10-12 16:26:00,008:INFO:Uploading results into container
2025-10-12 16:26:00,009:INFO:Uploading model into container now
2025-10-12 16:26:00,009:INFO:_master_model_container: 28
2025-10-12 16:26:00,009:INFO:_display_container: 11
2025-10-12 16:26:00,009:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:26:00,009:INFO:create_model() successfully completed......................................
2025-10-12 16:26:00,115:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:00,115:INFO:Creating metrics dataframe
2025-10-12 16:26:00,119:INFO:Initializing Decision Tree Classifier
2025-10-12 16:26:00,119:INFO:Total runtime is 0.011062431335449218 minutes
2025-10-12 16:26:00,123:INFO:SubProcess create_model() called ==================================
2025-10-12 16:26:00,123:INFO:Initializing create_model()
2025-10-12 16:26:00,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:00,123:INFO:Checking exceptions
2025-10-12 16:26:00,123:INFO:Importing libraries
2025-10-12 16:26:00,123:INFO:Copying training dataset
2025-10-12 16:26:00,125:INFO:Defining folds
2025-10-12 16:26:00,125:INFO:Declaring metric variables
2025-10-12 16:26:00,127:INFO:Importing untrained model
2025-10-12 16:26:00,131:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:26:00,138:INFO:Starting cross validation
2025-10-12 16:26:00,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:00,208:INFO:Calculating mean and std
2025-10-12 16:26:00,208:INFO:Creating metrics dataframe
2025-10-12 16:26:00,210:INFO:Uploading results into container
2025-10-12 16:26:00,210:INFO:Uploading model into container now
2025-10-12 16:26:00,210:INFO:_master_model_container: 29
2025-10-12 16:26:00,210:INFO:_display_container: 11
2025-10-12 16:26:00,211:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8866, splitter='best')
2025-10-12 16:26:00,211:INFO:create_model() successfully completed......................................
2025-10-12 16:26:00,312:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:00,312:INFO:Creating metrics dataframe
2025-10-12 16:26:00,317:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:26:00,317:INFO:Total runtime is 0.014358476797739664 minutes
2025-10-12 16:26:00,320:INFO:SubProcess create_model() called ==================================
2025-10-12 16:26:00,321:INFO:Initializing create_model()
2025-10-12 16:26:00,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:00,321:INFO:Checking exceptions
2025-10-12 16:26:00,321:INFO:Importing libraries
2025-10-12 16:26:00,321:INFO:Copying training dataset
2025-10-12 16:26:00,324:INFO:Defining folds
2025-10-12 16:26:00,324:INFO:Declaring metric variables
2025-10-12 16:26:00,326:INFO:Importing untrained model
2025-10-12 16:26:00,328:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:26:00,335:INFO:Starting cross validation
2025-10-12 16:26:00,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:00,371:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:26:00,397:INFO:Calculating mean and std
2025-10-12 16:26:00,398:INFO:Creating metrics dataframe
2025-10-12 16:26:00,399:INFO:Uploading results into container
2025-10-12 16:26:00,399:INFO:Uploading model into container now
2025-10-12 16:26:00,400:INFO:_master_model_container: 30
2025-10-12 16:26:00,400:INFO:_display_container: 11
2025-10-12 16:26:00,400:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8866, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:26:00,400:INFO:create_model() successfully completed......................................
2025-10-12 16:26:00,504:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:00,504:INFO:Creating metrics dataframe
2025-10-12 16:26:00,510:INFO:Initializing Ridge Classifier
2025-10-12 16:26:00,511:INFO:Total runtime is 0.01758569876352946 minutes
2025-10-12 16:26:00,512:INFO:SubProcess create_model() called ==================================
2025-10-12 16:26:00,514:INFO:Initializing create_model()
2025-10-12 16:26:00,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:00,514:INFO:Checking exceptions
2025-10-12 16:26:00,514:INFO:Importing libraries
2025-10-12 16:26:00,514:INFO:Copying training dataset
2025-10-12 16:26:00,516:INFO:Defining folds
2025-10-12 16:26:00,516:INFO:Declaring metric variables
2025-10-12 16:26:00,519:INFO:Importing untrained model
2025-10-12 16:26:00,524:INFO:Ridge Classifier Imported successfully
2025-10-12 16:26:00,531:INFO:Starting cross validation
2025-10-12 16:26:00,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:00,586:INFO:Calculating mean and std
2025-10-12 16:26:00,587:INFO:Creating metrics dataframe
2025-10-12 16:26:00,588:INFO:Uploading results into container
2025-10-12 16:26:00,589:INFO:Uploading model into container now
2025-10-12 16:26:00,589:INFO:_master_model_container: 31
2025-10-12 16:26:00,589:INFO:_display_container: 11
2025-10-12 16:26:00,589:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8866, solver='auto',
                tol=0.0001)
2025-10-12 16:26:00,589:INFO:create_model() successfully completed......................................
2025-10-12 16:26:00,691:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:00,691:INFO:Creating metrics dataframe
2025-10-12 16:26:00,698:INFO:Initializing Random Forest Classifier
2025-10-12 16:26:00,698:INFO:Total runtime is 0.02071082592010498 minutes
2025-10-12 16:26:00,701:INFO:SubProcess create_model() called ==================================
2025-10-12 16:26:00,701:INFO:Initializing create_model()
2025-10-12 16:26:00,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:00,701:INFO:Checking exceptions
2025-10-12 16:26:00,701:INFO:Importing libraries
2025-10-12 16:26:00,701:INFO:Copying training dataset
2025-10-12 16:26:00,705:INFO:Defining folds
2025-10-12 16:26:00,705:INFO:Declaring metric variables
2025-10-12 16:26:00,708:INFO:Importing untrained model
2025-10-12 16:26:00,713:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:26:00,719:INFO:Starting cross validation
2025-10-12 16:26:00,719:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:01,066:INFO:Calculating mean and std
2025-10-12 16:26:01,066:INFO:Creating metrics dataframe
2025-10-12 16:26:01,069:INFO:Uploading results into container
2025-10-12 16:26:01,070:INFO:Uploading model into container now
2025-10-12 16:26:01,070:INFO:_master_model_container: 32
2025-10-12 16:26:01,070:INFO:_display_container: 11
2025-10-12 16:26:01,071:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8866, verbose=0,
                       warm_start=False)
2025-10-12 16:26:01,071:INFO:create_model() successfully completed......................................
2025-10-12 16:26:01,175:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:01,175:INFO:Creating metrics dataframe
2025-10-12 16:26:01,182:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:26:01,182:INFO:Total runtime is 0.0287742018699646 minutes
2025-10-12 16:26:01,185:INFO:SubProcess create_model() called ==================================
2025-10-12 16:26:01,185:INFO:Initializing create_model()
2025-10-12 16:26:01,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:01,185:INFO:Checking exceptions
2025-10-12 16:26:01,185:INFO:Importing libraries
2025-10-12 16:26:01,186:INFO:Copying training dataset
2025-10-12 16:26:01,189:INFO:Defining folds
2025-10-12 16:26:01,189:INFO:Declaring metric variables
2025-10-12 16:26:01,192:INFO:Importing untrained model
2025-10-12 16:26:01,194:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:26:01,204:INFO:Starting cross validation
2025-10-12 16:26:01,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:01,268:INFO:Calculating mean and std
2025-10-12 16:26:01,268:INFO:Creating metrics dataframe
2025-10-12 16:26:01,270:INFO:Uploading results into container
2025-10-12 16:26:01,270:INFO:Uploading model into container now
2025-10-12 16:26:01,271:INFO:_master_model_container: 33
2025-10-12 16:26:01,271:INFO:_display_container: 11
2025-10-12 16:26:01,271:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:26:01,271:INFO:create_model() successfully completed......................................
2025-10-12 16:26:01,378:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:01,379:INFO:Creating metrics dataframe
2025-10-12 16:26:01,385:INFO:Initializing Ada Boost Classifier
2025-10-12 16:26:01,385:INFO:Total runtime is 0.03216652472813924 minutes
2025-10-12 16:26:01,388:INFO:SubProcess create_model() called ==================================
2025-10-12 16:26:01,388:INFO:Initializing create_model()
2025-10-12 16:26:01,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:01,388:INFO:Checking exceptions
2025-10-12 16:26:01,388:INFO:Importing libraries
2025-10-12 16:26:01,388:INFO:Copying training dataset
2025-10-12 16:26:01,394:INFO:Defining folds
2025-10-12 16:26:01,394:INFO:Declaring metric variables
2025-10-12 16:26:01,397:INFO:Importing untrained model
2025-10-12 16:26:01,401:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:26:01,409:INFO:Starting cross validation
2025-10-12 16:26:01,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:01,427:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:26:01,427:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:26:01,428:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:26:01,429:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:26:01,435:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:26:01,436:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:26:01,439:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:26:01,439:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:26:01,443:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:26:01,443:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:26:01,610:INFO:Calculating mean and std
2025-10-12 16:26:01,612:INFO:Creating metrics dataframe
2025-10-12 16:26:01,614:INFO:Uploading results into container
2025-10-12 16:26:01,614:INFO:Uploading model into container now
2025-10-12 16:26:01,615:INFO:_master_model_container: 34
2025-10-12 16:26:01,615:INFO:_display_container: 11
2025-10-12 16:26:01,615:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8866)
2025-10-12 16:26:01,615:INFO:create_model() successfully completed......................................
2025-10-12 16:26:01,718:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:01,718:INFO:Creating metrics dataframe
2025-10-12 16:26:01,726:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:26:01,726:INFO:Total runtime is 0.0378404418627421 minutes
2025-10-12 16:26:01,728:INFO:SubProcess create_model() called ==================================
2025-10-12 16:26:01,728:INFO:Initializing create_model()
2025-10-12 16:26:01,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:01,728:INFO:Checking exceptions
2025-10-12 16:26:01,729:INFO:Importing libraries
2025-10-12 16:26:01,729:INFO:Copying training dataset
2025-10-12 16:26:01,732:INFO:Defining folds
2025-10-12 16:26:01,733:INFO:Declaring metric variables
2025-10-12 16:26:01,736:INFO:Importing untrained model
2025-10-12 16:26:01,739:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:26:01,750:INFO:Starting cross validation
2025-10-12 16:26:01,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:01,983:INFO:Calculating mean and std
2025-10-12 16:26:01,984:INFO:Creating metrics dataframe
2025-10-12 16:26:01,986:INFO:Uploading results into container
2025-10-12 16:26:01,987:INFO:Uploading model into container now
2025-10-12 16:26:01,987:INFO:_master_model_container: 35
2025-10-12 16:26:01,988:INFO:_display_container: 11
2025-10-12 16:26:01,988:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:26:01,989:INFO:create_model() successfully completed......................................
2025-10-12 16:26:02,096:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:02,096:INFO:Creating metrics dataframe
2025-10-12 16:26:02,104:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:26:02,104:INFO:Total runtime is 0.04413702090581258 minutes
2025-10-12 16:26:02,107:INFO:SubProcess create_model() called ==================================
2025-10-12 16:26:02,107:INFO:Initializing create_model()
2025-10-12 16:26:02,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:02,107:INFO:Checking exceptions
2025-10-12 16:26:02,107:INFO:Importing libraries
2025-10-12 16:26:02,107:INFO:Copying training dataset
2025-10-12 16:26:02,111:INFO:Defining folds
2025-10-12 16:26:02,111:INFO:Declaring metric variables
2025-10-12 16:26:02,114:INFO:Importing untrained model
2025-10-12 16:26:02,117:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:26:02,125:INFO:Starting cross validation
2025-10-12 16:26:02,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:02,186:INFO:Calculating mean and std
2025-10-12 16:26:02,186:INFO:Creating metrics dataframe
2025-10-12 16:26:02,188:INFO:Uploading results into container
2025-10-12 16:26:02,188:INFO:Uploading model into container now
2025-10-12 16:26:02,189:INFO:_master_model_container: 36
2025-10-12 16:26:02,189:INFO:_display_container: 11
2025-10-12 16:26:02,189:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:26:02,189:INFO:create_model() successfully completed......................................
2025-10-12 16:26:02,296:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:02,297:INFO:Creating metrics dataframe
2025-10-12 16:26:02,304:INFO:Initializing Extra Trees Classifier
2025-10-12 16:26:02,304:INFO:Total runtime is 0.047482645511627196 minutes
2025-10-12 16:26:02,307:INFO:SubProcess create_model() called ==================================
2025-10-12 16:26:02,307:INFO:Initializing create_model()
2025-10-12 16:26:02,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:02,308:INFO:Checking exceptions
2025-10-12 16:26:02,308:INFO:Importing libraries
2025-10-12 16:26:02,308:INFO:Copying training dataset
2025-10-12 16:26:02,312:INFO:Defining folds
2025-10-12 16:26:02,312:INFO:Declaring metric variables
2025-10-12 16:26:02,314:INFO:Importing untrained model
2025-10-12 16:26:02,318:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:26:02,324:INFO:Starting cross validation
2025-10-12 16:26:02,325:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:02,652:INFO:Calculating mean and std
2025-10-12 16:26:02,653:INFO:Creating metrics dataframe
2025-10-12 16:26:02,654:INFO:Uploading results into container
2025-10-12 16:26:02,655:INFO:Uploading model into container now
2025-10-12 16:26:02,655:INFO:_master_model_container: 37
2025-10-12 16:26:02,655:INFO:_display_container: 11
2025-10-12 16:26:02,656:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8866, verbose=0,
                     warm_start=False)
2025-10-12 16:26:02,656:INFO:create_model() successfully completed......................................
2025-10-12 16:26:02,753:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:02,753:INFO:Creating metrics dataframe
2025-10-12 16:26:02,760:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:26:02,760:INFO:Total runtime is 0.05507443745930989 minutes
2025-10-12 16:26:02,762:INFO:SubProcess create_model() called ==================================
2025-10-12 16:26:02,763:INFO:Initializing create_model()
2025-10-12 16:26:02,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:02,763:INFO:Checking exceptions
2025-10-12 16:26:02,763:INFO:Importing libraries
2025-10-12 16:26:02,763:INFO:Copying training dataset
2025-10-12 16:26:02,767:INFO:Defining folds
2025-10-12 16:26:02,767:INFO:Declaring metric variables
2025-10-12 16:26:02,770:INFO:Importing untrained model
2025-10-12 16:26:02,774:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:26:02,779:INFO:Starting cross validation
2025-10-12 16:26:02,779:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:03,086:INFO:Calculating mean and std
2025-10-12 16:26:03,087:INFO:Creating metrics dataframe
2025-10-12 16:26:03,089:INFO:Uploading results into container
2025-10-12 16:26:03,089:INFO:Uploading model into container now
2025-10-12 16:26:03,089:INFO:_master_model_container: 38
2025-10-12 16:26:03,089:INFO:_display_container: 11
2025-10-12 16:26:03,092:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:26:03,092:INFO:create_model() successfully completed......................................
2025-10-12 16:26:03,192:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:03,192:INFO:Creating metrics dataframe
2025-10-12 16:26:03,199:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:26:03,200:INFO:Total runtime is 0.06240519285202026 minutes
2025-10-12 16:26:03,202:INFO:SubProcess create_model() called ==================================
2025-10-12 16:26:03,202:INFO:Initializing create_model()
2025-10-12 16:26:03,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:03,202:INFO:Checking exceptions
2025-10-12 16:26:03,202:INFO:Importing libraries
2025-10-12 16:26:03,202:INFO:Copying training dataset
2025-10-12 16:26:03,206:INFO:Defining folds
2025-10-12 16:26:03,206:INFO:Declaring metric variables
2025-10-12 16:26:03,208:INFO:Importing untrained model
2025-10-12 16:26:03,211:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:26:03,216:INFO:Starting cross validation
2025-10-12 16:26:03,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:04,496:INFO:Calculating mean and std
2025-10-12 16:26:04,498:INFO:Creating metrics dataframe
2025-10-12 16:26:04,500:INFO:Uploading results into container
2025-10-12 16:26:04,501:INFO:Uploading model into container now
2025-10-12 16:26:04,501:INFO:_master_model_container: 39
2025-10-12 16:26:04,501:INFO:_display_container: 11
2025-10-12 16:26:04,502:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8866, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:26:04,502:INFO:create_model() successfully completed......................................
2025-10-12 16:26:04,617:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:04,617:INFO:Creating metrics dataframe
2025-10-12 16:26:04,624:INFO:Initializing CatBoost Classifier
2025-10-12 16:26:04,624:INFO:Total runtime is 0.08613528410593668 minutes
2025-10-12 16:26:04,627:INFO:SubProcess create_model() called ==================================
2025-10-12 16:26:04,627:INFO:Initializing create_model()
2025-10-12 16:26:04,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:04,627:INFO:Checking exceptions
2025-10-12 16:26:04,627:INFO:Importing libraries
2025-10-12 16:26:04,627:INFO:Copying training dataset
2025-10-12 16:26:04,631:INFO:Defining folds
2025-10-12 16:26:04,631:INFO:Declaring metric variables
2025-10-12 16:26:04,634:INFO:Importing untrained model
2025-10-12 16:26:04,636:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:26:04,641:INFO:Starting cross validation
2025-10-12 16:26:04,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:09,003:INFO:Calculating mean and std
2025-10-12 16:26:09,004:INFO:Creating metrics dataframe
2025-10-12 16:26:09,006:INFO:Uploading results into container
2025-10-12 16:26:09,006:INFO:Uploading model into container now
2025-10-12 16:26:09,007:INFO:_master_model_container: 40
2025-10-12 16:26:09,007:INFO:_display_container: 11
2025-10-12 16:26:09,007:INFO:<catboost.core.CatBoostClassifier object at 0x00000279C723D4F0>
2025-10-12 16:26:09,007:INFO:create_model() successfully completed......................................
2025-10-12 16:26:09,109:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:09,109:INFO:Creating metrics dataframe
2025-10-12 16:26:09,117:INFO:Initializing Dummy Classifier
2025-10-12 16:26:09,117:INFO:Total runtime is 0.16101799805959066 minutes
2025-10-12 16:26:09,119:INFO:SubProcess create_model() called ==================================
2025-10-12 16:26:09,119:INFO:Initializing create_model()
2025-10-12 16:26:09,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000279C754E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:09,120:INFO:Checking exceptions
2025-10-12 16:26:09,120:INFO:Importing libraries
2025-10-12 16:26:09,120:INFO:Copying training dataset
2025-10-12 16:26:09,122:INFO:Defining folds
2025-10-12 16:26:09,122:INFO:Declaring metric variables
2025-10-12 16:26:09,125:INFO:Importing untrained model
2025-10-12 16:26:09,129:INFO:Dummy Classifier Imported successfully
2025-10-12 16:26:09,134:INFO:Starting cross validation
2025-10-12 16:26:09,135:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:26:09,167:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:26:09,169:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:26:09,171:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:26:09,177:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:26:09,179:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:26:09,181:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:26:09,181:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:26:09,182:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:26:09,186:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:26:09,197:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:26:09,204:INFO:Calculating mean and std
2025-10-12 16:26:09,204:INFO:Creating metrics dataframe
2025-10-12 16:26:09,206:INFO:Uploading results into container
2025-10-12 16:26:09,206:INFO:Uploading model into container now
2025-10-12 16:26:09,207:INFO:_master_model_container: 41
2025-10-12 16:26:09,207:INFO:_display_container: 11
2025-10-12 16:26:09,207:INFO:DummyClassifier(constant=None, random_state=8866, strategy='prior')
2025-10-12 16:26:09,207:INFO:create_model() successfully completed......................................
2025-10-12 16:26:09,307:INFO:SubProcess create_model() end ==================================
2025-10-12 16:26:09,307:INFO:Creating metrics dataframe
2025-10-12 16:26:09,315:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:26:09,322:INFO:Initializing create_model()
2025-10-12 16:26:09,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:26:09,322:INFO:Checking exceptions
2025-10-12 16:26:09,324:INFO:Importing libraries
2025-10-12 16:26:09,324:INFO:Copying training dataset
2025-10-12 16:26:09,326:INFO:Defining folds
2025-10-12 16:26:09,326:INFO:Declaring metric variables
2025-10-12 16:26:09,326:INFO:Importing untrained model
2025-10-12 16:26:09,326:INFO:Declaring custom model
2025-10-12 16:26:09,327:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:26:09,327:INFO:Cross validation set to False
2025-10-12 16:26:09,327:INFO:Fitting Model
2025-10-12 16:26:09,416:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:26:09,416:INFO:create_model() successfully completed......................................
2025-10-12 16:26:09,522:INFO:Creating Dashboard logs
2025-10-12 16:26:09,525:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:26:09,598:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8866, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:26:09,839:INFO:Initializing predict_model()
2025-10-12 16:26:09,840:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000279D5B11550>)
2025-10-12 16:26:09,840:INFO:Checking exceptions
2025-10-12 16:26:09,840:INFO:Preloading libraries
2025-10-12 16:26:09,999:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:26:09,999:INFO:Initializing plot_model()
2025-10-12 16:26:09,999:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp1rvwpv_w, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:26:09,999:INFO:Checking exceptions
2025-10-12 16:26:10,001:INFO:Preloading libraries
2025-10-12 16:26:10,005:INFO:Copying training dataset
2025-10-12 16:26:10,005:INFO:Plot type: auc
2025-10-12 16:26:10,050:INFO:Fitting Model
2025-10-12 16:26:10,050:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:26:10,050:INFO:Scoring test/hold-out set
2025-10-12 16:26:10,068:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp1rvwpv_w\AUC.png'
2025-10-12 16:26:10,228:INFO:Visual Rendered Successfully
2025-10-12 16:26:10,332:INFO:plot_model() successfully completed......................................
2025-10-12 16:26:10,348:INFO:Initializing plot_model()
2025-10-12 16:26:10,348:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp1rvwpv_w, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:26:10,348:INFO:Checking exceptions
2025-10-12 16:26:10,350:INFO:Preloading libraries
2025-10-12 16:26:10,354:INFO:Copying training dataset
2025-10-12 16:26:10,354:INFO:Plot type: confusion_matrix
2025-10-12 16:26:10,409:INFO:Fitting Model
2025-10-12 16:26:10,410:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:26:10,410:INFO:Scoring test/hold-out set
2025-10-12 16:26:10,427:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp1rvwpv_w\Confusion Matrix.png'
2025-10-12 16:26:10,507:INFO:Visual Rendered Successfully
2025-10-12 16:26:10,607:INFO:plot_model() successfully completed......................................
2025-10-12 16:26:10,627:INFO:Initializing plot_model()
2025-10-12 16:26:10,627:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp1rvwpv_w, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, system=False)
2025-10-12 16:26:10,627:INFO:Checking exceptions
2025-10-12 16:26:10,629:INFO:Preloading libraries
2025-10-12 16:26:10,634:INFO:Copying training dataset
2025-10-12 16:26:10,634:INFO:Plot type: feature
2025-10-12 16:26:10,634:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:26:10,665:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp1rvwpv_w\Feature Importance.png'
2025-10-12 16:26:10,772:INFO:Visual Rendered Successfully
2025-10-12 16:26:10,874:INFO:plot_model() successfully completed......................................
2025-10-12 16:26:10,892:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:26:11,077:INFO:Creating Dashboard logs
2025-10-12 16:26:11,081:INFO:Model: CatBoost Classifier
2025-10-12 16:26:11,153:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-10-12 16:26:11,153:INFO:Logged params: {}
2025-10-12 16:26:11,533:INFO:Creating Dashboard logs
2025-10-12 16:26:11,536:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:26:11,609:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 8866, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:26:12,049:INFO:Creating Dashboard logs
2025-10-12 16:26:12,053:INFO:Model: Ada Boost Classifier
2025-10-12 16:26:12,134:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 8866}
2025-10-12 16:26:12,526:INFO:Creating Dashboard logs
2025-10-12 16:26:12,528:INFO:Model: Random Forest Classifier
2025-10-12 16:26:12,599:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8866, 'verbose': 0, 'warm_start': False}
2025-10-12 16:26:12,991:INFO:Creating Dashboard logs
2025-10-12 16:26:12,994:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 16:26:13,063:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:26:13,431:INFO:Creating Dashboard logs
2025-10-12 16:26:13,434:INFO:Model: Ridge Classifier
2025-10-12 16:26:13,507:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 8866, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:26:13,896:INFO:Creating Dashboard logs
2025-10-12 16:26:13,899:INFO:Model: Extra Trees Classifier
2025-10-12 16:26:13,970:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8866, 'verbose': 0, 'warm_start': False}
2025-10-12 16:26:14,359:INFO:Creating Dashboard logs
2025-10-12 16:26:14,362:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:26:14,439:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 8866, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:26:14,889:INFO:Creating Dashboard logs
2025-10-12 16:26:14,891:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:26:14,972:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:26:15,399:INFO:Creating Dashboard logs
2025-10-12 16:26:15,401:INFO:Model: Logistic Regression
2025-10-12 16:26:15,475:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 8866, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:26:15,862:INFO:Creating Dashboard logs
2025-10-12 16:26:15,864:INFO:Model: Naive Bayes
2025-10-12 16:26:15,939:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:26:16,308:INFO:Creating Dashboard logs
2025-10-12 16:26:16,311:INFO:Model: Decision Tree Classifier
2025-10-12 16:26:16,382:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 8866, 'splitter': 'best'}
2025-10-12 16:26:16,773:INFO:Creating Dashboard logs
2025-10-12 16:26:16,776:INFO:Model: K Neighbors Classifier
2025-10-12 16:26:16,858:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:26:17,259:INFO:Creating Dashboard logs
2025-10-12 16:26:17,262:INFO:Model: SVM - Linear Kernel
2025-10-12 16:26:17,332:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 8866, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:26:17,729:INFO:Creating Dashboard logs
2025-10-12 16:26:17,732:INFO:Model: Dummy Classifier
2025-10-12 16:26:17,804:INFO:Logged params: {'constant': None, 'random_state': 8866, 'strategy': 'prior'}
2025-10-12 16:26:18,146:INFO:_master_model_container: 41
2025-10-12 16:26:18,146:INFO:_display_container: 11
2025-10-12 16:26:18,146:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8866, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:26:18,146:INFO:compare_models() successfully completed......................................
2025-10-12 16:26:21,653:INFO:Initializing predict_model()
2025-10-12 16:26:21,653:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000279A4D32E80>, estimator=mlflow.pyfunc.loaded_model:
  run_id: 39f894e7d3eb44a99b7896e490c21033
  artifact_path: model
  flavor: mlflow.sklearn
, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000279C724A8B0>)
2025-10-12 16:26:21,653:INFO:Checking exceptions
2025-10-12 16:26:21,654:INFO:Preloading libraries
2025-10-12 16:26:21,655:INFO:Set up data.
2025-10-12 16:26:21,659:INFO:Set up index.
2025-10-12 16:27:22,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 16:27:22,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 16:27:22,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 16:27:22,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-12 16:27:23,341:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\mlflow\utils\requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources  # noqa: TID251

2025-10-12 16:27:43,336:INFO:PyCaret ClassificationExperiment
2025-10-12 16:27:43,336:INFO:Logging name: titanic_exp_1
2025-10-12 16:27:43,336:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-12 16:27:43,336:INFO:version 3.3.2
2025-10-12 16:27:43,337:INFO:Initializing setup()
2025-10-12 16:27:43,337:INFO:self.USI: 1176
2025-10-12 16:27:43,337:INFO:self._variable_keys: {'exp_name_log', 'exp_id', 'logging_param', 'pipeline', 'idx', 'y_test', 'X_train', 'n_jobs_param', 'gpu_n_jobs_param', 'gpu_param', '_available_plots', 'fold_shuffle_param', 'fold_generator', 'is_multiclass', 'y', '_ml_usecase', 'fold_groups_param', 'fix_imbalance', 'X_test', 'log_plots_param', 'USI', 'seed', 'memory', 'y_train', 'data', 'target_param', 'X', 'html_param'}
2025-10-12 16:27:43,337:INFO:Checking environment
2025-10-12 16:27:43,337:INFO:python_version: 3.9.13
2025-10-12 16:27:43,337:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2025-10-12 16:27:43,337:INFO:machine: AMD64
2025-10-12 16:27:43,337:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-12 16:27:43,337:INFO:Memory: svmem(total=16778072064, available=6141063168, percent=63.4, used=10637008896, free=6141063168)
2025-10-12 16:27:43,337:INFO:Physical Core: 10
2025-10-12 16:27:43,337:INFO:Logical Core: 16
2025-10-12 16:27:43,337:INFO:Checking libraries
2025-10-12 16:27:43,337:INFO:System:
2025-10-12 16:27:43,337:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2025-10-12 16:27:43,337:INFO:executable: c:\Users\david\Programming\MLOps\.venv\Scripts\python.exe
2025-10-12 16:27:43,337:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-12 16:27:43,337:INFO:PyCaret required dependencies:
2025-10-12 16:27:44,132:INFO:                 pip: 25.2
2025-10-12 16:27:44,132:INFO:          setuptools: 80.9.0
2025-10-12 16:27:44,133:INFO:             pycaret: 3.3.2
2025-10-12 16:27:44,133:INFO:             IPython: 8.18.1
2025-10-12 16:27:44,133:INFO:          ipywidgets: 8.1.7
2025-10-12 16:27:44,133:INFO:                tqdm: 4.67.1
2025-10-12 16:27:44,133:INFO:               numpy: 1.26.4
2025-10-12 16:27:44,133:INFO:              pandas: 2.1.4
2025-10-12 16:27:44,133:INFO:              jinja2: 3.1.6
2025-10-12 16:27:44,133:INFO:               scipy: 1.11.4
2025-10-12 16:27:44,133:INFO:              joblib: 1.3.2
2025-10-12 16:27:44,133:INFO:             sklearn: 1.4.2
2025-10-12 16:27:44,133:INFO:                pyod: 2.0.5
2025-10-12 16:27:44,133:INFO:            imblearn: 0.12.4
2025-10-12 16:27:44,133:INFO:   category_encoders: 2.6.4
2025-10-12 16:27:44,133:INFO:            lightgbm: 4.6.0
2025-10-12 16:27:44,133:INFO:               numba: 0.60.0
2025-10-12 16:27:44,133:INFO:            requests: 2.32.5
2025-10-12 16:27:44,133:INFO:          matplotlib: 3.7.5
2025-10-12 16:27:44,133:INFO:          scikitplot: 0.3.7
2025-10-12 16:27:44,133:INFO:         yellowbrick: 1.5
2025-10-12 16:27:44,133:INFO:              plotly: 5.24.1
2025-10-12 16:27:44,133:INFO:    plotly-resampler: Not installed
2025-10-12 16:27:44,133:INFO:             kaleido: 1.1.0
2025-10-12 16:27:44,133:INFO:           schemdraw: 0.15
2025-10-12 16:27:44,133:INFO:         statsmodels: 0.14.5
2025-10-12 16:27:44,133:INFO:              sktime: 0.26.0
2025-10-12 16:27:44,133:INFO:               tbats: 1.1.3
2025-10-12 16:27:44,133:INFO:            pmdarima: 2.0.4
2025-10-12 16:27:44,133:INFO:              psutil: 7.1.0
2025-10-12 16:27:44,133:INFO:          markupsafe: 2.1.5
2025-10-12 16:27:44,133:INFO:             pickle5: Not installed
2025-10-12 16:27:44,133:INFO:         cloudpickle: 3.1.1
2025-10-12 16:27:44,133:INFO:         deprecation: 2.1.0
2025-10-12 16:27:44,133:INFO:              xxhash: 3.6.0
2025-10-12 16:27:44,133:INFO:           wurlitzer: Not installed
2025-10-12 16:27:44,133:INFO:PyCaret optional dependencies:
2025-10-12 16:27:45,731:INFO:                shap: 0.44.1
2025-10-12 16:27:45,731:INFO:           interpret: 0.7.2
2025-10-12 16:27:45,731:INFO:                umap: 0.5.7
2025-10-12 16:27:45,731:INFO:     ydata_profiling: 4.17.0
2025-10-12 16:27:45,731:INFO:  explainerdashboard: 0.5.1
2025-10-12 16:27:45,731:INFO:             autoviz: Not installed
2025-10-12 16:27:45,731:INFO:           fairlearn: 0.7.0
2025-10-12 16:27:45,731:INFO:          deepchecks: Not installed
2025-10-12 16:27:45,731:INFO:             xgboost: 2.1.4
2025-10-12 16:27:45,731:INFO:            catboost: 1.2.8
2025-10-12 16:27:45,731:INFO:              kmodes: 0.12.2
2025-10-12 16:27:45,731:INFO:             mlxtend: 0.23.4
2025-10-12 16:27:45,731:INFO:       statsforecast: 1.5.0
2025-10-12 16:27:45,731:INFO:        tune_sklearn: Not installed
2025-10-12 16:27:45,731:INFO:                 ray: Not installed
2025-10-12 16:27:45,731:INFO:            hyperopt: 0.2.7
2025-10-12 16:27:45,731:INFO:              optuna: 4.5.0
2025-10-12 16:27:45,731:INFO:               skopt: 0.10.2
2025-10-12 16:27:45,731:INFO:              mlflow: 3.1.4
2025-10-12 16:27:45,731:INFO:              gradio: Not installed
2025-10-12 16:27:45,731:INFO:             fastapi: 0.119.0
2025-10-12 16:27:45,731:INFO:             uvicorn: 0.37.0
2025-10-12 16:27:45,731:INFO:              m2cgen: 0.10.0
2025-10-12 16:27:45,731:INFO:           evidently: 0.4.40
2025-10-12 16:27:45,731:INFO:               fugue: 0.8.7
2025-10-12 16:27:45,731:INFO:           streamlit: Not installed
2025-10-12 16:27:45,731:INFO:             prophet: Not installed
2025-10-12 16:27:45,731:INFO:None
2025-10-12 16:27:45,731:INFO:Set up data.
2025-10-12 16:27:45,735:INFO:Set up folding strategy.
2025-10-12 16:27:45,735:INFO:Set up train/test split.
2025-10-12 16:27:45,738:INFO:Set up index.
2025-10-12 16:27:45,738:INFO:Assigning column types.
2025-10-12 16:27:45,740:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-12 16:27:45,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:27:45,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:27:45,795:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:27:45,797:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:27:45,849:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:27:45,849:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:27:45,867:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:27:45,869:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:27:45,870:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-12 16:27:45,898:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:27:45,916:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:27:45,918:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:27:45,946:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:27:45,964:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:27:45,966:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:27:45,967:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-12 16:27:46,015:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:27:46,017:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:27:46,065:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:27:46,068:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:27:46,070:INFO:Preparing preprocessing pipeline...
2025-10-12 16:27:46,070:INFO:Set up simple imputation.
2025-10-12 16:27:46,086:INFO:Finished creating preprocessing pipeline.
2025-10-12 16:27:46,090:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-12 16:27:46,090:INFO:Creating final display dataframe.
2025-10-12 16:27:46,135:INFO:Setup _display_container:                     Description            Value
0                    Session id             2478
1                        Target         Survived
2                   Target type           Binary
3           Original data shape         (712, 8)
4        Transformed data shape         (712, 8)
5   Transformed train set shape         (498, 8)
6    Transformed test set shape         (214, 8)
7              Numeric features                7
8                    Preprocess             True
9               Imputation type           simple
10           Numeric imputation             mean
11       Categorical imputation             mode
12               Fold Generator  StratifiedKFold
13                  Fold Number               10
14                     CPU Jobs               -1
15                      Use GPU            False
16               Log Experiment     MlflowLogger
17              Experiment Name    titanic_exp_1
18                          USI             1176
2025-10-12 16:27:46,187:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:27:46,189:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:27:46,236:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:27:46,238:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:27:46,239:INFO:Logging experiment in loggers
2025-10-12 16:27:46,503:INFO:SubProcess save_model() called ==================================
2025-10-12 16:27:46,507:INFO:Initializing save_model()
2025-10-12 16:27:46,507:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\david\AppData\Local\Temp\tmpxmffoz9k\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 16:27:46,507:INFO:Adding model into prep_pipe
2025-10-12 16:27:46,507:WARNING:Only Model saved as it was a pipeline.
2025-10-12 16:27:46,509:INFO:C:\Users\david\AppData\Local\Temp\tmpxmffoz9k\Transformation Pipeline.pkl saved in current working directory
2025-10-12 16:27:46,511:INFO:Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-12 16:27:46,511:INFO:save_model() successfully completed......................................
2025-10-12 16:27:46,604:INFO:SubProcess save_model() end ==================================
2025-10-12 16:27:46,682:INFO:setup() successfully completed in 2.91s...............
2025-10-12 16:27:46,713:INFO:Initializing compare_models()
2025-10-12 16:27:46,713:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016804D25DF0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016804D25DF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:27:46,713:INFO:Checking exceptions
2025-10-12 16:27:46,717:INFO:Preparing display monitor
2025-10-12 16:27:46,740:INFO:Initializing Logistic Regression
2025-10-12 16:27:46,742:INFO:Total runtime is 2.3035208384195962e-05 minutes
2025-10-12 16:27:46,747:INFO:SubProcess create_model() called ==================================
2025-10-12 16:27:46,748:INFO:Initializing create_model()
2025-10-12 16:27:46,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016804D25DF0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016804D25370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:27:46,748:INFO:Checking exceptions
2025-10-12 16:27:46,748:INFO:Importing libraries
2025-10-12 16:27:46,748:INFO:Copying training dataset
2025-10-12 16:27:46,755:INFO:Defining folds
2025-10-12 16:27:46,755:INFO:Declaring metric variables
2025-10-12 16:27:46,760:INFO:Importing untrained model
2025-10-12 16:27:46,766:INFO:Logistic Regression Imported successfully
2025-10-12 16:27:46,776:INFO:Starting cross validation
2025-10-12 16:27:46,777:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:08,628:INFO:PyCaret ClassificationExperiment
2025-10-12 16:28:08,628:INFO:Logging name: titanic_exp_2
2025-10-12 16:28:08,628:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-12 16:28:08,628:INFO:version 3.3.2
2025-10-12 16:28:08,628:INFO:Initializing setup()
2025-10-12 16:28:08,628:INFO:self.USI: a0b1
2025-10-12 16:28:08,628:INFO:self._variable_keys: {'exp_name_log', 'exp_id', 'logging_param', 'pipeline', 'idx', 'y_test', 'X_train', 'n_jobs_param', 'gpu_n_jobs_param', 'gpu_param', '_available_plots', 'fold_shuffle_param', 'fold_generator', 'is_multiclass', 'y', '_ml_usecase', 'fold_groups_param', 'fix_imbalance', 'X_test', 'log_plots_param', 'USI', 'seed', 'memory', 'y_train', 'data', 'target_param', 'X', 'html_param'}
2025-10-12 16:28:08,628:INFO:Checking environment
2025-10-12 16:28:08,628:INFO:python_version: 3.9.13
2025-10-12 16:28:08,628:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2025-10-12 16:28:08,628:INFO:machine: AMD64
2025-10-12 16:28:08,628:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-12 16:28:08,628:INFO:Memory: svmem(total=16778072064, available=6277668864, percent=62.6, used=10500403200, free=6277668864)
2025-10-12 16:28:08,628:INFO:Physical Core: 10
2025-10-12 16:28:08,628:INFO:Logical Core: 16
2025-10-12 16:28:08,628:INFO:Checking libraries
2025-10-12 16:28:08,628:INFO:System:
2025-10-12 16:28:08,628:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2025-10-12 16:28:08,628:INFO:executable: c:\Users\david\Programming\MLOps\.venv\Scripts\python.exe
2025-10-12 16:28:08,628:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-12 16:28:08,628:INFO:PyCaret required dependencies:
2025-10-12 16:28:08,628:INFO:                 pip: 25.2
2025-10-12 16:28:08,628:INFO:          setuptools: 80.9.0
2025-10-12 16:28:08,628:INFO:             pycaret: 3.3.2
2025-10-12 16:28:08,628:INFO:             IPython: 8.18.1
2025-10-12 16:28:08,628:INFO:          ipywidgets: 8.1.7
2025-10-12 16:28:08,630:INFO:                tqdm: 4.67.1
2025-10-12 16:28:08,630:INFO:               numpy: 1.26.4
2025-10-12 16:28:08,630:INFO:              pandas: 2.1.4
2025-10-12 16:28:08,630:INFO:              jinja2: 3.1.6
2025-10-12 16:28:08,630:INFO:               scipy: 1.11.4
2025-10-12 16:28:08,630:INFO:              joblib: 1.3.2
2025-10-12 16:28:08,630:INFO:             sklearn: 1.4.2
2025-10-12 16:28:08,630:INFO:                pyod: 2.0.5
2025-10-12 16:28:08,630:INFO:            imblearn: 0.12.4
2025-10-12 16:28:08,630:INFO:   category_encoders: 2.6.4
2025-10-12 16:28:08,630:INFO:            lightgbm: 4.6.0
2025-10-12 16:28:08,630:INFO:               numba: 0.60.0
2025-10-12 16:28:08,630:INFO:            requests: 2.32.5
2025-10-12 16:28:08,630:INFO:          matplotlib: 3.7.5
2025-10-12 16:28:08,630:INFO:          scikitplot: 0.3.7
2025-10-12 16:28:08,630:INFO:         yellowbrick: 1.5
2025-10-12 16:28:08,630:INFO:              plotly: 5.24.1
2025-10-12 16:28:08,630:INFO:    plotly-resampler: Not installed
2025-10-12 16:28:08,630:INFO:             kaleido: 1.1.0
2025-10-12 16:28:08,630:INFO:           schemdraw: 0.15
2025-10-12 16:28:08,630:INFO:         statsmodels: 0.14.5
2025-10-12 16:28:08,630:INFO:              sktime: 0.26.0
2025-10-12 16:28:08,630:INFO:               tbats: 1.1.3
2025-10-12 16:28:08,630:INFO:            pmdarima: 2.0.4
2025-10-12 16:28:08,630:INFO:              psutil: 7.1.0
2025-10-12 16:28:08,630:INFO:          markupsafe: 2.1.5
2025-10-12 16:28:08,630:INFO:             pickle5: Not installed
2025-10-12 16:28:08,630:INFO:         cloudpickle: 3.1.1
2025-10-12 16:28:08,630:INFO:         deprecation: 2.1.0
2025-10-12 16:28:08,630:INFO:              xxhash: 3.6.0
2025-10-12 16:28:08,630:INFO:           wurlitzer: Not installed
2025-10-12 16:28:08,630:INFO:PyCaret optional dependencies:
2025-10-12 16:28:08,630:INFO:                shap: 0.44.1
2025-10-12 16:28:08,630:INFO:           interpret: 0.7.2
2025-10-12 16:28:08,630:INFO:                umap: 0.5.7
2025-10-12 16:28:08,630:INFO:     ydata_profiling: 4.17.0
2025-10-12 16:28:08,630:INFO:  explainerdashboard: 0.5.1
2025-10-12 16:28:08,630:INFO:             autoviz: Not installed
2025-10-12 16:28:08,630:INFO:           fairlearn: 0.7.0
2025-10-12 16:28:08,630:INFO:          deepchecks: Not installed
2025-10-12 16:28:08,630:INFO:             xgboost: 2.1.4
2025-10-12 16:28:08,630:INFO:            catboost: 1.2.8
2025-10-12 16:28:08,630:INFO:              kmodes: 0.12.2
2025-10-12 16:28:08,630:INFO:             mlxtend: 0.23.4
2025-10-12 16:28:08,631:INFO:       statsforecast: 1.5.0
2025-10-12 16:28:08,631:INFO:        tune_sklearn: Not installed
2025-10-12 16:28:08,631:INFO:                 ray: Not installed
2025-10-12 16:28:08,631:INFO:            hyperopt: 0.2.7
2025-10-12 16:28:08,631:INFO:              optuna: 4.5.0
2025-10-12 16:28:08,631:INFO:               skopt: 0.10.2
2025-10-12 16:28:08,631:INFO:              mlflow: 3.1.4
2025-10-12 16:28:08,631:INFO:              gradio: Not installed
2025-10-12 16:28:08,631:INFO:             fastapi: 0.119.0
2025-10-12 16:28:08,631:INFO:             uvicorn: 0.37.0
2025-10-12 16:28:08,631:INFO:              m2cgen: 0.10.0
2025-10-12 16:28:08,631:INFO:           evidently: 0.4.40
2025-10-12 16:28:08,631:INFO:               fugue: 0.8.7
2025-10-12 16:28:08,631:INFO:           streamlit: Not installed
2025-10-12 16:28:08,631:INFO:             prophet: Not installed
2025-10-12 16:28:08,631:INFO:None
2025-10-12 16:28:08,631:INFO:Set up data.
2025-10-12 16:28:08,635:INFO:Set up folding strategy.
2025-10-12 16:28:08,635:INFO:Set up train/test split.
2025-10-12 16:28:08,638:INFO:Set up index.
2025-10-12 16:28:08,638:INFO:Assigning column types.
2025-10-12 16:28:08,641:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-12 16:28:08,666:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:28:08,667:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:28:08,684:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:28:08,686:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:28:08,714:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:28:08,715:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:28:08,733:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:28:08,734:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:28:08,735:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-12 16:28:08,764:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:28:08,781:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:28:08,782:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:28:08,810:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:28:08,828:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:28:08,830:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:28:08,831:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-12 16:28:08,875:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:28:08,877:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:28:08,921:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:28:08,924:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:28:08,925:INFO:Preparing preprocessing pipeline...
2025-10-12 16:28:08,926:INFO:Set up simple imputation.
2025-10-12 16:28:08,939:INFO:Finished creating preprocessing pipeline.
2025-10-12 16:28:08,941:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-12 16:28:08,941:INFO:Creating final display dataframe.
2025-10-12 16:28:08,981:INFO:Setup _display_container:                     Description            Value
0                    Session id             5816
1                        Target         Survived
2                   Target type           Binary
3           Original data shape         (712, 8)
4        Transformed data shape         (712, 8)
5   Transformed train set shape         (498, 8)
6    Transformed test set shape         (214, 8)
7              Numeric features                7
8                    Preprocess             True
9               Imputation type           simple
10           Numeric imputation             mean
11       Categorical imputation             mode
12               Fold Generator  StratifiedKFold
13                  Fold Number               10
14                     CPU Jobs               -1
15                      Use GPU            False
16               Log Experiment     MlflowLogger
17              Experiment Name    titanic_exp_2
18                          USI             a0b1
2025-10-12 16:28:09,034:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:28:09,036:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:28:09,081:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:28:09,084:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:28:09,085:INFO:Logging experiment in loggers
2025-10-12 16:28:09,218:INFO:SubProcess save_model() called ==================================
2025-10-12 16:28:09,221:INFO:Initializing save_model()
2025-10-12 16:28:09,221:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\david\AppData\Local\Temp\tmpd9ghf6en\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 16:28:09,221:INFO:Adding model into prep_pipe
2025-10-12 16:28:09,221:WARNING:Only Model saved as it was a pipeline.
2025-10-12 16:28:09,224:INFO:C:\Users\david\AppData\Local\Temp\tmpd9ghf6en\Transformation Pipeline.pkl saved in current working directory
2025-10-12 16:28:09,225:INFO:Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-12 16:28:09,225:INFO:save_model() successfully completed......................................
2025-10-12 16:28:09,338:INFO:SubProcess save_model() end ==================================
2025-10-12 16:28:09,410:INFO:setup() successfully completed in 0.46s...............
2025-10-12 16:28:16,882:INFO:Initializing compare_models()
2025-10-12 16:28:16,882:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:28:16,882:INFO:Checking exceptions
2025-10-12 16:28:16,886:INFO:Preparing display monitor
2025-10-12 16:28:16,914:INFO:Initializing Logistic Regression
2025-10-12 16:28:16,915:INFO:Total runtime is 1.666545867919922e-05 minutes
2025-10-12 16:28:16,919:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:16,920:INFO:Initializing create_model()
2025-10-12 16:28:16,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:16,921:INFO:Checking exceptions
2025-10-12 16:28:16,921:INFO:Importing libraries
2025-10-12 16:28:16,921:INFO:Copying training dataset
2025-10-12 16:28:16,926:INFO:Defining folds
2025-10-12 16:28:16,926:INFO:Declaring metric variables
2025-10-12 16:28:16,930:INFO:Importing untrained model
2025-10-12 16:28:16,935:INFO:Logistic Regression Imported successfully
2025-10-12 16:28:16,943:INFO:Starting cross validation
2025-10-12 16:28:16,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:23,469:INFO:Calculating mean and std
2025-10-12 16:28:23,471:INFO:Creating metrics dataframe
2025-10-12 16:28:23,474:INFO:Uploading results into container
2025-10-12 16:28:23,474:INFO:Uploading model into container now
2025-10-12 16:28:23,475:INFO:_master_model_container: 1
2025-10-12 16:28:23,475:INFO:_display_container: 2
2025-10-12 16:28:23,476:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5816, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:28:23,476:INFO:create_model() successfully completed......................................
2025-10-12 16:28:23,620:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:23,620:INFO:Creating metrics dataframe
2025-10-12 16:28:23,627:INFO:Initializing K Neighbors Classifier
2025-10-12 16:28:23,627:INFO:Total runtime is 0.1118917187054952 minutes
2025-10-12 16:28:23,629:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:23,630:INFO:Initializing create_model()
2025-10-12 16:28:23,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:23,630:INFO:Checking exceptions
2025-10-12 16:28:23,630:INFO:Importing libraries
2025-10-12 16:28:23,630:INFO:Copying training dataset
2025-10-12 16:28:23,634:INFO:Defining folds
2025-10-12 16:28:23,634:INFO:Declaring metric variables
2025-10-12 16:28:23,636:INFO:Importing untrained model
2025-10-12 16:28:23,639:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:28:23,644:INFO:Starting cross validation
2025-10-12 16:28:23,644:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:27,951:INFO:Calculating mean and std
2025-10-12 16:28:27,954:INFO:Creating metrics dataframe
2025-10-12 16:28:27,957:INFO:Uploading results into container
2025-10-12 16:28:27,959:INFO:Uploading model into container now
2025-10-12 16:28:27,959:INFO:_master_model_container: 2
2025-10-12 16:28:27,959:INFO:_display_container: 2
2025-10-12 16:28:27,960:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:28:27,960:INFO:create_model() successfully completed......................................
2025-10-12 16:28:28,087:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:28,087:INFO:Creating metrics dataframe
2025-10-12 16:28:28,094:INFO:Initializing Naive Bayes
2025-10-12 16:28:28,094:INFO:Total runtime is 0.18633490800857544 minutes
2025-10-12 16:28:28,099:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:28,099:INFO:Initializing create_model()
2025-10-12 16:28:28,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:28,099:INFO:Checking exceptions
2025-10-12 16:28:28,099:INFO:Importing libraries
2025-10-12 16:28:28,099:INFO:Copying training dataset
2025-10-12 16:28:28,102:INFO:Defining folds
2025-10-12 16:28:28,103:INFO:Declaring metric variables
2025-10-12 16:28:28,106:INFO:Importing untrained model
2025-10-12 16:28:28,109:INFO:Naive Bayes Imported successfully
2025-10-12 16:28:28,114:INFO:Starting cross validation
2025-10-12 16:28:28,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:28,186:INFO:Calculating mean and std
2025-10-12 16:28:28,186:INFO:Creating metrics dataframe
2025-10-12 16:28:28,188:INFO:Uploading results into container
2025-10-12 16:28:28,188:INFO:Uploading model into container now
2025-10-12 16:28:28,189:INFO:_master_model_container: 3
2025-10-12 16:28:28,189:INFO:_display_container: 2
2025-10-12 16:28:28,189:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:28:28,189:INFO:create_model() successfully completed......................................
2025-10-12 16:28:28,301:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:28,301:INFO:Creating metrics dataframe
2025-10-12 16:28:28,306:INFO:Initializing Decision Tree Classifier
2025-10-12 16:28:28,306:INFO:Total runtime is 0.1898692528406779 minutes
2025-10-12 16:28:28,310:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:28,310:INFO:Initializing create_model()
2025-10-12 16:28:28,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:28,310:INFO:Checking exceptions
2025-10-12 16:28:28,310:INFO:Importing libraries
2025-10-12 16:28:28,310:INFO:Copying training dataset
2025-10-12 16:28:28,314:INFO:Defining folds
2025-10-12 16:28:28,314:INFO:Declaring metric variables
2025-10-12 16:28:28,317:INFO:Importing untrained model
2025-10-12 16:28:28,320:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:28:28,328:INFO:Starting cross validation
2025-10-12 16:28:28,330:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:28,403:INFO:Calculating mean and std
2025-10-12 16:28:28,403:INFO:Creating metrics dataframe
2025-10-12 16:28:28,405:INFO:Uploading results into container
2025-10-12 16:28:28,406:INFO:Uploading model into container now
2025-10-12 16:28:28,406:INFO:_master_model_container: 4
2025-10-12 16:28:28,406:INFO:_display_container: 2
2025-10-12 16:28:28,406:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5816, splitter='best')
2025-10-12 16:28:28,407:INFO:create_model() successfully completed......................................
2025-10-12 16:28:28,521:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:28,521:INFO:Creating metrics dataframe
2025-10-12 16:28:28,527:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:28:28,527:INFO:Total runtime is 0.1935593088467916 minutes
2025-10-12 16:28:28,530:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:28,530:INFO:Initializing create_model()
2025-10-12 16:28:28,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:28,531:INFO:Checking exceptions
2025-10-12 16:28:28,531:INFO:Importing libraries
2025-10-12 16:28:28,531:INFO:Copying training dataset
2025-10-12 16:28:28,533:INFO:Defining folds
2025-10-12 16:28:28,534:INFO:Declaring metric variables
2025-10-12 16:28:28,537:INFO:Importing untrained model
2025-10-12 16:28:28,539:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:28:28,546:INFO:Starting cross validation
2025-10-12 16:28:28,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:28,580:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:28:28,581:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:28:28,607:INFO:Calculating mean and std
2025-10-12 16:28:28,607:INFO:Creating metrics dataframe
2025-10-12 16:28:28,609:INFO:Uploading results into container
2025-10-12 16:28:28,609:INFO:Uploading model into container now
2025-10-12 16:28:28,609:INFO:_master_model_container: 5
2025-10-12 16:28:28,609:INFO:_display_container: 2
2025-10-12 16:28:28,610:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5816, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:28:28,610:INFO:create_model() successfully completed......................................
2025-10-12 16:28:28,744:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:28,744:INFO:Creating metrics dataframe
2025-10-12 16:28:28,750:INFO:Initializing Ridge Classifier
2025-10-12 16:28:28,750:INFO:Total runtime is 0.19726970593134563 minutes
2025-10-12 16:28:28,753:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:28,753:INFO:Initializing create_model()
2025-10-12 16:28:28,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:28,753:INFO:Checking exceptions
2025-10-12 16:28:28,753:INFO:Importing libraries
2025-10-12 16:28:28,753:INFO:Copying training dataset
2025-10-12 16:28:28,756:INFO:Defining folds
2025-10-12 16:28:28,756:INFO:Declaring metric variables
2025-10-12 16:28:28,761:INFO:Importing untrained model
2025-10-12 16:28:28,764:INFO:Ridge Classifier Imported successfully
2025-10-12 16:28:28,770:INFO:Starting cross validation
2025-10-12 16:28:28,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:28,825:INFO:Calculating mean and std
2025-10-12 16:28:28,825:INFO:Creating metrics dataframe
2025-10-12 16:28:28,827:INFO:Uploading results into container
2025-10-12 16:28:28,827:INFO:Uploading model into container now
2025-10-12 16:28:28,828:INFO:_master_model_container: 6
2025-10-12 16:28:28,828:INFO:_display_container: 2
2025-10-12 16:28:28,828:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5816, solver='auto',
                tol=0.0001)
2025-10-12 16:28:28,828:INFO:create_model() successfully completed......................................
2025-10-12 16:28:28,939:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:28,939:INFO:Creating metrics dataframe
2025-10-12 16:28:28,945:INFO:Initializing Random Forest Classifier
2025-10-12 16:28:28,945:INFO:Total runtime is 0.20052676995595298 minutes
2025-10-12 16:28:28,947:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:28,948:INFO:Initializing create_model()
2025-10-12 16:28:28,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:28,948:INFO:Checking exceptions
2025-10-12 16:28:28,948:INFO:Importing libraries
2025-10-12 16:28:28,948:INFO:Copying training dataset
2025-10-12 16:28:28,951:INFO:Defining folds
2025-10-12 16:28:28,952:INFO:Declaring metric variables
2025-10-12 16:28:28,954:INFO:Importing untrained model
2025-10-12 16:28:28,957:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:28:28,961:INFO:Starting cross validation
2025-10-12 16:28:28,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:29,309:INFO:Calculating mean and std
2025-10-12 16:28:29,311:INFO:Creating metrics dataframe
2025-10-12 16:28:29,313:INFO:Uploading results into container
2025-10-12 16:28:29,314:INFO:Uploading model into container now
2025-10-12 16:28:29,314:INFO:_master_model_container: 7
2025-10-12 16:28:29,314:INFO:_display_container: 2
2025-10-12 16:28:29,315:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5816, verbose=0,
                       warm_start=False)
2025-10-12 16:28:29,315:INFO:create_model() successfully completed......................................
2025-10-12 16:28:29,430:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:29,430:INFO:Creating metrics dataframe
2025-10-12 16:28:29,437:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:28:29,437:INFO:Total runtime is 0.2087215065956116 minutes
2025-10-12 16:28:29,440:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:29,440:INFO:Initializing create_model()
2025-10-12 16:28:29,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:29,440:INFO:Checking exceptions
2025-10-12 16:28:29,440:INFO:Importing libraries
2025-10-12 16:28:29,440:INFO:Copying training dataset
2025-10-12 16:28:29,443:INFO:Defining folds
2025-10-12 16:28:29,443:INFO:Declaring metric variables
2025-10-12 16:28:29,446:INFO:Importing untrained model
2025-10-12 16:28:29,448:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:28:29,454:INFO:Starting cross validation
2025-10-12 16:28:29,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:29,527:INFO:Calculating mean and std
2025-10-12 16:28:29,527:INFO:Creating metrics dataframe
2025-10-12 16:28:29,529:INFO:Uploading results into container
2025-10-12 16:28:29,529:INFO:Uploading model into container now
2025-10-12 16:28:29,530:INFO:_master_model_container: 8
2025-10-12 16:28:29,530:INFO:_display_container: 2
2025-10-12 16:28:29,530:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:28:29,530:INFO:create_model() successfully completed......................................
2025-10-12 16:28:29,640:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:29,640:INFO:Creating metrics dataframe
2025-10-12 16:28:29,646:INFO:Initializing Ada Boost Classifier
2025-10-12 16:28:29,647:INFO:Total runtime is 0.21220611333847048 minutes
2025-10-12 16:28:29,649:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:29,649:INFO:Initializing create_model()
2025-10-12 16:28:29,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:29,649:INFO:Checking exceptions
2025-10-12 16:28:29,650:INFO:Importing libraries
2025-10-12 16:28:29,650:INFO:Copying training dataset
2025-10-12 16:28:29,653:INFO:Defining folds
2025-10-12 16:28:29,653:INFO:Declaring metric variables
2025-10-12 16:28:29,656:INFO:Importing untrained model
2025-10-12 16:28:29,659:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:28:29,665:INFO:Starting cross validation
2025-10-12 16:28:29,666:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:29,682:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:28:29,684:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:28:29,687:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:28:29,687:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:28:29,688:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:28:29,692:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:28:29,692:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:28:29,697:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:28:29,698:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:28:29,700:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:28:29,853:INFO:Calculating mean and std
2025-10-12 16:28:29,854:INFO:Creating metrics dataframe
2025-10-12 16:28:29,856:INFO:Uploading results into container
2025-10-12 16:28:29,856:INFO:Uploading model into container now
2025-10-12 16:28:29,857:INFO:_master_model_container: 9
2025-10-12 16:28:29,857:INFO:_display_container: 2
2025-10-12 16:28:29,857:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5816)
2025-10-12 16:28:29,857:INFO:create_model() successfully completed......................................
2025-10-12 16:28:29,968:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:29,968:INFO:Creating metrics dataframe
2025-10-12 16:28:29,974:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:28:29,974:INFO:Total runtime is 0.21767268180847169 minutes
2025-10-12 16:28:29,976:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:29,977:INFO:Initializing create_model()
2025-10-12 16:28:29,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:29,977:INFO:Checking exceptions
2025-10-12 16:28:29,977:INFO:Importing libraries
2025-10-12 16:28:29,977:INFO:Copying training dataset
2025-10-12 16:28:29,980:INFO:Defining folds
2025-10-12 16:28:29,980:INFO:Declaring metric variables
2025-10-12 16:28:29,983:INFO:Importing untrained model
2025-10-12 16:28:29,986:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:28:29,990:INFO:Starting cross validation
2025-10-12 16:28:29,991:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:30,212:INFO:Calculating mean and std
2025-10-12 16:28:30,213:INFO:Creating metrics dataframe
2025-10-12 16:28:30,215:INFO:Uploading results into container
2025-10-12 16:28:30,215:INFO:Uploading model into container now
2025-10-12 16:28:30,216:INFO:_master_model_container: 10
2025-10-12 16:28:30,216:INFO:_display_container: 2
2025-10-12 16:28:30,216:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5816, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:28:30,216:INFO:create_model() successfully completed......................................
2025-10-12 16:28:30,367:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:30,368:INFO:Creating metrics dataframe
2025-10-12 16:28:30,374:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:28:30,375:INFO:Total runtime is 0.2243542989095052 minutes
2025-10-12 16:28:30,378:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:30,378:INFO:Initializing create_model()
2025-10-12 16:28:30,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:30,378:INFO:Checking exceptions
2025-10-12 16:28:30,378:INFO:Importing libraries
2025-10-12 16:28:30,378:INFO:Copying training dataset
2025-10-12 16:28:30,381:INFO:Defining folds
2025-10-12 16:28:30,382:INFO:Declaring metric variables
2025-10-12 16:28:30,385:INFO:Importing untrained model
2025-10-12 16:28:30,389:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:28:30,394:INFO:Starting cross validation
2025-10-12 16:28:30,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:30,460:INFO:Calculating mean and std
2025-10-12 16:28:30,460:INFO:Creating metrics dataframe
2025-10-12 16:28:30,462:INFO:Uploading results into container
2025-10-12 16:28:30,462:INFO:Uploading model into container now
2025-10-12 16:28:30,462:INFO:_master_model_container: 11
2025-10-12 16:28:30,462:INFO:_display_container: 2
2025-10-12 16:28:30,463:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:28:30,463:INFO:create_model() successfully completed......................................
2025-10-12 16:28:30,574:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:30,575:INFO:Creating metrics dataframe
2025-10-12 16:28:30,581:INFO:Initializing Extra Trees Classifier
2025-10-12 16:28:30,581:INFO:Total runtime is 0.22779125769933065 minutes
2025-10-12 16:28:30,585:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:30,585:INFO:Initializing create_model()
2025-10-12 16:28:30,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:30,585:INFO:Checking exceptions
2025-10-12 16:28:30,585:INFO:Importing libraries
2025-10-12 16:28:30,585:INFO:Copying training dataset
2025-10-12 16:28:30,588:INFO:Defining folds
2025-10-12 16:28:30,588:INFO:Declaring metric variables
2025-10-12 16:28:30,591:INFO:Importing untrained model
2025-10-12 16:28:30,595:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:28:30,600:INFO:Starting cross validation
2025-10-12 16:28:30,601:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:30,891:INFO:Calculating mean and std
2025-10-12 16:28:30,892:INFO:Creating metrics dataframe
2025-10-12 16:28:30,894:INFO:Uploading results into container
2025-10-12 16:28:30,895:INFO:Uploading model into container now
2025-10-12 16:28:30,895:INFO:_master_model_container: 12
2025-10-12 16:28:30,896:INFO:_display_container: 2
2025-10-12 16:28:30,896:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5816, verbose=0,
                     warm_start=False)
2025-10-12 16:28:30,896:INFO:create_model() successfully completed......................................
2025-10-12 16:28:31,010:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:31,010:INFO:Creating metrics dataframe
2025-10-12 16:28:31,017:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:28:31,017:INFO:Total runtime is 0.23505254983901977 minutes
2025-10-12 16:28:31,020:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:31,020:INFO:Initializing create_model()
2025-10-12 16:28:31,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:31,020:INFO:Checking exceptions
2025-10-12 16:28:31,020:INFO:Importing libraries
2025-10-12 16:28:31,020:INFO:Copying training dataset
2025-10-12 16:28:31,023:INFO:Defining folds
2025-10-12 16:28:31,025:INFO:Declaring metric variables
2025-10-12 16:28:31,028:INFO:Importing untrained model
2025-10-12 16:28:31,030:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:28:31,036:INFO:Starting cross validation
2025-10-12 16:28:31,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:31,623:INFO:Calculating mean and std
2025-10-12 16:28:31,625:INFO:Creating metrics dataframe
2025-10-12 16:28:31,628:INFO:Uploading results into container
2025-10-12 16:28:31,629:INFO:Uploading model into container now
2025-10-12 16:28:31,629:INFO:_master_model_container: 13
2025-10-12 16:28:31,629:INFO:_display_container: 2
2025-10-12 16:28:31,629:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:28:31,630:INFO:create_model() successfully completed......................................
2025-10-12 16:28:31,765:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:31,765:INFO:Creating metrics dataframe
2025-10-12 16:28:31,772:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:28:31,772:INFO:Total runtime is 0.24763915538787842 minutes
2025-10-12 16:28:31,775:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:31,775:INFO:Initializing create_model()
2025-10-12 16:28:31,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:31,775:INFO:Checking exceptions
2025-10-12 16:28:31,775:INFO:Importing libraries
2025-10-12 16:28:31,775:INFO:Copying training dataset
2025-10-12 16:28:31,779:INFO:Defining folds
2025-10-12 16:28:31,779:INFO:Declaring metric variables
2025-10-12 16:28:31,781:INFO:Importing untrained model
2025-10-12 16:28:31,786:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:28:31,797:INFO:Starting cross validation
2025-10-12 16:28:31,798:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:32,998:INFO:Calculating mean and std
2025-10-12 16:28:33,000:INFO:Creating metrics dataframe
2025-10-12 16:28:33,001:INFO:Uploading results into container
2025-10-12 16:28:33,003:INFO:Uploading model into container now
2025-10-12 16:28:33,004:INFO:_master_model_container: 14
2025-10-12 16:28:33,004:INFO:_display_container: 2
2025-10-12 16:28:33,005:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5816, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:28:33,005:INFO:create_model() successfully completed......................................
2025-10-12 16:28:33,138:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:33,138:INFO:Creating metrics dataframe
2025-10-12 16:28:33,145:INFO:Initializing CatBoost Classifier
2025-10-12 16:28:33,146:INFO:Total runtime is 0.2705394983291626 minutes
2025-10-12 16:28:33,148:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:33,148:INFO:Initializing create_model()
2025-10-12 16:28:33,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:33,149:INFO:Checking exceptions
2025-10-12 16:28:33,149:INFO:Importing libraries
2025-10-12 16:28:33,149:INFO:Copying training dataset
2025-10-12 16:28:33,152:INFO:Defining folds
2025-10-12 16:28:33,152:INFO:Declaring metric variables
2025-10-12 16:28:33,155:INFO:Importing untrained model
2025-10-12 16:28:33,158:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:28:33,163:INFO:Starting cross validation
2025-10-12 16:28:33,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:37,742:INFO:Calculating mean and std
2025-10-12 16:28:37,743:INFO:Creating metrics dataframe
2025-10-12 16:28:37,745:INFO:Uploading results into container
2025-10-12 16:28:37,746:INFO:Uploading model into container now
2025-10-12 16:28:37,747:INFO:_master_model_container: 15
2025-10-12 16:28:37,747:INFO:_display_container: 2
2025-10-12 16:28:37,747:INFO:<catboost.core.CatBoostClassifier object at 0x000001685471EBB0>
2025-10-12 16:28:37,747:INFO:create_model() successfully completed......................................
2025-10-12 16:28:37,878:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:37,878:INFO:Creating metrics dataframe
2025-10-12 16:28:37,887:INFO:Initializing Dummy Classifier
2025-10-12 16:28:37,887:INFO:Total runtime is 0.34955604473749796 minutes
2025-10-12 16:28:37,890:INFO:SubProcess create_model() called ==================================
2025-10-12 16:28:37,891:INFO:Initializing create_model()
2025-10-12 16:28:37,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168549252E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:37,891:INFO:Checking exceptions
2025-10-12 16:28:37,891:INFO:Importing libraries
2025-10-12 16:28:37,891:INFO:Copying training dataset
2025-10-12 16:28:37,895:INFO:Defining folds
2025-10-12 16:28:37,895:INFO:Declaring metric variables
2025-10-12 16:28:37,900:INFO:Importing untrained model
2025-10-12 16:28:37,905:INFO:Dummy Classifier Imported successfully
2025-10-12 16:28:37,912:INFO:Starting cross validation
2025-10-12 16:28:37,913:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:28:37,947:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:28:37,955:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:28:37,956:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:28:37,956:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:28:37,959:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:28:37,959:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:28:37,960:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:28:37,960:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:28:37,965:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:28:37,969:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:28:37,991:INFO:Calculating mean and std
2025-10-12 16:28:37,991:INFO:Creating metrics dataframe
2025-10-12 16:28:37,993:INFO:Uploading results into container
2025-10-12 16:28:37,994:INFO:Uploading model into container now
2025-10-12 16:28:37,994:INFO:_master_model_container: 16
2025-10-12 16:28:37,995:INFO:_display_container: 2
2025-10-12 16:28:37,995:INFO:DummyClassifier(constant=None, random_state=5816, strategy='prior')
2025-10-12 16:28:37,995:INFO:create_model() successfully completed......................................
2025-10-12 16:28:38,111:INFO:SubProcess create_model() end ==================================
2025-10-12 16:28:38,112:INFO:Creating metrics dataframe
2025-10-12 16:28:38,120:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:28:38,127:INFO:Initializing create_model()
2025-10-12 16:28:38,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001685471EBB0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:28:38,127:INFO:Checking exceptions
2025-10-12 16:28:38,128:INFO:Importing libraries
2025-10-12 16:28:38,128:INFO:Copying training dataset
2025-10-12 16:28:38,130:INFO:Defining folds
2025-10-12 16:28:38,131:INFO:Declaring metric variables
2025-10-12 16:28:38,131:INFO:Importing untrained model
2025-10-12 16:28:38,131:INFO:Declaring custom model
2025-10-12 16:28:38,132:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:28:38,132:INFO:Cross validation set to False
2025-10-12 16:28:38,132:INFO:Fitting Model
2025-10-12 16:28:39,851:INFO:<catboost.core.CatBoostClassifier object at 0x000001685430A640>
2025-10-12 16:28:39,851:INFO:create_model() successfully completed......................................
2025-10-12 16:28:39,972:INFO:Creating Dashboard logs
2025-10-12 16:28:39,975:INFO:Model: CatBoost Classifier
2025-10-12 16:28:40,050:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'Logloss', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 5816, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.007650000043213368, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 10, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2025-10-12 16:28:40,504:INFO:Initializing predict_model()
2025-10-12 16:28:40,504:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001685430A640>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016854493700>)
2025-10-12 16:28:40,504:INFO:Checking exceptions
2025-10-12 16:28:40,504:INFO:Preloading libraries
2025-10-12 16:28:40,681:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:28:40,681:INFO:Initializing plot_model()
2025-10-12 16:28:40,681:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001685430A640>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpf9j934ty, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:28:40,681:INFO:Checking exceptions
2025-10-12 16:28:40,682:INFO:Preloading libraries
2025-10-12 16:28:40,683:INFO:Copying training dataset
2025-10-12 16:28:40,683:INFO:Plot type: auc
2025-10-12 16:28:40,727:INFO:Fitting Model
2025-10-12 16:28:40,742:INFO:Scoring test/hold-out set
2025-10-12 16:28:40,759:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpf9j934ty\AUC.png'
2025-10-12 16:28:40,968:INFO:Visual Rendered Successfully
2025-10-12 16:28:41,119:INFO:plot_model() successfully completed......................................
2025-10-12 16:28:41,135:INFO:Initializing plot_model()
2025-10-12 16:28:41,135:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001685430A640>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpf9j934ty, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:28:41,135:INFO:Checking exceptions
2025-10-12 16:28:41,136:INFO:Preloading libraries
2025-10-12 16:28:41,137:INFO:Copying training dataset
2025-10-12 16:28:41,137:INFO:Plot type: confusion_matrix
2025-10-12 16:28:41,179:INFO:Fitting Model
2025-10-12 16:28:41,180:INFO:Scoring test/hold-out set
2025-10-12 16:28:41,194:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpf9j934ty\Confusion Matrix.png'
2025-10-12 16:28:41,279:INFO:Visual Rendered Successfully
2025-10-12 16:28:41,400:INFO:plot_model() successfully completed......................................
2025-10-12 16:28:41,419:INFO:Initializing plot_model()
2025-10-12 16:28:41,419:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001685430A640>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpf9j934ty, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:28:41,419:INFO:Checking exceptions
2025-10-12 16:28:41,420:INFO:Preloading libraries
2025-10-12 16:28:41,421:INFO:Copying training dataset
2025-10-12 16:28:41,421:INFO:Plot type: feature
2025-10-12 16:28:41,421:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:28:41,448:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpf9j934ty\Feature Importance.png'
2025-10-12 16:28:41,554:INFO:Visual Rendered Successfully
2025-10-12 16:28:41,670:INFO:plot_model() successfully completed......................................
2025-10-12 16:28:41,689:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:28:41,691:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml

2025-10-12 16:28:43,734:INFO:Creating Dashboard logs
2025-10-12 16:28:43,738:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:28:43,809:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 5816, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:28:44,227:INFO:Creating Dashboard logs
2025-10-12 16:28:44,230:INFO:Model: Ada Boost Classifier
2025-10-12 16:28:44,307:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 5816}
2025-10-12 16:28:44,728:INFO:Creating Dashboard logs
2025-10-12 16:28:44,731:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:28:44,804:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5816, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:28:45,287:INFO:Creating Dashboard logs
2025-10-12 16:28:45,290:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 16:28:45,368:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:28:45,780:INFO:Creating Dashboard logs
2025-10-12 16:28:45,782:INFO:Model: Random Forest Classifier
2025-10-12 16:28:45,854:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5816, 'verbose': 0, 'warm_start': False}
2025-10-12 16:28:46,274:INFO:Creating Dashboard logs
2025-10-12 16:28:46,276:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:28:46,350:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 5816, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:28:46,820:INFO:Creating Dashboard logs
2025-10-12 16:28:46,824:INFO:Model: Extra Trees Classifier
2025-10-12 16:28:46,900:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5816, 'verbose': 0, 'warm_start': False}
2025-10-12 16:28:47,345:INFO:Creating Dashboard logs
2025-10-12 16:28:47,348:INFO:Model: Ridge Classifier
2025-10-12 16:28:47,423:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 5816, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:28:47,865:INFO:Creating Dashboard logs
2025-10-12 16:28:47,868:INFO:Model: Logistic Regression
2025-10-12 16:28:47,942:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 5816, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:28:48,385:INFO:Creating Dashboard logs
2025-10-12 16:28:48,389:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:28:48,472:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:28:48,906:INFO:Creating Dashboard logs
2025-10-12 16:28:48,909:INFO:Model: Naive Bayes
2025-10-12 16:28:48,987:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:28:49,390:INFO:Creating Dashboard logs
2025-10-12 16:28:49,393:INFO:Model: Decision Tree Classifier
2025-10-12 16:28:49,468:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 5816, 'splitter': 'best'}
2025-10-12 16:28:49,908:INFO:Creating Dashboard logs
2025-10-12 16:28:49,911:INFO:Model: SVM - Linear Kernel
2025-10-12 16:28:49,983:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 5816, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:28:50,442:INFO:Creating Dashboard logs
2025-10-12 16:28:50,445:INFO:Model: K Neighbors Classifier
2025-10-12 16:28:50,519:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:28:50,968:INFO:Creating Dashboard logs
2025-10-12 16:28:50,971:INFO:Model: Dummy Classifier
2025-10-12 16:28:51,045:INFO:Logged params: {'constant': None, 'random_state': 5816, 'strategy': 'prior'}
2025-10-12 16:28:51,414:INFO:_master_model_container: 16
2025-10-12 16:28:51,414:INFO:_display_container: 2
2025-10-12 16:28:51,414:INFO:<catboost.core.CatBoostClassifier object at 0x000001685430A640>
2025-10-12 16:28:51,414:INFO:compare_models() successfully completed......................................
2025-10-12 16:29:00,236:INFO:Initializing compare_models()
2025-10-12 16:29:00,237:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:29:00,237:INFO:Checking exceptions
2025-10-12 16:29:00,238:INFO:Preparing display monitor
2025-10-12 16:29:00,255:INFO:Initializing Logistic Regression
2025-10-12 16:29:00,255:INFO:Total runtime is 0.0 minutes
2025-10-12 16:29:00,258:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:00,259:INFO:Initializing create_model()
2025-10-12 16:29:00,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:00,259:INFO:Checking exceptions
2025-10-12 16:29:00,259:INFO:Importing libraries
2025-10-12 16:29:00,259:INFO:Copying training dataset
2025-10-12 16:29:00,261:INFO:Defining folds
2025-10-12 16:29:00,261:INFO:Declaring metric variables
2025-10-12 16:29:00,264:INFO:Importing untrained model
2025-10-12 16:29:00,267:INFO:Logistic Regression Imported successfully
2025-10-12 16:29:00,273:INFO:Starting cross validation
2025-10-12 16:29:00,274:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:00,349:INFO:Calculating mean and std
2025-10-12 16:29:00,349:INFO:Creating metrics dataframe
2025-10-12 16:29:00,350:INFO:Uploading results into container
2025-10-12 16:29:00,351:INFO:Uploading model into container now
2025-10-12 16:29:00,351:INFO:_master_model_container: 17
2025-10-12 16:29:00,351:INFO:_display_container: 3
2025-10-12 16:29:00,351:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5816, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:29:00,351:INFO:create_model() successfully completed......................................
2025-10-12 16:29:00,469:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:00,469:INFO:Creating metrics dataframe
2025-10-12 16:29:00,475:INFO:Initializing K Neighbors Classifier
2025-10-12 16:29:00,475:INFO:Total runtime is 0.003665479024251302 minutes
2025-10-12 16:29:00,478:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:00,478:INFO:Initializing create_model()
2025-10-12 16:29:00,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:00,479:INFO:Checking exceptions
2025-10-12 16:29:00,479:INFO:Importing libraries
2025-10-12 16:29:00,479:INFO:Copying training dataset
2025-10-12 16:29:00,481:INFO:Defining folds
2025-10-12 16:29:00,481:INFO:Declaring metric variables
2025-10-12 16:29:00,484:INFO:Importing untrained model
2025-10-12 16:29:00,487:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:29:00,495:INFO:Starting cross validation
2025-10-12 16:29:00,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:00,644:INFO:Calculating mean and std
2025-10-12 16:29:00,644:INFO:Creating metrics dataframe
2025-10-12 16:29:00,646:INFO:Uploading results into container
2025-10-12 16:29:00,646:INFO:Uploading model into container now
2025-10-12 16:29:00,646:INFO:_master_model_container: 18
2025-10-12 16:29:00,646:INFO:_display_container: 3
2025-10-12 16:29:00,646:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:29:00,647:INFO:create_model() successfully completed......................................
2025-10-12 16:29:00,758:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:00,758:INFO:Creating metrics dataframe
2025-10-12 16:29:00,764:INFO:Initializing Naive Bayes
2025-10-12 16:29:00,764:INFO:Total runtime is 0.008476634820302328 minutes
2025-10-12 16:29:00,767:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:00,767:INFO:Initializing create_model()
2025-10-12 16:29:00,767:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:00,767:INFO:Checking exceptions
2025-10-12 16:29:00,768:INFO:Importing libraries
2025-10-12 16:29:00,768:INFO:Copying training dataset
2025-10-12 16:29:00,771:INFO:Defining folds
2025-10-12 16:29:00,771:INFO:Declaring metric variables
2025-10-12 16:29:00,774:INFO:Importing untrained model
2025-10-12 16:29:00,777:INFO:Naive Bayes Imported successfully
2025-10-12 16:29:00,783:INFO:Starting cross validation
2025-10-12 16:29:00,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:00,847:INFO:Calculating mean and std
2025-10-12 16:29:00,847:INFO:Creating metrics dataframe
2025-10-12 16:29:00,849:INFO:Uploading results into container
2025-10-12 16:29:00,849:INFO:Uploading model into container now
2025-10-12 16:29:00,849:INFO:_master_model_container: 19
2025-10-12 16:29:00,850:INFO:_display_container: 3
2025-10-12 16:29:00,850:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:29:00,850:INFO:create_model() successfully completed......................................
2025-10-12 16:29:00,960:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:00,960:INFO:Creating metrics dataframe
2025-10-12 16:29:00,965:INFO:Initializing Decision Tree Classifier
2025-10-12 16:29:00,965:INFO:Total runtime is 0.011829423904418946 minutes
2025-10-12 16:29:00,968:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:00,968:INFO:Initializing create_model()
2025-10-12 16:29:00,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:00,968:INFO:Checking exceptions
2025-10-12 16:29:00,968:INFO:Importing libraries
2025-10-12 16:29:00,968:INFO:Copying training dataset
2025-10-12 16:29:00,971:INFO:Defining folds
2025-10-12 16:29:00,971:INFO:Declaring metric variables
2025-10-12 16:29:00,974:INFO:Importing untrained model
2025-10-12 16:29:00,977:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:29:00,983:INFO:Starting cross validation
2025-10-12 16:29:00,984:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:01,051:INFO:Calculating mean and std
2025-10-12 16:29:01,051:INFO:Creating metrics dataframe
2025-10-12 16:29:01,053:INFO:Uploading results into container
2025-10-12 16:29:01,054:INFO:Uploading model into container now
2025-10-12 16:29:01,054:INFO:_master_model_container: 20
2025-10-12 16:29:01,054:INFO:_display_container: 3
2025-10-12 16:29:01,054:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5816, splitter='best')
2025-10-12 16:29:01,054:INFO:create_model() successfully completed......................................
2025-10-12 16:29:01,164:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:01,165:INFO:Creating metrics dataframe
2025-10-12 16:29:01,170:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:29:01,170:INFO:Total runtime is 0.015251187483469646 minutes
2025-10-12 16:29:01,173:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:01,174:INFO:Initializing create_model()
2025-10-12 16:29:01,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:01,174:INFO:Checking exceptions
2025-10-12 16:29:01,174:INFO:Importing libraries
2025-10-12 16:29:01,174:INFO:Copying training dataset
2025-10-12 16:29:01,176:INFO:Defining folds
2025-10-12 16:29:01,176:INFO:Declaring metric variables
2025-10-12 16:29:01,178:INFO:Importing untrained model
2025-10-12 16:29:01,180:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:29:01,189:INFO:Starting cross validation
2025-10-12 16:29:01,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:01,230:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:29:01,233:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:29:01,273:INFO:Calculating mean and std
2025-10-12 16:29:01,274:INFO:Creating metrics dataframe
2025-10-12 16:29:01,276:INFO:Uploading results into container
2025-10-12 16:29:01,276:INFO:Uploading model into container now
2025-10-12 16:29:01,277:INFO:_master_model_container: 21
2025-10-12 16:29:01,277:INFO:_display_container: 3
2025-10-12 16:29:01,277:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5816, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:29:01,277:INFO:create_model() successfully completed......................................
2025-10-12 16:29:01,390:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:01,390:INFO:Creating metrics dataframe
2025-10-12 16:29:01,396:INFO:Initializing Ridge Classifier
2025-10-12 16:29:01,396:INFO:Total runtime is 0.019013305505116783 minutes
2025-10-12 16:29:01,400:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:01,400:INFO:Initializing create_model()
2025-10-12 16:29:01,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:01,400:INFO:Checking exceptions
2025-10-12 16:29:01,400:INFO:Importing libraries
2025-10-12 16:29:01,400:INFO:Copying training dataset
2025-10-12 16:29:01,403:INFO:Defining folds
2025-10-12 16:29:01,403:INFO:Declaring metric variables
2025-10-12 16:29:01,406:INFO:Importing untrained model
2025-10-12 16:29:01,408:INFO:Ridge Classifier Imported successfully
2025-10-12 16:29:01,416:INFO:Starting cross validation
2025-10-12 16:29:01,416:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:01,475:INFO:Calculating mean and std
2025-10-12 16:29:01,475:INFO:Creating metrics dataframe
2025-10-12 16:29:01,476:INFO:Uploading results into container
2025-10-12 16:29:01,477:INFO:Uploading model into container now
2025-10-12 16:29:01,477:INFO:_master_model_container: 22
2025-10-12 16:29:01,477:INFO:_display_container: 3
2025-10-12 16:29:01,477:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5816, solver='auto',
                tol=0.0001)
2025-10-12 16:29:01,477:INFO:create_model() successfully completed......................................
2025-10-12 16:29:01,590:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:01,590:INFO:Creating metrics dataframe
2025-10-12 16:29:01,595:INFO:Initializing Random Forest Classifier
2025-10-12 16:29:01,595:INFO:Total runtime is 0.022332060337066653 minutes
2025-10-12 16:29:01,598:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:01,598:INFO:Initializing create_model()
2025-10-12 16:29:01,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:01,598:INFO:Checking exceptions
2025-10-12 16:29:01,598:INFO:Importing libraries
2025-10-12 16:29:01,599:INFO:Copying training dataset
2025-10-12 16:29:01,601:INFO:Defining folds
2025-10-12 16:29:01,601:INFO:Declaring metric variables
2025-10-12 16:29:01,606:INFO:Importing untrained model
2025-10-12 16:29:01,613:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:29:01,620:INFO:Starting cross validation
2025-10-12 16:29:01,621:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:01,942:INFO:Calculating mean and std
2025-10-12 16:29:01,943:INFO:Creating metrics dataframe
2025-10-12 16:29:01,945:INFO:Uploading results into container
2025-10-12 16:29:01,945:INFO:Uploading model into container now
2025-10-12 16:29:01,946:INFO:_master_model_container: 23
2025-10-12 16:29:01,946:INFO:_display_container: 3
2025-10-12 16:29:01,947:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5816, verbose=0,
                       warm_start=False)
2025-10-12 16:29:01,947:INFO:create_model() successfully completed......................................
2025-10-12 16:29:02,056:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:02,056:INFO:Creating metrics dataframe
2025-10-12 16:29:02,062:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:29:02,062:INFO:Total runtime is 0.030114110310872397 minutes
2025-10-12 16:29:02,065:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:02,065:INFO:Initializing create_model()
2025-10-12 16:29:02,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:02,065:INFO:Checking exceptions
2025-10-12 16:29:02,065:INFO:Importing libraries
2025-10-12 16:29:02,065:INFO:Copying training dataset
2025-10-12 16:29:02,068:INFO:Defining folds
2025-10-12 16:29:02,068:INFO:Declaring metric variables
2025-10-12 16:29:02,072:INFO:Importing untrained model
2025-10-12 16:29:02,074:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:29:02,080:INFO:Starting cross validation
2025-10-12 16:29:02,081:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:02,146:INFO:Calculating mean and std
2025-10-12 16:29:02,146:INFO:Creating metrics dataframe
2025-10-12 16:29:02,148:INFO:Uploading results into container
2025-10-12 16:29:02,148:INFO:Uploading model into container now
2025-10-12 16:29:02,148:INFO:_master_model_container: 24
2025-10-12 16:29:02,148:INFO:_display_container: 3
2025-10-12 16:29:02,149:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:29:02,149:INFO:create_model() successfully completed......................................
2025-10-12 16:29:02,258:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:02,258:INFO:Creating metrics dataframe
2025-10-12 16:29:02,265:INFO:Initializing Ada Boost Classifier
2025-10-12 16:29:02,265:INFO:Total runtime is 0.03349790573120117 minutes
2025-10-12 16:29:02,268:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:02,268:INFO:Initializing create_model()
2025-10-12 16:29:02,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:02,268:INFO:Checking exceptions
2025-10-12 16:29:02,268:INFO:Importing libraries
2025-10-12 16:29:02,268:INFO:Copying training dataset
2025-10-12 16:29:02,271:INFO:Defining folds
2025-10-12 16:29:02,271:INFO:Declaring metric variables
2025-10-12 16:29:02,274:INFO:Importing untrained model
2025-10-12 16:29:02,277:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:29:02,281:INFO:Starting cross validation
2025-10-12 16:29:02,283:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:02,297:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:29:02,299:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:29:02,301:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:29:02,303:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:29:02,308:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:29:02,310:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:29:02,311:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:29:02,315:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:29:02,315:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:29:02,316:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:29:02,457:INFO:Calculating mean and std
2025-10-12 16:29:02,458:INFO:Creating metrics dataframe
2025-10-12 16:29:02,460:INFO:Uploading results into container
2025-10-12 16:29:02,460:INFO:Uploading model into container now
2025-10-12 16:29:02,460:INFO:_master_model_container: 25
2025-10-12 16:29:02,461:INFO:_display_container: 3
2025-10-12 16:29:02,461:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5816)
2025-10-12 16:29:02,461:INFO:create_model() successfully completed......................................
2025-10-12 16:29:02,572:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:02,573:INFO:Creating metrics dataframe
2025-10-12 16:29:02,579:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:29:02,579:INFO:Total runtime is 0.03872408469518025 minutes
2025-10-12 16:29:02,581:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:02,582:INFO:Initializing create_model()
2025-10-12 16:29:02,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:02,582:INFO:Checking exceptions
2025-10-12 16:29:02,582:INFO:Importing libraries
2025-10-12 16:29:02,582:INFO:Copying training dataset
2025-10-12 16:29:02,586:INFO:Defining folds
2025-10-12 16:29:02,586:INFO:Declaring metric variables
2025-10-12 16:29:02,588:INFO:Importing untrained model
2025-10-12 16:29:02,591:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:29:02,596:INFO:Starting cross validation
2025-10-12 16:29:02,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:02,800:INFO:Calculating mean and std
2025-10-12 16:29:02,801:INFO:Creating metrics dataframe
2025-10-12 16:29:02,803:INFO:Uploading results into container
2025-10-12 16:29:02,804:INFO:Uploading model into container now
2025-10-12 16:29:02,805:INFO:_master_model_container: 26
2025-10-12 16:29:02,805:INFO:_display_container: 3
2025-10-12 16:29:02,805:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5816, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:29:02,805:INFO:create_model() successfully completed......................................
2025-10-12 16:29:02,917:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:02,918:INFO:Creating metrics dataframe
2025-10-12 16:29:02,924:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:29:02,924:INFO:Total runtime is 0.04447715282440185 minutes
2025-10-12 16:29:02,926:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:02,927:INFO:Initializing create_model()
2025-10-12 16:29:02,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:02,927:INFO:Checking exceptions
2025-10-12 16:29:02,927:INFO:Importing libraries
2025-10-12 16:29:02,927:INFO:Copying training dataset
2025-10-12 16:29:02,930:INFO:Defining folds
2025-10-12 16:29:02,930:INFO:Declaring metric variables
2025-10-12 16:29:02,934:INFO:Importing untrained model
2025-10-12 16:29:02,935:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:29:02,941:INFO:Starting cross validation
2025-10-12 16:29:02,942:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:03,003:INFO:Calculating mean and std
2025-10-12 16:29:03,003:INFO:Creating metrics dataframe
2025-10-12 16:29:03,005:INFO:Uploading results into container
2025-10-12 16:29:03,005:INFO:Uploading model into container now
2025-10-12 16:29:03,005:INFO:_master_model_container: 27
2025-10-12 16:29:03,005:INFO:_display_container: 3
2025-10-12 16:29:03,006:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:29:03,006:INFO:create_model() successfully completed......................................
2025-10-12 16:29:03,114:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:03,114:INFO:Creating metrics dataframe
2025-10-12 16:29:03,121:INFO:Initializing Extra Trees Classifier
2025-10-12 16:29:03,121:INFO:Total runtime is 0.047767353057861325 minutes
2025-10-12 16:29:03,124:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:03,124:INFO:Initializing create_model()
2025-10-12 16:29:03,124:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:03,124:INFO:Checking exceptions
2025-10-12 16:29:03,124:INFO:Importing libraries
2025-10-12 16:29:03,125:INFO:Copying training dataset
2025-10-12 16:29:03,127:INFO:Defining folds
2025-10-12 16:29:03,127:INFO:Declaring metric variables
2025-10-12 16:29:03,129:INFO:Importing untrained model
2025-10-12 16:29:03,133:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:29:03,138:INFO:Starting cross validation
2025-10-12 16:29:03,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:03,424:INFO:Calculating mean and std
2025-10-12 16:29:03,425:INFO:Creating metrics dataframe
2025-10-12 16:29:03,427:INFO:Uploading results into container
2025-10-12 16:29:03,427:INFO:Uploading model into container now
2025-10-12 16:29:03,428:INFO:_master_model_container: 28
2025-10-12 16:29:03,428:INFO:_display_container: 3
2025-10-12 16:29:03,428:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5816, verbose=0,
                     warm_start=False)
2025-10-12 16:29:03,429:INFO:create_model() successfully completed......................................
2025-10-12 16:29:03,541:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:03,542:INFO:Creating metrics dataframe
2025-10-12 16:29:03,548:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:29:03,548:INFO:Total runtime is 0.054879196484883624 minutes
2025-10-12 16:29:03,551:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:03,551:INFO:Initializing create_model()
2025-10-12 16:29:03,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:03,551:INFO:Checking exceptions
2025-10-12 16:29:03,551:INFO:Importing libraries
2025-10-12 16:29:03,551:INFO:Copying training dataset
2025-10-12 16:29:03,554:INFO:Defining folds
2025-10-12 16:29:03,555:INFO:Declaring metric variables
2025-10-12 16:29:03,558:INFO:Importing untrained model
2025-10-12 16:29:03,561:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:29:03,568:INFO:Starting cross validation
2025-10-12 16:29:03,570:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:03,871:INFO:Calculating mean and std
2025-10-12 16:29:03,872:INFO:Creating metrics dataframe
2025-10-12 16:29:03,874:INFO:Uploading results into container
2025-10-12 16:29:03,874:INFO:Uploading model into container now
2025-10-12 16:29:03,875:INFO:_master_model_container: 29
2025-10-12 16:29:03,875:INFO:_display_container: 3
2025-10-12 16:29:03,875:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:29:03,875:INFO:create_model() successfully completed......................................
2025-10-12 16:29:03,986:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:03,986:INFO:Creating metrics dataframe
2025-10-12 16:29:03,993:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:29:03,993:INFO:Total runtime is 0.06229674816131592 minutes
2025-10-12 16:29:03,996:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:03,996:INFO:Initializing create_model()
2025-10-12 16:29:03,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:03,996:INFO:Checking exceptions
2025-10-12 16:29:03,996:INFO:Importing libraries
2025-10-12 16:29:03,996:INFO:Copying training dataset
2025-10-12 16:29:03,999:INFO:Defining folds
2025-10-12 16:29:03,999:INFO:Declaring metric variables
2025-10-12 16:29:04,001:INFO:Importing untrained model
2025-10-12 16:29:04,005:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:29:04,015:INFO:Starting cross validation
2025-10-12 16:29:04,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:06,028:INFO:Calculating mean and std
2025-10-12 16:29:06,030:INFO:Creating metrics dataframe
2025-10-12 16:29:06,032:INFO:Uploading results into container
2025-10-12 16:29:06,033:INFO:Uploading model into container now
2025-10-12 16:29:06,033:INFO:_master_model_container: 30
2025-10-12 16:29:06,034:INFO:_display_container: 3
2025-10-12 16:29:06,035:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5816, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:29:06,035:INFO:create_model() successfully completed......................................
2025-10-12 16:29:06,170:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:06,170:INFO:Creating metrics dataframe
2025-10-12 16:29:06,177:INFO:Initializing CatBoost Classifier
2025-10-12 16:29:06,177:INFO:Total runtime is 0.09869599342346191 minutes
2025-10-12 16:29:06,180:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:06,180:INFO:Initializing create_model()
2025-10-12 16:29:06,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:06,180:INFO:Checking exceptions
2025-10-12 16:29:06,180:INFO:Importing libraries
2025-10-12 16:29:06,180:INFO:Copying training dataset
2025-10-12 16:29:06,183:INFO:Defining folds
2025-10-12 16:29:06,184:INFO:Declaring metric variables
2025-10-12 16:29:06,187:INFO:Importing untrained model
2025-10-12 16:29:06,190:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:29:06,196:INFO:Starting cross validation
2025-10-12 16:29:06,196:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:10,291:INFO:Calculating mean and std
2025-10-12 16:29:10,292:INFO:Creating metrics dataframe
2025-10-12 16:29:10,294:INFO:Uploading results into container
2025-10-12 16:29:10,294:INFO:Uploading model into container now
2025-10-12 16:29:10,295:INFO:_master_model_container: 31
2025-10-12 16:29:10,295:INFO:_display_container: 3
2025-10-12 16:29:10,295:INFO:<catboost.core.CatBoostClassifier object at 0x00000168549D1A00>
2025-10-12 16:29:10,295:INFO:create_model() successfully completed......................................
2025-10-12 16:29:10,411:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:10,411:INFO:Creating metrics dataframe
2025-10-12 16:29:10,418:INFO:Initializing Dummy Classifier
2025-10-12 16:29:10,418:INFO:Total runtime is 0.16937555074691774 minutes
2025-10-12 16:29:10,420:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:10,421:INFO:Initializing create_model()
2025-10-12 16:29:10,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168547277C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:10,421:INFO:Checking exceptions
2025-10-12 16:29:10,421:INFO:Importing libraries
2025-10-12 16:29:10,421:INFO:Copying training dataset
2025-10-12 16:29:10,425:INFO:Defining folds
2025-10-12 16:29:10,425:INFO:Declaring metric variables
2025-10-12 16:29:10,428:INFO:Importing untrained model
2025-10-12 16:29:10,431:INFO:Dummy Classifier Imported successfully
2025-10-12 16:29:10,437:INFO:Starting cross validation
2025-10-12 16:29:10,438:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:10,461:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:29:10,470:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:29:10,470:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:29:10,475:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:29:10,475:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:29:10,478:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:29:10,478:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:29:10,480:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:29:10,483:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:29:10,485:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:29:10,493:INFO:Calculating mean and std
2025-10-12 16:29:10,493:INFO:Creating metrics dataframe
2025-10-12 16:29:10,495:INFO:Uploading results into container
2025-10-12 16:29:10,495:INFO:Uploading model into container now
2025-10-12 16:29:10,496:INFO:_master_model_container: 32
2025-10-12 16:29:10,496:INFO:_display_container: 3
2025-10-12 16:29:10,496:INFO:DummyClassifier(constant=None, random_state=5816, strategy='prior')
2025-10-12 16:29:10,496:INFO:create_model() successfully completed......................................
2025-10-12 16:29:10,610:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:10,610:INFO:Creating metrics dataframe
2025-10-12 16:29:10,618:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:29:10,625:INFO:Initializing create_model()
2025-10-12 16:29:10,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168549D1A00>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:10,625:INFO:Checking exceptions
2025-10-12 16:29:10,627:INFO:Importing libraries
2025-10-12 16:29:10,627:INFO:Copying training dataset
2025-10-12 16:29:10,629:INFO:Defining folds
2025-10-12 16:29:10,629:INFO:Declaring metric variables
2025-10-12 16:29:10,629:INFO:Importing untrained model
2025-10-12 16:29:10,629:INFO:Declaring custom model
2025-10-12 16:29:10,630:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:29:10,630:INFO:Cross validation set to False
2025-10-12 16:29:10,630:INFO:Fitting Model
2025-10-12 16:29:12,231:INFO:<catboost.core.CatBoostClassifier object at 0x00000168549E8850>
2025-10-12 16:29:12,231:INFO:create_model() successfully completed......................................
2025-10-12 16:29:12,348:INFO:Creating Dashboard logs
2025-10-12 16:29:12,351:INFO:Model: CatBoost Classifier
2025-10-12 16:29:12,429:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'Logloss', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 5816, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.007650000043213368, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 10, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2025-10-12 16:29:12,721:INFO:Initializing predict_model()
2025-10-12 16:29:12,721:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168549E8850>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000168546CDEE0>)
2025-10-12 16:29:12,721:INFO:Checking exceptions
2025-10-12 16:29:12,721:INFO:Preloading libraries
2025-10-12 16:29:12,882:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:29:12,882:INFO:Initializing plot_model()
2025-10-12 16:29:12,882:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168549E8850>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpbf26ab09, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:29:12,882:INFO:Checking exceptions
2025-10-12 16:29:12,884:INFO:Preloading libraries
2025-10-12 16:29:12,886:INFO:Copying training dataset
2025-10-12 16:29:12,886:INFO:Plot type: auc
2025-10-12 16:29:12,929:INFO:Fitting Model
2025-10-12 16:29:12,930:INFO:Scoring test/hold-out set
2025-10-12 16:29:12,946:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpbf26ab09\AUC.png'
2025-10-12 16:29:13,107:INFO:Visual Rendered Successfully
2025-10-12 16:29:13,225:INFO:plot_model() successfully completed......................................
2025-10-12 16:29:13,246:INFO:Initializing plot_model()
2025-10-12 16:29:13,246:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168549E8850>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpbf26ab09, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:29:13,246:INFO:Checking exceptions
2025-10-12 16:29:13,248:INFO:Preloading libraries
2025-10-12 16:29:13,250:INFO:Copying training dataset
2025-10-12 16:29:13,250:INFO:Plot type: confusion_matrix
2025-10-12 16:29:13,297:INFO:Fitting Model
2025-10-12 16:29:13,298:INFO:Scoring test/hold-out set
2025-10-12 16:29:13,317:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpbf26ab09\Confusion Matrix.png'
2025-10-12 16:29:13,398:INFO:Visual Rendered Successfully
2025-10-12 16:29:13,515:INFO:plot_model() successfully completed......................................
2025-10-12 16:29:13,529:INFO:Initializing plot_model()
2025-10-12 16:29:13,529:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168549E8850>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpbf26ab09, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:29:13,529:INFO:Checking exceptions
2025-10-12 16:29:13,530:INFO:Preloading libraries
2025-10-12 16:29:13,531:INFO:Copying training dataset
2025-10-12 16:29:13,531:INFO:Plot type: feature
2025-10-12 16:29:13,531:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:29:13,563:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpbf26ab09\Feature Importance.png'
2025-10-12 16:29:13,673:INFO:Visual Rendered Successfully
2025-10-12 16:29:13,787:INFO:plot_model() successfully completed......................................
2025-10-12 16:29:13,806:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:29:14,007:INFO:Creating Dashboard logs
2025-10-12 16:29:14,010:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:29:14,086:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 5816, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:29:14,538:INFO:Creating Dashboard logs
2025-10-12 16:29:14,542:INFO:Model: Ada Boost Classifier
2025-10-12 16:29:14,620:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 5816}
2025-10-12 16:29:15,007:INFO:Creating Dashboard logs
2025-10-12 16:29:15,010:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:29:15,099:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5816, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:29:15,520:INFO:Creating Dashboard logs
2025-10-12 16:29:15,523:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 16:29:15,596:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:29:16,001:INFO:Creating Dashboard logs
2025-10-12 16:29:16,005:INFO:Model: Random Forest Classifier
2025-10-12 16:29:16,078:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5816, 'verbose': 0, 'warm_start': False}
2025-10-12 16:29:16,491:INFO:Creating Dashboard logs
2025-10-12 16:29:16,494:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:29:16,564:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 5816, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:29:17,019:INFO:Creating Dashboard logs
2025-10-12 16:29:17,021:INFO:Model: Extra Trees Classifier
2025-10-12 16:29:17,094:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5816, 'verbose': 0, 'warm_start': False}
2025-10-12 16:29:17,488:INFO:Creating Dashboard logs
2025-10-12 16:29:17,491:INFO:Model: Ridge Classifier
2025-10-12 16:29:17,581:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 5816, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:29:17,997:INFO:Creating Dashboard logs
2025-10-12 16:29:18,001:INFO:Model: Logistic Regression
2025-10-12 16:29:18,083:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 5816, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:29:18,540:INFO:Creating Dashboard logs
2025-10-12 16:29:18,544:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:29:18,620:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:29:19,011:INFO:Creating Dashboard logs
2025-10-12 16:29:19,014:INFO:Model: Naive Bayes
2025-10-12 16:29:19,089:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:29:19,524:INFO:Creating Dashboard logs
2025-10-12 16:29:19,527:INFO:Model: Decision Tree Classifier
2025-10-12 16:29:19,603:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 5816, 'splitter': 'best'}
2025-10-12 16:29:20,008:INFO:Creating Dashboard logs
2025-10-12 16:29:20,011:INFO:Model: SVM - Linear Kernel
2025-10-12 16:29:20,090:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 5816, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:29:20,517:INFO:Creating Dashboard logs
2025-10-12 16:29:20,519:INFO:Model: K Neighbors Classifier
2025-10-12 16:29:20,591:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:29:20,987:INFO:Creating Dashboard logs
2025-10-12 16:29:20,990:INFO:Model: Dummy Classifier
2025-10-12 16:29:21,061:INFO:Logged params: {'constant': None, 'random_state': 5816, 'strategy': 'prior'}
2025-10-12 16:29:21,411:INFO:_master_model_container: 32
2025-10-12 16:29:21,411:INFO:_display_container: 3
2025-10-12 16:29:21,411:INFO:<catboost.core.CatBoostClassifier object at 0x00000168549E8850>
2025-10-12 16:29:21,411:INFO:compare_models() successfully completed......................................
2025-10-12 16:29:24,552:INFO:Initializing finalize_model()
2025-10-12 16:29:24,552:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168549E8850>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-12 16:29:24,552:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x00000168549E8850>
2025-10-12 16:29:24,554:INFO:Initializing create_model()
2025-10-12 16:29:24,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168549E8850>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:24,554:INFO:Checking exceptions
2025-10-12 16:29:24,556:INFO:Importing libraries
2025-10-12 16:29:24,556:INFO:Copying training dataset
2025-10-12 16:29:24,556:INFO:Defining folds
2025-10-12 16:29:24,556:INFO:Declaring metric variables
2025-10-12 16:29:24,557:INFO:Importing untrained model
2025-10-12 16:29:24,557:INFO:Declaring custom model
2025-10-12 16:29:24,557:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:29:24,557:INFO:Cross validation set to False
2025-10-12 16:29:24,558:INFO:Fitting Model
2025-10-12 16:29:26,354:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001685471E4C0>)],
         verbose=False)
2025-10-12 16:29:26,354:INFO:create_model() successfully completed......................................
2025-10-12 16:29:26,472:INFO:Creating Dashboard logs
2025-10-12 16:29:26,472:INFO:Model: CatBoost Classifier
2025-10-12 16:29:26,548:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'Logloss', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 5816, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.00891099963337183, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 10, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2025-10-12 16:29:26,743:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:29:26,746:INFO:Initializing plot_model()
2025-10-12 16:29:26,746:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001685471E4C0>)],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp_3d9r5h5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:29:26,746:INFO:Checking exceptions
2025-10-12 16:29:26,747:INFO:Preloading libraries
2025-10-12 16:29:26,749:INFO:Copying training dataset
2025-10-12 16:29:26,749:INFO:Plot type: auc
2025-10-12 16:29:26,796:INFO:Fitting Model
2025-10-12 16:29:26,797:INFO:Scoring test/hold-out set
2025-10-12 16:29:26,817:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp_3d9r5h5\AUC.png'
2025-10-12 16:29:26,993:INFO:Visual Rendered Successfully
2025-10-12 16:29:27,116:INFO:plot_model() successfully completed......................................
2025-10-12 16:29:27,151:INFO:Initializing plot_model()
2025-10-12 16:29:27,151:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001685471E4C0>)],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp_3d9r5h5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:29:27,151:INFO:Checking exceptions
2025-10-12 16:29:27,154:INFO:Preloading libraries
2025-10-12 16:29:27,157:INFO:Copying training dataset
2025-10-12 16:29:27,157:INFO:Plot type: confusion_matrix
2025-10-12 16:29:27,209:INFO:Fitting Model
2025-10-12 16:29:27,210:INFO:Scoring test/hold-out set
2025-10-12 16:29:27,225:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp_3d9r5h5\Confusion Matrix.png'
2025-10-12 16:29:27,326:INFO:Visual Rendered Successfully
2025-10-12 16:29:27,447:INFO:plot_model() successfully completed......................................
2025-10-12 16:29:27,470:INFO:Initializing plot_model()
2025-10-12 16:29:27,470:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001685471E4C0>)],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp_3d9r5h5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:29:27,470:INFO:Checking exceptions
2025-10-12 16:29:27,472:INFO:Preloading libraries
2025-10-12 16:29:27,474:INFO:Copying training dataset
2025-10-12 16:29:27,474:INFO:Plot type: feature
2025-10-12 16:29:27,474:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:29:27,502:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp_3d9r5h5\Feature Importance.png'
2025-10-12 16:29:27,611:INFO:Visual Rendered Successfully
2025-10-12 16:29:27,730:INFO:plot_model() successfully completed......................................
2025-10-12 16:29:27,750:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:29:27,957:INFO:_master_model_container: 32
2025-10-12 16:29:27,957:INFO:_display_container: 3
2025-10-12 16:29:27,959:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001685471E4C0>)],
         verbose=False)
2025-10-12 16:29:27,960:INFO:finalize_model() successfully completed......................................
2025-10-12 16:29:28,075:INFO:Initializing save_model()
2025-10-12 16:29:28,075:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001685471E4C0>)],
         verbose=False), model_name=Titanic_modelV1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 16:29:28,076:INFO:Adding model into prep_pipe
2025-10-12 16:29:28,076:WARNING:Only Model saved as it was a pipeline.
2025-10-12 16:29:28,093:INFO:Titanic_modelV1.pkl saved in current working directory
2025-10-12 16:29:28,095:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001685471E4C0>)],
         verbose=False)
2025-10-12 16:29:28,095:INFO:save_model() successfully completed......................................
2025-10-12 16:29:32,206:INFO:Initializing tune_model()
2025-10-12 16:29:32,206:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x00000168549E8850>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>)
2025-10-12 16:29:32,206:INFO:Checking exceptions
2025-10-12 16:29:32,218:INFO:Copying training dataset
2025-10-12 16:29:32,220:INFO:Checking base model
2025-10-12 16:29:32,220:INFO:Base model : CatBoost Classifier
2025-10-12 16:29:32,223:INFO:Declaring metric variables
2025-10-12 16:29:32,226:INFO:Defining Hyperparameters
2025-10-12 16:29:32,346:INFO:Tuning with n_jobs=-1
2025-10-12 16:29:32,346:INFO:Initializing RandomizedSearchCV
2025-10-12 16:29:36,926:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
10 fits failed out of a total of 100.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 5245, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 2395, in _fit
    train_params = self._prepare_train_params(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 2321, in _prepare_train_params
    _check_train_params(params)
  File "_catboost.pyx", line 6601, in _catboost._check_train_params
  File "_catboost.pyx", line 6623, in _catboost._check_train_params
_catboost.CatBoostError: catboost/private/libs/options/boosting_options.cpp:79: Learning rate should be non-zero


2025-10-12 16:29:36,927:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\model_selection\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.84415478 0.85612238 0.85363696 0.86555008 0.85930673 0.8621395
 0.85631353 0.86593605 0.83826104        nan]

2025-10-12 16:29:36,927:INFO:best_params: {'actual_estimator__random_strength': 0.8, 'actual_estimator__n_estimators': 280, 'actual_estimator__l2_leaf_reg': 50, 'actual_estimator__eta': 0.01, 'actual_estimator__depth': 6}
2025-10-12 16:29:36,928:INFO:Hyperparameter search completed
2025-10-12 16:29:36,928:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:36,928:INFO:Initializing create_model()
2025-10-12 16:29:36,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000016854991CD0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016803B5E550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.8, 'n_estimators': 280, 'l2_leaf_reg': 50, 'eta': 0.01, 'depth': 6})
2025-10-12 16:29:36,928:INFO:Checking exceptions
2025-10-12 16:29:36,928:INFO:Importing libraries
2025-10-12 16:29:36,928:INFO:Copying training dataset
2025-10-12 16:29:36,932:INFO:Defining folds
2025-10-12 16:29:36,932:INFO:Declaring metric variables
2025-10-12 16:29:36,935:INFO:Importing untrained model
2025-10-12 16:29:36,935:INFO:Declaring custom model
2025-10-12 16:29:36,937:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:29:36,943:INFO:Starting cross validation
2025-10-12 16:29:36,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:37,975:INFO:Calculating mean and std
2025-10-12 16:29:37,976:INFO:Creating metrics dataframe
2025-10-12 16:29:37,980:INFO:Finalizing model
2025-10-12 16:29:38,424:INFO:Uploading results into container
2025-10-12 16:29:38,425:INFO:Uploading model into container now
2025-10-12 16:29:38,426:INFO:_master_model_container: 33
2025-10-12 16:29:38,426:INFO:_display_container: 4
2025-10-12 16:29:38,426:INFO:<catboost.core.CatBoostClassifier object at 0x0000016854D65EE0>
2025-10-12 16:29:38,426:INFO:create_model() successfully completed......................................
2025-10-12 16:29:38,545:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:38,545:INFO:choose_better activated
2025-10-12 16:29:38,548:INFO:SubProcess create_model() called ==================================
2025-10-12 16:29:38,548:INFO:Initializing create_model()
2025-10-12 16:29:38,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168549E8850>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:29:38,548:INFO:Checking exceptions
2025-10-12 16:29:38,549:INFO:Importing libraries
2025-10-12 16:29:38,550:INFO:Copying training dataset
2025-10-12 16:29:38,552:INFO:Defining folds
2025-10-12 16:29:38,552:INFO:Declaring metric variables
2025-10-12 16:29:38,552:INFO:Importing untrained model
2025-10-12 16:29:38,552:INFO:Declaring custom model
2025-10-12 16:29:38,553:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:29:38,553:INFO:Starting cross validation
2025-10-12 16:29:38,553:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:29:42,103:INFO:Calculating mean and std
2025-10-12 16:29:42,103:INFO:Creating metrics dataframe
2025-10-12 16:29:42,105:INFO:Finalizing model
2025-10-12 16:29:43,662:INFO:Uploading results into container
2025-10-12 16:29:43,663:INFO:Uploading model into container now
2025-10-12 16:29:43,663:INFO:_master_model_container: 34
2025-10-12 16:29:43,663:INFO:_display_container: 5
2025-10-12 16:29:43,663:INFO:<catboost.core.CatBoostClassifier object at 0x0000016852F3CB80>
2025-10-12 16:29:43,663:INFO:create_model() successfully completed......................................
2025-10-12 16:29:43,773:INFO:SubProcess create_model() end ==================================
2025-10-12 16:29:43,773:INFO:<catboost.core.CatBoostClassifier object at 0x0000016852F3CB80> result for AUC is 0.854
2025-10-12 16:29:43,774:INFO:<catboost.core.CatBoostClassifier object at 0x0000016854D65EE0> result for AUC is 0.8659
2025-10-12 16:29:43,774:INFO:<catboost.core.CatBoostClassifier object at 0x0000016854D65EE0> is best model
2025-10-12 16:29:43,774:INFO:choose_better completed
2025-10-12 16:29:43,774:INFO:Creating Dashboard logs
2025-10-12 16:29:43,776:INFO:Model: CatBoost Classifier
2025-10-12 16:29:43,859:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'Logloss', 'iterations': 280, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 50, 'random_strength': 0.800000011920929, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 5816, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.009999999776482582, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 10, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2025-10-12 16:29:44,196:INFO:Initializing predict_model()
2025-10-12 16:29:44,196:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000016854D65EE0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016854D634C0>)
2025-10-12 16:29:44,196:INFO:Checking exceptions
2025-10-12 16:29:44,196:INFO:Preloading libraries
2025-10-12 16:29:44,366:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:29:44,366:INFO:Initializing plot_model()
2025-10-12 16:29:44,366:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000016854D65EE0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpyk3lggap, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:29:44,366:INFO:Checking exceptions
2025-10-12 16:29:44,368:INFO:Preloading libraries
2025-10-12 16:29:44,368:INFO:Copying training dataset
2025-10-12 16:29:44,368:INFO:Plot type: auc
2025-10-12 16:29:44,409:INFO:Fitting Model
2025-10-12 16:29:44,410:INFO:Scoring test/hold-out set
2025-10-12 16:29:44,426:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpyk3lggap\AUC.png'
2025-10-12 16:29:44,581:INFO:Visual Rendered Successfully
2025-10-12 16:29:44,692:INFO:plot_model() successfully completed......................................
2025-10-12 16:29:44,710:INFO:Initializing plot_model()
2025-10-12 16:29:44,710:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000016854D65EE0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpyk3lggap, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:29:44,710:INFO:Checking exceptions
2025-10-12 16:29:44,711:INFO:Preloading libraries
2025-10-12 16:29:44,712:INFO:Copying training dataset
2025-10-12 16:29:44,712:INFO:Plot type: confusion_matrix
2025-10-12 16:29:44,753:INFO:Fitting Model
2025-10-12 16:29:44,754:INFO:Scoring test/hold-out set
2025-10-12 16:29:44,766:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpyk3lggap\Confusion Matrix.png'
2025-10-12 16:29:44,843:INFO:Visual Rendered Successfully
2025-10-12 16:29:44,958:INFO:plot_model() successfully completed......................................
2025-10-12 16:29:44,976:INFO:Initializing plot_model()
2025-10-12 16:29:44,976:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000016854D65EE0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpyk3lggap, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:29:44,976:INFO:Checking exceptions
2025-10-12 16:29:44,978:INFO:Preloading libraries
2025-10-12 16:29:44,978:INFO:Copying training dataset
2025-10-12 16:29:44,978:INFO:Plot type: feature
2025-10-12 16:29:44,979:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:29:45,004:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpyk3lggap\Feature Importance.png'
2025-10-12 16:29:45,104:INFO:Visual Rendered Successfully
2025-10-12 16:29:45,217:INFO:plot_model() successfully completed......................................
2025-10-12 16:29:45,237:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:29:45,453:INFO:_master_model_container: 34
2025-10-12 16:29:45,453:INFO:_display_container: 4
2025-10-12 16:29:45,453:INFO:<catboost.core.CatBoostClassifier object at 0x0000016854D65EE0>
2025-10-12 16:29:45,453:INFO:tune_model() successfully completed......................................
2025-10-12 16:29:45,589:INFO:Initializing tune_model()
2025-10-12 16:29:45,589:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x00000168549E8850>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>)
2025-10-12 16:29:45,589:INFO:Checking exceptions
2025-10-12 16:29:45,589:INFO:Soft dependency imported: optuna: 4.5.0
2025-10-12 16:29:45,696:INFO:Copying training dataset
2025-10-12 16:29:45,698:INFO:Checking base model
2025-10-12 16:29:45,698:INFO:Base model : CatBoost Classifier
2025-10-12 16:29:45,701:INFO:Declaring metric variables
2025-10-12 16:29:45,703:INFO:Defining Hyperparameters
2025-10-12 16:29:45,824:INFO:Tuning with n_jobs=-1
2025-10-12 16:29:45,825:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.

2025-10-12 16:29:45,825:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.

2025-10-12 16:29:45,826:INFO:Initializing optuna.integration.OptunaSearchCV
2025-10-12 16:29:45,836:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.

2025-10-12 16:30:18,812:INFO:best_params: {'actual_estimator__eta': 0.17746594871366364, 'actual_estimator__depth': 2, 'actual_estimator__n_estimators': 286, 'actual_estimator__random_strength': 0.4525977273541935, 'actual_estimator__l2_leaf_reg': 1}
2025-10-12 16:30:18,813:INFO:Hyperparameter search completed
2025-10-12 16:30:18,813:INFO:SubProcess create_model() called ==================================
2025-10-12 16:30:18,814:INFO:Initializing create_model()
2025-10-12 16:30:18,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000016846377DF0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016853CDD850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'eta': 0.17746594871366364, 'depth': 2, 'n_estimators': 286, 'random_strength': 0.4525977273541935, 'l2_leaf_reg': 1})
2025-10-12 16:30:18,814:INFO:Checking exceptions
2025-10-12 16:30:18,814:INFO:Importing libraries
2025-10-12 16:30:18,814:INFO:Copying training dataset
2025-10-12 16:30:18,817:INFO:Defining folds
2025-10-12 16:30:18,817:INFO:Declaring metric variables
2025-10-12 16:30:18,820:INFO:Importing untrained model
2025-10-12 16:30:18,820:INFO:Declaring custom model
2025-10-12 16:30:18,823:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:30:18,828:INFO:Starting cross validation
2025-10-12 16:30:18,829:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:30:19,536:INFO:Calculating mean and std
2025-10-12 16:30:19,537:INFO:Creating metrics dataframe
2025-10-12 16:30:19,542:INFO:Finalizing model
2025-10-12 16:30:19,866:INFO:Uploading results into container
2025-10-12 16:30:19,868:INFO:Uploading model into container now
2025-10-12 16:30:19,868:INFO:_master_model_container: 35
2025-10-12 16:30:19,868:INFO:_display_container: 5
2025-10-12 16:30:19,869:INFO:<catboost.core.CatBoostClassifier object at 0x0000016854CB5670>
2025-10-12 16:30:19,869:INFO:create_model() successfully completed......................................
2025-10-12 16:30:19,991:INFO:SubProcess create_model() end ==================================
2025-10-12 16:30:19,991:INFO:choose_better activated
2025-10-12 16:30:19,994:INFO:SubProcess create_model() called ==================================
2025-10-12 16:30:19,994:INFO:Initializing create_model()
2025-10-12 16:30:19,994:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168549E8850>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:30:19,994:INFO:Checking exceptions
2025-10-12 16:30:19,995:INFO:Importing libraries
2025-10-12 16:30:19,995:INFO:Copying training dataset
2025-10-12 16:30:19,997:INFO:Defining folds
2025-10-12 16:30:19,997:INFO:Declaring metric variables
2025-10-12 16:30:19,997:INFO:Importing untrained model
2025-10-12 16:30:19,997:INFO:Declaring custom model
2025-10-12 16:30:19,997:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:30:19,997:INFO:Starting cross validation
2025-10-12 16:30:19,998:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:30:23,439:INFO:Calculating mean and std
2025-10-12 16:30:23,439:INFO:Creating metrics dataframe
2025-10-12 16:30:23,442:INFO:Finalizing model
2025-10-12 16:30:25,202:INFO:Uploading results into container
2025-10-12 16:30:25,203:INFO:Uploading model into container now
2025-10-12 16:30:25,203:INFO:_master_model_container: 36
2025-10-12 16:30:25,203:INFO:_display_container: 6
2025-10-12 16:30:25,203:INFO:<catboost.core.CatBoostClassifier object at 0x00000168549E69D0>
2025-10-12 16:30:25,203:INFO:create_model() successfully completed......................................
2025-10-12 16:30:25,316:INFO:SubProcess create_model() end ==================================
2025-10-12 16:30:25,317:INFO:<catboost.core.CatBoostClassifier object at 0x00000168549E69D0> result for AUC is 0.854
2025-10-12 16:30:25,317:INFO:<catboost.core.CatBoostClassifier object at 0x0000016854CB5670> result for AUC is 0.8649
2025-10-12 16:30:25,317:INFO:<catboost.core.CatBoostClassifier object at 0x0000016854CB5670> is best model
2025-10-12 16:30:25,317:INFO:choose_better completed
2025-10-12 16:30:25,317:INFO:Creating Dashboard logs
2025-10-12 16:30:25,319:INFO:Model: CatBoost Classifier
2025-10-12 16:30:25,408:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'Logloss', 'iterations': 286, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 1, 'random_strength': 0.4525977373123169, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 5816, 'depth': 2, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.17746594548225403, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 10, 'bootstrap_type': 'MVS', 'max_leaves': 4}
2025-10-12 16:30:25,757:INFO:Initializing predict_model()
2025-10-12 16:30:25,757:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000016854CB5670>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000168463BA1F0>)
2025-10-12 16:30:25,757:INFO:Checking exceptions
2025-10-12 16:30:25,757:INFO:Preloading libraries
2025-10-12 16:30:25,930:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:30:25,930:INFO:Initializing plot_model()
2025-10-12 16:30:25,930:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000016854CB5670>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp5u4fl363, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:25,930:INFO:Checking exceptions
2025-10-12 16:30:25,931:INFO:Preloading libraries
2025-10-12 16:30:25,932:INFO:Copying training dataset
2025-10-12 16:30:25,932:INFO:Plot type: auc
2025-10-12 16:30:25,976:INFO:Fitting Model
2025-10-12 16:30:25,976:INFO:Scoring test/hold-out set
2025-10-12 16:30:25,991:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp5u4fl363\AUC.png'
2025-10-12 16:30:26,162:INFO:Visual Rendered Successfully
2025-10-12 16:30:26,282:INFO:plot_model() successfully completed......................................
2025-10-12 16:30:26,302:INFO:Initializing plot_model()
2025-10-12 16:30:26,303:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000016854CB5670>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp5u4fl363, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:26,303:INFO:Checking exceptions
2025-10-12 16:30:26,305:INFO:Preloading libraries
2025-10-12 16:30:26,306:INFO:Copying training dataset
2025-10-12 16:30:26,306:INFO:Plot type: confusion_matrix
2025-10-12 16:30:26,352:INFO:Fitting Model
2025-10-12 16:30:26,353:INFO:Scoring test/hold-out set
2025-10-12 16:30:26,367:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp5u4fl363\Confusion Matrix.png'
2025-10-12 16:30:26,447:INFO:Visual Rendered Successfully
2025-10-12 16:30:26,564:INFO:plot_model() successfully completed......................................
2025-10-12 16:30:26,583:INFO:Initializing plot_model()
2025-10-12 16:30:26,583:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000016854CB5670>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp5u4fl363, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:26,583:INFO:Checking exceptions
2025-10-12 16:30:26,585:INFO:Preloading libraries
2025-10-12 16:30:26,585:INFO:Copying training dataset
2025-10-12 16:30:26,585:INFO:Plot type: feature
2025-10-12 16:30:26,586:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:30:26,613:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp5u4fl363\Feature Importance.png'
2025-10-12 16:30:26,720:INFO:Visual Rendered Successfully
2025-10-12 16:30:26,838:INFO:plot_model() successfully completed......................................
2025-10-12 16:30:26,857:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:30:27,071:INFO:_master_model_container: 36
2025-10-12 16:30:27,071:INFO:_display_container: 5
2025-10-12 16:30:27,071:INFO:<catboost.core.CatBoostClassifier object at 0x0000016854CB5670>
2025-10-12 16:30:27,071:INFO:tune_model() successfully completed......................................
2025-10-12 16:30:27,213:INFO:Initializing ensemble_model()
2025-10-12 16:30:27,213:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168549E8850>, method=Bagging, fold=None, n_estimators=5, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:30:27,213:INFO:Checking exceptions
2025-10-12 16:30:27,226:INFO:Importing libraries
2025-10-12 16:30:27,226:INFO:Copying training dataset
2025-10-12 16:30:27,226:INFO:Checking base model
2025-10-12 16:30:27,226:INFO:Base model : CatBoost Classifier
2025-10-12 16:30:27,233:INFO:Importing untrained ensembler
2025-10-12 16:30:27,233:INFO:Ensemble method set to Bagging
2025-10-12 16:30:27,233:INFO:SubProcess create_model() called ==================================
2025-10-12 16:30:27,234:INFO:Initializing create_model()
2025-10-12 16:30:27,234:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x00000168549E8850>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5816, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846351AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:30:27,234:INFO:Checking exceptions
2025-10-12 16:30:27,234:INFO:Importing libraries
2025-10-12 16:30:27,234:INFO:Copying training dataset
2025-10-12 16:30:27,237:INFO:Defining folds
2025-10-12 16:30:27,237:INFO:Declaring metric variables
2025-10-12 16:30:27,242:INFO:Importing untrained model
2025-10-12 16:30:27,242:INFO:Declaring custom model
2025-10-12 16:30:27,248:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:30:27,259:INFO:Starting cross validation
2025-10-12 16:30:27,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:30:44,958:INFO:Calculating mean and std
2025-10-12 16:30:44,959:INFO:Creating metrics dataframe
2025-10-12 16:30:44,963:INFO:Finalizing model
2025-10-12 16:30:53,091:INFO:Uploading results into container
2025-10-12 16:30:53,092:INFO:Uploading model into container now
2025-10-12 16:30:53,092:INFO:_master_model_container: 37
2025-10-12 16:30:53,092:INFO:_display_container: 6
2025-10-12 16:30:53,093:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854855A90>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5816, verbose=0,
                  warm_start=False)
2025-10-12 16:30:53,093:INFO:create_model() successfully completed......................................
2025-10-12 16:30:53,213:INFO:SubProcess create_model() end ==================================
2025-10-12 16:30:53,214:INFO:Creating Dashboard logs
2025-10-12 16:30:53,216:INFO:Model: CatBoost Classifier
2025-10-12 16:30:53,292:INFO:Logged params: {'bootstrap': True, 'bootstrap_features': False, 'estimator__border_count': 254, 'estimator__verbose': False, 'estimator__task_type': 'CPU', 'estimator__random_state': 5816, 'estimator': <catboost.core.CatBoostClassifier object at 0x0000016854855A90>, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 5, 'n_jobs': None, 'oob_score': False, 'random_state': 5816, 'verbose': 0, 'warm_start': False}
2025-10-12 16:30:53,573:INFO:Initializing predict_model()
2025-10-12 16:30:53,573:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854855A90>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5816, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000168463BAEE0>)
2025-10-12 16:30:53,573:INFO:Checking exceptions
2025-10-12 16:30:53,573:INFO:Preloading libraries
2025-10-12 16:30:53,745:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:30:53,746:INFO:Initializing plot_model()
2025-10-12 16:30:53,746:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854855A90>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5816, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmppid2ye_u, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:53,746:INFO:Checking exceptions
2025-10-12 16:30:53,747:INFO:Preloading libraries
2025-10-12 16:30:53,755:INFO:Copying training dataset
2025-10-12 16:30:53,755:INFO:Plot type: auc
2025-10-12 16:30:53,798:INFO:Fitting Model
2025-10-12 16:30:53,798:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 16:30:53,799:INFO:Scoring test/hold-out set
2025-10-12 16:30:53,819:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmppid2ye_u\AUC.png'
2025-10-12 16:30:53,976:INFO:Visual Rendered Successfully
2025-10-12 16:30:54,089:INFO:plot_model() successfully completed......................................
2025-10-12 16:30:54,107:INFO:Initializing plot_model()
2025-10-12 16:30:54,107:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854855A90>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5816, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmppid2ye_u, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:54,107:INFO:Checking exceptions
2025-10-12 16:30:54,108:INFO:Preloading libraries
2025-10-12 16:30:54,118:INFO:Copying training dataset
2025-10-12 16:30:54,118:INFO:Plot type: confusion_matrix
2025-10-12 16:30:54,162:INFO:Fitting Model
2025-10-12 16:30:54,162:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 16:30:54,162:INFO:Scoring test/hold-out set
2025-10-12 16:30:54,182:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmppid2ye_u\Confusion Matrix.png'
2025-10-12 16:30:54,258:INFO:Visual Rendered Successfully
2025-10-12 16:30:54,374:INFO:plot_model() successfully completed......................................
2025-10-12 16:30:54,392:INFO:Initializing plot_model()
2025-10-12 16:30:54,392:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854855A90>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5816, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmppid2ye_u, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:54,392:INFO:Checking exceptions
2025-10-12 16:30:54,393:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 16:30:54,393:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:30:54,607:INFO:_master_model_container: 37
2025-10-12 16:30:54,608:INFO:_display_container: 6
2025-10-12 16:30:54,608:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854855A90>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5816, verbose=0,
                  warm_start=False)
2025-10-12 16:30:54,608:INFO:ensemble_model() successfully completed......................................
2025-10-12 16:30:54,723:INFO:Initializing predict_model()
2025-10-12 16:30:54,723:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854855A90>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5816, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016854368820>)
2025-10-12 16:30:54,723:INFO:Checking exceptions
2025-10-12 16:30:54,723:INFO:Preloading libraries
2025-10-12 16:30:54,915:INFO:Initializing create_model()
2025-10-12 16:30:54,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:30:54,916:INFO:Checking exceptions
2025-10-12 16:30:54,926:INFO:Importing libraries
2025-10-12 16:30:54,926:INFO:Copying training dataset
2025-10-12 16:30:54,929:INFO:Defining folds
2025-10-12 16:30:54,929:INFO:Declaring metric variables
2025-10-12 16:30:54,931:INFO:Importing untrained model
2025-10-12 16:30:54,935:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:30:54,939:INFO:Starting cross validation
2025-10-12 16:30:54,940:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:30:55,008:INFO:Calculating mean and std
2025-10-12 16:30:55,009:INFO:Creating metrics dataframe
2025-10-12 16:30:55,016:INFO:Finalizing model
2025-10-12 16:30:55,025:INFO:Creating Dashboard logs
2025-10-12 16:30:55,028:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:30:55,102:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:30:55,323:INFO:Initializing predict_model()
2025-10-12 16:30:55,323:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001684679C670>)
2025-10-12 16:30:55,323:INFO:Checking exceptions
2025-10-12 16:30:55,323:INFO:Preloading libraries
2025-10-12 16:30:55,493:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:30:55,493:INFO:Initializing plot_model()
2025-10-12 16:30:55,494:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp0hh60gqz, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:55,494:INFO:Checking exceptions
2025-10-12 16:30:55,495:INFO:Preloading libraries
2025-10-12 16:30:55,495:INFO:Copying training dataset
2025-10-12 16:30:55,495:INFO:Plot type: auc
2025-10-12 16:30:55,534:INFO:Fitting Model
2025-10-12 16:30:55,534:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:30:55,534:INFO:Scoring test/hold-out set
2025-10-12 16:30:55,550:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp0hh60gqz\AUC.png'
2025-10-12 16:30:55,711:INFO:Visual Rendered Successfully
2025-10-12 16:30:55,826:INFO:plot_model() successfully completed......................................
2025-10-12 16:30:55,843:INFO:Initializing plot_model()
2025-10-12 16:30:55,843:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp0hh60gqz, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:55,843:INFO:Checking exceptions
2025-10-12 16:30:55,845:INFO:Preloading libraries
2025-10-12 16:30:55,845:INFO:Copying training dataset
2025-10-12 16:30:55,845:INFO:Plot type: confusion_matrix
2025-10-12 16:30:55,891:INFO:Fitting Model
2025-10-12 16:30:55,892:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:30:55,892:INFO:Scoring test/hold-out set
2025-10-12 16:30:55,908:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp0hh60gqz\Confusion Matrix.png'
2025-10-12 16:30:56,003:INFO:Visual Rendered Successfully
2025-10-12 16:30:56,131:INFO:plot_model() successfully completed......................................
2025-10-12 16:30:56,150:INFO:Initializing plot_model()
2025-10-12 16:30:56,150:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp0hh60gqz, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:56,150:INFO:Checking exceptions
2025-10-12 16:30:56,151:INFO:Preloading libraries
2025-10-12 16:30:56,151:INFO:Copying training dataset
2025-10-12 16:30:56,151:INFO:Plot type: feature
2025-10-12 16:30:56,182:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp0hh60gqz\Feature Importance.png'
2025-10-12 16:30:56,281:INFO:Visual Rendered Successfully
2025-10-12 16:30:56,401:INFO:plot_model() successfully completed......................................
2025-10-12 16:30:56,422:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:30:56,625:INFO:Uploading results into container
2025-10-12 16:30:56,626:INFO:Uploading model into container now
2025-10-12 16:30:56,633:INFO:_master_model_container: 38
2025-10-12 16:30:56,633:INFO:_display_container: 8
2025-10-12 16:30:56,633:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:30:56,634:INFO:create_model() successfully completed......................................
2025-10-12 16:30:56,762:INFO:Initializing create_model()
2025-10-12 16:30:56,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=ridge, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:30:56,762:INFO:Checking exceptions
2025-10-12 16:30:56,774:INFO:Importing libraries
2025-10-12 16:30:56,775:INFO:Copying training dataset
2025-10-12 16:30:56,779:INFO:Defining folds
2025-10-12 16:30:56,779:INFO:Declaring metric variables
2025-10-12 16:30:56,783:INFO:Importing untrained model
2025-10-12 16:30:56,786:INFO:Ridge Classifier Imported successfully
2025-10-12 16:30:56,793:INFO:Starting cross validation
2025-10-12 16:30:56,794:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:30:56,865:INFO:Calculating mean and std
2025-10-12 16:30:56,865:INFO:Creating metrics dataframe
2025-10-12 16:30:56,870:INFO:Finalizing model
2025-10-12 16:30:56,877:INFO:Creating Dashboard logs
2025-10-12 16:30:56,881:INFO:Model: Ridge Classifier
2025-10-12 16:30:56,956:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 5816, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:30:57,194:INFO:Initializing predict_model()
2025-10-12 16:30:57,194:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5816, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001684679C280>)
2025-10-12 16:30:57,194:INFO:Checking exceptions
2025-10-12 16:30:57,194:INFO:Preloading libraries
2025-10-12 16:30:57,370:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:30:57,370:INFO:Initializing plot_model()
2025-10-12 16:30:57,370:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5816, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpmu9l_1ez, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:57,370:INFO:Checking exceptions
2025-10-12 16:30:57,371:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:30:57,371:INFO:Initializing plot_model()
2025-10-12 16:30:57,371:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5816, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpmu9l_1ez, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:57,371:INFO:Checking exceptions
2025-10-12 16:30:57,373:INFO:Preloading libraries
2025-10-12 16:30:57,373:INFO:Copying training dataset
2025-10-12 16:30:57,373:INFO:Plot type: confusion_matrix
2025-10-12 16:30:57,418:INFO:Fitting Model
2025-10-12 16:30:57,418:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names

2025-10-12 16:30:57,418:INFO:Scoring test/hold-out set
2025-10-12 16:30:57,432:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpmu9l_1ez\Confusion Matrix.png'
2025-10-12 16:30:57,511:INFO:Visual Rendered Successfully
2025-10-12 16:30:57,624:INFO:plot_model() successfully completed......................................
2025-10-12 16:30:57,641:INFO:Initializing plot_model()
2025-10-12 16:30:57,641:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5816, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpmu9l_1ez, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:57,641:INFO:Checking exceptions
2025-10-12 16:30:57,641:INFO:Preloading libraries
2025-10-12 16:30:57,642:INFO:Copying training dataset
2025-10-12 16:30:57,642:INFO:Plot type: feature
2025-10-12 16:30:57,677:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpmu9l_1ez\Feature Importance.png'
2025-10-12 16:30:57,772:INFO:Visual Rendered Successfully
2025-10-12 16:30:57,887:INFO:plot_model() successfully completed......................................
2025-10-12 16:30:57,902:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:30:58,111:INFO:Uploading results into container
2025-10-12 16:30:58,111:INFO:Uploading model into container now
2025-10-12 16:30:58,118:INFO:_master_model_container: 39
2025-10-12 16:30:58,118:INFO:_display_container: 9
2025-10-12 16:30:58,118:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5816, solver='auto',
                tol=0.0001)
2025-10-12 16:30:58,118:INFO:create_model() successfully completed......................................
2025-10-12 16:30:58,233:INFO:Initializing create_model()
2025-10-12 16:30:58,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:30:58,233:INFO:Checking exceptions
2025-10-12 16:30:58,244:INFO:Importing libraries
2025-10-12 16:30:58,244:INFO:Copying training dataset
2025-10-12 16:30:58,248:INFO:Defining folds
2025-10-12 16:30:58,248:INFO:Declaring metric variables
2025-10-12 16:30:58,251:INFO:Importing untrained model
2025-10-12 16:30:58,254:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:30:58,258:INFO:Starting cross validation
2025-10-12 16:30:58,259:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:30:58,471:INFO:Calculating mean and std
2025-10-12 16:30:58,472:INFO:Creating metrics dataframe
2025-10-12 16:30:58,476:INFO:Finalizing model
2025-10-12 16:30:58,574:INFO:Creating Dashboard logs
2025-10-12 16:30:58,578:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:30:58,674:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 5816, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:30:58,913:INFO:Initializing predict_model()
2025-10-12 16:30:58,913:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5816, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000168467A10D0>)
2025-10-12 16:30:58,913:INFO:Checking exceptions
2025-10-12 16:30:58,913:INFO:Preloading libraries
2025-10-12 16:30:59,093:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:30:59,094:INFO:Initializing plot_model()
2025-10-12 16:30:59,094:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5816, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp9zifw23g, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:59,094:INFO:Checking exceptions
2025-10-12 16:30:59,095:INFO:Preloading libraries
2025-10-12 16:30:59,099:INFO:Copying training dataset
2025-10-12 16:30:59,100:INFO:Plot type: auc
2025-10-12 16:30:59,143:INFO:Fitting Model
2025-10-12 16:30:59,144:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:30:59,144:INFO:Scoring test/hold-out set
2025-10-12 16:30:59,158:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp9zifw23g\AUC.png'
2025-10-12 16:30:59,322:INFO:Visual Rendered Successfully
2025-10-12 16:30:59,440:INFO:plot_model() successfully completed......................................
2025-10-12 16:30:59,461:INFO:Initializing plot_model()
2025-10-12 16:30:59,461:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5816, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp9zifw23g, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:59,461:INFO:Checking exceptions
2025-10-12 16:30:59,463:INFO:Preloading libraries
2025-10-12 16:30:59,467:INFO:Copying training dataset
2025-10-12 16:30:59,467:INFO:Plot type: confusion_matrix
2025-10-12 16:30:59,516:INFO:Fitting Model
2025-10-12 16:30:59,516:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:30:59,516:INFO:Scoring test/hold-out set
2025-10-12 16:30:59,530:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp9zifw23g\Confusion Matrix.png'
2025-10-12 16:30:59,641:INFO:Visual Rendered Successfully
2025-10-12 16:30:59,771:INFO:plot_model() successfully completed......................................
2025-10-12 16:30:59,785:INFO:Initializing plot_model()
2025-10-12 16:30:59,785:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5816, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmp9zifw23g, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:30:59,785:INFO:Checking exceptions
2025-10-12 16:30:59,787:INFO:Preloading libraries
2025-10-12 16:30:59,791:INFO:Copying training dataset
2025-10-12 16:30:59,791:INFO:Plot type: feature
2025-10-12 16:30:59,791:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:30:59,819:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmp9zifw23g\Feature Importance.png'
2025-10-12 16:30:59,910:INFO:Visual Rendered Successfully
2025-10-12 16:31:00,028:INFO:plot_model() successfully completed......................................
2025-10-12 16:31:00,043:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:31:00,235:INFO:Uploading results into container
2025-10-12 16:31:00,236:INFO:Uploading model into container now
2025-10-12 16:31:00,244:INFO:_master_model_container: 40
2025-10-12 16:31:00,244:INFO:_display_container: 10
2025-10-12 16:31:00,244:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5816, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:31:00,245:INFO:create_model() successfully completed......................................
2025-10-12 16:31:00,361:INFO:Initializing blend_models()
2025-10-12 16:31:00,361:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x00000168549E8850>, LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5816, solver='auto',
                tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5816, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:31:00,361:INFO:Checking exceptions
2025-10-12 16:31:00,361:INFO:Estimator RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5816, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-12 16:31:00,372:INFO:Importing libraries
2025-10-12 16:31:00,372:INFO:Copying training dataset
2025-10-12 16:31:00,375:INFO:Getting model names
2025-10-12 16:31:00,379:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:00,381:INFO:Initializing create_model()
2025-10-12 16:31:00,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000168549E8850>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5816,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168468540D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:00,381:INFO:Checking exceptions
2025-10-12 16:31:00,381:INFO:Importing libraries
2025-10-12 16:31:00,381:INFO:Copying training dataset
2025-10-12 16:31:00,385:INFO:Defining folds
2025-10-12 16:31:00,385:INFO:Declaring metric variables
2025-10-12 16:31:00,389:INFO:Importing untrained model
2025-10-12 16:31:00,389:INFO:Declaring custom model
2025-10-12 16:31:00,392:INFO:Voting Classifier Imported successfully
2025-10-12 16:31:00,398:INFO:Starting cross validation
2025-10-12 16:31:00,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:02,272:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:31:02,333:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:31:03,172:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:31:03,190:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:31:03,207:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:31:03,221:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:31:03,266:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:31:03,266:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:31:03,282:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:31:03,341:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:31:03,362:INFO:Calculating mean and std
2025-10-12 16:31:03,363:INFO:Creating metrics dataframe
2025-10-12 16:31:03,368:INFO:Finalizing model
2025-10-12 16:31:04,888:INFO:Uploading results into container
2025-10-12 16:31:04,889:INFO:Uploading model into container now
2025-10-12 16:31:04,889:INFO:_master_model_container: 41
2025-10-12 16:31:04,889:INFO:_display_container: 11
2025-10-12 16:31:04,892:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000168466941C0>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5816,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:31:04,893:INFO:create_model() successfully completed......................................
2025-10-12 16:31:05,017:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:05,017:INFO:Creating Dashboard logs
2025-10-12 16:31:05,021:INFO:Model: Voting Classifier
2025-10-12 16:31:05,094:INFO:Logged params: {'flatten_transform': True, 'n_jobs': -1, 'verbose': False, 'voting': 'hard', 'weights': None, 'CatBoost Classifier': <catboost.core.CatBoostClassifier object at 0x00000168466941C0>, 'Linear Discriminant Analysis': LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), 'Ridge Classifier': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5816, solver='auto',
                tol=0.0001), 'CatBoost Classifier__border_count': 254, 'CatBoost Classifier__verbose': False, 'CatBoost Classifier__task_type': 'CPU', 'CatBoost Classifier__random_state': 5816, 'Linear Discriminant Analysis__covariance_estimator': None, 'Linear Discriminant Analysis__n_components': None, 'Linear Discriminant Analysis__priors': None, 'Linear Discriminant Analysis__shrinkage': None, 'Linear Discriminant Analysis__solver': 'svd', 'Linear Discriminant Analysis__store_covariance': False, 'Linear Discriminant Analysis__tol': 0.0001, 'Ridge Classifier__alpha': 1.0, 'Ridge Classifier__class_weight': None, 'Ridge Classifier__copy_X': True, 'Ridge Classifier__fit_intercept': True, 'Ridge Classifier__max_iter': None, 'Ridge Classifier__positive': False, 'Ridge Classifier__random_state': 5816, 'Ridge Classifier__solver': 'auto', 'Ridge Classifier__tol': 0.0001, 'Gradient Boosting Classifier__ccp_alpha': 0.0, 'Gradient Boosting Classifier__criterion': 'friedman_mse', 'Gradient Boosting Classifier__init': None, 'Gradient Boosting Classifier__learning_rate': 0.1, 'Gradient Boosting Classifier__loss': 'log_loss', 'Gradient Boosting Classifier__max_depth': 3, 'Gradient Boosting Classifier__max_features': None, 'Gradient Boosting Classifier__max_leaf_nodes': None, 'Gradient Boosting Classifier__min_impurity_decrease': 0.0, 'Gradient Boosting Classifier__min_samples_leaf': 1, 'Gradient Boosting Classifier__min_samples_split': 2, 'Gradient Boosting Classifier__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Classifier__n_estimators': 100, 'Gradient Boosting Classifier__n_iter_no_change': None, 'Gradient Boosting Classifier__random_state': 5816, 'Gradient Boosting Classifier__subsample': 1.0, 'Gradient Boosting Classifier__tol': 0.0001, 'Gradient Boosting Classifier__validation_fraction': 0.1, 'Gradient Boosting Classifier__verbose': 0, 'Gradient Boosting Classifier__warm_start': False}
2025-10-12 16:31:05,416:INFO:Initializing predict_model()
2025-10-12 16:31:05,417:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000168466941C0>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5816,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001684666DDC0>)
2025-10-12 16:31:05,417:INFO:Checking exceptions
2025-10-12 16:31:05,417:INFO:Preloading libraries
2025-10-12 16:31:05,591:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:31:05,593:INFO:Initializing plot_model()
2025-10-12 16:31:05,593:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000168466941C0>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5816,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpzqphcx3f, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:31:05,593:INFO:Checking exceptions
2025-10-12 16:31:05,593:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:31:05,595:INFO:Initializing plot_model()
2025-10-12 16:31:05,596:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000168466941C0>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5816,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpzqphcx3f, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:31:05,596:INFO:Checking exceptions
2025-10-12 16:31:05,597:INFO:Preloading libraries
2025-10-12 16:31:05,603:INFO:Copying training dataset
2025-10-12 16:31:05,603:INFO:Plot type: confusion_matrix
2025-10-12 16:31:05,645:INFO:Fitting Model
2025-10-12 16:31:05,646:INFO:Scoring test/hold-out set
2025-10-12 16:31:05,667:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpzqphcx3f\Confusion Matrix.png'
2025-10-12 16:31:05,743:INFO:Visual Rendered Successfully
2025-10-12 16:31:05,858:INFO:plot_model() successfully completed......................................
2025-10-12 16:31:05,881:INFO:Initializing plot_model()
2025-10-12 16:31:05,881:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000168466941C0>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5816,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpzqphcx3f, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:31:05,881:INFO:Checking exceptions
2025-10-12 16:31:05,882:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 16:31:05,882:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:31:06,080:INFO:_master_model_container: 41
2025-10-12 16:31:06,080:INFO:_display_container: 11
2025-10-12 16:31:06,082:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000168466941C0>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5816,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:31:06,082:INFO:blend_models() successfully completed......................................
2025-10-12 16:31:06,200:INFO:Initializing compare_models()
2025-10-12 16:31:06,200:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:31:06,200:INFO:Checking exceptions
2025-10-12 16:31:06,201:INFO:Preparing display monitor
2025-10-12 16:31:06,218:INFO:Initializing Logistic Regression
2025-10-12 16:31:06,218:INFO:Total runtime is 8.43207041422526e-06 minutes
2025-10-12 16:31:06,221:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:06,221:INFO:Initializing create_model()
2025-10-12 16:31:06,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:06,222:INFO:Checking exceptions
2025-10-12 16:31:06,222:INFO:Importing libraries
2025-10-12 16:31:06,222:INFO:Copying training dataset
2025-10-12 16:31:06,224:INFO:Defining folds
2025-10-12 16:31:06,224:INFO:Declaring metric variables
2025-10-12 16:31:06,226:INFO:Importing untrained model
2025-10-12 16:31:06,230:INFO:Logistic Regression Imported successfully
2025-10-12 16:31:06,236:INFO:Starting cross validation
2025-10-12 16:31:06,237:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:06,322:INFO:Calculating mean and std
2025-10-12 16:31:06,323:INFO:Creating metrics dataframe
2025-10-12 16:31:06,325:INFO:Uploading results into container
2025-10-12 16:31:06,325:INFO:Uploading model into container now
2025-10-12 16:31:06,325:INFO:_master_model_container: 42
2025-10-12 16:31:06,325:INFO:_display_container: 12
2025-10-12 16:31:06,325:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5816, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:31:06,326:INFO:create_model() successfully completed......................................
2025-10-12 16:31:06,442:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:06,442:INFO:Creating metrics dataframe
2025-10-12 16:31:06,448:INFO:Initializing K Neighbors Classifier
2025-10-12 16:31:06,448:INFO:Total runtime is 0.00384061336517334 minutes
2025-10-12 16:31:06,451:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:06,452:INFO:Initializing create_model()
2025-10-12 16:31:06,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:06,452:INFO:Checking exceptions
2025-10-12 16:31:06,452:INFO:Importing libraries
2025-10-12 16:31:06,452:INFO:Copying training dataset
2025-10-12 16:31:06,453:INFO:Defining folds
2025-10-12 16:31:06,453:INFO:Declaring metric variables
2025-10-12 16:31:06,456:INFO:Importing untrained model
2025-10-12 16:31:06,458:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:31:06,465:INFO:Starting cross validation
2025-10-12 16:31:06,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:06,615:INFO:Calculating mean and std
2025-10-12 16:31:06,615:INFO:Creating metrics dataframe
2025-10-12 16:31:06,617:INFO:Uploading results into container
2025-10-12 16:31:06,617:INFO:Uploading model into container now
2025-10-12 16:31:06,617:INFO:_master_model_container: 43
2025-10-12 16:31:06,617:INFO:_display_container: 12
2025-10-12 16:31:06,617:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:31:06,618:INFO:create_model() successfully completed......................................
2025-10-12 16:31:06,734:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:06,734:INFO:Creating metrics dataframe
2025-10-12 16:31:06,740:INFO:Initializing Naive Bayes
2025-10-12 16:31:06,740:INFO:Total runtime is 0.008705405394236247 minutes
2025-10-12 16:31:06,743:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:06,743:INFO:Initializing create_model()
2025-10-12 16:31:06,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:06,743:INFO:Checking exceptions
2025-10-12 16:31:06,743:INFO:Importing libraries
2025-10-12 16:31:06,743:INFO:Copying training dataset
2025-10-12 16:31:06,745:INFO:Defining folds
2025-10-12 16:31:06,745:INFO:Declaring metric variables
2025-10-12 16:31:06,748:INFO:Importing untrained model
2025-10-12 16:31:06,750:INFO:Naive Bayes Imported successfully
2025-10-12 16:31:06,755:INFO:Starting cross validation
2025-10-12 16:31:06,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:06,818:INFO:Calculating mean and std
2025-10-12 16:31:06,818:INFO:Creating metrics dataframe
2025-10-12 16:31:06,820:INFO:Uploading results into container
2025-10-12 16:31:06,820:INFO:Uploading model into container now
2025-10-12 16:31:06,820:INFO:_master_model_container: 44
2025-10-12 16:31:06,820:INFO:_display_container: 12
2025-10-12 16:31:06,821:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:31:06,821:INFO:create_model() successfully completed......................................
2025-10-12 16:31:06,942:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:06,942:INFO:Creating metrics dataframe
2025-10-12 16:31:06,947:INFO:Initializing Decision Tree Classifier
2025-10-12 16:31:06,948:INFO:Total runtime is 0.01217883030573527 minutes
2025-10-12 16:31:06,951:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:06,951:INFO:Initializing create_model()
2025-10-12 16:31:06,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:06,951:INFO:Checking exceptions
2025-10-12 16:31:06,951:INFO:Importing libraries
2025-10-12 16:31:06,951:INFO:Copying training dataset
2025-10-12 16:31:06,953:INFO:Defining folds
2025-10-12 16:31:06,954:INFO:Declaring metric variables
2025-10-12 16:31:06,956:INFO:Importing untrained model
2025-10-12 16:31:06,959:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:31:06,965:INFO:Starting cross validation
2025-10-12 16:31:06,966:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:07,019:INFO:Calculating mean and std
2025-10-12 16:31:07,019:INFO:Creating metrics dataframe
2025-10-12 16:31:07,021:INFO:Uploading results into container
2025-10-12 16:31:07,021:INFO:Uploading model into container now
2025-10-12 16:31:07,021:INFO:_master_model_container: 45
2025-10-12 16:31:07,021:INFO:_display_container: 12
2025-10-12 16:31:07,022:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5816, splitter='best')
2025-10-12 16:31:07,022:INFO:create_model() successfully completed......................................
2025-10-12 16:31:07,144:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:07,144:INFO:Creating metrics dataframe
2025-10-12 16:31:07,152:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:31:07,153:INFO:Total runtime is 0.015595718224843343 minutes
2025-10-12 16:31:07,155:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:07,156:INFO:Initializing create_model()
2025-10-12 16:31:07,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:07,156:INFO:Checking exceptions
2025-10-12 16:31:07,156:INFO:Importing libraries
2025-10-12 16:31:07,156:INFO:Copying training dataset
2025-10-12 16:31:07,159:INFO:Defining folds
2025-10-12 16:31:07,159:INFO:Declaring metric variables
2025-10-12 16:31:07,162:INFO:Importing untrained model
2025-10-12 16:31:07,165:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:31:07,171:INFO:Starting cross validation
2025-10-12 16:31:07,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:07,201:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:31:07,210:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:31:07,237:INFO:Calculating mean and std
2025-10-12 16:31:07,238:INFO:Creating metrics dataframe
2025-10-12 16:31:07,240:INFO:Uploading results into container
2025-10-12 16:31:07,241:INFO:Uploading model into container now
2025-10-12 16:31:07,241:INFO:_master_model_container: 46
2025-10-12 16:31:07,241:INFO:_display_container: 12
2025-10-12 16:31:07,242:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5816, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:31:07,242:INFO:create_model() successfully completed......................................
2025-10-12 16:31:07,371:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:07,371:INFO:Creating metrics dataframe
2025-10-12 16:31:07,377:INFO:Initializing Ridge Classifier
2025-10-12 16:31:07,378:INFO:Total runtime is 0.01934560537338257 minutes
2025-10-12 16:31:07,381:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:07,382:INFO:Initializing create_model()
2025-10-12 16:31:07,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:07,383:INFO:Checking exceptions
2025-10-12 16:31:07,383:INFO:Importing libraries
2025-10-12 16:31:07,383:INFO:Copying training dataset
2025-10-12 16:31:07,385:INFO:Defining folds
2025-10-12 16:31:07,385:INFO:Declaring metric variables
2025-10-12 16:31:07,388:INFO:Importing untrained model
2025-10-12 16:31:07,391:INFO:Ridge Classifier Imported successfully
2025-10-12 16:31:07,399:INFO:Starting cross validation
2025-10-12 16:31:07,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:07,472:INFO:Calculating mean and std
2025-10-12 16:31:07,473:INFO:Creating metrics dataframe
2025-10-12 16:31:07,474:INFO:Uploading results into container
2025-10-12 16:31:07,475:INFO:Uploading model into container now
2025-10-12 16:31:07,475:INFO:_master_model_container: 47
2025-10-12 16:31:07,475:INFO:_display_container: 12
2025-10-12 16:31:07,475:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5816, solver='auto',
                tol=0.0001)
2025-10-12 16:31:07,475:INFO:create_model() successfully completed......................................
2025-10-12 16:31:07,598:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:07,598:INFO:Creating metrics dataframe
2025-10-12 16:31:07,604:INFO:Initializing Random Forest Classifier
2025-10-12 16:31:07,604:INFO:Total runtime is 0.023112746079762776 minutes
2025-10-12 16:31:07,606:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:07,607:INFO:Initializing create_model()
2025-10-12 16:31:07,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:07,607:INFO:Checking exceptions
2025-10-12 16:31:07,607:INFO:Importing libraries
2025-10-12 16:31:07,607:INFO:Copying training dataset
2025-10-12 16:31:07,610:INFO:Defining folds
2025-10-12 16:31:07,611:INFO:Declaring metric variables
2025-10-12 16:31:07,613:INFO:Importing untrained model
2025-10-12 16:31:07,617:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:31:07,622:INFO:Starting cross validation
2025-10-12 16:31:07,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:07,958:INFO:Calculating mean and std
2025-10-12 16:31:07,960:INFO:Creating metrics dataframe
2025-10-12 16:31:07,961:INFO:Uploading results into container
2025-10-12 16:31:07,962:INFO:Uploading model into container now
2025-10-12 16:31:07,962:INFO:_master_model_container: 48
2025-10-12 16:31:07,962:INFO:_display_container: 12
2025-10-12 16:31:07,963:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5816, verbose=0,
                       warm_start=False)
2025-10-12 16:31:07,963:INFO:create_model() successfully completed......................................
2025-10-12 16:31:08,085:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:08,085:INFO:Creating metrics dataframe
2025-10-12 16:31:08,090:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:31:08,091:INFO:Total runtime is 0.03121700684229533 minutes
2025-10-12 16:31:08,093:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:08,093:INFO:Initializing create_model()
2025-10-12 16:31:08,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:08,094:INFO:Checking exceptions
2025-10-12 16:31:08,094:INFO:Importing libraries
2025-10-12 16:31:08,094:INFO:Copying training dataset
2025-10-12 16:31:08,097:INFO:Defining folds
2025-10-12 16:31:08,097:INFO:Declaring metric variables
2025-10-12 16:31:08,100:INFO:Importing untrained model
2025-10-12 16:31:08,104:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:31:08,110:INFO:Starting cross validation
2025-10-12 16:31:08,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:08,162:INFO:Calculating mean and std
2025-10-12 16:31:08,162:INFO:Creating metrics dataframe
2025-10-12 16:31:08,164:INFO:Uploading results into container
2025-10-12 16:31:08,164:INFO:Uploading model into container now
2025-10-12 16:31:08,165:INFO:_master_model_container: 49
2025-10-12 16:31:08,165:INFO:_display_container: 12
2025-10-12 16:31:08,165:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:31:08,165:INFO:create_model() successfully completed......................................
2025-10-12 16:31:08,282:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:08,282:INFO:Creating metrics dataframe
2025-10-12 16:31:08,288:INFO:Initializing Ada Boost Classifier
2025-10-12 16:31:08,288:INFO:Total runtime is 0.03450385332107544 minutes
2025-10-12 16:31:08,291:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:08,291:INFO:Initializing create_model()
2025-10-12 16:31:08,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:08,291:INFO:Checking exceptions
2025-10-12 16:31:08,292:INFO:Importing libraries
2025-10-12 16:31:08,292:INFO:Copying training dataset
2025-10-12 16:31:08,295:INFO:Defining folds
2025-10-12 16:31:08,295:INFO:Declaring metric variables
2025-10-12 16:31:08,298:INFO:Importing untrained model
2025-10-12 16:31:08,301:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:31:08,307:INFO:Starting cross validation
2025-10-12 16:31:08,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:08,323:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:31:08,324:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:31:08,325:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:31:08,326:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:31:08,331:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:31:08,331:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:31:08,333:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:31:08,336:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:31:08,340:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:31:08,340:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:31:08,509:INFO:Calculating mean and std
2025-10-12 16:31:08,511:INFO:Creating metrics dataframe
2025-10-12 16:31:08,513:INFO:Uploading results into container
2025-10-12 16:31:08,514:INFO:Uploading model into container now
2025-10-12 16:31:08,514:INFO:_master_model_container: 50
2025-10-12 16:31:08,514:INFO:_display_container: 12
2025-10-12 16:31:08,515:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5816)
2025-10-12 16:31:08,515:INFO:create_model() successfully completed......................................
2025-10-12 16:31:08,635:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:08,636:INFO:Creating metrics dataframe
2025-10-12 16:31:08,643:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:31:08,643:INFO:Total runtime is 0.04041715065638224 minutes
2025-10-12 16:31:08,647:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:08,647:INFO:Initializing create_model()
2025-10-12 16:31:08,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:08,647:INFO:Checking exceptions
2025-10-12 16:31:08,647:INFO:Importing libraries
2025-10-12 16:31:08,647:INFO:Copying training dataset
2025-10-12 16:31:08,650:INFO:Defining folds
2025-10-12 16:31:08,651:INFO:Declaring metric variables
2025-10-12 16:31:08,654:INFO:Importing untrained model
2025-10-12 16:31:08,657:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:31:08,663:INFO:Starting cross validation
2025-10-12 16:31:08,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:08,911:INFO:Calculating mean and std
2025-10-12 16:31:08,912:INFO:Creating metrics dataframe
2025-10-12 16:31:08,913:INFO:Uploading results into container
2025-10-12 16:31:08,915:INFO:Uploading model into container now
2025-10-12 16:31:08,916:INFO:_master_model_container: 51
2025-10-12 16:31:08,916:INFO:_display_container: 12
2025-10-12 16:31:08,916:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5816, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:31:08,916:INFO:create_model() successfully completed......................................
2025-10-12 16:31:09,037:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:09,037:INFO:Creating metrics dataframe
2025-10-12 16:31:09,044:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:31:09,044:INFO:Total runtime is 0.04711161454518636 minutes
2025-10-12 16:31:09,047:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:09,048:INFO:Initializing create_model()
2025-10-12 16:31:09,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:09,048:INFO:Checking exceptions
2025-10-12 16:31:09,048:INFO:Importing libraries
2025-10-12 16:31:09,048:INFO:Copying training dataset
2025-10-12 16:31:09,050:INFO:Defining folds
2025-10-12 16:31:09,051:INFO:Declaring metric variables
2025-10-12 16:31:09,054:INFO:Importing untrained model
2025-10-12 16:31:09,057:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:31:09,062:INFO:Starting cross validation
2025-10-12 16:31:09,063:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:09,112:INFO:Calculating mean and std
2025-10-12 16:31:09,113:INFO:Creating metrics dataframe
2025-10-12 16:31:09,114:INFO:Uploading results into container
2025-10-12 16:31:09,115:INFO:Uploading model into container now
2025-10-12 16:31:09,115:INFO:_master_model_container: 52
2025-10-12 16:31:09,115:INFO:_display_container: 12
2025-10-12 16:31:09,115:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:31:09,115:INFO:create_model() successfully completed......................................
2025-10-12 16:31:09,234:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:09,234:INFO:Creating metrics dataframe
2025-10-12 16:31:09,240:INFO:Initializing Extra Trees Classifier
2025-10-12 16:31:09,240:INFO:Total runtime is 0.050375346342722574 minutes
2025-10-12 16:31:09,244:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:09,244:INFO:Initializing create_model()
2025-10-12 16:31:09,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:09,244:INFO:Checking exceptions
2025-10-12 16:31:09,244:INFO:Importing libraries
2025-10-12 16:31:09,244:INFO:Copying training dataset
2025-10-12 16:31:09,247:INFO:Defining folds
2025-10-12 16:31:09,248:INFO:Declaring metric variables
2025-10-12 16:31:09,251:INFO:Importing untrained model
2025-10-12 16:31:09,253:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:31:09,258:INFO:Starting cross validation
2025-10-12 16:31:09,260:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:09,565:INFO:Calculating mean and std
2025-10-12 16:31:09,566:INFO:Creating metrics dataframe
2025-10-12 16:31:09,568:INFO:Uploading results into container
2025-10-12 16:31:09,568:INFO:Uploading model into container now
2025-10-12 16:31:09,568:INFO:_master_model_container: 53
2025-10-12 16:31:09,568:INFO:_display_container: 12
2025-10-12 16:31:09,570:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5816, verbose=0,
                     warm_start=False)
2025-10-12 16:31:09,570:INFO:create_model() successfully completed......................................
2025-10-12 16:31:09,688:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:09,688:INFO:Creating metrics dataframe
2025-10-12 16:31:09,696:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:31:09,696:INFO:Total runtime is 0.057968155543009436 minutes
2025-10-12 16:31:09,698:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:09,698:INFO:Initializing create_model()
2025-10-12 16:31:09,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:09,699:INFO:Checking exceptions
2025-10-12 16:31:09,699:INFO:Importing libraries
2025-10-12 16:31:09,699:INFO:Copying training dataset
2025-10-12 16:31:09,702:INFO:Defining folds
2025-10-12 16:31:09,702:INFO:Declaring metric variables
2025-10-12 16:31:09,706:INFO:Importing untrained model
2025-10-12 16:31:09,709:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:31:09,715:INFO:Starting cross validation
2025-10-12 16:31:09,716:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:09,924:INFO:Calculating mean and std
2025-10-12 16:31:09,925:INFO:Creating metrics dataframe
2025-10-12 16:31:09,926:INFO:Uploading results into container
2025-10-12 16:31:09,927:INFO:Uploading model into container now
2025-10-12 16:31:09,928:INFO:_master_model_container: 54
2025-10-12 16:31:09,928:INFO:_display_container: 12
2025-10-12 16:31:09,928:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:31:09,928:INFO:create_model() successfully completed......................................
2025-10-12 16:31:10,050:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:10,050:INFO:Creating metrics dataframe
2025-10-12 16:31:10,057:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:31:10,057:INFO:Total runtime is 0.06399820248285928 minutes
2025-10-12 16:31:10,060:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:10,060:INFO:Initializing create_model()
2025-10-12 16:31:10,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:10,061:INFO:Checking exceptions
2025-10-12 16:31:10,061:INFO:Importing libraries
2025-10-12 16:31:10,061:INFO:Copying training dataset
2025-10-12 16:31:10,063:INFO:Defining folds
2025-10-12 16:31:10,063:INFO:Declaring metric variables
2025-10-12 16:31:10,067:INFO:Importing untrained model
2025-10-12 16:31:10,070:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:31:10,076:INFO:Starting cross validation
2025-10-12 16:31:10,077:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:13,618:INFO:Calculating mean and std
2025-10-12 16:31:13,619:INFO:Creating metrics dataframe
2025-10-12 16:31:13,622:INFO:Uploading results into container
2025-10-12 16:31:13,622:INFO:Uploading model into container now
2025-10-12 16:31:13,623:INFO:_master_model_container: 55
2025-10-12 16:31:13,623:INFO:_display_container: 12
2025-10-12 16:31:13,623:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5816, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:31:13,624:INFO:create_model() successfully completed......................................
2025-10-12 16:31:13,763:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:13,763:INFO:Creating metrics dataframe
2025-10-12 16:31:13,772:INFO:Initializing CatBoost Classifier
2025-10-12 16:31:13,772:INFO:Total runtime is 0.1259119113286336 minutes
2025-10-12 16:31:13,775:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:13,775:INFO:Initializing create_model()
2025-10-12 16:31:13,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:13,775:INFO:Checking exceptions
2025-10-12 16:31:13,776:INFO:Importing libraries
2025-10-12 16:31:13,776:INFO:Copying training dataset
2025-10-12 16:31:13,779:INFO:Defining folds
2025-10-12 16:31:13,779:INFO:Declaring metric variables
2025-10-12 16:31:13,783:INFO:Importing untrained model
2025-10-12 16:31:13,786:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:31:13,793:INFO:Starting cross validation
2025-10-12 16:31:13,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:17,282:INFO:Calculating mean and std
2025-10-12 16:31:17,283:INFO:Creating metrics dataframe
2025-10-12 16:31:17,284:INFO:Uploading results into container
2025-10-12 16:31:17,285:INFO:Uploading model into container now
2025-10-12 16:31:17,285:INFO:_master_model_container: 56
2025-10-12 16:31:17,285:INFO:_display_container: 12
2025-10-12 16:31:17,285:INFO:<catboost.core.CatBoostClassifier object at 0x00000168466723A0>
2025-10-12 16:31:17,285:INFO:create_model() successfully completed......................................
2025-10-12 16:31:17,429:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:17,429:INFO:Creating metrics dataframe
2025-10-12 16:31:17,438:INFO:Initializing Dummy Classifier
2025-10-12 16:31:17,438:INFO:Total runtime is 0.18700684706370035 minutes
2025-10-12 16:31:17,440:INFO:SubProcess create_model() called ==================================
2025-10-12 16:31:17,441:INFO:Initializing create_model()
2025-10-12 16:31:17,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684635D910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:17,441:INFO:Checking exceptions
2025-10-12 16:31:17,441:INFO:Importing libraries
2025-10-12 16:31:17,441:INFO:Copying training dataset
2025-10-12 16:31:17,445:INFO:Defining folds
2025-10-12 16:31:17,445:INFO:Declaring metric variables
2025-10-12 16:31:17,448:INFO:Importing untrained model
2025-10-12 16:31:17,452:INFO:Dummy Classifier Imported successfully
2025-10-12 16:31:17,457:INFO:Starting cross validation
2025-10-12 16:31:17,459:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:31:17,487:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:31:17,491:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:31:17,491:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:31:17,492:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:31:17,497:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:31:17,499:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:31:17,499:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:31:17,502:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:31:17,503:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:31:17,506:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:31:17,514:INFO:Calculating mean and std
2025-10-12 16:31:17,515:INFO:Creating metrics dataframe
2025-10-12 16:31:17,517:INFO:Uploading results into container
2025-10-12 16:31:17,518:INFO:Uploading model into container now
2025-10-12 16:31:17,518:INFO:_master_model_container: 57
2025-10-12 16:31:17,518:INFO:_display_container: 12
2025-10-12 16:31:17,518:INFO:DummyClassifier(constant=None, random_state=5816, strategy='prior')
2025-10-12 16:31:17,518:INFO:create_model() successfully completed......................................
2025-10-12 16:31:17,639:INFO:SubProcess create_model() end ==================================
2025-10-12 16:31:17,639:INFO:Creating metrics dataframe
2025-10-12 16:31:17,649:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:31:17,656:INFO:Initializing create_model()
2025-10-12 16:31:17,657:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466723A0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:31:17,657:INFO:Checking exceptions
2025-10-12 16:31:17,659:INFO:Importing libraries
2025-10-12 16:31:17,660:INFO:Copying training dataset
2025-10-12 16:31:17,662:INFO:Defining folds
2025-10-12 16:31:17,662:INFO:Declaring metric variables
2025-10-12 16:31:17,662:INFO:Importing untrained model
2025-10-12 16:31:17,662:INFO:Declaring custom model
2025-10-12 16:31:17,662:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:31:17,662:INFO:Cross validation set to False
2025-10-12 16:31:17,663:INFO:Fitting Model
2025-10-12 16:31:19,280:INFO:<catboost.core.CatBoostClassifier object at 0x00000168466C9F40>
2025-10-12 16:31:19,280:INFO:create_model() successfully completed......................................
2025-10-12 16:31:19,410:INFO:Creating Dashboard logs
2025-10-12 16:31:19,412:INFO:Model: CatBoost Classifier
2025-10-12 16:31:19,492:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'Logloss', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 5816, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.007650000043213368, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 10, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2025-10-12 16:31:19,803:INFO:Initializing predict_model()
2025-10-12 16:31:19,803:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466C9F40>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001684677E040>)
2025-10-12 16:31:19,803:INFO:Checking exceptions
2025-10-12 16:31:19,803:INFO:Preloading libraries
2025-10-12 16:31:19,974:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:31:19,974:INFO:Initializing plot_model()
2025-10-12 16:31:19,974:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466C9F40>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmphfkuhy40, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:31:19,974:INFO:Checking exceptions
2025-10-12 16:31:19,977:INFO:Preloading libraries
2025-10-12 16:31:19,979:INFO:Copying training dataset
2025-10-12 16:31:19,979:INFO:Plot type: auc
2025-10-12 16:31:20,026:INFO:Fitting Model
2025-10-12 16:31:20,027:INFO:Scoring test/hold-out set
2025-10-12 16:31:20,045:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmphfkuhy40\AUC.png'
2025-10-12 16:31:20,202:INFO:Visual Rendered Successfully
2025-10-12 16:31:20,325:INFO:plot_model() successfully completed......................................
2025-10-12 16:31:20,347:INFO:Initializing plot_model()
2025-10-12 16:31:20,347:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466C9F40>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmphfkuhy40, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:31:20,347:INFO:Checking exceptions
2025-10-12 16:31:20,348:INFO:Preloading libraries
2025-10-12 16:31:20,350:INFO:Copying training dataset
2025-10-12 16:31:20,350:INFO:Plot type: confusion_matrix
2025-10-12 16:31:20,398:INFO:Fitting Model
2025-10-12 16:31:20,398:INFO:Scoring test/hold-out set
2025-10-12 16:31:20,412:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmphfkuhy40\Confusion Matrix.png'
2025-10-12 16:31:20,516:INFO:Visual Rendered Successfully
2025-10-12 16:31:20,638:INFO:plot_model() successfully completed......................................
2025-10-12 16:31:20,660:INFO:Initializing plot_model()
2025-10-12 16:31:20,660:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466C9F40>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmphfkuhy40, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, system=False)
2025-10-12 16:31:20,660:INFO:Checking exceptions
2025-10-12 16:31:20,662:INFO:Preloading libraries
2025-10-12 16:31:20,663:INFO:Copying training dataset
2025-10-12 16:31:20,663:INFO:Plot type: feature
2025-10-12 16:31:20,664:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:31:20,694:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmphfkuhy40\Feature Importance.png'
2025-10-12 16:31:20,795:INFO:Visual Rendered Successfully
2025-10-12 16:31:20,920:INFO:plot_model() successfully completed......................................
2025-10-12 16:31:20,938:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:31:21,145:INFO:Creating Dashboard logs
2025-10-12 16:31:21,148:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:31:21,226:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 5816, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:31:21,695:INFO:Creating Dashboard logs
2025-10-12 16:31:21,697:INFO:Model: Ada Boost Classifier
2025-10-12 16:31:21,775:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 5816}
2025-10-12 16:31:22,199:INFO:Creating Dashboard logs
2025-10-12 16:31:22,202:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:31:22,278:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5816, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:31:22,739:INFO:Creating Dashboard logs
2025-10-12 16:31:22,743:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 16:31:22,819:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:31:23,244:INFO:Creating Dashboard logs
2025-10-12 16:31:23,248:INFO:Model: Random Forest Classifier
2025-10-12 16:31:23,323:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5816, 'verbose': 0, 'warm_start': False}
2025-10-12 16:31:23,761:INFO:Creating Dashboard logs
2025-10-12 16:31:23,766:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:31:23,858:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 5816, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:31:24,356:INFO:Creating Dashboard logs
2025-10-12 16:31:24,358:INFO:Model: Extra Trees Classifier
2025-10-12 16:31:24,438:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5816, 'verbose': 0, 'warm_start': False}
2025-10-12 16:31:24,872:INFO:Creating Dashboard logs
2025-10-12 16:31:24,876:INFO:Model: Ridge Classifier
2025-10-12 16:31:24,951:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 5816, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:31:25,363:INFO:Creating Dashboard logs
2025-10-12 16:31:25,367:INFO:Model: Logistic Regression
2025-10-12 16:31:25,454:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 5816, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:31:25,868:INFO:Creating Dashboard logs
2025-10-12 16:31:25,870:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:31:25,941:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:31:26,349:INFO:Creating Dashboard logs
2025-10-12 16:31:26,352:INFO:Model: Naive Bayes
2025-10-12 16:31:26,428:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:31:26,848:INFO:Creating Dashboard logs
2025-10-12 16:31:26,851:INFO:Model: Decision Tree Classifier
2025-10-12 16:31:26,937:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 5816, 'splitter': 'best'}
2025-10-12 16:31:27,358:INFO:Creating Dashboard logs
2025-10-12 16:31:27,361:INFO:Model: SVM - Linear Kernel
2025-10-12 16:31:27,438:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 5816, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:31:27,894:INFO:Creating Dashboard logs
2025-10-12 16:31:27,897:INFO:Model: K Neighbors Classifier
2025-10-12 16:31:27,978:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:31:28,387:INFO:Creating Dashboard logs
2025-10-12 16:31:28,391:INFO:Model: Dummy Classifier
2025-10-12 16:31:28,464:INFO:Logged params: {'constant': None, 'random_state': 5816, 'strategy': 'prior'}
2025-10-12 16:31:28,876:INFO:_master_model_container: 57
2025-10-12 16:31:28,876:INFO:_display_container: 12
2025-10-12 16:31:28,876:INFO:<catboost.core.CatBoostClassifier object at 0x00000168466C9F40>
2025-10-12 16:31:28,876:INFO:compare_models() successfully completed......................................
2025-10-12 16:31:31,156:INFO:Initializing predict_model()
2025-10-12 16:31:31,156:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016852F3CDC0>, estimator=mlflow.pyfunc.loaded_model:
  run_id: c95044b7ed9c4c03b9679065b22ab096
  artifact_path: model
  flavor: mlflow.sklearn
, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016854BC8C10>)
2025-10-12 16:31:31,156:INFO:Checking exceptions
2025-10-12 16:31:31,157:INFO:Preloading libraries
2025-10-12 16:31:31,158:INFO:Set up data.
2025-10-12 16:31:31,164:INFO:Set up index.
2025-10-12 16:39:44,595:INFO:PyCaret ClassificationExperiment
2025-10-12 16:39:44,595:INFO:Logging name: titanic_exp_2
2025-10-12 16:39:44,596:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-12 16:39:44,596:INFO:version 3.3.2
2025-10-12 16:39:44,596:INFO:Initializing setup()
2025-10-12 16:39:44,596:INFO:self.USI: aa1e
2025-10-12 16:39:44,596:INFO:self._variable_keys: {'exp_name_log', 'exp_id', 'logging_param', 'pipeline', 'idx', 'y_test', 'X_train', 'n_jobs_param', 'gpu_n_jobs_param', 'gpu_param', '_available_plots', 'fold_shuffle_param', 'fold_generator', 'is_multiclass', 'y', '_ml_usecase', 'fold_groups_param', 'fix_imbalance', 'X_test', 'log_plots_param', 'USI', 'seed', 'memory', 'y_train', 'data', 'target_param', 'X', 'html_param'}
2025-10-12 16:39:44,596:INFO:Checking environment
2025-10-12 16:39:44,596:INFO:python_version: 3.9.13
2025-10-12 16:39:44,596:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2025-10-12 16:39:44,596:INFO:machine: AMD64
2025-10-12 16:39:44,596:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-12 16:39:44,596:INFO:Memory: svmem(total=16778072064, available=4555296768, percent=72.8, used=12222775296, free=4555296768)
2025-10-12 16:39:44,596:INFO:Physical Core: 10
2025-10-12 16:39:44,596:INFO:Logical Core: 16
2025-10-12 16:39:44,596:INFO:Checking libraries
2025-10-12 16:39:44,596:INFO:System:
2025-10-12 16:39:44,596:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2025-10-12 16:39:44,596:INFO:executable: c:\Users\david\Programming\MLOps\.venv\Scripts\python.exe
2025-10-12 16:39:44,596:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-12 16:39:44,596:INFO:PyCaret required dependencies:
2025-10-12 16:39:44,596:INFO:                 pip: 25.2
2025-10-12 16:39:44,596:INFO:          setuptools: 80.9.0
2025-10-12 16:39:44,596:INFO:             pycaret: 3.3.2
2025-10-12 16:39:44,596:INFO:             IPython: 8.18.1
2025-10-12 16:39:44,596:INFO:          ipywidgets: 8.1.7
2025-10-12 16:39:44,596:INFO:                tqdm: 4.67.1
2025-10-12 16:39:44,596:INFO:               numpy: 1.26.4
2025-10-12 16:39:44,596:INFO:              pandas: 2.1.4
2025-10-12 16:39:44,596:INFO:              jinja2: 3.1.6
2025-10-12 16:39:44,596:INFO:               scipy: 1.11.4
2025-10-12 16:39:44,596:INFO:              joblib: 1.3.2
2025-10-12 16:39:44,596:INFO:             sklearn: 1.4.2
2025-10-12 16:39:44,596:INFO:                pyod: 2.0.5
2025-10-12 16:39:44,596:INFO:            imblearn: 0.12.4
2025-10-12 16:39:44,596:INFO:   category_encoders: 2.6.4
2025-10-12 16:39:44,596:INFO:            lightgbm: 4.6.0
2025-10-12 16:39:44,596:INFO:               numba: 0.60.0
2025-10-12 16:39:44,596:INFO:            requests: 2.32.5
2025-10-12 16:39:44,596:INFO:          matplotlib: 3.7.5
2025-10-12 16:39:44,596:INFO:          scikitplot: 0.3.7
2025-10-12 16:39:44,596:INFO:         yellowbrick: 1.5
2025-10-12 16:39:44,596:INFO:              plotly: 5.24.1
2025-10-12 16:39:44,597:INFO:    plotly-resampler: Not installed
2025-10-12 16:39:44,597:INFO:             kaleido: 1.1.0
2025-10-12 16:39:44,597:INFO:           schemdraw: 0.15
2025-10-12 16:39:44,597:INFO:         statsmodels: 0.14.5
2025-10-12 16:39:44,597:INFO:              sktime: 0.26.0
2025-10-12 16:39:44,597:INFO:               tbats: 1.1.3
2025-10-12 16:39:44,597:INFO:            pmdarima: 2.0.4
2025-10-12 16:39:44,597:INFO:              psutil: 7.1.0
2025-10-12 16:39:44,597:INFO:          markupsafe: 2.1.5
2025-10-12 16:39:44,597:INFO:             pickle5: Not installed
2025-10-12 16:39:44,597:INFO:         cloudpickle: 3.1.1
2025-10-12 16:39:44,597:INFO:         deprecation: 2.1.0
2025-10-12 16:39:44,597:INFO:              xxhash: 3.6.0
2025-10-12 16:39:44,597:INFO:           wurlitzer: Not installed
2025-10-12 16:39:44,597:INFO:PyCaret optional dependencies:
2025-10-12 16:39:44,597:INFO:                shap: 0.44.1
2025-10-12 16:39:44,597:INFO:           interpret: 0.7.2
2025-10-12 16:39:44,597:INFO:                umap: 0.5.7
2025-10-12 16:39:44,597:INFO:     ydata_profiling: 4.17.0
2025-10-12 16:39:44,597:INFO:  explainerdashboard: 0.5.1
2025-10-12 16:39:44,597:INFO:             autoviz: Not installed
2025-10-12 16:39:44,597:INFO:           fairlearn: 0.7.0
2025-10-12 16:39:44,597:INFO:          deepchecks: Not installed
2025-10-12 16:39:44,597:INFO:             xgboost: 2.1.4
2025-10-12 16:39:44,597:INFO:            catboost: 1.2.8
2025-10-12 16:39:44,597:INFO:              kmodes: 0.12.2
2025-10-12 16:39:44,597:INFO:             mlxtend: 0.23.4
2025-10-12 16:39:44,597:INFO:       statsforecast: 1.5.0
2025-10-12 16:39:44,597:INFO:        tune_sklearn: Not installed
2025-10-12 16:39:44,597:INFO:                 ray: Not installed
2025-10-12 16:39:44,597:INFO:            hyperopt: 0.2.7
2025-10-12 16:39:44,597:INFO:              optuna: 4.5.0
2025-10-12 16:39:44,597:INFO:               skopt: 0.10.2
2025-10-12 16:39:44,597:INFO:              mlflow: 3.1.4
2025-10-12 16:39:44,597:INFO:              gradio: Not installed
2025-10-12 16:39:44,597:INFO:             fastapi: 0.119.0
2025-10-12 16:39:44,597:INFO:             uvicorn: 0.37.0
2025-10-12 16:39:44,597:INFO:              m2cgen: 0.10.0
2025-10-12 16:39:44,597:INFO:           evidently: 0.4.40
2025-10-12 16:39:44,597:INFO:               fugue: 0.8.7
2025-10-12 16:39:44,597:INFO:           streamlit: Not installed
2025-10-12 16:39:44,597:INFO:             prophet: Not installed
2025-10-12 16:39:44,597:INFO:None
2025-10-12 16:39:44,597:INFO:Set up data.
2025-10-12 16:39:44,601:INFO:Set up folding strategy.
2025-10-12 16:39:44,601:INFO:Set up train/test split.
2025-10-12 16:39:44,604:INFO:Set up index.
2025-10-12 16:39:44,604:INFO:Assigning column types.
2025-10-12 16:39:44,606:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-12 16:39:44,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:39:44,641:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:39:44,660:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:39:44,662:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:39:44,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-12 16:39:44,695:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:39:44,715:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:39:44,717:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:39:44,719:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-12 16:39:44,752:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:39:44,773:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:39:44,775:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:39:44,809:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-12 16:39:44,828:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:39:44,830:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:39:44,830:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-12 16:39:44,883:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:39:44,885:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:39:44,940:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:39:44,943:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:39:44,945:INFO:Preparing preprocessing pipeline...
2025-10-12 16:39:44,946:INFO:Set up simple imputation.
2025-10-12 16:39:44,962:INFO:Finished creating preprocessing pipeline.
2025-10-12 16:39:44,965:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-12 16:39:44,965:INFO:Creating final display dataframe.
2025-10-12 16:39:45,017:INFO:Setup _display_container:                     Description            Value
0                    Session id             5705
1                        Target         Survived
2                   Target type           Binary
3           Original data shape         (712, 8)
4        Transformed data shape         (712, 8)
5   Transformed train set shape         (498, 8)
6    Transformed test set shape         (214, 8)
7              Numeric features                7
8                    Preprocess             True
9               Imputation type           simple
10           Numeric imputation             mean
11       Categorical imputation             mode
12               Fold Generator  StratifiedKFold
13                  Fold Number               10
14                     CPU Jobs               -1
15                      Use GPU            False
16               Log Experiment     MlflowLogger
17              Experiment Name    titanic_exp_2
18                          USI             aa1e
2025-10-12 16:39:45,077:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:39:45,079:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:39:45,134:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-12 16:39:45,135:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-12 16:39:45,137:INFO:Logging experiment in loggers
2025-10-12 16:39:45,275:INFO:SubProcess save_model() called ==================================
2025-10-12 16:39:45,279:INFO:Initializing save_model()
2025-10-12 16:39:45,279:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\david\AppData\Local\Temp\tmp2hw1lrpc\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 16:39:45,279:INFO:Adding model into prep_pipe
2025-10-12 16:39:45,279:WARNING:Only Model saved as it was a pipeline.
2025-10-12 16:39:45,280:INFO:C:\Users\david\AppData\Local\Temp\tmp2hw1lrpc\Transformation Pipeline.pkl saved in current working directory
2025-10-12 16:39:45,282:INFO:Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-12 16:39:45,283:INFO:save_model() successfully completed......................................
2025-10-12 16:39:45,442:INFO:SubProcess save_model() end ==================================
2025-10-12 16:39:45,547:INFO:setup() successfully completed in 0.54s...............
2025-10-12 16:39:45,564:INFO:Initializing compare_models()
2025-10-12 16:39:45,564:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:39:45,564:INFO:Checking exceptions
2025-10-12 16:39:45,568:INFO:Preparing display monitor
2025-10-12 16:39:45,591:INFO:Initializing Logistic Regression
2025-10-12 16:39:45,591:INFO:Total runtime is 0.0 minutes
2025-10-12 16:39:45,594:INFO:SubProcess create_model() called ==================================
2025-10-12 16:39:45,594:INFO:Initializing create_model()
2025-10-12 16:39:45,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:39:45,595:INFO:Checking exceptions
2025-10-12 16:39:45,595:INFO:Importing libraries
2025-10-12 16:39:45,595:INFO:Copying training dataset
2025-10-12 16:39:45,597:INFO:Defining folds
2025-10-12 16:39:45,597:INFO:Declaring metric variables
2025-10-12 16:39:45,601:INFO:Importing untrained model
2025-10-12 16:39:45,605:INFO:Logistic Regression Imported successfully
2025-10-12 16:39:45,610:INFO:Starting cross validation
2025-10-12 16:39:45,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:39:53,895:INFO:Calculating mean and std
2025-10-12 16:39:53,897:INFO:Creating metrics dataframe
2025-10-12 16:39:53,902:INFO:Uploading results into container
2025-10-12 16:39:53,902:INFO:Uploading model into container now
2025-10-12 16:39:53,904:INFO:_master_model_container: 1
2025-10-12 16:39:53,904:INFO:_display_container: 2
2025-10-12 16:39:53,905:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5705, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:39:53,905:INFO:create_model() successfully completed......................................
2025-10-12 16:39:54,085:INFO:SubProcess create_model() end ==================================
2025-10-12 16:39:54,085:INFO:Creating metrics dataframe
2025-10-12 16:39:54,092:INFO:Initializing K Neighbors Classifier
2025-10-12 16:39:54,092:INFO:Total runtime is 0.14168330828348796 minutes
2025-10-12 16:39:54,095:INFO:SubProcess create_model() called ==================================
2025-10-12 16:39:54,095:INFO:Initializing create_model()
2025-10-12 16:39:54,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:39:54,095:INFO:Checking exceptions
2025-10-12 16:39:54,095:INFO:Importing libraries
2025-10-12 16:39:54,095:INFO:Copying training dataset
2025-10-12 16:39:54,102:INFO:Defining folds
2025-10-12 16:39:54,102:INFO:Declaring metric variables
2025-10-12 16:39:54,106:INFO:Importing untrained model
2025-10-12 16:39:54,108:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:39:54,117:INFO:Starting cross validation
2025-10-12 16:39:54,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:39:59,500:INFO:Calculating mean and std
2025-10-12 16:39:59,502:INFO:Creating metrics dataframe
2025-10-12 16:39:59,505:INFO:Uploading results into container
2025-10-12 16:39:59,506:INFO:Uploading model into container now
2025-10-12 16:39:59,506:INFO:_master_model_container: 2
2025-10-12 16:39:59,507:INFO:_display_container: 2
2025-10-12 16:39:59,507:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:39:59,507:INFO:create_model() successfully completed......................................
2025-10-12 16:39:59,641:INFO:SubProcess create_model() end ==================================
2025-10-12 16:39:59,642:INFO:Creating metrics dataframe
2025-10-12 16:39:59,647:INFO:Initializing Naive Bayes
2025-10-12 16:39:59,647:INFO:Total runtime is 0.23427119652430217 minutes
2025-10-12 16:39:59,649:INFO:SubProcess create_model() called ==================================
2025-10-12 16:39:59,650:INFO:Initializing create_model()
2025-10-12 16:39:59,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:39:59,650:INFO:Checking exceptions
2025-10-12 16:39:59,650:INFO:Importing libraries
2025-10-12 16:39:59,650:INFO:Copying training dataset
2025-10-12 16:39:59,653:INFO:Defining folds
2025-10-12 16:39:59,653:INFO:Declaring metric variables
2025-10-12 16:39:59,656:INFO:Importing untrained model
2025-10-12 16:39:59,660:INFO:Naive Bayes Imported successfully
2025-10-12 16:39:59,664:INFO:Starting cross validation
2025-10-12 16:39:59,666:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:39:59,732:INFO:Calculating mean and std
2025-10-12 16:39:59,732:INFO:Creating metrics dataframe
2025-10-12 16:39:59,734:INFO:Uploading results into container
2025-10-12 16:39:59,735:INFO:Uploading model into container now
2025-10-12 16:39:59,735:INFO:_master_model_container: 3
2025-10-12 16:39:59,735:INFO:_display_container: 2
2025-10-12 16:39:59,735:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:39:59,735:INFO:create_model() successfully completed......................................
2025-10-12 16:39:59,866:INFO:SubProcess create_model() end ==================================
2025-10-12 16:39:59,866:INFO:Creating metrics dataframe
2025-10-12 16:39:59,870:INFO:Initializing Decision Tree Classifier
2025-10-12 16:39:59,871:INFO:Total runtime is 0.23800743023554485 minutes
2025-10-12 16:39:59,873:INFO:SubProcess create_model() called ==================================
2025-10-12 16:39:59,873:INFO:Initializing create_model()
2025-10-12 16:39:59,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:39:59,874:INFO:Checking exceptions
2025-10-12 16:39:59,874:INFO:Importing libraries
2025-10-12 16:39:59,874:INFO:Copying training dataset
2025-10-12 16:39:59,877:INFO:Defining folds
2025-10-12 16:39:59,877:INFO:Declaring metric variables
2025-10-12 16:39:59,882:INFO:Importing untrained model
2025-10-12 16:39:59,884:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:39:59,890:INFO:Starting cross validation
2025-10-12 16:39:59,891:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:39:59,965:INFO:Calculating mean and std
2025-10-12 16:39:59,965:INFO:Creating metrics dataframe
2025-10-12 16:39:59,967:INFO:Uploading results into container
2025-10-12 16:39:59,968:INFO:Uploading model into container now
2025-10-12 16:39:59,968:INFO:_master_model_container: 4
2025-10-12 16:39:59,968:INFO:_display_container: 2
2025-10-12 16:39:59,968:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5705, splitter='best')
2025-10-12 16:39:59,968:INFO:create_model() successfully completed......................................
2025-10-12 16:40:00,113:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:00,113:INFO:Creating metrics dataframe
2025-10-12 16:40:00,120:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:40:00,120:INFO:Total runtime is 0.242161762714386 minutes
2025-10-12 16:40:00,125:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:00,125:INFO:Initializing create_model()
2025-10-12 16:40:00,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:00,125:INFO:Checking exceptions
2025-10-12 16:40:00,126:INFO:Importing libraries
2025-10-12 16:40:00,126:INFO:Copying training dataset
2025-10-12 16:40:00,130:INFO:Defining folds
2025-10-12 16:40:00,130:INFO:Declaring metric variables
2025-10-12 16:40:00,135:INFO:Importing untrained model
2025-10-12 16:40:00,139:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:40:00,146:INFO:Starting cross validation
2025-10-12 16:40:00,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:00,192:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:40:00,196:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:40:00,214:INFO:Calculating mean and std
2025-10-12 16:40:00,214:INFO:Creating metrics dataframe
2025-10-12 16:40:00,215:INFO:Uploading results into container
2025-10-12 16:40:00,217:INFO:Uploading model into container now
2025-10-12 16:40:00,217:INFO:_master_model_container: 5
2025-10-12 16:40:00,217:INFO:_display_container: 2
2025-10-12 16:40:00,217:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5705, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:40:00,217:INFO:create_model() successfully completed......................................
2025-10-12 16:40:00,345:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:00,346:INFO:Creating metrics dataframe
2025-10-12 16:40:00,352:INFO:Initializing Ridge Classifier
2025-10-12 16:40:00,353:INFO:Total runtime is 0.2460395654042562 minutes
2025-10-12 16:40:00,357:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:00,358:INFO:Initializing create_model()
2025-10-12 16:40:00,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:00,358:INFO:Checking exceptions
2025-10-12 16:40:00,358:INFO:Importing libraries
2025-10-12 16:40:00,359:INFO:Copying training dataset
2025-10-12 16:40:00,364:INFO:Defining folds
2025-10-12 16:40:00,364:INFO:Declaring metric variables
2025-10-12 16:40:00,369:INFO:Importing untrained model
2025-10-12 16:40:00,374:INFO:Ridge Classifier Imported successfully
2025-10-12 16:40:00,381:INFO:Starting cross validation
2025-10-12 16:40:00,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:00,464:INFO:Calculating mean and std
2025-10-12 16:40:00,465:INFO:Creating metrics dataframe
2025-10-12 16:40:00,468:INFO:Uploading results into container
2025-10-12 16:40:00,468:INFO:Uploading model into container now
2025-10-12 16:40:00,469:INFO:_master_model_container: 6
2025-10-12 16:40:00,469:INFO:_display_container: 2
2025-10-12 16:40:00,469:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5705, solver='auto',
                tol=0.0001)
2025-10-12 16:40:00,469:INFO:create_model() successfully completed......................................
2025-10-12 16:40:00,614:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:00,614:INFO:Creating metrics dataframe
2025-10-12 16:40:00,621:INFO:Initializing Random Forest Classifier
2025-10-12 16:40:00,621:INFO:Total runtime is 0.25050719579060876 minutes
2025-10-12 16:40:00,625:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:00,625:INFO:Initializing create_model()
2025-10-12 16:40:00,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:00,625:INFO:Checking exceptions
2025-10-12 16:40:00,625:INFO:Importing libraries
2025-10-12 16:40:00,625:INFO:Copying training dataset
2025-10-12 16:40:00,628:INFO:Defining folds
2025-10-12 16:40:00,628:INFO:Declaring metric variables
2025-10-12 16:40:00,633:INFO:Importing untrained model
2025-10-12 16:40:00,637:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:40:00,642:INFO:Starting cross validation
2025-10-12 16:40:00,643:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:01,017:INFO:Calculating mean and std
2025-10-12 16:40:01,019:INFO:Creating metrics dataframe
2025-10-12 16:40:01,020:INFO:Uploading results into container
2025-10-12 16:40:01,021:INFO:Uploading model into container now
2025-10-12 16:40:01,021:INFO:_master_model_container: 7
2025-10-12 16:40:01,021:INFO:_display_container: 2
2025-10-12 16:40:01,022:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5705, verbose=0,
                       warm_start=False)
2025-10-12 16:40:01,022:INFO:create_model() successfully completed......................................
2025-10-12 16:40:01,137:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:01,138:INFO:Creating metrics dataframe
2025-10-12 16:40:01,144:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:40:01,144:INFO:Total runtime is 0.2592251896858216 minutes
2025-10-12 16:40:01,148:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:01,148:INFO:Initializing create_model()
2025-10-12 16:40:01,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:01,148:INFO:Checking exceptions
2025-10-12 16:40:01,148:INFO:Importing libraries
2025-10-12 16:40:01,148:INFO:Copying training dataset
2025-10-12 16:40:01,152:INFO:Defining folds
2025-10-12 16:40:01,152:INFO:Declaring metric variables
2025-10-12 16:40:01,156:INFO:Importing untrained model
2025-10-12 16:40:01,161:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:40:01,172:INFO:Starting cross validation
2025-10-12 16:40:01,174:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:01,251:INFO:Calculating mean and std
2025-10-12 16:40:01,253:INFO:Creating metrics dataframe
2025-10-12 16:40:01,254:INFO:Uploading results into container
2025-10-12 16:40:01,255:INFO:Uploading model into container now
2025-10-12 16:40:01,255:INFO:_master_model_container: 8
2025-10-12 16:40:01,255:INFO:_display_container: 2
2025-10-12 16:40:01,256:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:40:01,256:INFO:create_model() successfully completed......................................
2025-10-12 16:40:01,384:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:01,384:INFO:Creating metrics dataframe
2025-10-12 16:40:01,392:INFO:Initializing Ada Boost Classifier
2025-10-12 16:40:01,392:INFO:Total runtime is 0.2633526007334392 minutes
2025-10-12 16:40:01,395:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:01,396:INFO:Initializing create_model()
2025-10-12 16:40:01,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:01,396:INFO:Checking exceptions
2025-10-12 16:40:01,396:INFO:Importing libraries
2025-10-12 16:40:01,396:INFO:Copying training dataset
2025-10-12 16:40:01,400:INFO:Defining folds
2025-10-12 16:40:01,400:INFO:Declaring metric variables
2025-10-12 16:40:01,404:INFO:Importing untrained model
2025-10-12 16:40:01,408:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:40:01,413:INFO:Starting cross validation
2025-10-12 16:40:01,415:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:01,433:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:40:01,436:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:40:01,436:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:40:01,439:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:40:01,443:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:40:01,443:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:40:01,447:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:40:01,451:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:40:01,454:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:40:01,628:INFO:Calculating mean and std
2025-10-12 16:40:01,629:INFO:Creating metrics dataframe
2025-10-12 16:40:01,631:INFO:Uploading results into container
2025-10-12 16:40:01,632:INFO:Uploading model into container now
2025-10-12 16:40:01,632:INFO:_master_model_container: 9
2025-10-12 16:40:01,633:INFO:_display_container: 2
2025-10-12 16:40:01,633:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5705)
2025-10-12 16:40:01,633:INFO:create_model() successfully completed......................................
2025-10-12 16:40:01,760:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:01,760:INFO:Creating metrics dataframe
2025-10-12 16:40:01,767:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:40:01,767:INFO:Total runtime is 0.269607166449229 minutes
2025-10-12 16:40:01,771:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:01,771:INFO:Initializing create_model()
2025-10-12 16:40:01,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:01,771:INFO:Checking exceptions
2025-10-12 16:40:01,771:INFO:Importing libraries
2025-10-12 16:40:01,771:INFO:Copying training dataset
2025-10-12 16:40:01,774:INFO:Defining folds
2025-10-12 16:40:01,774:INFO:Declaring metric variables
2025-10-12 16:40:01,778:INFO:Importing untrained model
2025-10-12 16:40:01,781:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:40:01,787:INFO:Starting cross validation
2025-10-12 16:40:01,788:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:02,028:INFO:Calculating mean and std
2025-10-12 16:40:02,029:INFO:Creating metrics dataframe
2025-10-12 16:40:02,031:INFO:Uploading results into container
2025-10-12 16:40:02,032:INFO:Uploading model into container now
2025-10-12 16:40:02,033:INFO:_master_model_container: 10
2025-10-12 16:40:02,033:INFO:_display_container: 2
2025-10-12 16:40:02,033:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5705, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:40:02,034:INFO:create_model() successfully completed......................................
2025-10-12 16:40:02,154:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:02,155:INFO:Creating metrics dataframe
2025-10-12 16:40:02,161:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:40:02,161:INFO:Total runtime is 0.27617147763570155 minutes
2025-10-12 16:40:02,164:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:02,164:INFO:Initializing create_model()
2025-10-12 16:40:02,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:02,166:INFO:Checking exceptions
2025-10-12 16:40:02,166:INFO:Importing libraries
2025-10-12 16:40:02,166:INFO:Copying training dataset
2025-10-12 16:40:02,168:INFO:Defining folds
2025-10-12 16:40:02,168:INFO:Declaring metric variables
2025-10-12 16:40:02,172:INFO:Importing untrained model
2025-10-12 16:40:02,175:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:40:02,181:INFO:Starting cross validation
2025-10-12 16:40:02,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:02,243:INFO:Calculating mean and std
2025-10-12 16:40:02,243:INFO:Creating metrics dataframe
2025-10-12 16:40:02,245:INFO:Uploading results into container
2025-10-12 16:40:02,245:INFO:Uploading model into container now
2025-10-12 16:40:02,246:INFO:_master_model_container: 11
2025-10-12 16:40:02,246:INFO:_display_container: 2
2025-10-12 16:40:02,246:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:40:02,246:INFO:create_model() successfully completed......................................
2025-10-12 16:40:02,367:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:02,367:INFO:Creating metrics dataframe
2025-10-12 16:40:02,374:INFO:Initializing Extra Trees Classifier
2025-10-12 16:40:02,374:INFO:Total runtime is 0.27972897291183474 minutes
2025-10-12 16:40:02,377:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:02,377:INFO:Initializing create_model()
2025-10-12 16:40:02,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:02,378:INFO:Checking exceptions
2025-10-12 16:40:02,378:INFO:Importing libraries
2025-10-12 16:40:02,378:INFO:Copying training dataset
2025-10-12 16:40:02,381:INFO:Defining folds
2025-10-12 16:40:02,381:INFO:Declaring metric variables
2025-10-12 16:40:02,385:INFO:Importing untrained model
2025-10-12 16:40:02,388:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:40:02,394:INFO:Starting cross validation
2025-10-12 16:40:02,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:02,739:INFO:Calculating mean and std
2025-10-12 16:40:02,740:INFO:Creating metrics dataframe
2025-10-12 16:40:02,742:INFO:Uploading results into container
2025-10-12 16:40:02,742:INFO:Uploading model into container now
2025-10-12 16:40:02,743:INFO:_master_model_container: 12
2025-10-12 16:40:02,743:INFO:_display_container: 2
2025-10-12 16:40:02,744:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5705, verbose=0,
                     warm_start=False)
2025-10-12 16:40:02,744:INFO:create_model() successfully completed......................................
2025-10-12 16:40:02,870:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:02,871:INFO:Creating metrics dataframe
2025-10-12 16:40:02,877:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:40:02,877:INFO:Total runtime is 0.28811238209406537 minutes
2025-10-12 16:40:02,881:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:02,881:INFO:Initializing create_model()
2025-10-12 16:40:02,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:02,881:INFO:Checking exceptions
2025-10-12 16:40:02,881:INFO:Importing libraries
2025-10-12 16:40:02,881:INFO:Copying training dataset
2025-10-12 16:40:02,884:INFO:Defining folds
2025-10-12 16:40:02,884:INFO:Declaring metric variables
2025-10-12 16:40:02,888:INFO:Importing untrained model
2025-10-12 16:40:02,891:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:40:02,896:INFO:Starting cross validation
2025-10-12 16:40:02,897:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:03,558:INFO:Calculating mean and std
2025-10-12 16:40:03,560:INFO:Creating metrics dataframe
2025-10-12 16:40:03,561:INFO:Uploading results into container
2025-10-12 16:40:03,562:INFO:Uploading model into container now
2025-10-12 16:40:03,562:INFO:_master_model_container: 13
2025-10-12 16:40:03,562:INFO:_display_container: 2
2025-10-12 16:40:03,563:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:40:03,563:INFO:create_model() successfully completed......................................
2025-10-12 16:40:03,700:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:03,701:INFO:Creating metrics dataframe
2025-10-12 16:40:03,707:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:40:03,707:INFO:Total runtime is 0.3019397219022115 minutes
2025-10-12 16:40:03,710:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:03,711:INFO:Initializing create_model()
2025-10-12 16:40:03,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:03,711:INFO:Checking exceptions
2025-10-12 16:40:03,711:INFO:Importing libraries
2025-10-12 16:40:03,711:INFO:Copying training dataset
2025-10-12 16:40:03,714:INFO:Defining folds
2025-10-12 16:40:03,714:INFO:Declaring metric variables
2025-10-12 16:40:03,717:INFO:Importing untrained model
2025-10-12 16:40:03,721:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:40:03,726:INFO:Starting cross validation
2025-10-12 16:40:03,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:04,654:INFO:Calculating mean and std
2025-10-12 16:40:04,657:INFO:Creating metrics dataframe
2025-10-12 16:40:04,661:INFO:Uploading results into container
2025-10-12 16:40:04,661:INFO:Uploading model into container now
2025-10-12 16:40:04,662:INFO:_master_model_container: 14
2025-10-12 16:40:04,662:INFO:_display_container: 2
2025-10-12 16:40:04,662:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5705, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:40:04,664:INFO:create_model() successfully completed......................................
2025-10-12 16:40:04,827:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:04,827:INFO:Creating metrics dataframe
2025-10-12 16:40:04,835:INFO:Initializing CatBoost Classifier
2025-10-12 16:40:04,835:INFO:Total runtime is 0.32074435949325564 minutes
2025-10-12 16:40:04,839:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:04,839:INFO:Initializing create_model()
2025-10-12 16:40:04,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:04,840:INFO:Checking exceptions
2025-10-12 16:40:04,840:INFO:Importing libraries
2025-10-12 16:40:04,840:INFO:Copying training dataset
2025-10-12 16:40:04,844:INFO:Defining folds
2025-10-12 16:40:04,844:INFO:Declaring metric variables
2025-10-12 16:40:04,847:INFO:Importing untrained model
2025-10-12 16:40:04,849:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:40:04,856:INFO:Starting cross validation
2025-10-12 16:40:04,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:10,305:INFO:Calculating mean and std
2025-10-12 16:40:10,307:INFO:Creating metrics dataframe
2025-10-12 16:40:10,309:INFO:Uploading results into container
2025-10-12 16:40:10,309:INFO:Uploading model into container now
2025-10-12 16:40:10,311:INFO:_master_model_container: 15
2025-10-12 16:40:10,311:INFO:_display_container: 2
2025-10-12 16:40:10,311:INFO:<catboost.core.CatBoostClassifier object at 0x00000168466C99A0>
2025-10-12 16:40:10,311:INFO:create_model() successfully completed......................................
2025-10-12 16:40:10,505:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:10,505:INFO:Creating metrics dataframe
2025-10-12 16:40:10,514:INFO:Initializing Dummy Classifier
2025-10-12 16:40:10,514:INFO:Total runtime is 0.41538322369257613 minutes
2025-10-12 16:40:10,517:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:10,517:INFO:Initializing create_model()
2025-10-12 16:40:10,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016846654EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:10,517:INFO:Checking exceptions
2025-10-12 16:40:10,517:INFO:Importing libraries
2025-10-12 16:40:10,517:INFO:Copying training dataset
2025-10-12 16:40:10,522:INFO:Defining folds
2025-10-12 16:40:10,522:INFO:Declaring metric variables
2025-10-12 16:40:10,526:INFO:Importing untrained model
2025-10-12 16:40:10,530:INFO:Dummy Classifier Imported successfully
2025-10-12 16:40:10,537:INFO:Starting cross validation
2025-10-12 16:40:10,538:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:10,570:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:40:10,575:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:40:10,577:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:40:10,578:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:40:10,583:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:40:10,584:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:40:10,584:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:40:10,589:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:40:10,592:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:40:10,594:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:40:10,613:INFO:Calculating mean and std
2025-10-12 16:40:10,613:INFO:Creating metrics dataframe
2025-10-12 16:40:10,616:INFO:Uploading results into container
2025-10-12 16:40:10,616:INFO:Uploading model into container now
2025-10-12 16:40:10,617:INFO:_master_model_container: 16
2025-10-12 16:40:10,617:INFO:_display_container: 2
2025-10-12 16:40:10,617:INFO:DummyClassifier(constant=None, random_state=5705, strategy='prior')
2025-10-12 16:40:10,617:INFO:create_model() successfully completed......................................
2025-10-12 16:40:10,757:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:10,757:INFO:Creating metrics dataframe
2025-10-12 16:40:10,767:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:40:10,777:INFO:Initializing create_model()
2025-10-12 16:40:10,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466C99A0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:10,777:INFO:Checking exceptions
2025-10-12 16:40:10,778:INFO:Importing libraries
2025-10-12 16:40:10,778:INFO:Copying training dataset
2025-10-12 16:40:10,781:INFO:Defining folds
2025-10-12 16:40:10,781:INFO:Declaring metric variables
2025-10-12 16:40:10,781:INFO:Importing untrained model
2025-10-12 16:40:10,781:INFO:Declaring custom model
2025-10-12 16:40:10,783:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:40:10,783:INFO:Cross validation set to False
2025-10-12 16:40:10,783:INFO:Fitting Model
2025-10-12 16:40:12,474:INFO:<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>
2025-10-12 16:40:12,474:INFO:create_model() successfully completed......................................
2025-10-12 16:40:12,627:INFO:Creating Dashboard logs
2025-10-12 16:40:12,631:INFO:Model: CatBoost Classifier
2025-10-12 16:40:12,723:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'Logloss', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 5705, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.007650000043213368, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 10, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2025-10-12 16:40:13,110:INFO:Initializing predict_model()
2025-10-12 16:40:13,110:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001684666D280>)
2025-10-12 16:40:13,110:INFO:Checking exceptions
2025-10-12 16:40:13,110:INFO:Preloading libraries
2025-10-12 16:40:13,294:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:40:13,294:INFO:Initializing plot_model()
2025-10-12 16:40:13,294:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpmrw26tfl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:40:13,294:INFO:Checking exceptions
2025-10-12 16:40:13,296:INFO:Preloading libraries
2025-10-12 16:40:13,298:INFO:Copying training dataset
2025-10-12 16:40:13,298:INFO:Plot type: auc
2025-10-12 16:40:13,342:INFO:Fitting Model
2025-10-12 16:40:13,343:INFO:Scoring test/hold-out set
2025-10-12 16:40:13,361:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpmrw26tfl\AUC.png'
2025-10-12 16:40:13,530:INFO:Visual Rendered Successfully
2025-10-12 16:40:13,684:INFO:plot_model() successfully completed......................................
2025-10-12 16:40:13,726:INFO:Initializing plot_model()
2025-10-12 16:40:13,726:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpmrw26tfl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:40:13,726:INFO:Checking exceptions
2025-10-12 16:40:13,729:INFO:Preloading libraries
2025-10-12 16:40:13,731:INFO:Copying training dataset
2025-10-12 16:40:13,731:INFO:Plot type: confusion_matrix
2025-10-12 16:40:13,774:INFO:Fitting Model
2025-10-12 16:40:13,775:INFO:Scoring test/hold-out set
2025-10-12 16:40:13,791:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpmrw26tfl\Confusion Matrix.png'
2025-10-12 16:40:13,875:INFO:Visual Rendered Successfully
2025-10-12 16:40:14,000:INFO:plot_model() successfully completed......................................
2025-10-12 16:40:14,017:INFO:Initializing plot_model()
2025-10-12 16:40:14,017:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpmrw26tfl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:40:14,017:INFO:Checking exceptions
2025-10-12 16:40:14,019:INFO:Preloading libraries
2025-10-12 16:40:14,021:INFO:Copying training dataset
2025-10-12 16:40:14,021:INFO:Plot type: feature
2025-10-12 16:40:14,021:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:40:14,050:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpmrw26tfl\Feature Importance.png'
2025-10-12 16:40:14,155:INFO:Visual Rendered Successfully
2025-10-12 16:40:14,291:INFO:plot_model() successfully completed......................................
2025-10-12 16:40:14,308:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:40:14,538:INFO:Creating Dashboard logs
2025-10-12 16:40:14,542:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:40:14,624:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 5705, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:40:15,081:INFO:Creating Dashboard logs
2025-10-12 16:40:15,084:INFO:Model: Ada Boost Classifier
2025-10-12 16:40:15,168:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 5705}
2025-10-12 16:40:15,615:INFO:Creating Dashboard logs
2025-10-12 16:40:15,618:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 16:40:15,709:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:40:16,162:INFO:Creating Dashboard logs
2025-10-12 16:40:16,165:INFO:Model: Ridge Classifier
2025-10-12 16:40:16,242:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 5705, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:40:16,743:INFO:Creating Dashboard logs
2025-10-12 16:40:16,746:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:40:16,821:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:40:17,263:INFO:Creating Dashboard logs
2025-10-12 16:40:17,266:INFO:Model: Logistic Regression
2025-10-12 16:40:17,348:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 5705, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:40:17,823:INFO:Creating Dashboard logs
2025-10-12 16:40:17,826:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:40:17,907:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 5705, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:40:18,405:INFO:Creating Dashboard logs
2025-10-12 16:40:18,408:INFO:Model: Random Forest Classifier
2025-10-12 16:40:18,482:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5705, 'verbose': 0, 'warm_start': False}
2025-10-12 16:40:18,940:INFO:Creating Dashboard logs
2025-10-12 16:40:18,943:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:40:19,041:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5705, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:40:19,522:INFO:Creating Dashboard logs
2025-10-12 16:40:19,525:INFO:Model: Extra Trees Classifier
2025-10-12 16:40:19,604:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5705, 'verbose': 0, 'warm_start': False}
2025-10-12 16:40:20,068:INFO:Creating Dashboard logs
2025-10-12 16:40:20,072:INFO:Model: Naive Bayes
2025-10-12 16:40:20,149:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:40:20,631:INFO:Creating Dashboard logs
2025-10-12 16:40:20,634:INFO:Model: Decision Tree Classifier
2025-10-12 16:40:20,708:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 5705, 'splitter': 'best'}
2025-10-12 16:40:21,176:INFO:Creating Dashboard logs
2025-10-12 16:40:21,180:INFO:Model: K Neighbors Classifier
2025-10-12 16:40:21,258:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:40:21,706:INFO:Creating Dashboard logs
2025-10-12 16:40:21,709:INFO:Model: SVM - Linear Kernel
2025-10-12 16:40:21,786:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 5705, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:40:22,242:INFO:Creating Dashboard logs
2025-10-12 16:40:22,245:INFO:Model: Dummy Classifier
2025-10-12 16:40:22,325:INFO:Logged params: {'constant': None, 'random_state': 5705, 'strategy': 'prior'}
2025-10-12 16:40:22,727:INFO:_master_model_container: 16
2025-10-12 16:40:22,727:INFO:_display_container: 2
2025-10-12 16:40:22,727:INFO:<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>
2025-10-12 16:40:22,727:INFO:compare_models() successfully completed......................................
2025-10-12 16:40:22,742:INFO:Initializing finalize_model()
2025-10-12 16:40:22,744:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-12 16:40:22,744:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x00000168466CAB50>
2025-10-12 16:40:22,746:INFO:Initializing create_model()
2025-10-12 16:40:22,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:22,746:INFO:Checking exceptions
2025-10-12 16:40:22,747:INFO:Importing libraries
2025-10-12 16:40:22,747:INFO:Copying training dataset
2025-10-12 16:40:22,749:INFO:Defining folds
2025-10-12 16:40:22,749:INFO:Declaring metric variables
2025-10-12 16:40:22,749:INFO:Importing untrained model
2025-10-12 16:40:22,749:INFO:Declaring custom model
2025-10-12 16:40:22,750:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:40:22,750:INFO:Cross validation set to False
2025-10-12 16:40:22,750:INFO:Fitting Model
2025-10-12 16:40:24,610:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x00000168466C1D90>)],
         verbose=False)
2025-10-12 16:40:24,610:INFO:create_model() successfully completed......................................
2025-10-12 16:40:24,743:INFO:Creating Dashboard logs
2025-10-12 16:40:24,744:INFO:Model: CatBoost Classifier
2025-10-12 16:40:24,832:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'Logloss', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 5705, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.00891099963337183, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 10, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2025-10-12 16:40:25,040:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:40:25,042:INFO:Initializing plot_model()
2025-10-12 16:40:25,043:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x00000168466C1D90>)],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpjl7674x4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:40:25,043:INFO:Checking exceptions
2025-10-12 16:40:25,044:INFO:Preloading libraries
2025-10-12 16:40:25,046:INFO:Copying training dataset
2025-10-12 16:40:25,046:INFO:Plot type: auc
2025-10-12 16:40:25,098:INFO:Fitting Model
2025-10-12 16:40:25,099:INFO:Scoring test/hold-out set
2025-10-12 16:40:25,116:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpjl7674x4\AUC.png'
2025-10-12 16:40:25,286:INFO:Visual Rendered Successfully
2025-10-12 16:40:25,416:INFO:plot_model() successfully completed......................................
2025-10-12 16:40:25,449:INFO:Initializing plot_model()
2025-10-12 16:40:25,449:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x00000168466C1D90>)],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpjl7674x4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:40:25,449:INFO:Checking exceptions
2025-10-12 16:40:25,451:INFO:Preloading libraries
2025-10-12 16:40:25,453:INFO:Copying training dataset
2025-10-12 16:40:25,453:INFO:Plot type: confusion_matrix
2025-10-12 16:40:25,500:INFO:Fitting Model
2025-10-12 16:40:25,501:INFO:Scoring test/hold-out set
2025-10-12 16:40:25,514:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpjl7674x4\Confusion Matrix.png'
2025-10-12 16:40:25,607:INFO:Visual Rendered Successfully
2025-10-12 16:40:25,740:INFO:plot_model() successfully completed......................................
2025-10-12 16:40:25,760:INFO:Initializing plot_model()
2025-10-12 16:40:25,761:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x00000168466C1D90>)],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpjl7674x4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:40:25,761:INFO:Checking exceptions
2025-10-12 16:40:25,762:INFO:Preloading libraries
2025-10-12 16:40:25,764:INFO:Copying training dataset
2025-10-12 16:40:25,764:INFO:Plot type: feature
2025-10-12 16:40:25,765:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:40:25,796:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpjl7674x4\Feature Importance.png'
2025-10-12 16:40:25,924:INFO:Visual Rendered Successfully
2025-10-12 16:40:26,053:INFO:plot_model() successfully completed......................................
2025-10-12 16:40:26,068:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:40:26,296:INFO:_master_model_container: 16
2025-10-12 16:40:26,296:INFO:_display_container: 2
2025-10-12 16:40:26,298:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x00000168466C1D90>)],
         verbose=False)
2025-10-12 16:40:26,299:INFO:finalize_model() successfully completed......................................
2025-10-12 16:40:26,440:INFO:Initializing save_model()
2025-10-12 16:40:26,440:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x00000168466C1D90>)],
         verbose=False), model_name=Titanic_modelV1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\david\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-12 16:40:26,441:INFO:Adding model into prep_pipe
2025-10-12 16:40:26,441:WARNING:Only Model saved as it was a pipeline.
2025-10-12 16:40:26,444:INFO:Titanic_modelV1.pkl saved in current working directory
2025-10-12 16:40:26,446:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'Parch',
                                             'Fare', 'SibSp', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x00000168466C1D90>)],
         verbose=False)
2025-10-12 16:40:26,446:INFO:save_model() successfully completed......................................
2025-10-12 16:40:26,610:INFO:Initializing tune_model()
2025-10-12 16:40:26,610:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>)
2025-10-12 16:40:26,610:INFO:Checking exceptions
2025-10-12 16:40:26,625:INFO:Copying training dataset
2025-10-12 16:40:26,628:INFO:Checking base model
2025-10-12 16:40:26,628:INFO:Base model : CatBoost Classifier
2025-10-12 16:40:26,633:INFO:Declaring metric variables
2025-10-12 16:40:26,636:INFO:Defining Hyperparameters
2025-10-12 16:40:26,769:INFO:Tuning with n_jobs=-1
2025-10-12 16:40:26,770:INFO:Initializing RandomizedSearchCV
2025-10-12 16:40:31,917:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
20 fits failed out of a total of 100.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
20 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 5245, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 2395, in _fit
    train_params = self._prepare_train_params(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\catboost\core.py", line 2321, in _prepare_train_params
    _check_train_params(params)
  File "_catboost.pyx", line 6601, in _catboost._check_train_params
  File "_catboost.pyx", line 6623, in _catboost._check_train_params
_catboost.CatBoostError: catboost/private/libs/options/boosting_options.cpp:79: Learning rate should be non-zero


2025-10-12 16:40:31,918:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\model_selection\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.87471477 0.86954584 0.87303141        nan 0.85507385        nan
 0.76284663 0.85594808 0.86597142 0.86766638]

2025-10-12 16:40:31,919:INFO:best_params: {'actual_estimator__random_strength': 0.4, 'actual_estimator__n_estimators': 110, 'actual_estimator__l2_leaf_reg': 8, 'actual_estimator__eta': 0.2, 'actual_estimator__depth': 5}
2025-10-12 16:40:31,919:INFO:Hyperparameter search completed
2025-10-12 16:40:31,919:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:31,920:INFO:Initializing create_model()
2025-10-12 16:40:31,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=<catboost.core.CatBoostClassifier object at 0x0000016846724970>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016854C126A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.4, 'n_estimators': 110, 'l2_leaf_reg': 8, 'eta': 0.2, 'depth': 5})
2025-10-12 16:40:31,920:INFO:Checking exceptions
2025-10-12 16:40:31,920:INFO:Importing libraries
2025-10-12 16:40:31,920:INFO:Copying training dataset
2025-10-12 16:40:31,923:INFO:Defining folds
2025-10-12 16:40:31,923:INFO:Declaring metric variables
2025-10-12 16:40:31,926:INFO:Importing untrained model
2025-10-12 16:40:31,926:INFO:Declaring custom model
2025-10-12 16:40:31,930:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:40:31,937:INFO:Starting cross validation
2025-10-12 16:40:31,938:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:32,349:INFO:Calculating mean and std
2025-10-12 16:40:32,350:INFO:Creating metrics dataframe
2025-10-12 16:40:32,355:INFO:Finalizing model
2025-10-12 16:40:32,500:INFO:Uploading results into container
2025-10-12 16:40:32,501:INFO:Uploading model into container now
2025-10-12 16:40:32,501:INFO:_master_model_container: 17
2025-10-12 16:40:32,501:INFO:_display_container: 3
2025-10-12 16:40:32,501:INFO:<catboost.core.CatBoostClassifier object at 0x00000168463BDF10>
2025-10-12 16:40:32,501:INFO:create_model() successfully completed......................................
2025-10-12 16:40:32,637:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:32,637:INFO:choose_better activated
2025-10-12 16:40:32,640:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:32,641:INFO:Initializing create_model()
2025-10-12 16:40:32,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:32,641:INFO:Checking exceptions
2025-10-12 16:40:32,643:INFO:Importing libraries
2025-10-12 16:40:32,643:INFO:Copying training dataset
2025-10-12 16:40:32,646:INFO:Defining folds
2025-10-12 16:40:32,646:INFO:Declaring metric variables
2025-10-12 16:40:32,646:INFO:Importing untrained model
2025-10-12 16:40:32,646:INFO:Declaring custom model
2025-10-12 16:40:32,646:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:40:32,646:INFO:Starting cross validation
2025-10-12 16:40:32,646:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:36,962:INFO:Calculating mean and std
2025-10-12 16:40:36,963:INFO:Creating metrics dataframe
2025-10-12 16:40:36,964:INFO:Finalizing model
2025-10-12 16:40:38,545:INFO:Uploading results into container
2025-10-12 16:40:38,545:INFO:Uploading model into container now
2025-10-12 16:40:38,545:INFO:_master_model_container: 18
2025-10-12 16:40:38,546:INFO:_display_container: 4
2025-10-12 16:40:38,546:INFO:<catboost.core.CatBoostClassifier object at 0x0000016846694B50>
2025-10-12 16:40:38,546:INFO:create_model() successfully completed......................................
2025-10-12 16:40:38,664:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:38,664:INFO:<catboost.core.CatBoostClassifier object at 0x0000016846694B50> result for AUC is 0.8703
2025-10-12 16:40:38,664:INFO:<catboost.core.CatBoostClassifier object at 0x00000168463BDF10> result for AUC is 0.8747
2025-10-12 16:40:38,664:INFO:<catboost.core.CatBoostClassifier object at 0x00000168463BDF10> is best model
2025-10-12 16:40:38,664:INFO:choose_better completed
2025-10-12 16:40:38,664:INFO:Creating Dashboard logs
2025-10-12 16:40:38,667:INFO:Model: CatBoost Classifier
2025-10-12 16:40:38,740:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'Logloss', 'iterations': 110, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 8, 'random_strength': 0.4000000059604645, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 5705, 'depth': 5, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.20000000298023224, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'MVS', 'max_leaves': 32}
2025-10-12 16:40:39,092:INFO:Initializing predict_model()
2025-10-12 16:40:39,092:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168463BDF10>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001684676E670>)
2025-10-12 16:40:39,093:INFO:Checking exceptions
2025-10-12 16:40:39,093:INFO:Preloading libraries
2025-10-12 16:40:39,266:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:40:39,266:INFO:Initializing plot_model()
2025-10-12 16:40:39,266:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168463BDF10>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpxmsu5f7c, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:40:39,266:INFO:Checking exceptions
2025-10-12 16:40:39,267:INFO:Preloading libraries
2025-10-12 16:40:39,268:INFO:Copying training dataset
2025-10-12 16:40:39,268:INFO:Plot type: auc
2025-10-12 16:40:39,312:INFO:Fitting Model
2025-10-12 16:40:39,313:INFO:Scoring test/hold-out set
2025-10-12 16:40:39,328:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpxmsu5f7c\AUC.png'
2025-10-12 16:40:39,486:INFO:Visual Rendered Successfully
2025-10-12 16:40:39,608:INFO:plot_model() successfully completed......................................
2025-10-12 16:40:39,621:INFO:Initializing plot_model()
2025-10-12 16:40:39,621:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168463BDF10>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpxmsu5f7c, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:40:39,621:INFO:Checking exceptions
2025-10-12 16:40:39,623:INFO:Preloading libraries
2025-10-12 16:40:39,623:INFO:Copying training dataset
2025-10-12 16:40:39,623:INFO:Plot type: confusion_matrix
2025-10-12 16:40:39,668:INFO:Fitting Model
2025-10-12 16:40:39,668:INFO:Scoring test/hold-out set
2025-10-12 16:40:39,682:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpxmsu5f7c\Confusion Matrix.png'
2025-10-12 16:40:39,763:INFO:Visual Rendered Successfully
2025-10-12 16:40:39,884:INFO:plot_model() successfully completed......................................
2025-10-12 16:40:39,901:INFO:Initializing plot_model()
2025-10-12 16:40:39,901:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168463BDF10>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpxmsu5f7c, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:40:39,901:INFO:Checking exceptions
2025-10-12 16:40:39,902:INFO:Preloading libraries
2025-10-12 16:40:39,902:INFO:Copying training dataset
2025-10-12 16:40:39,902:INFO:Plot type: feature
2025-10-12 16:40:39,903:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:40:39,930:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpxmsu5f7c\Feature Importance.png'
2025-10-12 16:40:40,026:INFO:Visual Rendered Successfully
2025-10-12 16:40:40,150:INFO:plot_model() successfully completed......................................
2025-10-12 16:40:40,163:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:40:40,407:INFO:_master_model_container: 18
2025-10-12 16:40:40,407:INFO:_display_container: 3
2025-10-12 16:40:40,407:INFO:<catboost.core.CatBoostClassifier object at 0x00000168463BDF10>
2025-10-12 16:40:40,407:INFO:tune_model() successfully completed......................................
2025-10-12 16:40:40,555:INFO:Initializing tune_model()
2025-10-12 16:40:40,555:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>)
2025-10-12 16:40:40,555:INFO:Checking exceptions
2025-10-12 16:40:40,555:INFO:Soft dependency imported: optuna: 4.5.0
2025-10-12 16:40:40,572:INFO:Copying training dataset
2025-10-12 16:40:40,575:INFO:Checking base model
2025-10-12 16:40:40,576:INFO:Base model : CatBoost Classifier
2025-10-12 16:40:40,582:INFO:Declaring metric variables
2025-10-12 16:40:40,588:INFO:Defining Hyperparameters
2025-10-12 16:40:40,745:INFO:Tuning with n_jobs=-1
2025-10-12 16:40:40,745:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.

2025-10-12 16:40:40,746:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\optuna\_experimental.py:32: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.

2025-10-12 16:40:40,746:INFO:Initializing optuna.integration.OptunaSearchCV
2025-10-12 16:40:40,746:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.

2025-10-12 16:40:47,042:INFO:best_params: {'actual_estimator__eta': 0.1305834118241046, 'actual_estimator__depth': 3, 'actual_estimator__n_estimators': 166, 'actual_estimator__random_strength': 0.1429446489484807, 'actual_estimator__l2_leaf_reg': 115}
2025-10-12 16:40:47,044:INFO:Hyperparameter search completed
2025-10-12 16:40:47,044:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:47,044:INFO:Initializing create_model()
2025-10-12 16:40:47,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=<catboost.core.CatBoostClassifier object at 0x000001684663B820>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001684662FBB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'eta': 0.1305834118241046, 'depth': 3, 'n_estimators': 166, 'random_strength': 0.1429446489484807, 'l2_leaf_reg': 115})
2025-10-12 16:40:47,044:INFO:Checking exceptions
2025-10-12 16:40:47,044:INFO:Importing libraries
2025-10-12 16:40:47,045:INFO:Copying training dataset
2025-10-12 16:40:47,049:INFO:Defining folds
2025-10-12 16:40:47,049:INFO:Declaring metric variables
2025-10-12 16:40:47,052:INFO:Importing untrained model
2025-10-12 16:40:47,052:INFO:Declaring custom model
2025-10-12 16:40:47,055:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:40:47,061:INFO:Starting cross validation
2025-10-12 16:40:47,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:47,366:INFO:Calculating mean and std
2025-10-12 16:40:47,366:INFO:Creating metrics dataframe
2025-10-12 16:40:47,372:INFO:Finalizing model
2025-10-12 16:40:47,481:INFO:Uploading results into container
2025-10-12 16:40:47,482:INFO:Uploading model into container now
2025-10-12 16:40:47,482:INFO:_master_model_container: 19
2025-10-12 16:40:47,482:INFO:_display_container: 4
2025-10-12 16:40:47,482:INFO:<catboost.core.CatBoostClassifier object at 0x00000168463BD610>
2025-10-12 16:40:47,482:INFO:create_model() successfully completed......................................
2025-10-12 16:40:47,609:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:47,609:INFO:choose_better activated
2025-10-12 16:40:47,612:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:47,612:INFO:Initializing create_model()
2025-10-12 16:40:47,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:47,613:INFO:Checking exceptions
2025-10-12 16:40:47,614:INFO:Importing libraries
2025-10-12 16:40:47,614:INFO:Copying training dataset
2025-10-12 16:40:47,616:INFO:Defining folds
2025-10-12 16:40:47,616:INFO:Declaring metric variables
2025-10-12 16:40:47,616:INFO:Importing untrained model
2025-10-12 16:40:47,616:INFO:Declaring custom model
2025-10-12 16:40:47,617:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:40:47,617:INFO:Starting cross validation
2025-10-12 16:40:47,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:40:51,718:INFO:Calculating mean and std
2025-10-12 16:40:51,718:INFO:Creating metrics dataframe
2025-10-12 16:40:51,720:INFO:Finalizing model
2025-10-12 16:40:53,300:INFO:Uploading results into container
2025-10-12 16:40:53,301:INFO:Uploading model into container now
2025-10-12 16:40:53,301:INFO:_master_model_container: 20
2025-10-12 16:40:53,301:INFO:_display_container: 5
2025-10-12 16:40:53,301:INFO:<catboost.core.CatBoostClassifier object at 0x00000168463BDB50>
2025-10-12 16:40:53,301:INFO:create_model() successfully completed......................................
2025-10-12 16:40:53,420:INFO:SubProcess create_model() end ==================================
2025-10-12 16:40:53,420:INFO:<catboost.core.CatBoostClassifier object at 0x00000168463BDB50> result for AUC is 0.8703
2025-10-12 16:40:53,420:INFO:<catboost.core.CatBoostClassifier object at 0x00000168463BD610> result for AUC is 0.8748
2025-10-12 16:40:53,420:INFO:<catboost.core.CatBoostClassifier object at 0x00000168463BD610> is best model
2025-10-12 16:40:53,420:INFO:choose_better completed
2025-10-12 16:40:53,420:INFO:Creating Dashboard logs
2025-10-12 16:40:53,423:INFO:Model: CatBoost Classifier
2025-10-12 16:40:53,513:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'Logloss', 'iterations': 166, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 115, 'random_strength': 0.14294464886188507, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 5705, 'depth': 3, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.13058340549468994, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'MVS', 'max_leaves': 8}
2025-10-12 16:40:53,928:INFO:Initializing predict_model()
2025-10-12 16:40:53,928:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168463BD610>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016846702DC0>)
2025-10-12 16:40:53,928:INFO:Checking exceptions
2025-10-12 16:40:53,928:INFO:Preloading libraries
2025-10-12 16:40:54,103:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:40:54,104:INFO:Initializing plot_model()
2025-10-12 16:40:54,104:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168463BD610>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpja9pu1ox, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:40:54,104:INFO:Checking exceptions
2025-10-12 16:40:54,105:INFO:Preloading libraries
2025-10-12 16:40:54,106:INFO:Copying training dataset
2025-10-12 16:40:54,106:INFO:Plot type: auc
2025-10-12 16:40:54,148:INFO:Fitting Model
2025-10-12 16:40:54,149:INFO:Scoring test/hold-out set
2025-10-12 16:40:54,164:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpja9pu1ox\AUC.png'
2025-10-12 16:40:54,324:INFO:Visual Rendered Successfully
2025-10-12 16:40:54,449:INFO:plot_model() successfully completed......................................
2025-10-12 16:40:54,466:INFO:Initializing plot_model()
2025-10-12 16:40:54,466:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168463BD610>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpja9pu1ox, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:40:54,466:INFO:Checking exceptions
2025-10-12 16:40:54,469:INFO:Preloading libraries
2025-10-12 16:40:54,470:INFO:Copying training dataset
2025-10-12 16:40:54,471:INFO:Plot type: confusion_matrix
2025-10-12 16:40:54,538:INFO:Fitting Model
2025-10-12 16:40:54,539:INFO:Scoring test/hold-out set
2025-10-12 16:40:54,552:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpja9pu1ox\Confusion Matrix.png'
2025-10-12 16:40:54,630:INFO:Visual Rendered Successfully
2025-10-12 16:40:54,751:INFO:plot_model() successfully completed......................................
2025-10-12 16:40:54,771:INFO:Initializing plot_model()
2025-10-12 16:40:54,771:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000168463BD610>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpja9pu1ox, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:40:54,771:INFO:Checking exceptions
2025-10-12 16:40:54,772:INFO:Preloading libraries
2025-10-12 16:40:54,773:INFO:Copying training dataset
2025-10-12 16:40:54,773:INFO:Plot type: feature
2025-10-12 16:40:54,773:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:40:54,796:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpja9pu1ox\Feature Importance.png'
2025-10-12 16:40:54,888:INFO:Visual Rendered Successfully
2025-10-12 16:40:55,008:INFO:plot_model() successfully completed......................................
2025-10-12 16:40:55,023:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:40:55,258:INFO:_master_model_container: 20
2025-10-12 16:40:55,258:INFO:_display_container: 4
2025-10-12 16:40:55,258:INFO:<catboost.core.CatBoostClassifier object at 0x00000168463BD610>
2025-10-12 16:40:55,258:INFO:tune_model() successfully completed......................................
2025-10-12 16:40:55,392:INFO:Initializing ensemble_model()
2025-10-12 16:40:55,392:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>, method=Bagging, fold=None, n_estimators=5, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:40:55,392:INFO:Checking exceptions
2025-10-12 16:40:55,404:INFO:Importing libraries
2025-10-12 16:40:55,404:INFO:Copying training dataset
2025-10-12 16:40:55,404:INFO:Checking base model
2025-10-12 16:40:55,405:INFO:Base model : CatBoost Classifier
2025-10-12 16:40:55,411:INFO:Importing untrained ensembler
2025-10-12 16:40:55,411:INFO:Ensemble method set to Bagging
2025-10-12 16:40:55,411:INFO:SubProcess create_model() called ==================================
2025-10-12 16:40:55,411:INFO:Initializing create_model()
2025-10-12 16:40:55,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5705, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016854AB7AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:40:55,411:INFO:Checking exceptions
2025-10-12 16:40:55,411:INFO:Importing libraries
2025-10-12 16:40:55,411:INFO:Copying training dataset
2025-10-12 16:40:55,414:INFO:Defining folds
2025-10-12 16:40:55,414:INFO:Declaring metric variables
2025-10-12 16:40:55,417:INFO:Importing untrained model
2025-10-12 16:40:55,417:INFO:Declaring custom model
2025-10-12 16:40:55,421:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:40:55,425:INFO:Starting cross validation
2025-10-12 16:40:55,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:14,122:INFO:Calculating mean and std
2025-10-12 16:41:14,123:INFO:Creating metrics dataframe
2025-10-12 16:41:14,128:INFO:Finalizing model
2025-10-12 16:41:21,928:INFO:Uploading results into container
2025-10-12 16:41:21,928:INFO:Uploading model into container now
2025-10-12 16:41:21,928:INFO:_master_model_container: 21
2025-10-12 16:41:21,928:INFO:_display_container: 5
2025-10-12 16:41:21,928:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854BDE7F0>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5705, verbose=0,
                  warm_start=False)
2025-10-12 16:41:21,930:INFO:create_model() successfully completed......................................
2025-10-12 16:41:22,050:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:22,051:INFO:Creating Dashboard logs
2025-10-12 16:41:22,053:INFO:Model: CatBoost Classifier
2025-10-12 16:41:22,138:INFO:Logged params: {'bootstrap': True, 'bootstrap_features': False, 'estimator__border_count': 254, 'estimator__verbose': False, 'estimator__task_type': 'CPU', 'estimator__random_state': 5705, 'estimator': <catboost.core.CatBoostClassifier object at 0x0000016854BDE7F0>, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 5, 'n_jobs': None, 'oob_score': False, 'random_state': 5705, 'verbose': 0, 'warm_start': False}
2025-10-12 16:41:22,404:INFO:Initializing predict_model()
2025-10-12 16:41:22,404:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854BDE7F0>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5705, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000168467025E0>)
2025-10-12 16:41:22,405:INFO:Checking exceptions
2025-10-12 16:41:22,405:INFO:Preloading libraries
2025-10-12 16:41:22,574:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:41:22,575:INFO:Initializing plot_model()
2025-10-12 16:41:22,575:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854BDE7F0>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5705, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpfv9d713s, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:22,575:INFO:Checking exceptions
2025-10-12 16:41:22,575:INFO:Preloading libraries
2025-10-12 16:41:22,584:INFO:Copying training dataset
2025-10-12 16:41:22,584:INFO:Plot type: auc
2025-10-12 16:41:22,628:INFO:Fitting Model
2025-10-12 16:41:22,629:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 16:41:22,629:INFO:Scoring test/hold-out set
2025-10-12 16:41:22,652:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpfv9d713s\AUC.png'
2025-10-12 16:41:22,801:INFO:Visual Rendered Successfully
2025-10-12 16:41:22,920:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:22,937:INFO:Initializing plot_model()
2025-10-12 16:41:22,937:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854BDE7F0>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5705, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpfv9d713s, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:22,937:INFO:Checking exceptions
2025-10-12 16:41:22,939:INFO:Preloading libraries
2025-10-12 16:41:22,945:INFO:Copying training dataset
2025-10-12 16:41:22,945:INFO:Plot type: confusion_matrix
2025-10-12 16:41:22,987:INFO:Fitting Model
2025-10-12 16:41:22,987:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names

2025-10-12 16:41:22,988:INFO:Scoring test/hold-out set
2025-10-12 16:41:23,007:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpfv9d713s\Confusion Matrix.png'
2025-10-12 16:41:23,081:INFO:Visual Rendered Successfully
2025-10-12 16:41:23,199:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:23,215:INFO:Initializing plot_model()
2025-10-12 16:41:23,215:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854BDE7F0>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5705, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpfv9d713s, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:23,215:INFO:Checking exceptions
2025-10-12 16:41:23,216:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 16:41:23,216:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:41:23,427:INFO:_master_model_container: 21
2025-10-12 16:41:23,427:INFO:_display_container: 5
2025-10-12 16:41:23,428:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854BDE7F0>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5705, verbose=0,
                  warm_start=False)
2025-10-12 16:41:23,428:INFO:ensemble_model() successfully completed......................................
2025-10-12 16:41:23,544:INFO:Initializing predict_model()
2025-10-12 16:41:23,544:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000016854BDE7F0>,
                  max_features=1.0, max_samples=1.0, n_estimators=5,
                  n_jobs=None, oob_score=False, random_state=5705, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016846794C10>)
2025-10-12 16:41:23,544:INFO:Checking exceptions
2025-10-12 16:41:23,544:INFO:Preloading libraries
2025-10-12 16:41:23,720:INFO:Initializing create_model()
2025-10-12 16:41:23,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:23,720:INFO:Checking exceptions
2025-10-12 16:41:23,736:INFO:Importing libraries
2025-10-12 16:41:23,737:INFO:Copying training dataset
2025-10-12 16:41:23,744:INFO:Defining folds
2025-10-12 16:41:23,744:INFO:Declaring metric variables
2025-10-12 16:41:23,747:INFO:Importing untrained model
2025-10-12 16:41:23,754:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:41:23,763:INFO:Starting cross validation
2025-10-12 16:41:23,764:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:23,835:INFO:Calculating mean and std
2025-10-12 16:41:23,835:INFO:Creating metrics dataframe
2025-10-12 16:41:23,839:INFO:Finalizing model
2025-10-12 16:41:23,846:INFO:Creating Dashboard logs
2025-10-12 16:41:23,848:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:41:23,923:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:41:24,153:INFO:Initializing predict_model()
2025-10-12 16:41:24,153:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001684676E790>)
2025-10-12 16:41:24,153:INFO:Checking exceptions
2025-10-12 16:41:24,153:INFO:Preloading libraries
2025-10-12 16:41:24,327:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:41:24,327:INFO:Initializing plot_model()
2025-10-12 16:41:24,327:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpg82faj7y, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:24,327:INFO:Checking exceptions
2025-10-12 16:41:24,328:INFO:Preloading libraries
2025-10-12 16:41:24,328:INFO:Copying training dataset
2025-10-12 16:41:24,328:INFO:Plot type: auc
2025-10-12 16:41:24,371:INFO:Fitting Model
2025-10-12 16:41:24,372:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:41:24,372:INFO:Scoring test/hold-out set
2025-10-12 16:41:24,387:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpg82faj7y\AUC.png'
2025-10-12 16:41:24,549:INFO:Visual Rendered Successfully
2025-10-12 16:41:24,668:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:24,689:INFO:Initializing plot_model()
2025-10-12 16:41:24,690:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpg82faj7y, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:24,690:INFO:Checking exceptions
2025-10-12 16:41:24,690:INFO:Preloading libraries
2025-10-12 16:41:24,691:INFO:Copying training dataset
2025-10-12 16:41:24,691:INFO:Plot type: confusion_matrix
2025-10-12 16:41:24,733:INFO:Fitting Model
2025-10-12 16:41:24,734:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names

2025-10-12 16:41:24,734:INFO:Scoring test/hold-out set
2025-10-12 16:41:24,748:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpg82faj7y\Confusion Matrix.png'
2025-10-12 16:41:24,826:INFO:Visual Rendered Successfully
2025-10-12 16:41:24,946:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:24,966:INFO:Initializing plot_model()
2025-10-12 16:41:24,966:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpg82faj7y, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:24,966:INFO:Checking exceptions
2025-10-12 16:41:24,967:INFO:Preloading libraries
2025-10-12 16:41:24,968:INFO:Copying training dataset
2025-10-12 16:41:24,968:INFO:Plot type: feature
2025-10-12 16:41:25,002:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpg82faj7y\Feature Importance.png'
2025-10-12 16:41:25,107:INFO:Visual Rendered Successfully
2025-10-12 16:41:25,236:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:25,258:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:41:25,463:INFO:Uploading results into container
2025-10-12 16:41:25,463:INFO:Uploading model into container now
2025-10-12 16:41:25,471:INFO:_master_model_container: 22
2025-10-12 16:41:25,471:INFO:_display_container: 7
2025-10-12 16:41:25,472:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:41:25,472:INFO:create_model() successfully completed......................................
2025-10-12 16:41:25,592:INFO:Initializing create_model()
2025-10-12 16:41:25,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=ridge, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:25,592:INFO:Checking exceptions
2025-10-12 16:41:25,603:INFO:Importing libraries
2025-10-12 16:41:25,603:INFO:Copying training dataset
2025-10-12 16:41:25,606:INFO:Defining folds
2025-10-12 16:41:25,606:INFO:Declaring metric variables
2025-10-12 16:41:25,609:INFO:Importing untrained model
2025-10-12 16:41:25,612:INFO:Ridge Classifier Imported successfully
2025-10-12 16:41:25,616:INFO:Starting cross validation
2025-10-12 16:41:25,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:25,684:INFO:Calculating mean and std
2025-10-12 16:41:25,684:INFO:Creating metrics dataframe
2025-10-12 16:41:25,688:INFO:Finalizing model
2025-10-12 16:41:25,694:INFO:Creating Dashboard logs
2025-10-12 16:41:25,697:INFO:Model: Ridge Classifier
2025-10-12 16:41:25,785:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 5705, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:41:26,026:INFO:Initializing predict_model()
2025-10-12 16:41:26,027:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5705, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001684676EB80>)
2025-10-12 16:41:26,027:INFO:Checking exceptions
2025-10-12 16:41:26,027:INFO:Preloading libraries
2025-10-12 16:41:26,199:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:41:26,200:INFO:Initializing plot_model()
2025-10-12 16:41:26,200:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5705, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpajtz1mjd, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:26,200:INFO:Checking exceptions
2025-10-12 16:41:26,200:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:41:26,200:INFO:Initializing plot_model()
2025-10-12 16:41:26,200:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5705, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpajtz1mjd, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:26,200:INFO:Checking exceptions
2025-10-12 16:41:26,201:INFO:Preloading libraries
2025-10-12 16:41:26,202:INFO:Copying training dataset
2025-10-12 16:41:26,202:INFO:Plot type: confusion_matrix
2025-10-12 16:41:26,244:INFO:Fitting Model
2025-10-12 16:41:26,244:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names

2025-10-12 16:41:26,244:INFO:Scoring test/hold-out set
2025-10-12 16:41:26,257:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpajtz1mjd\Confusion Matrix.png'
2025-10-12 16:41:26,335:INFO:Visual Rendered Successfully
2025-10-12 16:41:26,467:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:26,486:INFO:Initializing plot_model()
2025-10-12 16:41:26,486:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5705, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpajtz1mjd, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:26,486:INFO:Checking exceptions
2025-10-12 16:41:26,487:INFO:Preloading libraries
2025-10-12 16:41:26,487:INFO:Copying training dataset
2025-10-12 16:41:26,487:INFO:Plot type: feature
2025-10-12 16:41:26,528:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpajtz1mjd\Feature Importance.png'
2025-10-12 16:41:26,624:INFO:Visual Rendered Successfully
2025-10-12 16:41:26,760:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:26,776:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:41:26,997:INFO:Uploading results into container
2025-10-12 16:41:26,997:INFO:Uploading model into container now
2025-10-12 16:41:27,004:INFO:_master_model_container: 23
2025-10-12 16:41:27,005:INFO:_display_container: 8
2025-10-12 16:41:27,005:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5705, solver='auto',
                tol=0.0001)
2025-10-12 16:41:27,005:INFO:create_model() successfully completed......................................
2025-10-12 16:41:27,152:INFO:Initializing create_model()
2025-10-12 16:41:27,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:27,152:INFO:Checking exceptions
2025-10-12 16:41:27,164:INFO:Importing libraries
2025-10-12 16:41:27,164:INFO:Copying training dataset
2025-10-12 16:41:27,168:INFO:Defining folds
2025-10-12 16:41:27,168:INFO:Declaring metric variables
2025-10-12 16:41:27,172:INFO:Importing untrained model
2025-10-12 16:41:27,175:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:41:27,181:INFO:Starting cross validation
2025-10-12 16:41:27,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:27,411:INFO:Calculating mean and std
2025-10-12 16:41:27,411:INFO:Creating metrics dataframe
2025-10-12 16:41:27,415:INFO:Finalizing model
2025-10-12 16:41:27,501:INFO:Creating Dashboard logs
2025-10-12 16:41:27,504:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:41:27,580:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 5705, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:41:27,852:INFO:Initializing predict_model()
2025-10-12 16:41:27,852:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5705, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001684676EB80>)
2025-10-12 16:41:27,852:INFO:Checking exceptions
2025-10-12 16:41:27,852:INFO:Preloading libraries
2025-10-12 16:41:28,034:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:41:28,034:INFO:Initializing plot_model()
2025-10-12 16:41:28,034:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5705, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmptrgyvxop, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:28,034:INFO:Checking exceptions
2025-10-12 16:41:28,035:INFO:Preloading libraries
2025-10-12 16:41:28,041:INFO:Copying training dataset
2025-10-12 16:41:28,041:INFO:Plot type: auc
2025-10-12 16:41:28,086:INFO:Fitting Model
2025-10-12 16:41:28,087:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:41:28,087:INFO:Scoring test/hold-out set
2025-10-12 16:41:28,104:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmptrgyvxop\AUC.png'
2025-10-12 16:41:28,275:INFO:Visual Rendered Successfully
2025-10-12 16:41:28,401:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:28,418:INFO:Initializing plot_model()
2025-10-12 16:41:28,418:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5705, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmptrgyvxop, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:28,418:INFO:Checking exceptions
2025-10-12 16:41:28,419:INFO:Preloading libraries
2025-10-12 16:41:28,423:INFO:Copying training dataset
2025-10-12 16:41:28,423:INFO:Plot type: confusion_matrix
2025-10-12 16:41:28,468:INFO:Fitting Model
2025-10-12 16:41:28,468:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names

2025-10-12 16:41:28,468:INFO:Scoring test/hold-out set
2025-10-12 16:41:28,482:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmptrgyvxop\Confusion Matrix.png'
2025-10-12 16:41:28,577:INFO:Visual Rendered Successfully
2025-10-12 16:41:28,702:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:28,720:INFO:Initializing plot_model()
2025-10-12 16:41:28,720:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5705, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmptrgyvxop, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:28,720:INFO:Checking exceptions
2025-10-12 16:41:28,722:INFO:Preloading libraries
2025-10-12 16:41:28,726:INFO:Copying training dataset
2025-10-12 16:41:28,726:INFO:Plot type: feature
2025-10-12 16:41:28,727:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:41:28,750:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmptrgyvxop\Feature Importance.png'
2025-10-12 16:41:28,847:INFO:Visual Rendered Successfully
2025-10-12 16:41:28,977:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:28,993:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:41:29,202:INFO:Uploading results into container
2025-10-12 16:41:29,203:INFO:Uploading model into container now
2025-10-12 16:41:29,210:INFO:_master_model_container: 24
2025-10-12 16:41:29,210:INFO:_display_container: 9
2025-10-12 16:41:29,211:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5705, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:41:29,211:INFO:create_model() successfully completed......................................
2025-10-12 16:41:29,339:INFO:Initializing blend_models()
2025-10-12 16:41:29,339:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x00000168466CAB50>, LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5705, solver='auto',
                tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5705, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-12 16:41:29,339:INFO:Checking exceptions
2025-10-12 16:41:29,339:INFO:Estimator RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5705, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-12 16:41:29,353:INFO:Importing libraries
2025-10-12 16:41:29,353:INFO:Copying training dataset
2025-10-12 16:41:29,357:INFO:Getting model names
2025-10-12 16:41:29,361:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:29,364:INFO:Initializing create_model()
2025-10-12 16:41:29,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000168466CAB50>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5705,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016854CC11C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:29,364:INFO:Checking exceptions
2025-10-12 16:41:29,364:INFO:Importing libraries
2025-10-12 16:41:29,364:INFO:Copying training dataset
2025-10-12 16:41:29,368:INFO:Defining folds
2025-10-12 16:41:29,368:INFO:Declaring metric variables
2025-10-12 16:41:29,372:INFO:Importing untrained model
2025-10-12 16:41:29,372:INFO:Declaring custom model
2025-10-12 16:41:29,376:INFO:Voting Classifier Imported successfully
2025-10-12 16:41:29,382:INFO:Starting cross validation
2025-10-12 16:41:29,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:31,525:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:41:31,525:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:41:31,528:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:41:32,502:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:41:32,577:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:41:32,623:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:41:32,637:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:41:32,638:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:41:32,727:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-12 16:41:32,748:INFO:Calculating mean and std
2025-10-12 16:41:32,749:INFO:Creating metrics dataframe
2025-10-12 16:41:32,753:INFO:Finalizing model
2025-10-12 16:41:34,425:INFO:Uploading results into container
2025-10-12 16:41:34,425:INFO:Uploading model into container now
2025-10-12 16:41:34,426:INFO:_master_model_container: 25
2025-10-12 16:41:34,426:INFO:_display_container: 10
2025-10-12 16:41:34,428:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001684663A1C0>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5705,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:41:34,428:INFO:create_model() successfully completed......................................
2025-10-12 16:41:34,547:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:34,547:INFO:Creating Dashboard logs
2025-10-12 16:41:34,551:INFO:Model: Voting Classifier
2025-10-12 16:41:34,639:INFO:Logged params: {'flatten_transform': True, 'n_jobs': -1, 'verbose': False, 'voting': 'hard', 'weights': None, 'CatBoost Classifier': <catboost.core.CatBoostClassifier object at 0x000001684663A1C0>, 'Linear Discriminant Analysis': LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), 'Ridge Classifier': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5705, solver='auto',
                tol=0.0001), 'CatBoost Classifier__border_count': 254, 'CatBoost Classifier__verbose': False, 'CatBoost Classifier__task_type': 'CPU', 'CatBoost Classifier__random_state': 5705, 'Linear Discriminant Analysis__covariance_estimator': None, 'Linear Discriminant Analysis__n_components': None, 'Linear Discriminant Analysis__priors': None, 'Linear Discriminant Analysis__shrinkage': None, 'Linear Discriminant Analysis__solver': 'svd', 'Linear Discriminant Analysis__store_covariance': False, 'Linear Discriminant Analysis__tol': 0.0001, 'Ridge Classifier__alpha': 1.0, 'Ridge Classifier__class_weight': None, 'Ridge Classifier__copy_X': True, 'Ridge Classifier__fit_intercept': True, 'Ridge Classifier__max_iter': None, 'Ridge Classifier__positive': False, 'Ridge Classifier__random_state': 5705, 'Ridge Classifier__solver': 'auto', 'Ridge Classifier__tol': 0.0001, 'Gradient Boosting Classifier__ccp_alpha': 0.0, 'Gradient Boosting Classifier__criterion': 'friedman_mse', 'Gradient Boosting Classifier__init': None, 'Gradient Boosting Classifier__learning_rate': 0.1, 'Gradient Boosting Classifier__loss': 'log_loss', 'Gradient Boosting Classifier__max_depth': 3, 'Gradient Boosting Classifier__max_features': None, 'Gradient Boosting Classifier__max_leaf_nodes': None, 'Gradient Boosting Classifier__min_impurity_decrease': 0.0, 'Gradient Boosting Classifier__min_samples_leaf': 1, 'Gradient Boosting Classifier__min_samples_split': 2, 'Gradient Boosting Classifier__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Classifier__n_estimators': 100, 'Gradient Boosting Classifier__n_iter_no_change': None, 'Gradient Boosting Classifier__random_state': 5705, 'Gradient Boosting Classifier__subsample': 1.0, 'Gradient Boosting Classifier__tol': 0.0001, 'Gradient Boosting Classifier__validation_fraction': 0.1, 'Gradient Boosting Classifier__verbose': 0, 'Gradient Boosting Classifier__warm_start': False}
2025-10-12 16:41:35,005:INFO:Initializing predict_model()
2025-10-12 16:41:35,005:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001684663A1C0>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5705,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001684640C280>)
2025-10-12 16:41:35,005:INFO:Checking exceptions
2025-10-12 16:41:35,005:INFO:Preloading libraries
2025-10-12 16:41:35,183:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:41:35,185:INFO:Initializing plot_model()
2025-10-12 16:41:35,185:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001684663A1C0>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5705,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpi3mshu2j, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:35,185:INFO:Checking exceptions
2025-10-12 16:41:35,185:WARNING:Couldn't create plot auc for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 439, in _plot_model
    raise TypeError(
TypeError: AUC plot not available for estimators with no predict_proba attribute.

2025-10-12 16:41:35,188:INFO:Initializing plot_model()
2025-10-12 16:41:35,188:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001684663A1C0>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5705,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpi3mshu2j, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:35,188:INFO:Checking exceptions
2025-10-12 16:41:35,189:INFO:Preloading libraries
2025-10-12 16:41:35,195:INFO:Copying training dataset
2025-10-12 16:41:35,196:INFO:Plot type: confusion_matrix
2025-10-12 16:41:35,237:INFO:Fitting Model
2025-10-12 16:41:35,238:INFO:Scoring test/hold-out set
2025-10-12 16:41:35,261:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpi3mshu2j\Confusion Matrix.png'
2025-10-12 16:41:35,345:INFO:Visual Rendered Successfully
2025-10-12 16:41:35,485:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:35,505:INFO:Initializing plot_model()
2025-10-12 16:41:35,505:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001684663A1C0>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5705,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpi3mshu2j, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:35,505:INFO:Checking exceptions
2025-10-12 16:41:35,505:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 470, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2025-10-12 16:41:35,505:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:41:35,735:INFO:_master_model_container: 25
2025-10-12 16:41:35,735:INFO:_display_container: 10
2025-10-12 16:41:35,738:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001684663A1C0>),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=No...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=5705,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2025-10-12 16:41:35,738:INFO:blend_models() successfully completed......................................
2025-10-12 16:41:35,878:INFO:Initializing compare_models()
2025-10-12 16:41:35,878:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-12 16:41:35,878:INFO:Checking exceptions
2025-10-12 16:41:35,880:INFO:Preparing display monitor
2025-10-12 16:41:35,897:INFO:Initializing Logistic Regression
2025-10-12 16:41:35,897:INFO:Total runtime is 0.0 minutes
2025-10-12 16:41:35,900:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:35,900:INFO:Initializing create_model()
2025-10-12 16:41:35,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:35,900:INFO:Checking exceptions
2025-10-12 16:41:35,900:INFO:Importing libraries
2025-10-12 16:41:35,901:INFO:Copying training dataset
2025-10-12 16:41:35,903:INFO:Defining folds
2025-10-12 16:41:35,903:INFO:Declaring metric variables
2025-10-12 16:41:35,905:INFO:Importing untrained model
2025-10-12 16:41:35,909:INFO:Logistic Regression Imported successfully
2025-10-12 16:41:35,915:INFO:Starting cross validation
2025-10-12 16:41:35,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:35,994:INFO:Calculating mean and std
2025-10-12 16:41:35,995:INFO:Creating metrics dataframe
2025-10-12 16:41:35,997:INFO:Uploading results into container
2025-10-12 16:41:35,998:INFO:Uploading model into container now
2025-10-12 16:41:35,998:INFO:_master_model_container: 26
2025-10-12 16:41:35,998:INFO:_display_container: 11
2025-10-12 16:41:35,998:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5705, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-12 16:41:35,998:INFO:create_model() successfully completed......................................
2025-10-12 16:41:36,120:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:36,120:INFO:Creating metrics dataframe
2025-10-12 16:41:36,125:INFO:Initializing K Neighbors Classifier
2025-10-12 16:41:36,125:INFO:Total runtime is 0.0037923733393351237 minutes
2025-10-12 16:41:36,127:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:36,127:INFO:Initializing create_model()
2025-10-12 16:41:36,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:36,127:INFO:Checking exceptions
2025-10-12 16:41:36,127:INFO:Importing libraries
2025-10-12 16:41:36,127:INFO:Copying training dataset
2025-10-12 16:41:36,130:INFO:Defining folds
2025-10-12 16:41:36,130:INFO:Declaring metric variables
2025-10-12 16:41:36,132:INFO:Importing untrained model
2025-10-12 16:41:36,135:INFO:K Neighbors Classifier Imported successfully
2025-10-12 16:41:36,141:INFO:Starting cross validation
2025-10-12 16:41:36,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:36,257:INFO:Calculating mean and std
2025-10-12 16:41:36,257:INFO:Creating metrics dataframe
2025-10-12 16:41:36,258:INFO:Uploading results into container
2025-10-12 16:41:36,259:INFO:Uploading model into container now
2025-10-12 16:41:36,259:INFO:_master_model_container: 27
2025-10-12 16:41:36,259:INFO:_display_container: 11
2025-10-12 16:41:36,259:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-12 16:41:36,259:INFO:create_model() successfully completed......................................
2025-10-12 16:41:36,380:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:36,380:INFO:Creating metrics dataframe
2025-10-12 16:41:36,385:INFO:Initializing Naive Bayes
2025-10-12 16:41:36,385:INFO:Total runtime is 0.008137067159016928 minutes
2025-10-12 16:41:36,389:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:36,389:INFO:Initializing create_model()
2025-10-12 16:41:36,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:36,389:INFO:Checking exceptions
2025-10-12 16:41:36,389:INFO:Importing libraries
2025-10-12 16:41:36,390:INFO:Copying training dataset
2025-10-12 16:41:36,392:INFO:Defining folds
2025-10-12 16:41:36,393:INFO:Declaring metric variables
2025-10-12 16:41:36,395:INFO:Importing untrained model
2025-10-12 16:41:36,399:INFO:Naive Bayes Imported successfully
2025-10-12 16:41:36,405:INFO:Starting cross validation
2025-10-12 16:41:36,406:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:36,472:INFO:Calculating mean and std
2025-10-12 16:41:36,473:INFO:Creating metrics dataframe
2025-10-12 16:41:36,474:INFO:Uploading results into container
2025-10-12 16:41:36,474:INFO:Uploading model into container now
2025-10-12 16:41:36,474:INFO:_master_model_container: 28
2025-10-12 16:41:36,475:INFO:_display_container: 11
2025-10-12 16:41:36,475:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-12 16:41:36,475:INFO:create_model() successfully completed......................................
2025-10-12 16:41:36,603:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:36,603:INFO:Creating metrics dataframe
2025-10-12 16:41:36,608:INFO:Initializing Decision Tree Classifier
2025-10-12 16:41:36,608:INFO:Total runtime is 0.011844158172607422 minutes
2025-10-12 16:41:36,611:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:36,611:INFO:Initializing create_model()
2025-10-12 16:41:36,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:36,612:INFO:Checking exceptions
2025-10-12 16:41:36,612:INFO:Importing libraries
2025-10-12 16:41:36,612:INFO:Copying training dataset
2025-10-12 16:41:36,614:INFO:Defining folds
2025-10-12 16:41:36,614:INFO:Declaring metric variables
2025-10-12 16:41:36,617:INFO:Importing untrained model
2025-10-12 16:41:36,619:INFO:Decision Tree Classifier Imported successfully
2025-10-12 16:41:36,627:INFO:Starting cross validation
2025-10-12 16:41:36,627:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:36,691:INFO:Calculating mean and std
2025-10-12 16:41:36,691:INFO:Creating metrics dataframe
2025-10-12 16:41:36,693:INFO:Uploading results into container
2025-10-12 16:41:36,693:INFO:Uploading model into container now
2025-10-12 16:41:36,693:INFO:_master_model_container: 29
2025-10-12 16:41:36,693:INFO:_display_container: 11
2025-10-12 16:41:36,693:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5705, splitter='best')
2025-10-12 16:41:36,694:INFO:create_model() successfully completed......................................
2025-10-12 16:41:36,823:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:36,823:INFO:Creating metrics dataframe
2025-10-12 16:41:36,828:INFO:Initializing SVM - Linear Kernel
2025-10-12 16:41:36,829:INFO:Total runtime is 0.01553948720296224 minutes
2025-10-12 16:41:36,833:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:36,833:INFO:Initializing create_model()
2025-10-12 16:41:36,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:36,833:INFO:Checking exceptions
2025-10-12 16:41:36,834:INFO:Importing libraries
2025-10-12 16:41:36,834:INFO:Copying training dataset
2025-10-12 16:41:36,837:INFO:Defining folds
2025-10-12 16:41:36,837:INFO:Declaring metric variables
2025-10-12 16:41:36,839:INFO:Importing untrained model
2025-10-12 16:41:36,842:INFO:SVM - Linear Kernel Imported successfully
2025-10-12 16:41:36,848:INFO:Starting cross validation
2025-10-12 16:41:36,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:36,883:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:41:36,892:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:41:36,910:INFO:Calculating mean and std
2025-10-12 16:41:36,912:INFO:Creating metrics dataframe
2025-10-12 16:41:36,914:INFO:Uploading results into container
2025-10-12 16:41:36,915:INFO:Uploading model into container now
2025-10-12 16:41:36,916:INFO:_master_model_container: 30
2025-10-12 16:41:36,916:INFO:_display_container: 11
2025-10-12 16:41:36,917:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5705, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-12 16:41:36,917:INFO:create_model() successfully completed......................................
2025-10-12 16:41:37,047:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:37,047:INFO:Creating metrics dataframe
2025-10-12 16:41:37,053:INFO:Initializing Ridge Classifier
2025-10-12 16:41:37,054:INFO:Total runtime is 0.019278756777445477 minutes
2025-10-12 16:41:37,056:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:37,057:INFO:Initializing create_model()
2025-10-12 16:41:37,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:37,057:INFO:Checking exceptions
2025-10-12 16:41:37,057:INFO:Importing libraries
2025-10-12 16:41:37,057:INFO:Copying training dataset
2025-10-12 16:41:37,059:INFO:Defining folds
2025-10-12 16:41:37,059:INFO:Declaring metric variables
2025-10-12 16:41:37,062:INFO:Importing untrained model
2025-10-12 16:41:37,064:INFO:Ridge Classifier Imported successfully
2025-10-12 16:41:37,071:INFO:Starting cross validation
2025-10-12 16:41:37,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:37,126:INFO:Calculating mean and std
2025-10-12 16:41:37,126:INFO:Creating metrics dataframe
2025-10-12 16:41:37,127:INFO:Uploading results into container
2025-10-12 16:41:37,128:INFO:Uploading model into container now
2025-10-12 16:41:37,128:INFO:_master_model_container: 31
2025-10-12 16:41:37,128:INFO:_display_container: 11
2025-10-12 16:41:37,128:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5705, solver='auto',
                tol=0.0001)
2025-10-12 16:41:37,128:INFO:create_model() successfully completed......................................
2025-10-12 16:41:37,251:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:37,251:INFO:Creating metrics dataframe
2025-10-12 16:41:37,257:INFO:Initializing Random Forest Classifier
2025-10-12 16:41:37,257:INFO:Total runtime is 0.02266133228937785 minutes
2025-10-12 16:41:37,260:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:37,260:INFO:Initializing create_model()
2025-10-12 16:41:37,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:37,260:INFO:Checking exceptions
2025-10-12 16:41:37,260:INFO:Importing libraries
2025-10-12 16:41:37,260:INFO:Copying training dataset
2025-10-12 16:41:37,263:INFO:Defining folds
2025-10-12 16:41:37,264:INFO:Declaring metric variables
2025-10-12 16:41:37,267:INFO:Importing untrained model
2025-10-12 16:41:37,270:INFO:Random Forest Classifier Imported successfully
2025-10-12 16:41:37,275:INFO:Starting cross validation
2025-10-12 16:41:37,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:37,622:INFO:Calculating mean and std
2025-10-12 16:41:37,623:INFO:Creating metrics dataframe
2025-10-12 16:41:37,625:INFO:Uploading results into container
2025-10-12 16:41:37,625:INFO:Uploading model into container now
2025-10-12 16:41:37,626:INFO:_master_model_container: 32
2025-10-12 16:41:37,626:INFO:_display_container: 11
2025-10-12 16:41:37,626:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5705, verbose=0,
                       warm_start=False)
2025-10-12 16:41:37,626:INFO:create_model() successfully completed......................................
2025-10-12 16:41:37,747:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:37,747:INFO:Creating metrics dataframe
2025-10-12 16:41:37,753:INFO:Initializing Quadratic Discriminant Analysis
2025-10-12 16:41:37,754:INFO:Total runtime is 0.030948960781097413 minutes
2025-10-12 16:41:37,757:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:37,757:INFO:Initializing create_model()
2025-10-12 16:41:37,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:37,757:INFO:Checking exceptions
2025-10-12 16:41:37,757:INFO:Importing libraries
2025-10-12 16:41:37,757:INFO:Copying training dataset
2025-10-12 16:41:37,760:INFO:Defining folds
2025-10-12 16:41:37,761:INFO:Declaring metric variables
2025-10-12 16:41:37,764:INFO:Importing untrained model
2025-10-12 16:41:37,767:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-12 16:41:37,773:INFO:Starting cross validation
2025-10-12 16:41:37,774:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:37,838:INFO:Calculating mean and std
2025-10-12 16:41:37,838:INFO:Creating metrics dataframe
2025-10-12 16:41:37,840:INFO:Uploading results into container
2025-10-12 16:41:37,841:INFO:Uploading model into container now
2025-10-12 16:41:37,841:INFO:_master_model_container: 33
2025-10-12 16:41:37,841:INFO:_display_container: 11
2025-10-12 16:41:37,841:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-12 16:41:37,841:INFO:create_model() successfully completed......................................
2025-10-12 16:41:37,979:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:37,979:INFO:Creating metrics dataframe
2025-10-12 16:41:37,985:INFO:Initializing Ada Boost Classifier
2025-10-12 16:41:37,985:INFO:Total runtime is 0.03479618231455485 minutes
2025-10-12 16:41:37,987:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:37,987:INFO:Initializing create_model()
2025-10-12 16:41:37,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:37,988:INFO:Checking exceptions
2025-10-12 16:41:37,988:INFO:Importing libraries
2025-10-12 16:41:37,988:INFO:Copying training dataset
2025-10-12 16:41:37,991:INFO:Defining folds
2025-10-12 16:41:37,991:INFO:Declaring metric variables
2025-10-12 16:41:37,994:INFO:Importing untrained model
2025-10-12 16:41:37,997:INFO:Ada Boost Classifier Imported successfully
2025-10-12 16:41:38,002:INFO:Starting cross validation
2025-10-12 16:41:38,003:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:38,018:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:41:38,018:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:41:38,020:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:41:38,021:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:41:38,023:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:41:38,028:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:41:38,030:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:41:38,030:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:41:38,034:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:41:38,034:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-12 16:41:38,176:INFO:Calculating mean and std
2025-10-12 16:41:38,178:INFO:Creating metrics dataframe
2025-10-12 16:41:38,179:INFO:Uploading results into container
2025-10-12 16:41:38,180:INFO:Uploading model into container now
2025-10-12 16:41:38,180:INFO:_master_model_container: 34
2025-10-12 16:41:38,181:INFO:_display_container: 11
2025-10-12 16:41:38,181:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5705)
2025-10-12 16:41:38,181:INFO:create_model() successfully completed......................................
2025-10-12 16:41:38,303:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:38,304:INFO:Creating metrics dataframe
2025-10-12 16:41:38,310:INFO:Initializing Gradient Boosting Classifier
2025-10-12 16:41:38,310:INFO:Total runtime is 0.04021206299463908 minutes
2025-10-12 16:41:38,313:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:38,313:INFO:Initializing create_model()
2025-10-12 16:41:38,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:38,313:INFO:Checking exceptions
2025-10-12 16:41:38,313:INFO:Importing libraries
2025-10-12 16:41:38,313:INFO:Copying training dataset
2025-10-12 16:41:38,316:INFO:Defining folds
2025-10-12 16:41:38,316:INFO:Declaring metric variables
2025-10-12 16:41:38,319:INFO:Importing untrained model
2025-10-12 16:41:38,321:INFO:Gradient Boosting Classifier Imported successfully
2025-10-12 16:41:38,327:INFO:Starting cross validation
2025-10-12 16:41:38,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:38,565:INFO:Calculating mean and std
2025-10-12 16:41:38,566:INFO:Creating metrics dataframe
2025-10-12 16:41:38,568:INFO:Uploading results into container
2025-10-12 16:41:38,569:INFO:Uploading model into container now
2025-10-12 16:41:38,569:INFO:_master_model_container: 35
2025-10-12 16:41:38,570:INFO:_display_container: 11
2025-10-12 16:41:38,570:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5705, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-12 16:41:38,570:INFO:create_model() successfully completed......................................
2025-10-12 16:41:38,693:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:38,693:INFO:Creating metrics dataframe
2025-10-12 16:41:38,699:INFO:Initializing Linear Discriminant Analysis
2025-10-12 16:41:38,699:INFO:Total runtime is 0.04669988950093587 minutes
2025-10-12 16:41:38,702:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:38,702:INFO:Initializing create_model()
2025-10-12 16:41:38,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:38,702:INFO:Checking exceptions
2025-10-12 16:41:38,703:INFO:Importing libraries
2025-10-12 16:41:38,703:INFO:Copying training dataset
2025-10-12 16:41:38,705:INFO:Defining folds
2025-10-12 16:41:38,705:INFO:Declaring metric variables
2025-10-12 16:41:38,709:INFO:Importing untrained model
2025-10-12 16:41:38,712:INFO:Linear Discriminant Analysis Imported successfully
2025-10-12 16:41:38,721:INFO:Starting cross validation
2025-10-12 16:41:38,723:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:38,795:INFO:Calculating mean and std
2025-10-12 16:41:38,795:INFO:Creating metrics dataframe
2025-10-12 16:41:38,797:INFO:Uploading results into container
2025-10-12 16:41:38,797:INFO:Uploading model into container now
2025-10-12 16:41:38,797:INFO:_master_model_container: 36
2025-10-12 16:41:38,797:INFO:_display_container: 11
2025-10-12 16:41:38,798:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-12 16:41:38,798:INFO:create_model() successfully completed......................................
2025-10-12 16:41:38,923:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:38,923:INFO:Creating metrics dataframe
2025-10-12 16:41:38,931:INFO:Initializing Extra Trees Classifier
2025-10-12 16:41:38,931:INFO:Total runtime is 0.05056252082188924 minutes
2025-10-12 16:41:38,934:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:38,934:INFO:Initializing create_model()
2025-10-12 16:41:38,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:38,934:INFO:Checking exceptions
2025-10-12 16:41:38,934:INFO:Importing libraries
2025-10-12 16:41:38,934:INFO:Copying training dataset
2025-10-12 16:41:38,938:INFO:Defining folds
2025-10-12 16:41:38,938:INFO:Declaring metric variables
2025-10-12 16:41:38,942:INFO:Importing untrained model
2025-10-12 16:41:38,946:INFO:Extra Trees Classifier Imported successfully
2025-10-12 16:41:38,952:INFO:Starting cross validation
2025-10-12 16:41:38,952:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:39,272:INFO:Calculating mean and std
2025-10-12 16:41:39,273:INFO:Creating metrics dataframe
2025-10-12 16:41:39,274:INFO:Uploading results into container
2025-10-12 16:41:39,276:INFO:Uploading model into container now
2025-10-12 16:41:39,276:INFO:_master_model_container: 37
2025-10-12 16:41:39,276:INFO:_display_container: 11
2025-10-12 16:41:39,277:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5705, verbose=0,
                     warm_start=False)
2025-10-12 16:41:39,277:INFO:create_model() successfully completed......................................
2025-10-12 16:41:39,403:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:39,403:INFO:Creating metrics dataframe
2025-10-12 16:41:39,410:INFO:Initializing Extreme Gradient Boosting
2025-10-12 16:41:39,410:INFO:Total runtime is 0.058558253447214756 minutes
2025-10-12 16:41:39,413:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:39,415:INFO:Initializing create_model()
2025-10-12 16:41:39,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:39,415:INFO:Checking exceptions
2025-10-12 16:41:39,415:INFO:Importing libraries
2025-10-12 16:41:39,415:INFO:Copying training dataset
2025-10-12 16:41:39,417:INFO:Defining folds
2025-10-12 16:41:39,417:INFO:Declaring metric variables
2025-10-12 16:41:39,420:INFO:Importing untrained model
2025-10-12 16:41:39,423:INFO:Extreme Gradient Boosting Imported successfully
2025-10-12 16:41:39,429:INFO:Starting cross validation
2025-10-12 16:41:39,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:39,863:INFO:Calculating mean and std
2025-10-12 16:41:39,865:INFO:Creating metrics dataframe
2025-10-12 16:41:39,867:INFO:Uploading results into container
2025-10-12 16:41:39,868:INFO:Uploading model into container now
2025-10-12 16:41:39,868:INFO:_master_model_container: 38
2025-10-12 16:41:39,868:INFO:_display_container: 11
2025-10-12 16:41:39,869:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-12 16:41:39,869:INFO:create_model() successfully completed......................................
2025-10-12 16:41:39,994:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:39,994:INFO:Creating metrics dataframe
2025-10-12 16:41:40,002:INFO:Initializing Light Gradient Boosting Machine
2025-10-12 16:41:40,002:INFO:Total runtime is 0.06841659148534138 minutes
2025-10-12 16:41:40,004:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:40,005:INFO:Initializing create_model()
2025-10-12 16:41:40,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:40,005:INFO:Checking exceptions
2025-10-12 16:41:40,005:INFO:Importing libraries
2025-10-12 16:41:40,005:INFO:Copying training dataset
2025-10-12 16:41:40,008:INFO:Defining folds
2025-10-12 16:41:40,008:INFO:Declaring metric variables
2025-10-12 16:41:40,011:INFO:Importing untrained model
2025-10-12 16:41:40,013:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-12 16:41:40,020:INFO:Starting cross validation
2025-10-12 16:41:40,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:40,815:INFO:Calculating mean and std
2025-10-12 16:41:40,817:INFO:Creating metrics dataframe
2025-10-12 16:41:40,819:INFO:Uploading results into container
2025-10-12 16:41:40,820:INFO:Uploading model into container now
2025-10-12 16:41:40,820:INFO:_master_model_container: 39
2025-10-12 16:41:40,820:INFO:_display_container: 11
2025-10-12 16:41:40,821:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5705, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-12 16:41:40,822:INFO:create_model() successfully completed......................................
2025-10-12 16:41:40,967:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:40,968:INFO:Creating metrics dataframe
2025-10-12 16:41:40,975:INFO:Initializing CatBoost Classifier
2025-10-12 16:41:40,975:INFO:Total runtime is 0.08463509082794188 minutes
2025-10-12 16:41:40,979:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:40,979:INFO:Initializing create_model()
2025-10-12 16:41:40,979:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:40,979:INFO:Checking exceptions
2025-10-12 16:41:40,979:INFO:Importing libraries
2025-10-12 16:41:40,979:INFO:Copying training dataset
2025-10-12 16:41:40,982:INFO:Defining folds
2025-10-12 16:41:40,982:INFO:Declaring metric variables
2025-10-12 16:41:40,986:INFO:Importing untrained model
2025-10-12 16:41:40,988:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:41:40,995:INFO:Starting cross validation
2025-10-12 16:41:40,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:45,430:INFO:Calculating mean and std
2025-10-12 16:41:45,431:INFO:Creating metrics dataframe
2025-10-12 16:41:45,432:INFO:Uploading results into container
2025-10-12 16:41:45,434:INFO:Uploading model into container now
2025-10-12 16:41:45,434:INFO:_master_model_container: 40
2025-10-12 16:41:45,434:INFO:_display_container: 11
2025-10-12 16:41:45,434:INFO:<catboost.core.CatBoostClassifier object at 0x00000168464C1A30>
2025-10-12 16:41:45,435:INFO:create_model() successfully completed......................................
2025-10-12 16:41:45,587:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:45,587:INFO:Creating metrics dataframe
2025-10-12 16:41:45,596:INFO:Initializing Dummy Classifier
2025-10-12 16:41:45,596:INFO:Total runtime is 0.16164918740590412 minutes
2025-10-12 16:41:45,599:INFO:SubProcess create_model() called ==================================
2025-10-12 16:41:45,599:INFO:Initializing create_model()
2025-10-12 16:41:45,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000168466D6970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:45,599:INFO:Checking exceptions
2025-10-12 16:41:45,599:INFO:Importing libraries
2025-10-12 16:41:45,599:INFO:Copying training dataset
2025-10-12 16:41:45,604:INFO:Defining folds
2025-10-12 16:41:45,604:INFO:Declaring metric variables
2025-10-12 16:41:45,607:INFO:Importing untrained model
2025-10-12 16:41:45,610:INFO:Dummy Classifier Imported successfully
2025-10-12 16:41:45,617:INFO:Starting cross validation
2025-10-12 16:41:45,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-12 16:41:45,648:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:41:45,649:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:41:45,651:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:41:45,654:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:41:45,656:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:41:45,660:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:41:45,662:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:41:45,667:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:41:45,668:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:41:45,668:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-12 16:41:45,677:INFO:Calculating mean and std
2025-10-12 16:41:45,677:INFO:Creating metrics dataframe
2025-10-12 16:41:45,679:INFO:Uploading results into container
2025-10-12 16:41:45,680:INFO:Uploading model into container now
2025-10-12 16:41:45,680:INFO:_master_model_container: 41
2025-10-12 16:41:45,680:INFO:_display_container: 11
2025-10-12 16:41:45,680:INFO:DummyClassifier(constant=None, random_state=5705, strategy='prior')
2025-10-12 16:41:45,680:INFO:create_model() successfully completed......................................
2025-10-12 16:41:45,807:INFO:SubProcess create_model() end ==================================
2025-10-12 16:41:45,807:INFO:Creating metrics dataframe
2025-10-12 16:41:45,814:WARNING:c:\Users\david\Programming\MLOps\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-12 16:41:45,825:INFO:Initializing create_model()
2025-10-12 16:41:45,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=<catboost.core.CatBoostClassifier object at 0x00000168464C1A30>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-12 16:41:45,826:INFO:Checking exceptions
2025-10-12 16:41:45,828:INFO:Importing libraries
2025-10-12 16:41:45,829:INFO:Copying training dataset
2025-10-12 16:41:45,832:INFO:Defining folds
2025-10-12 16:41:45,832:INFO:Declaring metric variables
2025-10-12 16:41:45,832:INFO:Importing untrained model
2025-10-12 16:41:45,832:INFO:Declaring custom model
2025-10-12 16:41:45,834:INFO:CatBoost Classifier Imported successfully
2025-10-12 16:41:45,834:INFO:Cross validation set to False
2025-10-12 16:41:45,834:INFO:Fitting Model
2025-10-12 16:41:47,434:INFO:<catboost.core.CatBoostClassifier object at 0x0000016855E50B50>
2025-10-12 16:41:47,434:INFO:create_model() successfully completed......................................
2025-10-12 16:41:47,566:INFO:Creating Dashboard logs
2025-10-12 16:41:47,571:INFO:Model: CatBoost Classifier
2025-10-12 16:41:47,663:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'Logloss', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 5705, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.007650000043213368, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 10, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2025-10-12 16:41:47,979:INFO:Initializing predict_model()
2025-10-12 16:41:47,979:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=<catboost.core.CatBoostClassifier object at 0x0000016855E50B50>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016855F00040>)
2025-10-12 16:41:47,979:INFO:Checking exceptions
2025-10-12 16:41:47,979:INFO:Preloading libraries
2025-10-12 16:41:48,145:INFO:SubProcess plot_model() called ==================================
2025-10-12 16:41:48,145:INFO:Initializing plot_model()
2025-10-12 16:41:48,145:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000016855E50B50>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpprx5jpnw, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:48,145:INFO:Checking exceptions
2025-10-12 16:41:48,147:INFO:Preloading libraries
2025-10-12 16:41:48,150:INFO:Copying training dataset
2025-10-12 16:41:48,150:INFO:Plot type: auc
2025-10-12 16:41:48,194:INFO:Fitting Model
2025-10-12 16:41:48,195:INFO:Scoring test/hold-out set
2025-10-12 16:41:48,212:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpprx5jpnw\AUC.png'
2025-10-12 16:41:48,382:INFO:Visual Rendered Successfully
2025-10-12 16:41:48,505:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:48,528:INFO:Initializing plot_model()
2025-10-12 16:41:48,528:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000016855E50B50>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpprx5jpnw, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:48,528:INFO:Checking exceptions
2025-10-12 16:41:48,530:INFO:Preloading libraries
2025-10-12 16:41:48,532:INFO:Copying training dataset
2025-10-12 16:41:48,532:INFO:Plot type: confusion_matrix
2025-10-12 16:41:48,588:INFO:Fitting Model
2025-10-12 16:41:48,590:INFO:Scoring test/hold-out set
2025-10-12 16:41:48,608:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpprx5jpnw\Confusion Matrix.png'
2025-10-12 16:41:48,692:INFO:Visual Rendered Successfully
2025-10-12 16:41:48,815:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:48,832:INFO:Initializing plot_model()
2025-10-12 16:41:48,833:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000016855E50B50>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\david\AppData\Local\Temp\tmpprx5jpnw, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, system=False)
2025-10-12 16:41:48,833:INFO:Checking exceptions
2025-10-12 16:41:48,834:INFO:Preloading libraries
2025-10-12 16:41:48,835:INFO:Copying training dataset
2025-10-12 16:41:48,835:INFO:Plot type: feature
2025-10-12 16:41:48,835:WARNING:No coef_ found. Trying feature_importances_
2025-10-12 16:41:48,859:INFO:Saving 'C:\Users\david\AppData\Local\Temp\tmpprx5jpnw\Feature Importance.png'
2025-10-12 16:41:48,954:INFO:Visual Rendered Successfully
2025-10-12 16:41:49,078:INFO:plot_model() successfully completed......................................
2025-10-12 16:41:49,097:INFO:SubProcess plot_model() end ==================================
2025-10-12 16:41:49,303:INFO:Creating Dashboard logs
2025-10-12 16:41:49,307:INFO:Model: Gradient Boosting Classifier
2025-10-12 16:41:49,378:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 5705, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:41:49,819:INFO:Creating Dashboard logs
2025-10-12 16:41:49,822:INFO:Model: Ada Boost Classifier
2025-10-12 16:41:49,895:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 5705}
2025-10-12 16:41:50,305:INFO:Creating Dashboard logs
2025-10-12 16:41:50,309:INFO:Model: Quadratic Discriminant Analysis
2025-10-12 16:41:50,389:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:41:50,837:INFO:Creating Dashboard logs
2025-10-12 16:41:50,841:INFO:Model: Ridge Classifier
2025-10-12 16:41:50,921:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 5705, 'solver': 'auto', 'tol': 0.0001}
2025-10-12 16:41:51,349:INFO:Creating Dashboard logs
2025-10-12 16:41:51,352:INFO:Model: Linear Discriminant Analysis
2025-10-12 16:41:51,433:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-10-12 16:41:51,871:INFO:Creating Dashboard logs
2025-10-12 16:41:51,875:INFO:Model: Logistic Regression
2025-10-12 16:41:51,965:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 5705, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-10-12 16:41:52,421:INFO:Creating Dashboard logs
2025-10-12 16:41:52,426:INFO:Model: Extreme Gradient Boosting
2025-10-12 16:41:52,528:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 5705, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-10-12 16:41:53,019:INFO:Creating Dashboard logs
2025-10-12 16:41:53,022:INFO:Model: Random Forest Classifier
2025-10-12 16:41:53,115:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5705, 'verbose': 0, 'warm_start': False}
2025-10-12 16:41:53,543:INFO:Creating Dashboard logs
2025-10-12 16:41:53,546:INFO:Model: Light Gradient Boosting Machine
2025-10-12 16:41:53,621:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5705, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-10-12 16:41:54,033:INFO:Creating Dashboard logs
2025-10-12 16:41:54,037:INFO:Model: Extra Trees Classifier
2025-10-12 16:41:54,113:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5705, 'verbose': 0, 'warm_start': False}
2025-10-12 16:41:54,551:INFO:Creating Dashboard logs
2025-10-12 16:41:54,554:INFO:Model: Naive Bayes
2025-10-12 16:41:54,637:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-10-12 16:41:55,045:INFO:Creating Dashboard logs
2025-10-12 16:41:55,047:INFO:Model: Decision Tree Classifier
2025-10-12 16:41:55,138:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 5705, 'splitter': 'best'}
2025-10-12 16:41:55,550:INFO:Creating Dashboard logs
2025-10-12 16:41:55,553:INFO:Model: K Neighbors Classifier
2025-10-12 16:41:55,638:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-10-12 16:41:56,109:INFO:Creating Dashboard logs
2025-10-12 16:41:56,111:INFO:Model: SVM - Linear Kernel
2025-10-12 16:41:56,187:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 5705, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-10-12 16:41:56,622:INFO:Creating Dashboard logs
2025-10-12 16:41:56,625:INFO:Model: Dummy Classifier
2025-10-12 16:41:56,713:INFO:Logged params: {'constant': None, 'random_state': 5705, 'strategy': 'prior'}
2025-10-12 16:41:57,090:INFO:_master_model_container: 41
2025-10-12 16:41:57,090:INFO:_display_container: 11
2025-10-12 16:41:57,090:INFO:<catboost.core.CatBoostClassifier object at 0x0000016855E50B50>
2025-10-12 16:41:57,090:INFO:compare_models() successfully completed......................................
2025-10-12 16:41:59,259:INFO:Initializing predict_model()
2025-10-12 16:41:59,259:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000168467E1130>, estimator=mlflow.pyfunc.loaded_model:
  run_id: 367ea09110ef48c784af7f4b24b463b6
  artifact_path: model
  flavor: mlflow.sklearn
, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016846794C10>)
2025-10-12 16:41:59,259:INFO:Checking exceptions
2025-10-12 16:41:59,259:INFO:Preloading libraries
2025-10-12 16:41:59,262:INFO:Set up data.
2025-10-12 16:41:59,267:INFO:Set up index.
